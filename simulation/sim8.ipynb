{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Ordered response + PCA\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation\n",
    "\n",
    "* Background: Cancer has two stages - early and late # TODO: this needs a better interpretation, early and late are in the embedding space, not in the feature space\n",
    "\n",
    "* Data: Source data is dense in early stage, but sparse in late stage. Target data is sparse in early stage, but dense in late stage.\n",
    "\n",
    "* Question: Does transporting source representations onto target representations help with late stage cancer prediction?\n",
    "\n",
    "* Note: This question is different from previous simulation questions. We only benchmark a subset of the source data; that is, data in the late stage.\n",
    "\n",
    "Simulation\n",
    "\n",
    "* Suppose the embedding dimension is 1.\n",
    "\n",
    "* $r$ for indexing domains\n",
    "\n",
    "* Let $[0, S]$ be early stage, and $(S, E]$ be late stage\n",
    "\n",
    "* Let $N$ be the total number of data, $N_{se}$ be the number of data in early stage in the source data, and $N_{tl}$ be the number of data in late stage in the target data. Note that $N_{se}$ and $N_{tl}$ are supposed to be $> \\frac{N}{2}$.\n",
    "\n",
    "* Simulate $X_{se} \\sim \\operatorname{Unif}\\left( 0, S \\right)$ where $|X_{se}| = N_{se}$\n",
    "\n",
    "* Generate $Y_{se} = k_1 X_{se} + \\epsilon$\n",
    "\n",
    "* Simulate $X_{sl} \\sim \\operatorname{Unif}\\left(S, E \\right)$ where $|X_{sl}| = N-N_{se}$\n",
    "\n",
    "* Generate $Y_{sl} = k_2 X_{sl} + \\epsilon$\n",
    "\n",
    "* Simulate $X_{te} \\sim \\operatorname{Unif}\\left(0, S \\right)$ where $|X_{te}| = N-N_{tl}$\n",
    "\n",
    "* Generate $Y_{te} = k_1 X_{te} + \\epsilon$\n",
    "\n",
    "* Simulate $X_{tl} \\sim \\operatorname{Unif}\\left(S, E \\right)$ where $|X_{tl}| = N_{tl}$\n",
    "\n",
    "* Generate $Y_{tl} = k_2 X_{tl} + \\epsilon$\n",
    "\n",
    "* The source representations are: $[X_{se}, X_{sl}]$. Source labels are $[Y_{se}, Y_{sl}]$. \n",
    "\n",
    "* The target representations are: $[X_{te}, X_{tl}]$. Target labels are $[Y_{te}, Y_{tl}]$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "from math import floor\n",
    "from random import randint\n",
    "from numpy.random import uniform\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_func(k):\n",
    "    \"\"\" \n",
    "    Make a linear function with coefficient k and intercept 0\n",
    "\n",
    "    returns\n",
    "        - the above described function\n",
    "    \"\"\"\n",
    "    \n",
    "    def f(x):\n",
    "        return k*x\n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_X(x_num, low, high):\n",
    "    \"\"\" \n",
    "    Sample x_num of x within [low, high]\n",
    "    \"\"\"\n",
    "    return uniform(low=low, high=high, size=x_num)\n",
    "\n",
    "def sample_y(X, k, random_state=None, nz=0.5):\n",
    "    \"\"\"\n",
    "    Sample y based on y=kx+noise\n",
    "\n",
    "    :param float nz: noise level\n",
    "    \"\"\"\n",
    "\n",
    "    generator = check_random_state(random_state)\n",
    "\n",
    "    f = make_func(k)\n",
    "    y = [f(x) for x in X]\n",
    "    y += 1.5 * nz * generator.randn(sum(y), 1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_emb_labels(num_patient, early_prop, k_1, k_2):\n",
    "    \"\"\" \n",
    "    Simulate desired early and late stage embeddings and labels (assume the embedding dimension is 1)\n",
    "\n",
    "    :param int num_patient: number of patients\n",
    "    :param float early_prop: proportion of patients in the early stage\n",
    "    :param float k_1: the desired coefficient for modeling the relationship between x and y in early stage\n",
    "    :param float k_2: the desired coefficient for modeling the relationship between x and y in late stage\n",
    "    \"\"\"\n",
    "    early_patient_num = floor(early_prop*num_patient)\n",
    "    late_patient_num = num_patient-early_patient_num\n",
    "    early_X = sample_X(early_patient_num, 0, 1)\n",
    "    early_y = sample_y(early_X, k_1)\n",
    "    late_X = sample_X(late_patient_num, 1, 2)\n",
    "    late_y = sample_y(late_X, k_2)\n",
    "    embs = early_X.extend(late_X)\n",
    "    labels = early_y.extend(late_y)\n",
    "    return embs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate_pca_train(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2, for PCA training\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    unit_1 = 1/(2*d_1-2*d_2+3*D)\n",
    "    alpha_1 = [5*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([3*unit_1]*(D-d_1-d_2))\n",
    "  \n",
    "    unit_2 = 1/(-2*d_1+2*d_2+3*D)\n",
    "    alpha_2 = [unit_2]*d_1\n",
    "    alpha_2.extend([5*unit_2]*d_2)\n",
    "    alpha_2.extend([3*unit_2]*(D-d_1-d_2))  \n",
    "    W = np.random.normal(size=D)\n",
    "    W  = [abs(W_k) for W_k in W] # only sample positive weights\n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            cur_sum = np.sum(np.multiply(W, X_i))\n",
    "            all_sum.append(cur_sum)\n",
    "        \n",
    "        # print(\"all_sum before preprocessing is:\", all_sum)\n",
    "        # standardize\n",
    "        all_sum = preprocessing.scale(all_sum)\n",
    "        # print(\"all_sum after preprocessing is:\", all_sum)\n",
    "\n",
    "        all_sum = np.array(all_sum)\n",
    "        \n",
    "        P = []\n",
    "        for cur_sum in all_sum:\n",
    "            p_i = sigmoid(cur_sum)\n",
    "            P.append(p_i)\n",
    "            Y_i = 0\n",
    "            if p_i >= 0.5: # TODO: mimic exact logistic regression, change to np.random.binomial later\n",
    "                Y_i = 1\n",
    "            # Y_i = np.random.binomial(1, p_i) # too much noise, domain 1 data cannot learn well\n",
    "            Y.append(int(Y_i))\n",
    "        # print(\"P is:\", P)\n",
    "\n",
    "            \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), label_1, np.array(feature_2), label_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5 (default, Nov 23 2021, 15:27:38) \n[GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
