{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation goals\n",
    "\n",
    "* Continuous response variable\n",
    "\n",
    "* Different feature distributions for different domains\n",
    "\n",
    "\n",
    "Simulation\n",
    "\n",
    "* $D$: total number of features\n",
    "\n",
    "* $d_{1}$: number of features with higher frequency in a domain 1\n",
    "\n",
    "* $d_{2}$: number of features with higher frequency in a domain 2\n",
    "\n",
    "\n",
    "* $d_{1} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$\n",
    "\n",
    "* $d_{2} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$ ($d_{1} + d_{2} \\le D$)\n",
    "\n",
    "* $k \\in [D]$ for indexing feature\n",
    "\n",
    "* Let $\\Delta_{r} = \\{j \\in [D]: \\textrm{feature } j \\textrm{ is more frequent in a domain } r \\}$\n",
    "\n",
    "* Sample $\\Delta_{1} \\subseteq [D]$ such that $|\\Delta_{1}| = d_{1}$ \n",
    "\n",
    "* Sample $\\Delta_{2} \\subseteq [D]\\backslash \\Delta_{1}$ such that $|\\Delta_{2}| = d_{2}$\n",
    "\n",
    "* Let $\\alpha_{1} \\overset{\\Delta}{=} \\left( \\alpha_{11}, \\ldots, \\alpha_{1D} \\right)$ be a feature frequency vector for a domain 1\n",
    "\n",
    "* Let $\\alpha_{2} \\overset{\\Delta}{=} \\left( \\alpha_{21}, \\ldots, \\alpha_{2D} \\right)$ be a feature frequency vector for a domain 2\n",
    "\n",
    "\n",
    "* For each $k \\in [D]$: \n",
    "\n",
    "    * If $k \\in \\Delta_{1}$, $\\alpha_{1k} > \\alpha_{2k}$\n",
    "\n",
    "    * If $k \\in \\Delta_{2}$, $\\alpha_{2k} > \\alpha_{1k}$\n",
    "\n",
    "    * Otherwise $\\alpha_{1k} = \\alpha_{2k}$\n",
    "\n",
    "\n",
    "* Sample $\\rho_{1} \\sim \\operatorname{Dir}(\\alpha_{1})$\n",
    "\n",
    "* Sample $\\rho_{2} \\sim \\operatorname{Dir}(\\alpha_{2})$\n",
    "\n",
    "* Sample a domain-specific contribution to mortality: $W_{k} \\sim  \\max\\{ \\mathcal{N}\\!\\left(0,1\\right), 0\\}$ # TODO: this W needs to be reconsidered\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "    * $\\tilde{X}_{i} \\sim \\operatorname{Multi}(n_{i}; \\rho_{r})$ where $\\tilde{X}_{i}$ is a vector of counts for each diagnosis code/feature, $n_i = 3k$.\n",
    "\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "\t* $\\lambda_i = \\sum_{k} (W_{k} X_{ik} + b)$ \n",
    "\n",
    "    * Sample $Y_i = \\operatorname{Poisson}(\\lambda_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='../outputs/EHR_sim_pipeline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/deep_patient/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from deep_patient.sda import SDA\n",
    "from math import floor, exp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "from numpy.random import poisson\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "base_dir = \"/home/wanxinli/deep_patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    # We set the proportions of d_1 codes, d_2 codes, and (D-d_1-d_2) codes to be 2:1:1.5\n",
    "    unit_1 = 1/(0.5*d_1-0.5*d_2+1.5*D)\n",
    "    alpha_1 = [2*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([1.5*unit_1]*(D-d_1-d_2))\n",
    "\n",
    "    # We set the proportions of d_1 codes, d_2 codes, and (D-d_1-d_2) codes to be 1:2:1.5\n",
    "    unit_2 = 1/(-0.5*d_1+0.5*d_2+1.5*D)\n",
    "    alpha_2 = [2*unit_2]*d_1\n",
    "    alpha_2.extend([unit_2]*d_2)\n",
    "    alpha_2.extend([1.5*unit_2]*(D-d_1-d_2))    \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [max(0, W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(3*len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            lambda_i= np.sum(np.multiply(W, X_i))\n",
    "            Y_i = poisson(lam = lambda_i)\n",
    "            Y.append(Y_i)\n",
    "      \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), np.array(label_1), np.array(feature_2), np.array(label_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_wrapper(num_patient):\n",
    "    D = 20\n",
    "    d_1 = 5\n",
    "    d_2 = 5\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train deep patient model and generate representations for targets and sources\n",
    "\"\"\"\n",
    "\n",
    "def custom_train_reps(target_seqs, source_seqs):\n",
    "    \"\"\" \n",
    "    Customized training algorithm for generating target representations and source representations\n",
    "    \n",
    "    :returns: target representations, source representations\n",
    "    \"\"\"\n",
    "\n",
    "    # customized parameters\n",
    "    nhidden = 3\n",
    "    nlayer = 1\n",
    "\n",
    "    # for targets\n",
    "    # initiate the model\n",
    "    target_sda = SDA(target_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    target_sda.train(target_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    target_reps = target_sda.apply(target_seqs)\n",
    "\n",
    "    # for sources\n",
    "    # initiate the model\n",
    "    source_sda = SDA(source_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    source_sda.train(source_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    source_reps = source_sda.apply(source_seqs)\n",
    "    return target_reps, source_reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "data is: [[ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 8  9 10 11 13]\n",
      " [ 4  9 10 11 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 8  9 10 11 13]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 8  9 10 11 13]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 -1 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 -1 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 0  9 10 11 13]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [10 11 13 -1 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 -1 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 8  9 10 11 13]\n",
      " [ 9 10 11 -1 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 8  9 10 11 13]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 -1 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 9 10 11 13 -1]\n",
      " [ 8  9 10 11 13]\n",
      " [ 8  9 10 11 13]]\n",
      "(*) preprocessing: normalize features\n",
      "normalized data is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.4        0.         0.         0.85714286 0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.         0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [1.         1.         1.         0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]]\n",
      "normalizer params are: {'copy': True, 'feature_range': (0, 1)}\n",
      "normalizer is: MinMaxScaler()\n",
      "wp is: [[-1.51336286 -1.21724736  3.21122699 -2.7694753   2.07372478]\n",
      " [ 1.12753737  2.35697002  1.25759968  1.62044409 -2.193909  ]\n",
      " [ 1.8612386  -2.22830096  3.24485483  3.16275754 -1.05874781]]\n",
      "bp is: [0. 0. 0. 0. 0.]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.94882287 0.52068866 0.98941757 0.99067348 0.04065422]\n",
      " [0.94882287 0.52068866 0.98941757 0.99067348 0.04065422]\n",
      " [0.94882287 0.52068866 0.98941757 0.99067348 0.04065422]\n",
      " [0.94882287 0.52068866 0.98941757 0.99067348 0.04065422]\n",
      " [0.94821329 0.52990696 0.98818642 0.99052583 0.04060667]]\n",
      "x is: [[0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.4        0.         0.         0.85714286 0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.88943437 0.24404099 0.98489322 0.96700946 0.1421651 ]\n",
      " [0.93625474 0.45182584 0.98520436 0.98699469 0.05570472]\n",
      " [0.94793538 0.5185786  0.98714457 0.99065973 0.04020829]\n",
      " [0.94793538 0.5185786  0.98714457 0.99065973 0.04020829]\n",
      " [0.94793538 0.5185786  0.98714457 0.99065973 0.04020829]]\n",
      "x is: [[0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.88194784 0.22893364 0.98118902 0.96503596 0.14981626]\n",
      " [0.6937497  0.52263045 0.98532674 0.75180558 0.26097191]\n",
      " [0.94445795 0.50766786 0.98393996 0.99025488 0.04070853]\n",
      " [0.88194784 0.22893364 0.98118902 0.96503596 0.14981626]\n",
      " [0.94445795 0.50766786 0.98393996 0.99025488 0.04070853]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.88334596 0.48237149 0.98401356 0.96224656 0.09199244]\n",
      " [0.9422487  0.50061922 0.9802552  0.989875   0.04172195]\n",
      " [0.88334596 0.48237149 0.98401356 0.96224656 0.09199244]\n",
      " [0.9422487  0.50061922 0.9802552  0.989875   0.04172195]\n",
      " [0.9422487  0.50061922 0.9802552  0.989875   0.04172195]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.         0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.93995334 0.49652042 0.97591432 0.98871749 0.0411711 ]\n",
      " [0.93995334 0.49652042 0.97591432 0.98871749 0.0411711 ]\n",
      " [0.93995334 0.49652042 0.97591432 0.98871749 0.0411711 ]\n",
      " [0.75423685 0.14257107 0.97688121 0.85814572 0.35953107]\n",
      " [0.93995334 0.49652042 0.97591432 0.98871749 0.0411711 ]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [1.         1.         1.         0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]]\n",
      "z is: [[0.93737581 0.49487929 0.9708035  0.9884358  0.04087882]\n",
      " [0.93737581 0.49487929 0.9708035  0.9884358  0.04087882]\n",
      " [0.84674345 0.37093628 0.99377212 0.93328219 0.12800304]\n",
      " [0.93737581 0.49487929 0.9708035  0.9884358  0.04087882]\n",
      " [0.87110557 0.48758115 0.97524092 0.95485412 0.09235205]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]]\n",
      "z is: [[0.93601159 0.50037873 0.96581001 0.98710855 0.04026021]\n",
      " [0.93601159 0.50037873 0.96581001 0.98710855 0.04026021]\n",
      " [0.93601159 0.50037873 0.96581001 0.98710855 0.04026021]\n",
      " [0.93601159 0.50037873 0.96581001 0.98710855 0.04026021]\n",
      " [0.86143777 0.20498672 0.96092335 0.95280889 0.16762338]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.86192322 0.49691998 0.96455378 0.94618864 0.09438308]\n",
      " [0.93408844 0.4971379  0.95860038 0.98679822 0.0407723 ]\n",
      " [0.93408844 0.4971379  0.95860038 0.98679822 0.0407723 ]\n",
      " [0.85747064 0.19854019 0.95356284 0.95143168 0.1740374 ]\n",
      " [0.86192322 0.49691998 0.96455378 0.94618864 0.09438308]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.63445416 0.22252052 0.9823298  0.66509679 0.41145416]\n",
      " [0.93136999 0.49166231 0.94985091 0.9858136  0.04113033]\n",
      " [0.93136999 0.49166231 0.94985091 0.9858136  0.04113033]\n",
      " [0.93136999 0.49166231 0.94985091 0.9858136  0.04113033]\n",
      " [0.93136999 0.49166231 0.94985091 0.9858136  0.04113033]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]]\n",
      "z is: [[0.93144154 0.49510588 0.94044084 0.98538659 0.04008193]\n",
      " [0.93144154 0.49510588 0.94044084 0.98538659 0.04008193]\n",
      " [0.93144154 0.49510588 0.94044084 0.98538659 0.04008193]\n",
      " [0.85167149 0.19257559 0.93481255 0.94655911 0.17777197]\n",
      " [0.85167149 0.19257559 0.93481255 0.94655911 0.17777197]]\n",
      "(*) epoch 1, cost 4.428\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.92850563 0.48961667 0.928258   0.98473097 0.04160264]\n",
      " [0.92850563 0.48961667 0.928258   0.98473097 0.04160264]\n",
      " [0.92850563 0.48961667 0.928258   0.98473097 0.04160264]\n",
      " [0.92850563 0.48961667 0.928258   0.98473097 0.04160264]\n",
      " [0.92850563 0.48961667 0.928258   0.98473097 0.04160264]]\n",
      "x is: [[0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.4        0.         0.         0.85714286 0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.84443954 0.18225789 0.91164096 0.94387756 0.19061301]\n",
      " [0.91011841 0.40356786 0.90766136 0.97808427 0.06313786]\n",
      " [0.92769587 0.48993175 0.91557335 0.9847277  0.04117741]\n",
      " [0.92769587 0.48993175 0.91557335 0.9847277  0.04117741]\n",
      " [0.92769587 0.48993175 0.91557335 0.9847277  0.04117741]]\n",
      "x is: [[0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.83729956 0.17376129 0.89648738 0.94166671 0.19869473]\n",
      " [0.92378731 0.48174594 0.89891406 0.98416224 0.04179992]\n",
      " [0.92378731 0.48174594 0.89891406 0.98416224 0.04179992]\n",
      " [0.83729956 0.17376129 0.89648738 0.94166671 0.19869473]\n",
      " [0.922242   0.49384672 0.89014812 0.98360021 0.04220402]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.82890868 0.49935524 0.8901272  0.92619177 0.1049875 ]\n",
      " [0.9209775  0.4770876  0.88088056 0.98351314 0.04343518]\n",
      " [0.82890868 0.49935524 0.8901272  0.92619177 0.1049875 ]\n",
      " [0.9209775  0.4770876  0.88088056 0.98351314 0.04343518]\n",
      " [0.9209775  0.4770876  0.88088056 0.98351314 0.04343518]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.         0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.91842316 0.47359061 0.86175881 0.98176744 0.04295115]\n",
      " [0.91842316 0.47359061 0.86175881 0.98176744 0.04295115]\n",
      " [0.91842316 0.47359061 0.86175881 0.98176744 0.04295115]\n",
      " [0.6979318  0.12748974 0.89800376 0.79720907 0.41410801]\n",
      " [0.91842316 0.47359061 0.86175881 0.98176744 0.04295115]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [1.         1.         1.         0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]]\n",
      "z is: [[0.91568568 0.47367065 0.84126136 0.98149286 0.04285303]\n",
      " [0.91568568 0.47367065 0.84126136 0.98149286 0.04285303]\n",
      " [0.77827962 0.42066904 0.94824232 0.86966867 0.13778461]\n",
      " [0.91568568 0.47367065 0.84126136 0.98149286 0.04285303]\n",
      " [0.81456651 0.50929905 0.85001988 0.91323457 0.10650279]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]]\n",
      "z is: [[0.91428438 0.47808478 0.82281552 0.97958111 0.04226109]\n",
      " [0.91428438 0.47808478 0.82281552 0.97958111 0.04226109]\n",
      " [0.91428438 0.47808478 0.82281552 0.97958111 0.04226109]\n",
      " [0.91428438 0.47808478 0.82281552 0.97958111 0.04226109]\n",
      " [0.81685171 0.16237627 0.83066773 0.92591918 0.21795822]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.80483975 0.52233347 0.81097751 0.89854073 0.10932186]\n",
      " [0.91272612 0.47683892 0.79937464 0.97925045 0.0428725 ]\n",
      " [0.91272612 0.47683892 0.79937464 0.97925045 0.0428725 ]\n",
      " [0.81431091 0.15962111 0.81195602 0.92485925 0.22381568]\n",
      " [0.91272612 0.47683892 0.79937464 0.97925045 0.0428725 ]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.79805994 0.52470417 0.78599042 0.88969641 0.11216866]\n",
      " [0.91031582 0.4732387  0.77407261 0.97787941 0.0434941 ]\n",
      " [0.8880574  0.47252361 0.77228033 0.96626093 0.05792734]\n",
      " [0.91031582 0.4732387  0.77407261 0.97787941 0.0434941 ]\n",
      " [0.91031582 0.4732387  0.77407261 0.97787941 0.0434941 ]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]]\n",
      "z is: [[0.90909459 0.47240864 0.75007601 0.97684824 0.04299662]\n",
      " [0.90909459 0.47240864 0.75007601 0.97684824 0.04299662]\n",
      " [0.90909459 0.47240864 0.75007601 0.97684824 0.04299662]\n",
      " [0.80691829 0.15474401 0.772919   0.91717578 0.23097911]\n",
      " [0.80691829 0.15474401 0.772919   0.91717578 0.23097911]]\n",
      "(*) epoch 2, cost 3.118\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.90677517 0.4691729  0.72233733 0.97614649 0.04473182]\n",
      " [0.90677517 0.4691729  0.72233733 0.97614649 0.04473182]\n",
      " [0.90677517 0.4691729  0.72233733 0.97614649 0.04473182]\n",
      " [0.90458942 0.48569199 0.70454127 0.97507988 0.04515287]\n",
      " [0.90458942 0.48569199 0.70454127 0.97507988 0.04515287]]\n",
      "x is: [[0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.4        0.         0.         0.85714286 0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.80272977 0.15048579 0.73449294 0.91529214 0.24226198]\n",
      " [0.88330332 0.3685767  0.69433787 0.96572995 0.0736745 ]\n",
      " [0.90427458 0.48743053 0.68152259 0.97518715 0.0445973 ]\n",
      " [0.78658626 0.53189136 0.7151731  0.87706885 0.1164687 ]\n",
      " [0.90639469 0.47074133 0.69972487 0.97622189 0.04423707]]\n",
      "x is: [[0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.79793761 0.14567444 0.71197257 0.91402447 0.24811942]\n",
      " [0.90326648 0.46387772 0.67141061 0.97572125 0.04476767]\n",
      " [0.90326648 0.46387772 0.67141061 0.97572125 0.04476767]\n",
      " [0.43575264 0.14449834 0.84513368 0.35283017 0.68689439]\n",
      " [0.90326648 0.46387772 0.67141061 0.97572125 0.04476767]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.78002008 0.5303604  0.65738166 0.87501254 0.11996247]\n",
      " [0.89678347 0.38969414 0.66065921 0.97343355 0.05810113]\n",
      " [0.78002008 0.5303604  0.65738166 0.87501254 0.11996247]\n",
      " [0.90339435 0.46218721 0.64484525 0.97586347 0.04595135]\n",
      " [0.90339435 0.46218721 0.64484525 0.97586347 0.04595135]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.         0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.90166911 0.46087472 0.6218838  0.97365049 0.04539547]\n",
      " [0.90166911 0.46087472 0.6218838  0.97365049 0.04539547]\n",
      " [0.90166911 0.46087472 0.6218838  0.97365049 0.04539547]\n",
      " [0.25764228 0.18263221 0.84005754 0.10792069 0.83448464]\n",
      " [0.7742287  0.5366135  0.63504214 0.86081066 0.12056666]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [1.         1.         1.         0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 0.         0.        ]]\n",
      "z is: [[0.87585176 0.46589473 0.59800998 0.95989189 0.06122958]\n",
      " [0.90180353 0.4613626  0.60156832 0.97444289 0.04499391]\n",
      " [0.7198201  0.49215614 0.801008   0.78241682 0.15081688]\n",
      " [0.90180353 0.4613626  0.60156832 0.97444289 0.04499391]\n",
      " [0.57713553 0.68513357 0.47551339 0.55029883 0.25438897]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]]\n",
      "z is: [[0.90305061 0.46529777 0.58905519 0.97288686 0.04402859]\n",
      " [0.90084267 0.48367895 0.56957276 0.97165136 0.04431385]\n",
      " [0.90305061 0.46529777 0.58905519 0.97288686 0.04402859]\n",
      " [0.90305061 0.46529777 0.58905519 0.97288686 0.04402859]\n",
      " [0.7961032  0.14372142 0.64395388 0.9072891  0.25097368]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.77311749 0.54822645 0.5831511  0.85370535 0.11938314]\n",
      " [0.9020398  0.4650761  0.56817509 0.9726519  0.04465882]\n",
      " [0.77311749 0.54822645 0.5831511  0.85370535 0.11938314]\n",
      " [0.79463751 0.14224101 0.62806234 0.90664927 0.25633835]\n",
      " [0.9020398  0.4650761  0.56817509 0.9726519  0.04465882]]\n",
      "x is: [[0.9        0.5        0.33333333 0.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]]\n",
      "z is: [[0.77035243 0.54950304 0.56234437 0.84593862 0.12108614]\n",
      " [0.90121185 0.46197893 0.54754581 0.97134083 0.0451202 ]\n",
      " [0.90121185 0.46197893 0.54754581 0.97134083 0.0451202 ]\n",
      " [0.90121185 0.46197893 0.54754581 0.97134083 0.0451202 ]\n",
      " [0.8942583  0.38151805 0.56802963 0.96871577 0.05824931]]\n",
      "x is: [[0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.9        0.5        0.33333333 1.         0.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]\n",
      " [0.8        0.         0.         0.85714286 1.        ]]\n",
      "z is: [[0.90059126 0.46344346 0.53113985 0.97027975 0.04454731]\n",
      " [0.89833566 0.48296459 0.51154734 0.96890686 0.04475778]\n",
      " [0.90059126 0.46344346 0.53113985 0.97027975 0.04454731]\n",
      " [0.79103302 0.13994411 0.59889405 0.89993446 0.26120546]\n",
      " [0.79103302 0.13994411 0.59889405 0.89993446 0.26120546]]\n",
      "(*) epoch 3, cost 2.462\n",
      "(*) training time: 0.02 sec.\n",
      "\n",
      "training time: 1.89 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "data is: [[ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 2  9 11 18]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 18 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 2  9 11 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]\n",
      " [ 9 11 -1 -1]]\n",
      "(*) preprocessing: normalize features\n",
      "normalized data is: [[0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 1.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         1.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "normalizer params are: {'copy': True, 'feature_range': (0, 1)}\n",
      "normalizer is: MinMaxScaler()\n",
      "wp is: [[-0.77830067 -0.82289462 -2.07946586 -2.37898103]\n",
      " [-0.92736422  2.07390124  2.72268226  1.60594591]\n",
      " [ 1.71518011  0.06804886  0.34866279 -2.80686008]]\n",
      "bp is: [0. 0. 0. 0.]\n",
      "x is: [[0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.50005402 0.83509657 0.88713395 0.33191443]\n",
      " [0.65339385 0.81667792 0.88243637 0.17030739]\n",
      " [0.50005402 0.83509657 0.88713395 0.33191443]\n",
      " [0.65339385 0.81667792 0.88243637 0.17030739]\n",
      " [0.65339385 0.81667792 0.88243637 0.17030739]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.65561538 0.79917569 0.85676158 0.15502557]\n",
      " [0.65561538 0.79917569 0.85676158 0.15502557]\n",
      " [0.65561538 0.79917569 0.85676158 0.15502557]\n",
      " [0.49494233 0.82248591 0.86777394 0.31897195]\n",
      " [0.65561538 0.79917569 0.85676158 0.15502557]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 1.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.66643414 0.7881551  0.82351379 0.14030063]\n",
      " [0.49730606 0.81519485 0.84344879 0.30942433]\n",
      " [0.30369304 0.8657902  0.91085261 0.77226381]\n",
      " [0.49730606 0.81519485 0.84344879 0.30942433]\n",
      " [0.66643414 0.7881551  0.82351379 0.14030063]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.66440298 0.76379469 0.79499346 0.13033615]\n",
      " [0.4877963  0.79769646 0.82466186 0.30085341]\n",
      " [0.66440298 0.76379469 0.79499346 0.13033615]\n",
      " [0.4877963  0.79769646 0.82466186 0.30085341]\n",
      " [0.66440298 0.76379469 0.79499346 0.13033615]]\n",
      "x is: [[0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         1.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.48361929 0.78536623 0.80092241 0.29020331]\n",
      " [0.48361929 0.78536623 0.80092241 0.29020331]\n",
      " [0.63266308 0.85424807 0.90483344 0.23357915]\n",
      " [0.48361929 0.78536623 0.80092241 0.29020331]\n",
      " [0.66830429 0.74571169 0.7593205  0.11872052]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]]\n",
      "z is: [[0.66595067 0.72270782 0.73875256 0.10988567]\n",
      " [0.66595067 0.72270782 0.73875256 0.10988567]\n",
      " [0.66595067 0.72270782 0.73875256 0.10988567]\n",
      " [0.66595067 0.72270782 0.73875256 0.10988567]\n",
      " [0.47596582 0.76849743 0.78774491 0.27616323]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.67819966 0.71429645 0.69545892 0.09990025]\n",
      " [0.51450246 0.57811537 0.41965552 0.09927221]\n",
      " [0.47943692 0.76356191 0.75938666 0.2693042 ]\n",
      " [0.67819966 0.71429645 0.69545892 0.09990025]\n",
      " [0.4507856  0.76133723 0.73347162 0.22702483]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.68392108 0.70380323 0.66433518 0.09270131]\n",
      " [0.68392108 0.70380323 0.66433518 0.09270131]\n",
      " [0.68392108 0.70380323 0.66433518 0.09270131]\n",
      " [0.51829142 0.57083583 0.39458221 0.09408899]\n",
      " [0.68392108 0.70380323 0.66433518 0.09270131]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.75662666 0.51114162 0.32235465 0.03592764]\n",
      " [0.69479292 0.70116967 0.6265951  0.08608097]\n",
      " [0.48363316 0.75454933 0.71384478 0.25705088]\n",
      " [0.69479292 0.70116967 0.6265951  0.08608097]\n",
      " [0.75662666 0.51114162 0.32235465 0.03592764]]\n",
      "x is: [[1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]]\n",
      "z is: [[0.70384446 0.70237707 0.59586184 0.08056513]\n",
      " [0.70384446 0.70237707 0.59586184 0.08056513]\n",
      " [0.47046341 0.75356223 0.65686528 0.1923632 ]\n",
      " [0.70384446 0.70237707 0.59586184 0.08056513]\n",
      " [0.70384446 0.70237707 0.59586184 0.08056513]]\n",
      "(*) epoch 1, cost 2.532\n",
      "x is: [[0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.50122446 0.76046501 0.66208181 0.24769994]\n",
      " [0.72208978 0.70889576 0.54960718 0.07354271]\n",
      " [0.50122446 0.76046501 0.66208181 0.24769994]\n",
      " [0.72208978 0.70889576 0.54960718 0.07354271]\n",
      " [0.72208978 0.70889576 0.54960718 0.07354271]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.7252156  0.69577365 0.51488479 0.06821056]\n",
      " [0.7252156  0.69577365 0.51488479 0.06821056]\n",
      " [0.7252156  0.69577365 0.51488479 0.06821056]\n",
      " [0.55376135 0.57892998 0.29639394 0.07960249]\n",
      " [0.7252156  0.69577365 0.51488479 0.06821056]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 1.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.73337675 0.69673785 0.48468248 0.06431488]\n",
      " [0.49979266 0.75234631 0.6204633  0.23899615]\n",
      " [0.28298772 0.81578971 0.8108373  0.72430926]\n",
      " [0.49979266 0.75234631 0.6204633  0.23899615]\n",
      " [0.73337675 0.69673785 0.48468248 0.06431488]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.49209309 0.73417352 0.5478577  0.15549229]\n",
      " [0.49149669 0.7374976  0.60457008 0.23525425]\n",
      " [0.73288497 0.67628815 0.45778966 0.06088858]\n",
      " [0.49149669 0.7374976  0.60457008 0.23525425]\n",
      " [0.73288497 0.67628815 0.45778966 0.06088858]]\n",
      "x is: [[0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         1.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.49197487 0.73033624 0.58530759 0.22799804]\n",
      " [0.49197487 0.73033624 0.58530759 0.22799804]\n",
      " [0.65734875 0.8185813  0.75571426 0.16811932]\n",
      " [0.49197487 0.73033624 0.58530759 0.22799804]\n",
      " [0.73744286 0.66744546 0.43041817 0.05670419]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]]\n",
      "z is: [[0.73532104 0.64896414 0.42074707 0.05372798]\n",
      " [0.73532104 0.64896414 0.42074707 0.05372798]\n",
      " [0.73532104 0.64896414 0.42074707 0.05372798]\n",
      " [0.48877376 0.71075264 0.51814504 0.14067908]\n",
      " [0.48412218 0.71656977 0.58063809 0.22013057]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.74528249 0.6525587  0.39289269 0.05017392]\n",
      " [0.49163201 0.71821327 0.55958893 0.21528716]\n",
      " [0.49163201 0.71821327 0.55958893 0.21528716]\n",
      " [0.74528249 0.6525587  0.39289269 0.05017392]\n",
      " [0.74528249 0.6525587  0.39289269 0.05017392]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.74779657 0.6450724  0.37157267 0.04737811]\n",
      " [0.74779657 0.6450724  0.37157267 0.04737811]\n",
      " [0.74779657 0.6450724  0.37157267 0.04737811]\n",
      " [0.48804441 0.71254205 0.54536682 0.2111718 ]\n",
      " [0.74779657 0.6450724  0.37157267 0.04737811]]\n",
      "x is: [[1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [0.         0.         0.63157895 0.        ]\n",
      " [1.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.        ]]\n",
      "z is: [[0.75537875 0.64911049 0.34876646 0.04475198]\n",
      " [0.75537875 0.64911049 0.34876646 0.04475198]\n",
      " [0.49138399 0.71510661 0.52874798 0.20859433]\n",
      " [0.75537875 0.64911049 0.34876646 0.04475198]\n",
      " [0.75537875 0.64911049 0.34876646 0.04475198]]\n",
      "x is: [[1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]]\n",
      "z is: [[0.76244533 0.65341184 0.32804555 0.0423861 ]\n",
      " [0.76244533 0.65341184 0.32804555 0.0423861 ]\n",
      " [0.76244533 0.65341184 0.32804555 0.0423861 ]\n",
      " [0.76244533 0.65341184 0.32804555 0.0423861 ]\n",
      " [0.76244533 0.65341184 0.32804555 0.0423861 ]]\n",
      "(*) epoch 2, cost 1.849\n",
      "(*) training time: 0.01 sec.\n",
      "\n",
      "training time: 0.18 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n"
     ]
    }
   ],
   "source": [
    "target_seqs, target_labels, source_seqs, source_labels = simulation_wrapper(50)\n",
    "target_reps, source_reps = custom_train_reps(target_seqs, source_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.592\n",
      "(*) epoch 2, cost 5.060\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.349\n",
      "(*) epoch 2, cost 2.883\n",
      "(*) epoch 3, cost 2.183\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.849\n",
      "(*) epoch 2, cost 2.682\n",
      "(*) epoch 3, cost 2.260\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.844\n",
      "(*) epoch 2, cost 1.480\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.270\n",
      "(*) epoch 2, cost 2.560\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.173\n",
      "(*) epoch 2, cost 4.380\n",
      "(*) epoch 3, cost 3.782\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.618\n",
      "(*) epoch 2, cost 3.258\n",
      "(*) epoch 3, cost 2.701\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.099\n",
      "(*) epoch 2, cost 3.410\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.209\n",
      "(*) epoch 2, cost 0.935\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.765\n",
      "(*) epoch 2, cost 2.596\n",
      "(*) epoch 3, cost 2.042\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.132\n",
      "(*) epoch 2, cost 3.726\n",
      "(*) epoch 3, cost 3.120\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.068\n",
      "(*) epoch 2, cost 1.219\n",
      "(*) epoch 3, cost 0.839\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.253\n",
      "(*) epoch 2, cost 5.627\n",
      "(*) epoch 3, cost 4.915\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.397\n",
      "(*) epoch 2, cost 3.303\n",
      "(*) epoch 3, cost 2.883\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.530\n",
      "(*) epoch 2, cost 2.801\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.614\n",
      "(*) epoch 2, cost 2.021\n",
      "(*) epoch 3, cost 1.417\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.449\n",
      "(*) epoch 2, cost 2.317\n",
      "(*) epoch 3, cost 1.957\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.235\n",
      "(*) epoch 2, cost 2.762\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.516\n",
      "(*) epoch 2, cost 3.300\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.124\n",
      "(*) epoch 2, cost 4.429\n",
      "(*) epoch 3, cost 3.797\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.487\n",
      "(*) epoch 2, cost 2.135\n",
      "(*) epoch 3, cost 1.722\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.351\n",
      "(*) epoch 2, cost 2.531\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.357\n",
      "(*) epoch 2, cost 3.975\n",
      "(*) epoch 3, cost 3.408\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.359\n",
      "(*) epoch 2, cost 3.129\n",
      "(*) epoch 3, cost 2.362\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.170\n",
      "(*) epoch 2, cost 3.226\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.830\n",
      "(*) epoch 2, cost 2.930\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.488\n",
      "(*) epoch 2, cost 1.871\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.851\n",
      "(*) epoch 2, cost 2.377\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.549\n",
      "(*) epoch 2, cost 3.153\n",
      "(*) epoch 3, cost 2.672\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.462\n",
      "(*) epoch 2, cost 2.892\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.425\n",
      "(*) epoch 2, cost 1.501\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.520\n",
      "(*) epoch 2, cost 3.271\n",
      "(*) epoch 3, cost 2.814\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.308\n",
      "(*) epoch 2, cost 1.687\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.678\n",
      "(*) epoch 2, cost 3.340\n",
      "(*) epoch 3, cost 2.785\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.459\n",
      "(*) epoch 2, cost 4.304\n",
      "(*) epoch 3, cost 3.266\n",
      "(*) epoch 4, cost 2.844\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.971\n",
      "(*) epoch 2, cost 3.162\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.686\n",
      "(*) epoch 2, cost 0.832\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.053\n",
      "(*) epoch 2, cost 3.167\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.543\n",
      "(*) epoch 2, cost 1.173\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.618\n",
      "(*) epoch 2, cost 3.800\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.930\n",
      "(*) epoch 2, cost 3.655\n",
      "(*) epoch 3, cost 3.173\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.990\n",
      "(*) epoch 2, cost 2.071\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.636\n",
      "(*) epoch 2, cost 4.263\n",
      "(*) epoch 3, cost 3.736\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.101\n",
      "(*) epoch 2, cost 2.955\n",
      "(*) epoch 3, cost 1.936\n",
      "(*) epoch 4, cost 1.462\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.758\n",
      "(*) epoch 2, cost 3.547\n",
      "(*) epoch 3, cost 2.013\n",
      "(*) epoch 4, cost 1.415\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.981\n",
      "(*) epoch 2, cost 2.572\n",
      "(*) epoch 3, cost 1.903\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.480\n",
      "(*) epoch 2, cost 2.575\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.803\n",
      "(*) epoch 2, cost 2.691\n",
      "(*) epoch 3, cost 2.216\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.300\n",
      "(*) epoch 2, cost 4.287\n",
      "(*) epoch 3, cost 3.838\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.303\n",
      "(*) epoch 2, cost 0.811\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.694\n",
      "(*) epoch 2, cost 4.063\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.332\n",
      "(*) epoch 2, cost 4.339\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.284\n",
      "(*) epoch 2, cost 2.533\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.911\n",
      "(*) epoch 2, cost 3.854\n",
      "(*) epoch 3, cost 3.376\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.327\n",
      "(*) epoch 2, cost 1.110\n",
      "(*) epoch 3, cost 0.690\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.690\n",
      "(*) epoch 2, cost 3.640\n",
      "(*) epoch 3, cost 3.222\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.253\n",
      "(*) epoch 2, cost 2.675\n",
      "(*) epoch 3, cost 1.941\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.767\n",
      "(*) epoch 2, cost 2.267\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.267\n",
      "(*) epoch 2, cost 3.693\n",
      "(*) epoch 3, cost 3.032\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.649\n",
      "(*) epoch 2, cost 1.097\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.347\n",
      "(*) epoch 2, cost 4.607\n",
      "(*) epoch 3, cost 3.543\n",
      "(*) epoch 4, cost 3.165\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.733\n",
      "(*) epoch 2, cost 2.982\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.974\n",
      "(*) epoch 2, cost 3.475\n",
      "(*) epoch 3, cost 2.948\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.315\n",
      "(*) epoch 2, cost 1.148\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.259\n",
      "(*) epoch 2, cost 3.392\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.754\n",
      "(*) epoch 2, cost 2.264\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 9.591\n",
      "(*) epoch 2, cost 3.953\n",
      "(*) epoch 3, cost 1.922\n",
      "(*) epoch 4, cost 1.432\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.922\n",
      "(*) epoch 2, cost 3.559\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.769\n",
      "(*) epoch 2, cost 0.642\n",
      "(*) epoch 3, cost 0.439\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.374\n",
      "(*) epoch 2, cost 4.377\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.547\n",
      "(*) epoch 2, cost 1.414\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.545\n",
      "(*) epoch 2, cost 2.252\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.372\n",
      "(*) epoch 2, cost 2.424\n",
      "(*) epoch 3, cost 1.539\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.976\n",
      "(*) epoch 2, cost 1.234\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.822\n",
      "(*) epoch 2, cost 1.109\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.859\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.794\n",
      "(*) epoch 2, cost 3.018\n",
      "(*) epoch 3, cost 2.525\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.488\n",
      "(*) epoch 2, cost 4.274\n",
      "(*) epoch 3, cost 3.546\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.713\n",
      "(*) epoch 2, cost 5.132\n",
      "(*) epoch 3, cost 4.412\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.489\n",
      "(*) epoch 2, cost 2.754\n",
      "(*) epoch 3, cost 2.061\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.686\n",
      "(*) epoch 2, cost 2.650\n",
      "(*) epoch 3, cost 2.277\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.880\n",
      "(*) epoch 2, cost 4.005\n",
      "(*) epoch 3, cost 3.293\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.843\n",
      "(*) epoch 2, cost 3.607\n",
      "(*) epoch 3, cost 3.063\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.473\n",
      "(*) epoch 2, cost 4.389\n",
      "(*) epoch 3, cost 3.756\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.424\n",
      "(*) epoch 2, cost 2.925\n",
      "(*) epoch 3, cost 2.437\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.861\n",
      "(*) epoch 2, cost 2.895\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.658\n",
      "(*) epoch 2, cost 2.966\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.382\n",
      "(*) epoch 2, cost 1.971\n",
      "(*) epoch 3, cost 1.405\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.099\n",
      "(*) epoch 2, cost 1.700\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.196\n",
      "(*) epoch 2, cost 3.393\n",
      "(*) epoch 3, cost 2.852\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.548\n",
      "(*) epoch 2, cost 2.973\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.340\n",
      "(*) epoch 2, cost 1.907\n",
      "(*) epoch 3, cost 1.189\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.052\n",
      "(*) epoch 2, cost 3.145\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.311\n",
      "(*) epoch 2, cost 3.401\n",
      "(*) epoch 3, cost 2.524\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.324\n",
      "(*) epoch 2, cost 1.596\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.842\n",
      "(*) epoch 2, cost 4.141\n",
      "(*) epoch 3, cost 3.710\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.700\n",
      "(*) epoch 2, cost 3.764\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.275\n",
      "(*) epoch 2, cost 2.821\n",
      "(*) epoch 3, cost 2.284\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.605\n",
      "(*) epoch 2, cost 3.905\n",
      "(*) epoch 3, cost 3.504\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.900\n",
      "(*) epoch 2, cost 2.351\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.218\n",
      "(*) epoch 2, cost 5.009\n",
      "(*) epoch 3, cost 4.559\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.751\n",
      "(*) epoch 2, cost 4.461\n",
      "(*) epoch 3, cost 4.014\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.793\n",
      "(*) epoch 2, cost 1.219\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.336\n",
      "(*) epoch 2, cost 1.973\n",
      "(*) epoch 3, cost 1.373\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.137\n",
      "(*) epoch 2, cost 2.425\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.320\n",
      "(*) epoch 2, cost 4.272\n",
      "(*) epoch 3, cost 3.892\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.499\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.312\n",
      "(*) epoch 2, cost 2.631\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.284\n",
      "(*) epoch 2, cost 2.223\n",
      "(*) epoch 3, cost 1.730\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.19 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.993\n",
      "(*) epoch 2, cost 3.178\n",
      "(*) epoch 3, cost 2.493\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.070\n",
      "(*) epoch 2, cost 1.188\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.769\n",
      "(*) epoch 2, cost 2.158\n",
      "(*) epoch 3, cost 1.557\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.18 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.492\n",
      "(*) epoch 2, cost 3.630\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.763\n",
      "(*) epoch 2, cost 1.221\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.037\n",
      "(*) epoch 2, cost 2.052\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.174\n",
      "(*) epoch 2, cost 1.036\n",
      "(*) epoch 3, cost 0.689\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.075\n",
      "(*) epoch 2, cost 2.681\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.995\n",
      "(*) epoch 2, cost 1.366\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.789\n",
      "(*) epoch 2, cost 2.386\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.916\n",
      "(*) epoch 2, cost 3.575\n",
      "(*) epoch 3, cost 2.625\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.360\n",
      "(*) epoch 2, cost 0.734\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.431\n",
      "(*) epoch 2, cost 2.472\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.136\n",
      "(*) epoch 2, cost 1.343\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.100\n",
      "(*) epoch 2, cost 4.692\n",
      "(*) epoch 3, cost 3.470\n",
      "(*) epoch 4, cost 3.031\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.260\n",
      "(*) epoch 2, cost 5.234\n",
      "(*) epoch 3, cost 4.788\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.687\n",
      "(*) epoch 2, cost 1.502\n",
      "(*) epoch 3, cost 1.133\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.807\n",
      "(*) epoch 2, cost 0.819\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.949\n",
      "(*) epoch 2, cost 3.612\n",
      "(*) epoch 3, cost 3.107\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.555\n",
      "(*) epoch 2, cost 1.285\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.991\n",
      "(*) epoch 2, cost 4.203\n",
      "(*) epoch 3, cost 3.629\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.906\n",
      "(*) epoch 2, cost 2.782\n",
      "(*) epoch 3, cost 2.170\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.929\n",
      "(*) epoch 2, cost 4.433\n",
      "(*) epoch 3, cost 3.376\n",
      "(*) epoch 4, cost 2.928\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.049\n",
      "(*) epoch 2, cost 2.823\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.901\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.423\n",
      "(*) epoch 2, cost 3.739\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.217\n",
      "(*) epoch 2, cost 3.695\n",
      "(*) epoch 3, cost 2.687\n",
      "(*) epoch 4, cost 2.292\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.979\n",
      "(*) epoch 2, cost 1.587\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.729\n",
      "(*) epoch 2, cost 4.381\n",
      "(*) epoch 3, cost 3.950\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.838\n",
      "(*) epoch 2, cost 1.424\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.143\n",
      "(*) epoch 2, cost 4.202\n",
      "(*) epoch 3, cost 3.315\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.391\n",
      "(*) epoch 2, cost 2.793\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.300\n",
      "(*) epoch 2, cost 2.403\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.412\n",
      "(*) epoch 2, cost 1.769\n",
      "(*) epoch 3, cost 1.386\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.632\n",
      "(*) epoch 2, cost 4.283\n",
      "(*) epoch 3, cost 3.788\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.486\n",
      "(*) epoch 2, cost 1.807\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.875\n",
      "(*) epoch 2, cost 2.356\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.789\n",
      "(*) epoch 2, cost 1.762\n",
      "(*) epoch 3, cost 1.473\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.870\n",
      "(*) epoch 2, cost 4.464\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.776\n",
      "(*) epoch 2, cost 4.487\n",
      "(*) epoch 3, cost 3.974\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.128\n",
      "(*) epoch 2, cost 2.584\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.785\n",
      "(*) epoch 2, cost 2.332\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.642\n",
      "(*) epoch 2, cost 2.332\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.466\n",
      "(*) epoch 2, cost 2.389\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.536\n",
      "(*) epoch 2, cost 4.707\n",
      "(*) epoch 3, cost 3.784\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.008\n",
      "(*) epoch 2, cost 2.586\n",
      "(*) epoch 3, cost 2.258\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.652\n",
      "(*) epoch 2, cost 5.287\n",
      "(*) epoch 3, cost 4.393\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.425\n",
      "(*) epoch 2, cost 2.130\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.380\n",
      "(*) epoch 2, cost 2.656\n",
      "(*) epoch 3, cost 2.018\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.939\n",
      "(*) epoch 2, cost 1.883\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.175\n",
      "(*) epoch 2, cost 1.555\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.424\n",
      "(*) epoch 2, cost 2.116\n",
      "(*) epoch 3, cost 1.770\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.440\n",
      "(*) epoch 2, cost 2.797\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.344\n",
      "(*) epoch 2, cost 3.002\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.691\n",
      "(*) epoch 2, cost 0.952\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.240\n",
      "(*) epoch 2, cost 3.841\n",
      "(*) epoch 3, cost 3.223\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.164\n",
      "(*) epoch 2, cost 2.033\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.454\n",
      "(*) epoch 2, cost 4.006\n",
      "(*) epoch 3, cost 3.079\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.513\n",
      "(*) epoch 2, cost 2.082\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.349\n",
      "(*) epoch 2, cost 1.377\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 10\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 9.389\n",
      "(*) epoch 2, cost 5.347\n",
      "(*) epoch 3, cost 4.200\n",
      "(*) epoch 4, cost 3.682\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.290\n",
      "(*) epoch 2, cost 2.066\n",
      "(*) epoch 3, cost 1.548\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.390\n",
      "(*) epoch 2, cost 4.098\n",
      "(*) epoch 3, cost 2.858\n",
      "(*) epoch 4, cost 2.425\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.170\n",
      "(*) epoch 2, cost 1.689\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.779\n",
      "(*) epoch 2, cost 2.912\n",
      "(*) epoch 3, cost 2.220\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.609\n",
      "(*) epoch 2, cost 4.037\n",
      "(*) epoch 3, cost 2.558\n",
      "(*) epoch 4, cost 2.126\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.080\n",
      "(*) epoch 2, cost 2.527\n",
      "(*) epoch 3, cost 1.892\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.616\n",
      "(*) epoch 2, cost 2.801\n",
      "(*) epoch 3, cost 2.037\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.105\n",
      "(*) epoch 2, cost 3.360\n",
      "(*) epoch 3, cost 2.625\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.014\n",
      "(*) epoch 2, cost 3.333\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.918\n",
      "(*) epoch 2, cost 3.211\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.697\n",
      "(*) epoch 2, cost 3.237\n",
      "(*) epoch 3, cost 2.702\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.578\n",
      "(*) epoch 2, cost 1.902\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.216\n",
      "(*) epoch 2, cost 1.888\n",
      "(*) epoch 3, cost 1.243\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.188\n",
      "(*) epoch 2, cost 1.866\n",
      "(*) epoch 3, cost 1.395\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.599\n",
      "(*) epoch 2, cost 3.008\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.573\n",
      "(*) epoch 2, cost 2.735\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.325\n",
      "(*) epoch 2, cost 2.602\n",
      "(*) epoch 3, cost 1.885\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.953\n",
      "(*) epoch 2, cost 3.433\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.889\n",
      "(*) epoch 2, cost 3.440\n",
      "(*) epoch 3, cost 2.541\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.771\n",
      "(*) epoch 2, cost 1.967\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.108\n",
      "(*) epoch 2, cost 2.303\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.900\n",
      "(*) epoch 2, cost 2.880\n",
      "(*) epoch 3, cost 2.363\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.477\n",
      "(*) epoch 2, cost 1.481\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.523\n",
      "(*) epoch 2, cost 4.291\n",
      "(*) epoch 3, cost 3.851\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.799\n",
      "(*) epoch 2, cost 1.996\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.319\n",
      "(*) epoch 2, cost 3.637\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.793\n",
      "(*) epoch 2, cost 2.420\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.311\n",
      "(*) epoch 2, cost 2.834\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.352\n",
      "(*) epoch 2, cost 2.524\n",
      "(*) epoch 3, cost 1.897\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.391\n",
      "(*) epoch 2, cost 3.539\n",
      "(*) epoch 3, cost 2.678\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n"
     ]
    }
   ],
   "source": [
    "target_maes, target_mses, target_rmses,  source_maes, source_mses, source_rmses, \\\n",
    "    trans_source_maes, trans_source_mses, trans_source_rmses = \\\n",
    "    run_proc_multi_cts(simulation_wrapper, custom_train_reps, linear_model.LinearRegression, n_times = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = \"../outputs/sim2_lr_scores.csv\"\n",
    "save_scores_cts(target_maes, target_mses, target_rmses,  source_maes, source_mses, source_rmses, \\\n",
    "        trans_source_maes, trans_source_mses, trans_source_rmses, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans source to source mae is 51.5%\n",
      "median trans source to source mae is 47.0%\n",
      "average trans source to source rmse is 52.7%\n",
      "median trans source to source rmse f1 is 49.8%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Smaller is better\n",
    "\"\"\"\n",
    "\n",
    "hist_plot_cts(score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
