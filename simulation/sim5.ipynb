{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nTry PCA on simulation 2\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Try PCA on simulation 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/deep_patient/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from deep_patient.sda import SDA\n",
    "from math import floor, exp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "from numpy.random import poisson\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "base_dir = \"/home/wanxinli/deep_patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 feature vectors\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 feature vectors\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    # We set the proportions of d_1 codes, d_2 codes, and (D-d_1-d_2) codes to be 2:1:1.5\n",
    "    unit_1 = 1/(0.5*d_1-0.5*d_2+1.5*D)\n",
    "    alpha_1 = [2*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([1.5*unit_1]*(D-d_1-d_2))\n",
    "\n",
    "    # We set the proportions of d_1 codes, d_2 codes, and (D-d_1-d_2) codes to be 1:2:1.5\n",
    "    unit_2 = 1/(-0.5*d_1+0.5*d_2+1.5*D)\n",
    "    alpha_2 = [2*unit_2]*d_1\n",
    "    alpha_2.extend([unit_2]*d_2)\n",
    "    alpha_2.extend([1.5*unit_2]*(D-d_1-d_2))    \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [max(0, W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(3*len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            lambda_i= np.sum(np.multiply(W, X_i))\n",
    "            Y_i = poisson(lam = lambda_i)\n",
    "            Y.append(Y_i)\n",
    "      \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    return feature_vector_1, np.array(label_1), feature_vector_2, np.array(label_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_wrapper():\n",
    "    num_patient = 1000\n",
    "    D = 20\n",
    "    d_1 = 5\n",
    "    d_2 = 5\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Fit PCA\n",
    "\"\"\"\n",
    "\n",
    "target_features, target_labels, source_features, source_labels = simulation_wrapper()\n",
    "target_pca = PCA(n_components=3)\n",
    "target_reps = target_pca.fit_transform(target_features)\n",
    "source_pca = PCA(n_components=3)\n",
    "source_reps = source_pca.fit_transform(source_features)\n",
    "reconstrcuted_source_features = source_pca.inverse_transform(source_reps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Sinkhorn transport source reps onto domain domain\n",
    "\"\"\"\n",
    "trans_source_reps =  trans_source2target(source_reps, target_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Fit models \n",
    "\"\"\"\n",
    "\n",
    "target_model = linear_model.LinearRegression()\n",
    "target_model.fit(target_reps, target_labels)\n",
    "\n",
    "# calculate the stats\n",
    "target_pred_labels = target_model.predict(target_reps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(target_mae, target_mse, target_rmse)\n",
    "# print(source_mae, source_mse, source_rmse)\n",
    "# print(trans_source_mae, trans_source_mse, trans_source_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72814115, -0.02864572, -0.00699313],\n",
       "       [-0.27174617, -0.02667547, -0.01715596],\n",
       "       [-0.27174617, -0.02667547, -0.01715596],\n",
       "       ...,\n",
       "       [ 0.72814115, -0.02864572, -0.00699313],\n",
       "       [-0.27174617, -0.02667547, -0.01715596],\n",
       "       [ 0.72814115, -0.02864572, -0.00699313]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_emb_dim2_ordered(target_reps, target_labels, source_reps, source_labels, trans_source_reps, target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5055538695378754 3.677434476889134 1.9176638070551193\n",
      "2.4617833415703334 7.42792758618692 2.7254224601310746\n",
      "2.3930226408349253 6.926306459077263 2.6317876926297195\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Calculate stats \n",
    "\"\"\"\n",
    "target_mae, target_mse, target_rmse, source_mae, source_mse, source_rmse,\\\n",
    "        trans_source_mae, trans_source_mse, trans_source_rmse = \\\n",
    "    cal_stats_cts(target_reps, target_labels, source_reps, source_labels, \\\n",
    "    trans_source_reps, linear_model.LinearRegression)\n",
    "print(target_mae, target_mse, target_rmse)\n",
    "print(source_mae, source_mse, source_rmse)\n",
    "print(trans_source_mae, trans_source_mse, trans_source_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Nov 23 2021, 15:27:38) \n[GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
