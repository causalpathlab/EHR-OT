{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation goals\n",
    "\n",
    "* Categorical response variable\n",
    "\n",
    "* Different feature distribution for different domains\n",
    "\n",
    "Simulation\n",
    "\n",
    "* $D$: total number of features\n",
    "\n",
    "* $d_{1}$: number of features with higher frequency in a domain 1\n",
    "\n",
    "* $d_{2}$: number of features with higher frequency in a domain 2\n",
    "\n",
    "\n",
    "* $d_{1} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$\n",
    "\n",
    "* $d_{2} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$ ($d_{1} + d_{2} \\le D$)\n",
    "\n",
    "* $k \\in [D]$ for indexing feature\n",
    "\n",
    "* Let $\\Delta_{r} = \\{j \\in [D]: \\textrm{feature } j \\textrm{ is more frequent in a domain } r \\}$\n",
    "\n",
    "* Sample $\\Delta_{1} \\subseteq [D]$ such that $|\\Delta_{1}| = d_{1}$ \n",
    "\n",
    "* Sample $\\Delta_{2} \\subseteq [D]\\backslash \\Delta_{1}$ such that $|\\Delta_{2}| = d_{2}$\n",
    "\n",
    "* Let $\\alpha_{1} \\overset{\\Delta}{=} \\left( \\alpha_{11}, \\ldots, \\alpha_{1D} \\right)$ be a feature frequency vector for a domain 1\n",
    "\n",
    "* Let $\\alpha_{2} \\overset{\\Delta}{=} \\left( \\alpha_{21}, \\ldots, \\alpha_{2D} \\right)$ be a feature frequency vector for a domain 2\n",
    "\n",
    "\n",
    "* For each $k \\in [D]$: \n",
    "\n",
    "    * If $k \\in \\Delta_{1}$, $\\alpha_{1k} > \\alpha_{2k}$\n",
    "\n",
    "    * If $k \\in \\Delta_{2}$, $\\alpha_{2k} > \\alpha_{1k}$\n",
    "\n",
    "    * Otherwise $\\alpha_{1k} = \\alpha_{2k}$\n",
    "\n",
    "\n",
    "* Sample $\\rho_{1} \\sim \\operatorname{Dir}(\\alpha_{1})$\n",
    "\n",
    "* Sample $\\rho_{2} \\sim \\operatorname{Dir}(\\alpha_{2})$\n",
    "\n",
    "* Sample a code-specific contribution to mortality: $W_{i} \\sim   \\mathcal{N}\\!\\left(0,1\\right)$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "    * $\\tilde{X}_{i} \\sim \\operatorname{Multi}(n_{i}; \\rho_{r})$ where $\\tilde{X}_{i}$ is a vector of counts for each diagnosis code/feature, $n_i = 3k$.\n",
    "\n",
    "\t* We set $X_{ik} = \\min \\left\\{ \\tilde{X}_{ik}, 1 \\right\\}$ where $\\tilde{X}_{ik}$ is a count for a diagnosis code/feature $k$, $k \\in [D]$\n",
    "\n",
    "* For all patient $i$ in a domain $r$\n",
    "\n",
    "    * $b = -\\operatorname{Mean}(\\sum_{k} W_{k} X_{ik})$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "\t* pathogenic score $\\bar{p}_{i} = \\operatorname{sigmoid}(\\sum_{k} W_{k} X_{ik} + b)$ (aka a liability model)\n",
    "\n",
    "    <!-- * If $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; else $Y_{i} = 0$. -->\n",
    "\n",
    "\t* Sample $Y_{i} \\sim \\operatorname{Bern}(\\bar{p}_{i})$\n",
    "\n",
    "    * Alternatively, if $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; otherwise, $Y_{i} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/deep_patient/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from deep_patient.sda import SDA\n",
    "from math import floor, exp, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "base_dir = \"/home/wanxinli/deep_patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    unit_1 = 1/(2*d_1-2*d_2+3*D)\n",
    "    alpha_1 = [5*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([3*unit_1]*(D-d_1-d_2))\n",
    "  \n",
    "    unit_2 = 1/(-2*d_1+2*d_2+3*D)\n",
    "    alpha_2 = [unit_2]*d_1\n",
    "    alpha_2.extend([5*unit_2]*d_2)\n",
    "    alpha_2.extend([3*unit_2]*(D-d_1-d_2))  \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [abs(W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            cur_sum = np.sum(np.multiply(W, X_i))\n",
    "            all_sum.append(cur_sum)\n",
    "        \n",
    "        print(\"all_sum before preprocessing is:\", all_sum)\n",
    "        # standardize\n",
    "        all_sum = preprocessing.scale(all_sum)\n",
    "        print(\"all_sum after preprocessing is:\", all_sum)\n",
    "\n",
    "        all_sum = np.array(all_sum)\n",
    "        \n",
    "        P = []\n",
    "        for cur_sum in all_sum:\n",
    "            p_i = sigmoid(cur_sum)\n",
    "            P.append(p_i)\n",
    "            Y_i = 0\n",
    "            if p_i >= 0.5: # TODO: mimic exact logistic regression, change to np.random.binomial later\n",
    "                Y_i = 1\n",
    "            # Y_i = np.random.binomial(1, p_i) # too much noise, domain 1 data cannot learn well\n",
    "            Y.append(int(Y_i))\n",
    "        print(\"P is:\", P)\n",
    "\n",
    "            \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), label_1, np.array(feature_2), label_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Wrapper function with different set ups for simulate()\n",
    "\"\"\"\n",
    "def simulate_wrapper(num_patient):\n",
    "    D = 20\n",
    "    d_1 = 8\n",
    "    d_2 = 8\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train deep patient model and generate representations for males and females\n",
    "\"\"\"\n",
    "\n",
    "def custom_train_reps(male_seqs, female_seqs):\n",
    "    \"\"\" \n",
    "    Customized training algorithm for generating male representations and female representations\n",
    "    \n",
    "    :returns: male representations, female representations\n",
    "    \"\"\"\n",
    "\n",
    "    # customized parameters\n",
    "    nhidden = 3\n",
    "    nlayer = 1\n",
    "\n",
    "    # for males\n",
    "    # initiate the model\n",
    "    male_sda = SDA(male_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    male_sda.train(male_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    male_reps = male_sda.apply(male_seqs)\n",
    "\n",
    "    # for females\n",
    "    # initiate the model\n",
    "    female_sda = SDA(female_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    female_sda.train(female_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    female_reps = female_sda.apply(female_seqs)\n",
    "    return male_reps, female_reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(male_reps, male_labels, female_reps, female_labels, trans_female_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=130)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\", s=130)\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=100)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\", s=100)\n",
    "\n",
    "    ax.scatter(trans_female_reps[female_0,0], trans_female_reps[female_0,1], trans_female_reps[female_0,2], color='green', label=\"trans female 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_female_reps[female_1,0], trans_female_reps[female_1,1], trans_female_reps[female_1,2], color='green', label=\"trans female 1\",  alpha=0.5, marker=\"x\", s=70)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_opp(male_reps, male_labels, female_reps, female_labels, trans_male_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(trans_male_reps[male_0,0], trans_male_reps[male_0,1], trans_male_reps[male_0,2], color='green', label=\"trans male 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_male_reps[male_1,0], trans_male_reps[male_1,1], trans_male_reps[male_1,2], color='green', label=\"trans male 1\",  alpha=0.5, marker=\"x\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_sum before preprocessing is: [1.5210423872630612, 2.4724675526854654, 1.5210423872630612, 2.4724675526854654, 1.6395202017053598, 1.6395202017053598, 2.4724675526854654, 2.4724675526854654, 1.5210423872630612, 0.6880950362829557, 1.5210423872630612, 2.4724675526854654, 1.5210423872630612, 1.5210423872630612, 2.4724675526854654, 1.5210423872630612, 1.6395202017053598, 2.4724675526854654, 2.4724675526854654, 1.6395202017053598, 1.6395202017053598, 1.5210423872630612, 1.6395202017053598, 1.6395202017053598, 1.6395202017053598, 1.5210423872630612, 1.9077971901422925, 1.5210423872630612, 2.4724675526854654, 1.6395202017053598, 2.4724675526854654, 2.4724675526854654, 2.4724675526854654, 2.4724675526854654, 1.6395202017053598, 0.6880950362829557, 1.6395202017053598, 1.6395202017053598, 2.4724675526854654, 2.4724675526854654, 1.5210423872630612, 0.6880950362829557, 1.6395202017053598, 2.4724675526854654, 2.4724675526854654, 2.4724675526854654, 1.5210423872630612, 1.5210423872630612, 2.4724675526854654, 2.4724675526854654]\n",
      "all_sum after preprocessing is: [-0.70507008  1.11222132 -0.70507008  1.11222132 -0.47876882 -0.47876882\n",
      "  1.11222132  1.11222132 -0.70507008 -2.29606021 -0.70507008  1.11222132\n",
      " -0.70507008 -0.70507008  1.11222132 -0.70507008 -0.47876882  1.11222132\n",
      "  1.11222132 -0.47876882 -0.47876882 -0.70507008 -0.47876882 -0.47876882\n",
      " -0.47876882 -0.70507008  0.03365978 -0.70507008  1.11222132 -0.47876882\n",
      "  1.11222132  1.11222132  1.11222132  1.11222132 -0.47876882 -2.29606021\n",
      " -0.47876882 -0.47876882  1.11222132  1.11222132 -0.70507008 -2.29606021\n",
      " -0.47876882  1.11222132  1.11222132  1.11222132 -0.70507008 -0.70507008\n",
      "  1.11222132  1.11222132]\n",
      "P is: [0.3306890869568955, 0.75254300268296, 0.3306890869568955, 0.75254300268296, 0.3825428934687817, 0.3825428934687817, 0.75254300268296, 0.75254300268296, 0.3306890869568955, 0.09144977839182322, 0.3306890869568955, 0.75254300268296, 0.3306890869568955, 0.3306890869568955, 0.75254300268296, 0.3306890869568955, 0.3825428934687817, 0.75254300268296, 0.75254300268296, 0.3825428934687817, 0.3825428934687817, 0.3306890869568955, 0.3825428934687817, 0.3825428934687817, 0.3825428934687817, 0.3306890869568955, 0.5084141509887754, 0.3306890869568955, 0.75254300268296, 0.3825428934687817, 0.75254300268296, 0.75254300268296, 0.75254300268296, 0.75254300268296, 0.3825428934687817, 0.09144977839182322, 0.3825428934687817, 0.3825428934687817, 0.75254300268296, 0.75254300268296, 0.3306890869568955, 0.09144977839182322, 0.3825428934687817, 0.75254300268296, 0.75254300268296, 0.75254300268296, 0.3306890869568955, 0.3306890869568955, 0.75254300268296, 0.75254300268296]\n",
      "all_sum before preprocessing is: [1.975168702054985, 2.5644098306532555, 1.975168702054985, 1.492431641254925, 1.975168702054985, 3.0471468914533157, 2.5644098306532555, 1.975168702054985, 2.3529940790749095, 2.675661250867078, 1.492431641254925, 3.2260940478478153, 3.437509799426161, 1.975168702054985, 2.5644098306532555, 4.031145311690931, 1.492431641254925, 2.3655316100278307, 3.437509799426161, 2.3655316100278307, 2.3655316100278307, 2.3655316100278307, 2.3655316100278307, 3.437509799426161, 2.17404692268041, 1.492431641254925, 3.0471468914533157, 1.1020687332820793, 1.975168702054985, 2.17404692268041, 2.496714094472578, 1.975168702054985, 4.10973965978765, 1.953245750038067, 2.3655316100278307, 3.2366396910147435, 2.5644098306532555, 2.3655316100278307, 2.675661250867078, 2.5644098306532555, 2.17404692268041, 2.3655316100278307, 3.9590551918437544, 2.0860671535196946, 2.3655316100278307, 2.3655316100278307, 2.3655316100278307, 3.578628329629237, 2.3655316100278307, 2.3655316100278307]\n",
      "all_sum after preprocessing is: [-0.76190137  0.13512075 -0.76190137 -1.49678868 -0.76190137  0.87000806\n",
      "  0.13512075 -0.76190137 -0.18672475  0.30448264 -1.49678868  1.1424255\n",
      "  1.464271   -0.76190137  0.13512075  2.36798285 -1.49678868 -0.16763843\n",
      "  1.464271   -0.16763843 -0.16763843 -0.16763843 -0.16763843  1.464271\n",
      " -0.45914219 -1.49678868  0.87000806 -2.09105162 -0.76190137 -0.45914219\n",
      "  0.0320652  -0.76190137  2.48762974 -0.79527544 -0.16763843  1.1584795\n",
      "  0.13512075 -0.16763843  0.30448264  0.13512075 -0.45914219 -0.16763843\n",
      "  2.25823757 -0.59307683 -0.16763843 -0.16763843 -0.16763843  1.67910062\n",
      " -0.16763843 -0.16763843]\n",
      "P is: [0.3182335998411483, 0.5337288868234416, 0.3182335998411483, 0.18290496937787823, 0.3182335998411483, 0.7047473752513963, 0.5337288868234416, 0.3182335998411483, 0.4534539743622674, 0.5755379668772015, 0.18290496937787823, 0.7581246852431253, 0.8121850444603044, 0.3182335998411483, 0.5337288868234416, 0.9143530265647185, 0.18290496937787823, 0.45818826455864164, 0.8121850444603044, 0.45818826455864164, 0.45818826455864164, 0.45818826455864164, 0.45818826455864164, 0.8121850444603044, 0.38718934062606836, 0.18290496937787823, 0.7047473752513963, 0.10996960333222094, 0.3182335998411483, 0.38718934062606836, 0.5080156123517573, 0.3182335998411483, 0.9232700562682931, 0.3110370538930208, 0.45818826455864164, 0.7610563216325573, 0.5337288868234416, 0.45818826455864164, 0.5755379668772015, 0.5337288868234416, 0.38718934062606836, 0.45818826455864164, 0.9053587265282351, 0.35592919858886046, 0.45818826455864164, 0.45818826455864164, 0.45818826455864164, 0.8427854011877515, 0.45818826455864164, 0.45818826455864164]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.632\n",
      "(*) epoch 2, cost 1.178\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.169\n",
      "(*) epoch 2, cost 3.425\n",
      "(*) epoch 3, cost 2.823\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.910165940204998, 5.069278930364338, 5.069278930364338, 5.069278930364338, 4.700937519764146, 5.069278930364338, 4.244764423636164, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 4.700937519764146, 5.069278930364338, 5.069278930364338, 4.700937519764146, 3.7722188243956953, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.910165940204998, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 4.700937519764146, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338, 5.069278930364338]\n",
      "all_sum after preprocessing is: [ 0.13130596  0.13130596  0.13130596  0.13130596  3.01692753  0.13130596\n",
      "  0.13130596  0.13130596 -1.13270919  0.13130596 -2.69813108  0.13130596\n",
      "  0.13130596  0.13130596  0.13130596  0.13130596  0.13130596  0.13130596\n",
      " -1.13270919  0.13130596  0.13130596 -1.13270919 -4.3197375   0.13130596\n",
      "  0.13130596  0.13130596  0.13130596  0.13130596  0.13130596  0.13130596\n",
      "  0.13130596  0.13130596  0.13130596  0.13130596  0.13130596  3.01692753\n",
      "  0.13130596  0.13130596  0.13130596  0.13130596 -1.13270919  0.13130596\n",
      "  0.13130596  0.13130596  0.13130596  0.13130596  0.13130596  0.13130596\n",
      "  0.13130596  0.13130596]\n",
      "P is: [0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.9533330241963522, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.24366147569330204, 0.5327794067740372, 0.0630837270725726, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.24366147569330204, 0.5327794067740372, 0.5327794067740372, 0.24366147569330204, 0.013128718960062371, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.9533330241963522, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.24366147569330204, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372, 0.5327794067740372]\n",
      "all_sum before preprocessing is: [2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 1.2881381788575532, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.3702543661377575, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.3702543661377575, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.3702543661377575, 2.9713327302603654, 2.3702543661377575, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.4695539335425445, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654, 2.9713327302603654]\n",
      "all_sum after preprocessing is: [ 0.32018332  0.32018332  0.32018332 -5.55143508  0.32018332  0.32018332\n",
      "  0.32018332  0.32018332  0.32018332  0.32018332 -1.77660507  0.32018332\n",
      "  0.32018332  0.32018332  0.32018332 -1.77660507  0.32018332  0.32018332\n",
      "  0.32018332  0.32018332  0.32018332  0.32018332  0.32018332  0.32018332\n",
      "  0.32018332 -1.77660507  0.32018332 -1.77660507  0.32018332  0.32018332\n",
      "  0.32018332  0.32018332  0.32018332  0.32018332  0.32018332  0.32018332\n",
      "  0.32018332  0.32018332  0.32018332  0.32018332  0.32018332  0.32018332\n",
      "  0.32018332  0.32018332  0.32018332 -1.43021067  0.32018332  0.32018332\n",
      "  0.32018332  0.32018332]\n",
      "P is: [0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.003866871677537098, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.14472284610933256, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.14472284610933256, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.14472284610933256, 0.5793689276121168, 0.14472284610933256, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.1930658622368404, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168, 0.5793689276121168]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.394\n",
      "(*) epoch 2, cost 2.513\n",
      "(*) epoch 3, cost 1.743\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.151\n",
      "(*) epoch 2, cost 1.126\n",
      "(*) epoch 3, cost 0.714\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.0567551984937367, 3.066672306509857, 3.066672306509857, 3.066672306509857, 1.0567551984937367, 3.066672306509857, 3.066672306509857, 4.93315667417481, 3.066672306509857, 3.066672306509857, 1.0567551984937367, 3.066672306509857, 1.0567551984937367, 3.066672306509857, 2.4996331328832033, 1.0567551984937367, 1.0567551984937367, 4.395616502623032, 3.066672306509857, 3.066672306509857, 1.0567551984937367, 3.066672306509857, 3.066672306509857, 4.395616502623032, 3.066672306509857, 3.066672306509857, 1.0567551984937367, 3.066672306509857, 3.066672306509857, 1.0567551984937367, 1.0567551984937367, 3.066672306509857, 4.93315667417481, 3.066672306509857, 1.0567551984937367, 2.3856993946069105, 4.395616502623032, 2.9232395661586885, 3.066672306509857, 3.066672306509857, 3.066672306509857, 1.0567551984937367, 3.066672306509857, 3.066672306509857, 3.066672306509857, 4.93315667417481, 3.066672306509857, 4.93315667417481, 4.395616502623032, 4.93315667417481]\n",
      "all_sum after preprocessing is: [-1.50008936  0.18178838  0.18178838  0.18178838 -1.50008936  0.18178838\n",
      "  0.18178838  1.74364309  0.18178838  0.18178838 -1.50008936  0.18178838\n",
      " -1.50008936  0.18178838 -0.2927041  -1.50008936 -1.50008936  1.29383507\n",
      "  0.18178838  0.18178838 -1.50008936  0.18178838  0.18178838  1.29383507\n",
      "  0.18178838  0.18178838 -1.50008936  0.18178838  0.18178838 -1.50008936\n",
      " -1.50008936  0.18178838  1.74364309  0.18178838 -1.50008936 -0.38804267\n",
      "  1.29383507  0.06176536  0.18178838  0.18178838  0.18178838 -1.50008936\n",
      "  0.18178838  0.18178838  0.18178838  1.74364309  0.18178838  1.74364309\n",
      "  1.29383507  1.74364309]\n",
      "P is: [0.18241219713884824, 0.545322350222716, 0.545322350222716, 0.545322350222716, 0.18241219713884824, 0.545322350222716, 0.545322350222716, 0.851149215181422, 0.545322350222716, 0.545322350222716, 0.18241219713884824, 0.545322350222716, 0.18241219713884824, 0.545322350222716, 0.4273419872948996, 0.18241219713884824, 0.18241219713884824, 0.7847956067939815, 0.545322350222716, 0.545322350222716, 0.18241219713884824, 0.545322350222716, 0.545322350222716, 0.7847956067939815, 0.545322350222716, 0.545322350222716, 0.18241219713884824, 0.545322350222716, 0.545322350222716, 0.18241219713884824, 0.18241219713884824, 0.545322350222716, 0.851149215181422, 0.545322350222716, 0.18241219713884824, 0.4041885767329446, 0.7847956067939815, 0.5154364319895715, 0.545322350222716, 0.545322350222716, 0.545322350222716, 0.18241219713884824, 0.545322350222716, 0.545322350222716, 0.545322350222716, 0.851149215181422, 0.545322350222716, 0.851149215181422, 0.7847956067939815, 0.851149215181422]\n",
      "all_sum before preprocessing is: [0.8936268096166019, 2.124293831064586, 2.6552345764649474, 1.2098221375943972, 2.6520448958044707, 1.9526667371383801, 2.752640468916685, 2.3390392484871523, 3.0032893675834287, 2.3390392484871523, 1.4245675550169636, 2.3390392484871523, 1.1355693207543467, 3.561320588223989, 2.124293831064586, 2.9767395777671157, 2.752640468916685, 0.6788813921940355, 0.8936268096166019, 0.6788813921940355, 2.869979993887514, 2.580981759624897, 3.111922505025259, 2.752640468916685, 1.6665100661547085, 0.6788813921940355, 2.580981759624897, 2.5725960779137496, 2.869979993887514, 2.124293831064586, 1.2098221375943972, 2.124293831064586, 0.7856409760736374, 2.580981759624897, 2.795727177047463, 2.3390392484871523, 2.3390392484871523, 2.124293831064586, 2.580981759624897, 2.795727177047463, 2.124293831064586, 3.326667922447825, 1.1355693207543467, 0.6788813921940355, 2.124293831064586, 2.580981759624897, 1.5662626104240258, 2.580981759624897, 2.752640468916685, 3.111922505025259]\n",
      "all_sum after preprocessing is: [-1.61806475 -0.04448083  0.6344029  -1.21376377  0.63032443 -0.26393063\n",
      "  0.75895027  0.23010192  1.07944076  0.23010192 -0.93918102  0.23010192\n",
      " -1.30870662  1.79296354 -0.04448083  1.04549306  0.75895027 -1.8926475\n",
      " -1.61806475 -1.8926475   0.90898565  0.53946004  1.21834378  0.75895027\n",
      " -0.62982289 -1.8926475   0.53946004  0.52873775  0.90898565 -0.04448083\n",
      " -1.21376377 -0.04448083 -1.75614009  0.53946004  0.8140428   0.23010192\n",
      "  0.23010192 -0.04448083  0.53946004  0.8140428  -0.04448083  1.49292653\n",
      " -1.30870662 -1.8926475  -0.04448083  0.53946004 -0.75800361  0.53946004\n",
      "  0.75895027  1.21834378]\n",
      "P is: [0.16547193786970613, 0.488881625140918, 0.6534871345402944, 0.22903577295019759, 0.652563023191214, 0.4343977178601832, 0.6811257831455213, 0.5572729999715151, 0.74638813804952, 0.5572729999715151, 0.28106580257384917, 0.5572729999715151, 0.212703353462592, 0.8572902311456612, 0.488881625140918, 0.7399085034094961, 0.6811257831455213, 0.13094289785474095, 0.16547193786970613, 0.13094289785474095, 0.7127925501705558, 0.631686801488782, 0.7717719532701036, 0.6811257831455213, 0.34755069750336753, 0.13094289785474095, 0.631686801488782, 0.6291886642785437, 0.7127925501705558, 0.488881625140918, 0.22903577295019759, 0.488881625140918, 0.14727442537209956, 0.631686801488782, 0.6929703296724444, 0.5572729999715151, 0.5572729999715151, 0.488881625140918, 0.631686801488782, 0.6929703296724444, 0.488881625140918, 0.8165171217247249, 0.212703353462592, 0.13094289785474095, 0.488881625140918, 0.631686801488782, 0.31907986054775855, 0.631686801488782, 0.6811257831455213, 0.7717719532701036]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.437\n",
      "(*) epoch 2, cost 1.709\n",
      "(*) epoch 3, cost 1.266\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.151\n",
      "(*) epoch 2, cost 3.027\n",
      "(*) epoch 3, cost 2.741\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.7083846750210347, 2.2714079080941696, 0.7083846750210347, 2.2714079080941696, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 2.2714079080941696, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 2.2714079080941696, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 2.2714079080941696, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 2.2714079080941696, 2.2714079080941696, 2.2714079080941696, 0.7083846750210347, 0.7083846750210347, 2.2714079080941696, 0.7083846750210347, 2.2714079080941696, 2.2714079080941696, 2.2714079080941696, 0.7083846750210347, 2.2714079080941696, 2.2714079080941696, 2.2714079080941696, 0.7083846750210347, 2.2714079080941696, 2.2714079080941696, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 2.2714079080941696, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347, 0.7083846750210347]\n",
      "all_sum after preprocessing is: [-0.75        1.33333333 -0.75        1.33333333 -0.75       -0.75\n",
      " -0.75       -0.75        1.33333333 -0.75       -0.75       -0.75\n",
      " -0.75       -0.75       -0.75        1.33333333 -0.75       -0.75\n",
      " -0.75        1.33333333 -0.75       -0.75       -0.75       -0.75\n",
      "  1.33333333  1.33333333  1.33333333 -0.75       -0.75        1.33333333\n",
      " -0.75        1.33333333  1.33333333  1.33333333 -0.75        1.33333333\n",
      "  1.33333333  1.33333333 -0.75        1.33333333  1.33333333 -0.75\n",
      " -0.75       -0.75       -0.75        1.33333333 -0.75       -0.75\n",
      " -0.75       -0.75      ]\n",
      "P is: [0.32082130082460697, 0.791391472673955, 0.32082130082460697, 0.791391472673955, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.791391472673955, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.791391472673955, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.791391472673955, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.791391472673955, 0.791391472673955, 0.791391472673955, 0.32082130082460697, 0.32082130082460697, 0.791391472673955, 0.32082130082460697, 0.791391472673955, 0.791391472673955, 0.791391472673955, 0.32082130082460697, 0.791391472673955, 0.791391472673955, 0.791391472673955, 0.32082130082460697, 0.791391472673955, 0.791391472673955, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.791391472673955, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697, 0.32082130082460697]\n",
      "all_sum before preprocessing is: [1.6653357710765837, 1.450556116754247, 2.967095909777452, 1.8580821149284135, 3.0653995312744904, 2.1030830798065687, 2.7523162554551157, 2.967095909777452, 1.0161025954280365, 2.967095909777452, 1.6653357710765837, 1.0161025954280365, 1.6653357710765837, 1.6620064956267149, 2.317862734128905, 1.0161025954280365, 1.6653357710765837, 2.967095909777452, 2.1030830798065687, 2.317862734128905, 2.317862734128905, 1.1144062169250746, 1.6653357710765837, 2.317862734128905, 2.3112396712752616, 1.450556116754247, 0.14546670260350966, 1.0161025954280365, 1.6653357710765837, 1.0161025954280365, 2.1030830798065687, 1.0161025954280365, 2.1030830798065687, 2.317862734128905, 1.0161025954280365, 2.1030830798065687, 1.6653357710765837, 1.450556116754247, 2.967095909777452, 2.967095909777452, 1.0161025954280365, 1.0161025954280365, 2.7523162554551157, 2.317862734128905, 0.8013229411057, 3.0653995312744904, 2.967095909777452, 2.317862734128905, 1.6653357710765837, 1.0161025954280365]\n",
      "all_sum after preprocessing is: [-0.31268114 -0.60198689  1.44077495 -0.05305401  1.57318881  0.2769595\n",
      "  1.1514692   1.44077495 -1.18719084  1.44077495 -0.31268114 -1.18719084\n",
      " -0.31268114 -0.31716564  0.56626525 -1.18719084 -0.31268114  1.44077495\n",
      "  0.2769595   0.56626525  0.56626525 -1.05477698 -0.31268114  0.56626525\n",
      "  0.55734406 -0.60198689 -2.35992748 -1.18719084 -0.31268114 -1.18719084\n",
      "  0.2769595  -1.18719084  0.2769595   0.56626525 -1.18719084  0.2769595\n",
      " -0.31268114 -0.60198689  1.44077495  1.44077495 -1.18719084 -1.18719084\n",
      "  1.1514692   0.56626525 -1.47649659  1.57318881  1.44077495  0.56626525\n",
      " -0.31268114 -1.18719084]\n",
      "P is: [0.42246043757434215, 0.3538892557587739, 0.8085746276203252, 0.48673960729417476, 0.8282377226501276, 0.5688006475744798, 0.7597791693972727, 0.8085746276203252, 0.23376172815696142, 0.8085746276203252, 0.42246043757434215, 0.23376172815696142, 0.42246043757434215, 0.42136665822080843, 0.637900954950683, 0.23376172815696142, 0.42246043757434215, 0.8085746276203252, 0.5688006475744798, 0.637900954950683, 0.637900954950683, 0.258308844910007, 0.42246043757434215, 0.637900954950683, 0.6358377842306295, 0.3538892557587739, 0.08627991166816443, 0.23376172815696142, 0.42246043757434215, 0.23376172815696142, 0.5688006475744798, 0.23376172815696142, 0.5688006475744798, 0.637900954950683, 0.23376172815696142, 0.5688006475744798, 0.42246043757434215, 0.3538892557587739, 0.8085746276203252, 0.8085746276203252, 0.23376172815696142, 0.23376172815696142, 0.7597791693972727, 0.637900954950683, 0.18595717196728834, 0.8282377226501276, 0.8085746276203252, 0.637900954950683, 0.42246043757434215, 0.23376172815696142]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.285\n",
      "(*) epoch 2, cost 0.736\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.371\n",
      "(*) epoch 2, cost 3.831\n",
      "(*) epoch 3, cost 3.066\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8934797018565912, 2.413769629854668, 2.413769629854668, 2.413769629854668, 2.413769629854668, 2.413769629854668, 1.8934797018565912, 2.413769629854668, 1.8934797018565912, 1.8934797018565912, 2.413769629854668, 1.8934797018565912, 1.8934797018565912, 2.413769629854668, 2.413769629854668, 2.413769629854668, 1.8934797018565912, 1.8934797018565912, 2.413769629854668, 2.413769629854668, 1.8934797018565912, 2.413769629854668, 1.8934797018565912, 2.413769629854668, 1.8934797018565912, 1.8934797018565912, 1.8934797018565912, 2.413769629854668, 1.8934797018565912, 2.413769629854668, 1.8934797018565912, 2.798640561342891, 1.8934797018565912, 1.8934797018565912, 2.413769629854668, 1.8934797018565912, 2.2783506333448145, 2.413769629854668, 2.798640561342891, 2.413769629854668, 2.413769629854668, 1.8934797018565912, 2.798640561342891, 1.8934797018565912, 2.413769629854668, 2.413769629854668, 2.413769629854668, 2.413769629854668, 2.413769629854668, 2.413769629854668]\n",
      "all_sum after preprocessing is: [-1.15928284  0.65442631  0.65442631  0.65442631  0.65442631  0.65442631\n",
      " -1.15928284  0.65442631 -1.15928284 -1.15928284  0.65442631 -1.15928284\n",
      " -1.15928284  0.65442631  0.65442631  0.65442631 -1.15928284 -1.15928284\n",
      "  0.65442631  0.65442631 -1.15928284  0.65442631 -1.15928284  0.65442631\n",
      " -1.15928284 -1.15928284 -1.15928284  0.65442631 -1.15928284  0.65442631\n",
      " -1.15928284  1.99607045 -1.15928284 -1.15928284  0.65442631 -1.15928284\n",
      "  0.1823613   0.65442631  1.99607045  0.65442631  0.65442631 -1.15928284\n",
      "  1.99607045 -1.15928284  0.65442631  0.65442631  0.65442631  0.65442631\n",
      "  0.65442631  0.65442631]\n",
      "P is: [0.23879762177321243, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873, 0.23879762177321243, 0.6580072276173873, 0.23879762177321243, 0.23879762177321243, 0.6580072276173873, 0.23879762177321243, 0.23879762177321243, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873, 0.23879762177321243, 0.23879762177321243, 0.6580072276173873, 0.6580072276173873, 0.23879762177321243, 0.6580072276173873, 0.23879762177321243, 0.6580072276173873, 0.23879762177321243, 0.23879762177321243, 0.23879762177321243, 0.6580072276173873, 0.23879762177321243, 0.6580072276173873, 0.23879762177321243, 0.8803838822358079, 0.23879762177321243, 0.23879762177321243, 0.6580072276173873, 0.23879762177321243, 0.5454643982436298, 0.6580072276173873, 0.8803838822358079, 0.6580072276173873, 0.6580072276173873, 0.23879762177321243, 0.8803838822358079, 0.23879762177321243, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873, 0.6580072276173873]\n",
      "all_sum before preprocessing is: [2.036042281119508, 1.1314737883723196, 1.2355640937389474, 1.8950320623534571, 1.7840433815528993, 1.8950320623534571, 1.801923761584649, 1.2355640937389474, 1.7840433815528993, 1.3286723945077554, 1.11359340834057, 1.7840433815528993, 2.3504030493986012, 1.7840433815528993, 2.3504030493986012, 1.2355640937389474, 1.2355640937389474, 1.7840433815528993, 1.8950320623534571, 1.7840433815528993, 1.014311626228662, 1.7840433815528993, 1.2355640937389474, 1.7840433815528993, 1.7840433815528993, 2.3504030493986012, 1.801923761584649, 1.469682613273806, 1.2355640937389474, 1.469682613273806, 1.801923761584649, 1.2355640937389474, 1.4263503510473359, 1.7840433815528993, 1.2355640937389474, 0.9212033254598538, 1.7840433815528993, 1.3286723945077554, 1.801923761584649, 2.3504030493986012, 1.6799530761862718, 1.469682613273806, 1.11359340834057, 1.3286723945077554, 1.2355640937389474, 2.3504030493986012, 1.7840433815528993, 2.3504030493986012, 1.014311626228662, 1.2355640937389474]\n",
      "all_sum after preprocessing is: [ 1.06868653 -1.21160603 -0.94920871  0.71321919  0.43343202  0.71321919\n",
      "  0.47850599 -0.94920871  0.43343202 -0.71449551 -1.25668     0.43343202\n",
      "  1.86114672  0.43343202  1.86114672 -0.94920871 -0.94920871  0.43343202\n",
      "  0.71321919  0.43343202 -1.5069557   0.43343202 -0.94920871  0.43343202\n",
      "  0.43343202  1.86114672  0.47850599 -0.35902817 -0.94920871 -0.35902817\n",
      "  0.47850599 -0.94920871 -0.46826284  0.43343202 -0.94920871 -1.7416689\n",
      "  0.43343202 -0.71449551  0.47850599  1.86114672  0.1710347  -0.35902817\n",
      " -1.25668    -0.71449551 -0.94920871  1.86114672  0.43343202  1.86114672\n",
      " -1.5069557  -0.94920871]\n",
      "P is: [0.7443470497701105, 0.22941700583183075, 0.27904398476858144, 0.6711120931717492, 0.6066929041975414, 0.6711120931717492, 0.6173950247819637, 0.27904398476858144, 0.6066929041975414, 0.3286062589711161, 0.22154594030221872, 0.6066929041975414, 0.8654305516800891, 0.6066929041975414, 0.8654305516800891, 0.27904398476858144, 0.27904398476858144, 0.6066929041975414, 0.6711120931717492, 0.6066929041975414, 0.1813903964438887, 0.6066929041975414, 0.27904398476858144, 0.6066929041975414, 0.6066929041975414, 0.8654305516800891, 0.6173950247819637, 0.4111948381631051, 0.27904398476858144, 0.4111948381631051, 0.6173950247819637, 0.27904398476858144, 0.38502748915414103, 0.6066929041975414, 0.27904398476858144, 0.14910107718511265, 0.6066929041975414, 0.3286062589711161, 0.6173950247819637, 0.8654305516800891, 0.5426547439164701, 0.4111948381631051, 0.22154594030221872, 0.3286062589711161, 0.27904398476858144, 0.8654305516800891, 0.6066929041975414, 0.8654305516800891, 0.1813903964438887, 0.27904398476858144]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.334\n",
      "(*) epoch 2, cost 2.149\n",
      "(*) epoch 3, cost 1.750\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.507\n",
      "(*) epoch 2, cost 2.106\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.9195880006472144, 4.529334468644079, 4.529334468644079, 2.7901898641505385, 2.7901898641505385, 3.3999363321474023, 3.9195880006472144, 2.7901898641505385, 3.9195880006472144, 2.7901898641505385, 2.7901898641505385, 2.7901898641505385, 2.7901898641505385, 2.7901898641505385, 4.172107863493679, 2.7901898641505385, 4.172107863493679, 2.5376700013040745, 4.172107863493679, 2.7901898641505385, 3.9195880006472144, 4.172107863493679, 3.9195880006472144, 2.5376700013040745, 3.1474164693009383, 5.62452355978605, 2.5376700013040745, 2.7901898641505385, 3.9195880006472144, 2.7901898641505385, 3.9195880006472144, 2.5376700013040745, 3.9195880006472144, 2.5376700013040745, 4.172107863493679, 2.7901898641505385, 2.5376700013040745, 4.172107863493679, 2.7901898641505385, 3.9195880006472144, 3.9195880006472144, 2.7901898641505385, 4.172107863493679, 5.372003696939586, 2.7901898641505385, 2.7901898641505385, 4.172107863493679, 2.5376700013040745, 4.242605560442911, 2.7901898641505385]\n",
      "all_sum after preprocessing is: [ 0.61931248  1.38763984  1.38763984 -0.80381587 -0.80381587 -0.03548851\n",
      "  0.61931248 -0.80381587  0.61931248 -0.80381587 -0.80381587 -0.80381587\n",
      " -0.80381587 -0.80381587  0.9375069  -0.80381587  0.9375069  -1.12201028\n",
      "  0.9375069  -0.80381587  0.61931248  0.9375069   0.61931248 -1.12201028\n",
      " -0.35368292  2.76766217 -1.12201028 -0.80381587  0.61931248 -0.80381587\n",
      "  0.61931248 -1.12201028  0.61931248 -1.12201028  0.9375069  -0.80381587\n",
      " -1.12201028  0.9375069  -0.80381587  0.61931248  0.61931248 -0.80381587\n",
      "  0.9375069   2.44946776 -0.80381587 -0.80381587  0.9375069  -1.12201028\n",
      "  1.02633941 -0.80381587]\n",
      "P is: [0.6500621675718989, 0.8002151899390078, 0.8002151899390078, 0.30920985997331496, 0.30920985997331496, 0.49112880344206733, 0.6500621675718989, 0.30920985997331496, 0.6500621675718989, 0.30920985997331496, 0.30920985997331496, 0.30920985997331496, 0.30920985997331496, 0.30920985997331496, 0.7185957870260853, 0.30920985997331496, 0.7185957870260853, 0.24563858762780522, 0.7185957870260853, 0.30920985997331496, 0.6500621675718989, 0.7185957870260853, 0.6500621675718989, 0.24563858762780522, 0.41248960777147603, 0.9409031267241749, 0.24563858762780522, 0.30920985997331496, 0.6500621675718989, 0.30920985997331496, 0.6500621675718989, 0.24563858762780522, 0.6500621675718989, 0.24563858762780522, 0.7185957870260853, 0.30920985997331496, 0.24563858762780522, 0.7185957870260853, 0.30920985997331496, 0.6500621675718989, 0.6500621675718989, 0.30920985997331496, 0.7185957870260853, 0.9205225202429419, 0.30920985997331496, 0.30920985997331496, 0.7185957870260853, 0.24563858762780522, 0.7362055980922954, 0.30920985997331496]\n",
      "all_sum before preprocessing is: [2.80313270249852, 2.80313270249852, 0.417351769135437, 0.417351769135437, 2.80313270249852, 0.417351769135437, 0.417351769135437, 1.6730885466936396, 0.417351769135437, 2.80313270249852, 1.5473959249403175, 1.5473959249403175, 3.0162136615322694, 0.417351769135437, 1.6730885466936396, 1.5473959249403175, 3.0162136615322694, 0.417351769135437, 1.5473959249403175, 1.6730885466936396, 0.417351769135437, 1.6730885466936396, 1.5473959249403175, 1.6730885466936396, 0.417351769135437, 2.80313270249852, 1.6730885466936396, 0.417351769135437, 1.5473959249403175, 1.6730885466936396, 2.80313270249852, 1.6730885466936396, 1.6730885466936396, 1.6730885466936396, 1.6730885466936396, 0.417351769135437, 1.6730885466936396, 0.417351769135437, 1.5473959249403175, 0.417351769135437, 1.6730885466936396, 1.6730885466936396, 1.6730885466936396, 0.417351769135437, 2.80313270249852, 0.417351769135437, 1.6730885466936396, 2.80313270249852, 0.417351769135437, 0.417351769135437]\n",
      "all_sum after preprocessing is: [ 1.52642397  1.52642397 -1.19115167 -1.19115167  1.52642397 -1.19115167\n",
      " -1.19115167  0.23922261 -1.19115167  1.52642397  0.0960497   0.0960497\n",
      "  1.76913847 -1.19115167  0.23922261  0.0960497   1.76913847 -1.19115167\n",
      "  0.0960497   0.23922261 -1.19115167  0.23922261  0.0960497   0.23922261\n",
      " -1.19115167  1.52642397  0.23922261 -1.19115167  0.0960497   0.23922261\n",
      "  1.52642397  0.23922261  0.23922261  0.23922261  0.23922261 -1.19115167\n",
      "  0.23922261 -1.19115167  0.0960497  -1.19115167  0.23922261  0.23922261\n",
      "  0.23922261 -1.19115167  1.52642397 -1.19115167  0.23922261  1.52642397\n",
      " -1.19115167 -1.19115167]\n",
      "P is: [0.821482495794355, 0.821482495794355, 0.2330530245636042, 0.2330530245636042, 0.821482495794355, 0.2330530245636042, 0.2330530245636042, 0.5595220645927167, 0.2330530245636042, 0.821482495794355, 0.5239939803234217, 0.5239939803234217, 0.854350498547967, 0.2330530245636042, 0.5595220645927167, 0.5239939803234217, 0.854350498547967, 0.2330530245636042, 0.5239939803234217, 0.5595220645927167, 0.2330530245636042, 0.5595220645927167, 0.5239939803234217, 0.5595220645927167, 0.2330530245636042, 0.821482495794355, 0.5595220645927167, 0.2330530245636042, 0.5239939803234217, 0.5595220645927167, 0.821482495794355, 0.5595220645927167, 0.5595220645927167, 0.5595220645927167, 0.5595220645927167, 0.2330530245636042, 0.5595220645927167, 0.2330530245636042, 0.5239939803234217, 0.2330530245636042, 0.5595220645927167, 0.5595220645927167, 0.5595220645927167, 0.2330530245636042, 0.821482495794355, 0.2330530245636042, 0.5595220645927167, 0.821482495794355, 0.2330530245636042, 0.2330530245636042]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.298\n",
      "(*) epoch 2, cost 2.144\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.242\n",
      "(*) epoch 2, cost 1.980\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.821299930112587, 0.6571555439595049, 4.425020619540988, 2.5998968469724155, 3.1479693171351353, 2.5998968469724155, 0.6571555439595049, 0.6579454593121384, 4.009641977425495, 4.009641977425495, 4.009641977425495, 2.066900674412585, 2.483069231880711, 1.821299930112587, 2.845497591272413, 2.3693724002753065, 2.5998968469724155, 2.845497591272413, 4.588961212299423, 0.6571555439595049, 3.1479693171351353, 2.5998968469724155, 3.7640412331254973, 3.3111199945409364, 1.821299930112587, 1.9844506075183883, 3.7640412331254973, 3.1479693171351353, 1.821299930112587, 2.5998968469724155, 4.973093089703708, 1.3683786915280258, 3.7640412331254973, 3.5192304041781335, 3.7640412331254973, 4.312113703288217, 4.009641977425495, 0.6571555439595049, 2.5998968469724155, 4.312113703288217, 4.312113703288217, 2.066900674412585, 1.821299930112587, 3.393570061435133, 3.7640412331254973, 1.2052280141222247, 3.7640412331254973, 1.821299930112587, 3.7640412331254973, 3.1479693171351353]\n",
      "all_sum after preprocessing is: [-0.86619279 -1.87235036  1.38417521 -0.19325979  0.2804334  -0.19325979\n",
      " -1.87235036 -1.87166765  1.02516788  1.02516788  1.02516788 -0.65392269\n",
      " -0.29423265 -0.86619279  0.01901031 -0.39249961 -0.19325979  0.01901031\n",
      "  1.52586731 -1.87235036  0.2804334  -0.19325979  0.81289778  0.42144278\n",
      " -0.86619279 -0.72518341  0.81289778  0.2804334  -0.86619279 -0.19325979\n",
      "  1.85786839 -1.25764779  0.81289778  0.60131039  0.81289778  1.28659096\n",
      "  1.02516788 -1.87235036 -0.19325979  1.28659096  1.28659096 -0.65392269\n",
      " -0.86619279  0.4927035   0.81289778 -1.39865718  0.81289778 -0.86619279\n",
      "  0.81289778  0.2804334 ]\n",
      "P is: [0.2960471192353839, 0.1332700002396588, 0.7996607194706059, 0.45183487052238464, 0.5696524734297013, 0.45183487052238464, 0.1332700002396588, 0.13334887983313376, 0.7359780164149076, 0.7359780164149076, 0.7359780164149076, 0.3421061126294339, 0.42696796123268216, 0.2960471192353839, 0.5047524347372684, 0.40311571581329625, 0.45183487052238464, 0.5047524347372684, 0.8214008474195416, 0.1332700002396588, 0.5696524734297013, 0.45183487052238464, 0.6927266589474248, 0.6038284439453406, 0.2960471192353839, 0.3262525844743718, 0.6927266589474248, 0.5696524734297013, 0.2960471192353839, 0.45183487052238464, 0.8650482981481565, 0.22137907833723813, 0.6927266589474248, 0.6459560456192958, 0.6927266589474248, 0.7835696153041123, 0.7359780164149076, 0.1332700002396588, 0.45183487052238464, 0.7835696153041123, 0.7835696153041123, 0.3421061126294339, 0.2960471192353839, 0.6207431001096042, 0.6927266589474248, 0.1980292837942006, 0.6927266589474248, 0.2960471192353839, 0.6927266589474248, 0.5696524734297013]\n",
      "all_sum before preprocessing is: [4.230680533478835, 4.230680533478835, 2.944963610526806, 2.9273505044079777, 2.9273505044079777, 1.8928683201630054, 2.9273505044079777, 2.944963610526806, 2.9273505044079777, 2.944963610526806, 2.9273505044079777, 2.9273505044079777, 4.230680533478835, 4.230680533478835, 2.9273505044079777, 2.944963610526806, 3.969359024882062, 4.230680533478835, 2.9273505044079777, 2.944963610526806, 4.230680533478835, 2.9273505044079777, 3.0039246201769396, 2.9273505044079777, 4.230680533478835, 2.9273505044079777, 4.248293639597663, 3.0039246201769396, 2.9273505044079777, 4.248293639597663, 2.9273505044079777, 4.493680770776014, 3.1903507417051564, 2.9273505044079777, 2.944963610526806, 2.9273505044079777, 2.9273505044079777, 2.944963610526806, 2.9273505044079777, 4.307254649247797, 3.1903507417051564, 2.9273505044079777, 3.1903507417051564, 4.3248677553666255, 4.230680533478835, 2.944963610526806, 2.9273505044079777, 2.944963610526806, 4.307254649247797, 2.9273505044079777]\n",
      "all_sum after preprocessing is: [ 1.44042395  1.44042395 -0.60523095 -0.63325449 -0.63325449 -2.27917944\n",
      " -0.63325449 -0.60523095 -0.63325449 -0.60523095 -0.63325449 -0.63325449\n",
      "  1.44042395  1.44042395 -0.63325449 -0.60523095  1.02464532  1.44042395\n",
      " -0.63325449 -0.60523095  1.44042395 -0.63325449 -0.51142035 -0.63325449\n",
      "  1.44042395 -0.63325449  1.46844749 -0.51142035 -0.63325449  1.46844749\n",
      " -0.63325449  1.85887355 -0.2148049  -0.63325449 -0.60523095 -0.63325449\n",
      " -0.63325449 -0.60523095 -0.63325449  1.56225809 -0.2148049  -0.63325449\n",
      " -0.2148049   1.59028163  1.44042395 -0.60523095 -0.63325449 -0.60523095\n",
      "  1.56225809 -0.63325449]\n",
      "P is: [0.8085202939955348, 0.8085202939955348, 0.353147847837405, 0.34677295837831257, 0.34677295837831257, 0.09286205334573956, 0.34677295837831257, 0.353147847837405, 0.34677295837831257, 0.353147847837405, 0.34677295837831257, 0.34677295837831257, 0.8085202939955348, 0.8085202939955348, 0.34677295837831257, 0.353147847837405, 0.7358764626141867, 0.8085202939955348, 0.34677295837831257, 0.353147847837405, 0.8085202939955348, 0.34677295837831257, 0.3748606209710091, 0.34677295837831257, 0.8085202939955348, 0.34677295837831257, 0.8128212971982737, 0.3748606209710091, 0.34677295837831257, 0.8128212971982737, 0.34677295837831257, 0.8651655965134638, 0.44650431372669014, 0.34677295837831257, 0.353147847837405, 0.34677295837831257, 0.34677295837831257, 0.353147847837405, 0.34677295837831257, 0.8266771354864502, 0.44650431372669014, 0.34677295837831257, 0.44650431372669014, 0.830655722484283, 0.8085202939955348, 0.353147847837405, 0.34677295837831257, 0.353147847837405, 0.8266771354864502, 0.34677295837831257]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.314\n",
      "(*) epoch 2, cost 2.812\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.787\n",
      "(*) epoch 2, cost 2.292\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.7777513828468003, 2.204878082401197, 2.2832429465948842, 2.204878082401197, 2.2832429465948842, 2.204878082401197, 2.204878082401197, 2.204878082401197, 1.2032619190853944, 2.0828348863599255, 1.7103696461492808, 2.204878082401197, 1.7103696461492808, 2.7777513828468003, 2.7777513828468003, 1.6977703553373105, 2.7777513828468003, 1.6977703553373105, 1.7103696461492808, 1.2032619190853944, 2.204878082401197, 2.204878082401197, 2.2832429465948842, 1.7103696461492808, 1.7103696461492808, 1.7103696461492808, 1.7103696461492808, 2.204878082401197, 2.204878082401197, 1.6977703553373105, 2.204878082401197, 2.204878082401197, 2.7777513828468003, 2.2832429465948842, 2.204878082401197, 2.204878082401197, 2.7777513828468003, 1.0154531496624062, 2.204878082401197, 1.7103696461492808, 2.204878082401197, 2.204878082401197, 1.6977703553373105, 1.7103696461492808, 1.0154531496624062, 2.204878082401197, 2.204878082401197, 2.2832429465948842, 2.204878082401197, 2.7777513828468003]\n",
      "all_sum after preprocessing is: [ 1.61266164  0.30129972  0.48068441  0.30129972  0.48068441  0.30129972\n",
      "  0.30129972  0.30129972 -1.99149572  0.02193114 -0.83067751  0.30129972\n",
      " -0.83067751  1.61266164  1.61266164 -0.85951849  1.61266164 -0.85951849\n",
      " -0.83067751 -1.99149572  0.30129972  0.30129972  0.48068441 -0.83067751\n",
      " -0.83067751 -0.83067751 -0.83067751  0.30129972  0.30129972 -0.85951849\n",
      "  0.30129972  0.30129972  1.61266164  0.48068441  0.30129972  0.30129972\n",
      "  1.61266164 -2.42140801  0.30129972 -0.83067751  0.30129972  0.30129972\n",
      " -0.85951849 -0.83067751 -2.42140801  0.30129972  0.30129972  0.48068441\n",
      "  0.30129972  1.61266164]\n",
      "P is: [0.8337805919107226, 0.5747602132383145, 0.6179094747244811, 0.5747602132383145, 0.6179094747244811, 0.5747602132383145, 0.5747602132383145, 0.5747602132383145, 0.1200987119602092, 0.5054825654641315, 0.3035018333126796, 0.5747602132383145, 0.3035018333126796, 0.8337805919107226, 0.8337805919107226, 0.2974399557044536, 0.8337805919107226, 0.2974399557044536, 0.3035018333126796, 0.1200987119602092, 0.5747602132383145, 0.5747602132383145, 0.6179094747244811, 0.3035018333126796, 0.3035018333126796, 0.3035018333126796, 0.3035018333126796, 0.5747602132383145, 0.5747602132383145, 0.2974399557044536, 0.5747602132383145, 0.5747602132383145, 0.8337805919107226, 0.6179094747244811, 0.5747602132383145, 0.5747602132383145, 0.8337805919107226, 0.08155472861040987, 0.5747602132383145, 0.3035018333126796, 0.5747602132383145, 0.5747602132383145, 0.2974399557044536, 0.3035018333126796, 0.08155472861040987, 0.5747602132383145, 0.5747602132383145, 0.6179094747244811, 0.5747602132383145, 0.8337805919107226]\n",
      "all_sum before preprocessing is: [2.52016351798171, 2.8087266025953217, 2.7114795514841217, 2.61741056909291, 2.8087266025953217, 2.52016351798171, 4.112654189672805, 2.7114795514841217, 2.7114795514841217, 2.8087266025953217, 2.7114795514841217, 2.61741056909291, 2.61741056909291, 2.7114795514841217, 2.7114795514841217, 2.7114795514841217, 2.52016351798171, 2.7114795514841217, 2.7114795514841217, 2.8087266025953217, 2.52016351798171, 2.8087266025953217, 3.8240911050591926, 2.8087266025953217, 2.7114795514841217, 2.52016351798171, 2.52016351798171, 2.7114795514841217, 2.7114795514841217, 2.9239555734345952, 2.7114795514841217, 2.7114795514841217, 2.52016351798171, 4.015407138561605, 2.52016351798171, 2.7114795514841217, 2.7114795514841217, 2.7114795514841217, 2.52016351798171, 2.8087266025953217, 2.7114795514841217, 2.8087266025953217, 2.8087266025953217, 2.52016351798171, 2.7114795514841217, 2.7114795514841217, 2.7114795514841217, 2.52016351798171, 2.7114795514841217, 2.7114795514841217]\n",
      "all_sum after preprocessing is: [-0.73997938  0.14350845 -0.1542309  -0.44224003  0.14350845 -0.73997938\n",
      "  4.13571751 -0.1542309  -0.1542309   0.14350845 -0.1542309  -0.44224003\n",
      " -0.44224003 -0.1542309  -0.1542309  -0.1542309  -0.73997938 -0.1542309\n",
      " -0.1542309   0.14350845 -0.73997938  0.14350845  3.25222968  0.14350845\n",
      " -0.1542309  -0.73997938 -0.73997938 -0.1542309  -0.1542309   0.49630269\n",
      " -0.1542309  -0.1542309  -0.73997938  3.83797816 -0.73997938 -0.1542309\n",
      " -0.1542309  -0.1542309  -0.73997938  0.14350845 -0.1542309   0.14350845\n",
      "  0.14350845 -0.73997938 -0.1542309  -0.1542309  -0.1542309  -0.73997938\n",
      " -0.1542309  -0.1542309 ]\n",
      "P is: [0.3230086520027538, 0.535815666189289, 0.4615185243100497, 0.39120734483548836, 0.535815666189289, 0.3230086520027538, 0.9842605060241819, 0.4615185243100497, 0.4615185243100497, 0.535815666189289, 0.4615185243100497, 0.39120734483548836, 0.39120734483548836, 0.4615185243100497, 0.4615185243100497, 0.4615185243100497, 0.3230086520027538, 0.4615185243100497, 0.4615185243100497, 0.535815666189289, 0.3230086520027538, 0.535815666189289, 0.9627531503065172, 0.535815666189289, 0.4615185243100497, 0.3230086520027538, 0.3230086520027538, 0.4615185243100497, 0.4615185243100497, 0.621590057141389, 0.4615185243100497, 0.4615185243100497, 0.3230086520027538, 0.9789169654427229, 0.3230086520027538, 0.4615185243100497, 0.4615185243100497, 0.4615185243100497, 0.3230086520027538, 0.535815666189289, 0.4615185243100497, 0.535815666189289, 0.535815666189289, 0.3230086520027538, 0.4615185243100497, 0.4615185243100497, 0.4615185243100497, 0.3230086520027538, 0.4615185243100497, 0.4615185243100497]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.127\n",
      "(*) epoch 2, cost 2.552\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.326\n",
      "(*) epoch 2, cost 3.301\n",
      "(*) epoch 3, cost 2.862\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.622681631176607, 4.4307843492463945, 5.339066151821707, 3.3885640803615056, 4.295684931029061, 4.295684931029061, 4.3197645905018796, 4.193328496328616, 4.295684931029061, 4.486874704572531, 4.3197645905018796, 5.474165570039041, 3.3324737250353698, 4.510954364045349, 3.3885640803615056, 4.3197645905018796, 3.3885640803615056, 3.3885640803615056, 5.28297579649557, 4.351775286355197, 3.3324737250353698, 4.375854945828015, 3.4675731432527037, 3.5236634985788395, 3.2165615012470106, 3.3885640803615056, 5.28297579649557, 3.3324737250353698, 4.3197645905018796, 3.070938212644772, 5.474165570039041, 3.5236634985788395, 4.4548640087192135, 4.295684931029061, 5.28297579649557, 5.339066151821707, 3.3885640803615056, 4.295684931029061, 3.3885640803615056, 4.3197645905018796, 5.339066151821707, 3.3324737250353698, 3.3324737250353698, 4.4548640087192135, 5.418075214712905, 3.3324737250353698, 3.5236634985788395, 4.193328496328616, 3.3324737250353698, 4.295684931029061]\n",
      "all_sum after preprocessing is: [ 0.6588301   0.39631386  1.63884692 -1.02944754  0.21149733  0.21149733\n",
      "  0.2444384   0.07147333  0.21149733  0.47304569  0.2444384   1.82366346\n",
      " -1.10617937  0.50598676 -1.02944754  0.2444384  -1.02944754 -1.02944754\n",
      "  1.5621151   0.28822916 -1.10617937  0.32117023 -0.92136283 -0.84463101\n",
      " -1.26474774 -1.02944754  1.5621151  -1.10617937  0.2444384  -1.46396097\n",
      "  1.82366346 -0.84463101  0.42925493  0.21149733  1.5621151   1.63884692\n",
      " -1.02944754  0.21149733 -1.02944754  0.2444384   1.63884692 -1.10617937\n",
      " -1.10617937  0.42925493  1.74693163 -1.10617937 -0.84463101  0.07147333\n",
      " -1.10617937  0.21149733]\n",
      "P is: [0.6589975369025399, 0.597801705094438, 0.8373779769170534, 0.2631912240862897, 0.5526781165579185, 0.5526781165579185, 0.5608071315801819, 0.5178607294516439, 0.5526781165579185, 0.6161043764936214, 0.5608071315801819, 0.8610051322169119, 0.24858385887694723, 0.6238652066670745, 0.2631912240862897, 0.5608071315801819, 0.2631912240862897, 0.2631912240862897, 0.8266566461845647, 0.5715625461187599, 0.24858385887694723, 0.5796094185670512, 0.28468028910066523, 0.30056033765496437, 0.22015767786665866, 0.2631912240862897, 0.8266566461845647, 0.24858385887694723, 0.5608071315801819, 0.1878622527206735, 0.8610051322169119, 0.30056033765496437, 0.6056957391788066, 0.5526781165579185, 0.8266566461845647, 0.8373779769170534, 0.2631912240862897, 0.5526781165579185, 0.2631912240862897, 0.5608071315801819, 0.8373779769170534, 0.24858385887694723, 0.24858385887694723, 0.6056957391788066, 0.8515653727080646, 0.24858385887694723, 0.30056033765496437, 0.5178607294516439, 0.24858385887694723, 0.5526781165579185]\n",
      "all_sum before preprocessing is: [2.9863694760370336, 3.0617597133379033, 4.0415696627686755, 4.75051176577639, 2.3528176103301885, 4.0415696627686755, 3.408017797061831, 3.0617597133379033, 3.408017797061831, 4.75051176577639, 2.9863694760370336, 4.0415696627686755, 5.473798575354617, 2.3528176103301885, 2.3528176103301885, 3.408017797061831, 2.9863694760370336, 3.0617597133379033, 2.3528176103301885, 4.0415696627686755, 4.75051176577639, 4.0415696627686755, 3.408017797061831, 4.0415696627686755, 3.408017797061831, 2.3528176103301885, 2.3528176103301885, 2.3528176103301885, 4.626598607639784, 4.0415696627686755, 4.0415696627686755, 3.7850465229161294, 2.9863694760370336, 4.0415696627686755, 2.9863694760370336, 4.116959900069546, 3.0617597133379033, 3.408017797061831, 4.840246709647771, 2.3528176103301885, 3.408017797061831, 2.9863694760370336, 3.0617597133379033, 1.5299241838783688, 2.9863694760370336, 2.3528176103301885, 3.6953115790447484, 2.9863694760370336, 2.9863694760370336, 2.3528176103301885]\n",
      "all_sum after preprocessing is: [-0.45734693 -0.3663504   0.81628689  1.67198484 -1.22204835  0.81628689\n",
      "  0.05158547 -0.3663504   0.05158547  1.67198484 -0.45734693  0.81628689\n",
      "  2.54499696 -1.22204835 -1.22204835  0.05158547 -0.45734693 -0.3663504\n",
      " -1.22204835  0.81628689  1.67198484  0.81628689  0.05158547  0.81628689\n",
      "  0.05158547 -1.22204835 -1.22204835 -1.22204835  1.52242082  0.81628689\n",
      "  0.81628689  0.50666171 -0.45734693  0.81628689 -0.45734693  0.90728342\n",
      " -0.3663504   0.05158547  1.78029553 -1.22204835  0.05158547 -0.45734693\n",
      " -0.3663504  -2.21528633 -0.45734693 -1.22204835  0.39835102 -0.45734693\n",
      " -0.45734693 -1.22204835]\n",
      "P is: [0.3876153937653999, 0.4094231867675953, 0.6934475819976054, 0.8418402729618072, 0.22757617908868455, 0.6934475819976054, 0.5128935077630808, 0.4094231867675953, 0.5128935077630808, 0.8418402729618072, 0.3876153937653999, 0.6934475819976054, 0.9272366858475247, 0.22757617908868455, 0.22757617908868455, 0.5128935077630808, 0.3876153937653999, 0.4094231867675953, 0.22757617908868455, 0.6934475819976054, 0.8418402729618072, 0.6934475819976054, 0.5128935077630808, 0.6934475819976054, 0.5128935077630808, 0.22757617908868455, 0.22757617908868455, 0.22757617908868455, 0.8208946815805619, 0.6934475819976054, 0.6934475819976054, 0.6240235761071314, 0.3876153937653999, 0.6934475819976054, 0.3876153937653999, 0.7124439451212714, 0.4094231867675953, 0.5128935077630808, 0.8557333544038166, 0.22757617908868455, 0.5128935077630808, 0.3876153937653999, 0.4094231867675953, 0.09838614550348858, 0.3876153937653999, 0.22757617908868455, 0.5982914109398141, 0.3876153937653999, 0.3876153937653999, 0.22757617908868455]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.099\n",
      "(*) epoch 2, cost 3.866\n",
      "(*) epoch 3, cost 3.293\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.661\n",
      "(*) epoch 2, cost 3.452\n",
      "(*) epoch 3, cost 2.970\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.2755579598486166, 1.2966592307131002, 1.3888622603907173, 1.2966592307131002, 1.2966592307131002, 1.2966592307131002, 1.2755579598486166, 1.2755579598486166, 1.2966592307131002, 1.2966592307131002, 1.2966592307131002, 1.2755579598486166, 1.2966592307131002, 1.2966592307131002, 1.2966592307131002, 1.2755579598486166, 1.2966592307131002, 1.2966592307131002, 1.2966592307131002, 1.2966592307131002, 1.3888622603907173, 1.2966592307131002, 1.3888622603907173, 1.3888622603907173, 1.2755579598486166, 1.2966592307131002, 1.2966592307131002, 1.2966592307131002, 1.2755579598486166, 0.7641645662155061, 1.2966592307131002, 1.3677609895262337, 1.2966592307131002, 1.2755579598486166, 1.2966592307131002, 1.3677609895262337, 1.2966592307131002, 1.3677609895262337, 0.8774688667576067, 0.8774688667576067, 1.2966592307131002, 1.3888622603907173, 1.2966592307131002, 1.2966592307131002, 1.3888622603907173, 1.2966592307131002, 1.2755579598486166, 1.2966592307131002, 1.2966592307131002, 1.2966592307131002]\n",
      "all_sum after preprocessing is: [-0.04431953  0.13497454  0.91840871  0.13497454  0.13497454  0.13497454\n",
      " -0.04431953 -0.04431953  0.13497454  0.13497454  0.13497454 -0.04431953\n",
      "  0.13497454  0.13497454  0.13497454 -0.04431953  0.13497454  0.13497454\n",
      "  0.13497454  0.13497454  0.91840871  0.13497454  0.91840871  0.91840871\n",
      " -0.04431953  0.13497454  0.13497454  0.13497454 -0.04431953 -4.38954616\n",
      "  0.13497454  0.73911464  0.13497454 -0.04431953  0.13497454  0.73911464\n",
      "  0.13497454  0.73911464 -3.42681792 -3.42681792  0.13497454  0.91840871\n",
      "  0.13497454  0.13497454  0.91840871  0.13497454 -0.04431953  0.13497454\n",
      "  0.13497454  0.13497454]\n",
      "P is: [0.48892192986770056, 0.5336924990362081, 0.7147177586731374, 0.5336924990362081, 0.5336924990362081, 0.5336924990362081, 0.48892192986770056, 0.48892192986770056, 0.5336924990362081, 0.5336924990362081, 0.5336924990362081, 0.48892192986770056, 0.5336924990362081, 0.5336924990362081, 0.5336924990362081, 0.48892192986770056, 0.5336924990362081, 0.5336924990362081, 0.5336924990362081, 0.5336924990362081, 0.7147177586731374, 0.5336924990362081, 0.7147177586731374, 0.7147177586731374, 0.48892192986770056, 0.5336924990362081, 0.5336924990362081, 0.5336924990362081, 0.48892192986770056, 0.012254326818558401, 0.5336924990362081, 0.6768022217566856, 0.5336924990362081, 0.48892192986770056, 0.5336924990362081, 0.6768022217566856, 0.5336924990362081, 0.6768022217566856, 0.031467769791613524, 0.031467769791613524, 0.5336924990362081, 0.7147177586731374, 0.5336924990362081, 0.5336924990362081, 0.7147177586731374, 0.5336924990362081, 0.48892192986770056, 0.5336924990362081, 0.5336924990362081, 0.5336924990362081]\n",
      "all_sum before preprocessing is: [2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 1.518318921045866, 1.518318921045866, 3.397965102346794, 3.0078498437534265, 3.397965102346794, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 4.59344857924579, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 1.518318921045866, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 3.397965102346794, 3.397965102346794, 2.8230218886261533, 2.8230218886261533, 3.190861491041481, 2.8230218886261533, 2.8230218886261533, 1.518318921045866, 3.190861491041481, 2.8230218886261533, 2.8230218886261533, 2.8230218886261533, 3.397965102346794, 3.190861491041481, 3.397965102346794, 2.8230218886261533, 2.8230218886261533, 3.397965102346794, 2.8230218886261533, 1.518318921045866, 2.8230218886261533, 2.0932621347665066, 3.397965102346794, 1.518318921045866]\n",
      "all_sum after preprocessing is: [ 0.03090458  0.03090458  0.03090458  0.03090458  0.03090458  0.03090458\n",
      "  0.03090458  0.03090458 -2.21001781 -2.21001781  1.01841143  0.34836005\n",
      "  1.01841143  0.03090458  0.03090458  0.03090458  0.03090458  3.07174138\n",
      "  0.03090458  0.03090458  0.03090458 -2.21001781  0.03090458  0.03090458\n",
      "  0.03090458  0.03090458  1.01841143  1.01841143  0.03090458  0.03090458\n",
      "  0.66269589  0.03090458  0.03090458 -2.21001781  0.66269589  0.03090458\n",
      "  0.03090458  0.03090458  1.01841143  0.66269589  1.01841143  0.03090458\n",
      "  0.03090458  1.01841143  0.03090458 -2.21001781  0.03090458 -1.22251096\n",
      "  1.01841143 -2.21001781]\n",
      "P is: [0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.09885448702269965, 0.09885448702269965, 0.7346630488765672, 0.586219839494646, 0.7346630488765672, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.9557119375209826, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.09885448702269965, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.7346630488765672, 0.7346630488765672, 0.5077255292647941, 0.5077255292647941, 0.659865721870987, 0.5077255292647941, 0.5077255292647941, 0.09885448702269965, 0.659865721870987, 0.5077255292647941, 0.5077255292647941, 0.5077255292647941, 0.7346630488765672, 0.659865721870987, 0.7346630488765672, 0.5077255292647941, 0.5077255292647941, 0.7346630488765672, 0.5077255292647941, 0.09885448702269965, 0.5077255292647941, 0.22749487072566213, 0.7346630488765672, 0.09885448702269965]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.152\n",
      "(*) epoch 2, cost 1.804\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.346\n",
      "(*) epoch 2, cost 2.273\n",
      "(*) epoch 3, cost 1.906\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.494450531732471, 2.9274011494190852, 4.156681882065427, 1.6140964576278836, 1.6140964576278836, 5.082434496995258, 2.9274011494190852, 1.181145839941269, 2.41042657258761, 2.843377190274224, 1.6140964576278836, 2.9274011494190852, 4.901682223551419, 2.843377190274224, 1.6140964576278836, 2.494450531732471, 2.41042657258761, 2.8581731595643216, 2.494450531732471, 2.1173443370826828, 2.494450531732471, 1.181145839941269, 5.09288037920684, 4.202080422890671, 1.181145839941269, 1.181145839941269, 2.9274011494190852, 3.346625069729024, 1.181145839941269, 4.705328302345471, 1.181145839941269, 1.181145839941269, 2.494450531732471, 2.9727996902443303, 2.843377190274224, 1.6140964576278836, 3.346625069729024, 2.9274011494190852, 2.843377190274224, 4.6599297615202255, 1.6140964576278836, 3.7691298052040567, 3.346625069729024, 4.156681882065427, 1.181145839941269, 2.843377190274224, 3.7691298052040567, 3.723731264378812, 2.494450531732471, 2.9274011494190852]\n",
      "all_sum after preprocessing is: [-0.21902369  0.16999348  1.27453355 -1.01004426 -1.01004426  2.10634587\n",
      "  0.16999348 -1.39906143 -0.29452136  0.09449581 -1.01004426  0.16999348\n",
      "  1.94393535  0.09449581 -1.01004426 -0.21902369 -0.29452136  0.10779037\n",
      " -0.21902369 -0.55786321 -0.21902369 -1.39906143  2.11573176  1.3153253\n",
      " -1.39906143 -1.39906143  0.16999348  0.54667686 -1.39906143  1.76750634\n",
      " -1.39906143 -1.39906143 -0.21902369  0.21078522  0.09449581 -1.01004426\n",
      "  0.54667686  0.16999348  0.09449581  1.7267146  -1.01004426  0.92630813\n",
      "  0.54667686  1.27453355 -1.39906143  0.09449581  0.92630813  0.88551638\n",
      " -0.21902369  0.16999348]\n",
      "P is: [0.44546192637131404, 0.542396322105017, 0.7815178289776071, 0.26697118882006243, 0.26697118882006243, 0.8915184354799405, 0.542396322105017, 0.1979650910914788, 0.42689732639565975, 0.5236063889643442, 0.26697118882006243, 0.542396322105017, 0.8747838458214076, 0.5236063889643442, 0.26697118882006243, 0.44546192637131404, 0.42689732639565975, 0.5269215300630041, 0.44546192637131404, 0.36404201462632796, 0.44546192637131404, 0.1979650910914788, 0.8924228460284558, 0.7884029061043849, 0.1979650910914788, 0.1979650910914788, 0.542396322105017, 0.63336425314671, 0.1979650910914788, 0.8541472861890598, 0.1979650910914788, 0.1979650910914788, 0.44546192637131404, 0.5525020592505234, 0.5236063889643442, 0.26697118882006243, 0.63336425314671, 0.542396322105017, 0.5236063889643442, 0.8489916984920087, 0.26697118882006243, 0.7163256852449126, 0.63336425314671, 0.7815178289776071, 0.1979650910914788, 0.5236063889643442, 0.7163256852449126, 0.7079640457840903, 0.44546192637131404, 0.542396322105017]\n",
      "all_sum before preprocessing is: [0.5981497798811876, 0.006725384540968621, 0.006725384540968621, 1.358915690170514, 1.5331324268927093, 0.006725384540968621, 0.006725384540968621, 0.006725384540968621, 0.767491294830295, 0.767491294830295, 0.8151921825430715, 0.5981497798811876, 0.006725384540968621, 0.767491294830295, 0.006725384540968621, 1.358915690170514, 0.006725384540968621, 0.5981497798811876, 0.8151921825430715, 0.767491294830295, 0.006725384540968621, 0.767491294830295, 0.767491294830295, 0.006725384540968621, 0.767491294830295, 0.5981497798811876, 0.5981497798811876, 0.006725384540968621, 0.767491294830295, 0.006725384540968621, 0.006725384540968621, 0.5981497798811876, 1.358915690170514, 0.006725384540968621, 0.006725384540968621, 0.328023268218656, 0.006725384540968621, 0.006725384540968621, 0.006725384540968621, 1.4066165778832904, 0.006725384540968621, 1.0887891785079824, 0.006725384540968621, 0.328023268218656, 0.328023268218656, 0.006725384540968621, 0.8151921825430715, 1.5759580928323977, 0.5981497798811876, 0.006725384540968621]\n",
      "all_sum after preprocessing is: [ 0.25865763 -0.95128077 -0.95128077  1.81503558  2.17144887 -0.95128077\n",
      " -0.95128077 -0.95128077  0.60509718  0.60509718  0.70268385  0.25865763\n",
      " -0.95128077  0.60509718 -0.95128077  1.81503558 -0.95128077  0.25865763\n",
      "  0.70268385  0.60509718 -0.95128077  0.60509718  0.60509718 -0.95128077\n",
      "  0.60509718  0.25865763  0.25865763 -0.95128077  0.60509718 -0.95128077\n",
      " -0.95128077  0.25865763  1.81503558 -0.95128077 -0.95128077 -0.29396827\n",
      " -0.95128077 -0.95128077 -0.95128077  1.91262224 -0.95128077  1.26240968\n",
      " -0.95128077 -0.29396827 -0.29396827 -0.95128077  0.70268385  2.25906179\n",
      "  0.25865763 -0.95128077]\n",
      "P is: [0.5643062788416043, 0.2786273222142807, 0.2786273222142807, 0.8599693686256955, 0.8976561507612087, 0.2786273222142807, 0.2786273222142807, 0.2786273222142807, 0.6468215928401851, 0.6468215928401851, 0.6687825466431249, 0.5643062788416043, 0.2786273222142807, 0.6468215928401851, 0.2786273222142807, 0.8599693686256955, 0.2786273222142807, 0.5643062788416043, 0.6687825466431249, 0.6468215928401851, 0.2786273222142807, 0.6468215928401851, 0.6468215928401851, 0.2786273222142807, 0.6468215928401851, 0.5643062788416043, 0.5643062788416043, 0.2786273222142807, 0.6468215928401851, 0.2786273222142807, 0.2786273222142807, 0.5643062788416043, 0.8599693686256955, 0.2786273222142807, 0.2786273222142807, 0.4270326475993196, 0.2786273222142807, 0.2786273222142807, 0.2786273222142807, 0.8713134567743553, 0.2786273222142807, 0.7794406413099215, 0.2786273222142807, 0.4270326475993196, 0.4270326475993196, 0.2786273222142807, 0.6687825466431249, 0.905429325725204, 0.5643062788416043, 0.2786273222142807]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.134\n",
      "(*) epoch 2, cost 2.922\n",
      "(*) epoch 3, cost 2.424\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.461\n",
      "(*) epoch 2, cost 1.238\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.953344765372138, 3.953344765372138, 4.5396097091756, 3.953344765372138, 4.5396097091756, 4.339525743167621, 3.3896250999806954, 4.737187751931829, 3.953344765372138, 3.953344765372138, 3.953344765372138, 5.123368729727312, 5.323452695735291, 3.953344765372138, 3.953344765372138, 3.953344765372138, 4.5396097091756, 4.737187751931829, 1.5014544921158157, 3.3896250999806954, 3.953344765372138, 3.3896250999806954, 3.953344765372138, 3.3896250999806954, 3.3896250999806954, 4.339525743167621, 3.953344765372138, 4.36207102157964, 3.953344765372138, 3.953344765372138, 4.559649064335869, 4.616931984781551, 3.4669473755866465, 3.3896250999806954, 3.953344765372138, 3.3896250999806954, 3.953344765372138, 3.3896250999806954, 4.616931984781551, 3.3896250999806954, 1.6789931797117759, 4.559649064335869, 3.953344765372138, 3.7758060777761777, 3.81685622769447, 4.737187751931829, 3.7758060777761777, 4.5396097091756, 4.5396097091756, 5.323452695735291]\n",
      "all_sum after preprocessing is: [-0.06037759 -0.06037759  0.76810046 -0.06037759  0.76810046  0.48535257\n",
      " -0.85699586  1.0473071  -0.06037759 -0.06037759 -0.06037759  1.59303726\n",
      "  1.87578515 -0.06037759 -0.06037759 -0.06037759  0.76810046  1.0473071\n",
      " -3.52525688 -0.85699586 -0.06037759 -0.85699586 -0.06037759 -0.85699586\n",
      " -0.85699586  0.48535257 -0.06037759  0.51721234 -0.06037759 -0.06037759\n",
      "  0.79641899  0.87736813 -0.74772819 -0.85699586 -0.06037759 -0.85699586\n",
      " -0.06037759 -0.85699586  0.87736813 -0.85699586 -3.27436877  0.79641899\n",
      " -0.06037759 -0.3112657  -0.25325584  1.0473071  -0.3112657   0.76810046\n",
      "  0.76810046  1.87578515]\n",
      "P is: [0.48491018619762466, 0.48491018619762466, 0.6831098408497168, 0.48491018619762466, 0.6831098408497168, 0.619011007057439, 0.29796737790289746, 0.7402574541658936, 0.48491018619762466, 0.48491018619762466, 0.48491018619762466, 0.8310429959460676, 0.8671262495644286, 0.48491018619762466, 0.48491018619762466, 0.48491018619762466, 0.6831098408497168, 0.7402574541658936, 0.02860207630236131, 0.29796737790289746, 0.48491018619762466, 0.29796737790289746, 0.48491018619762466, 0.29796737790289746, 0.29796737790289746, 0.619011007057439, 0.48491018619762466, 0.6264956881729156, 0.48491018619762466, 0.48491018619762466, 0.6892079482619913, 0.7062765364163884, 0.3213165188641623, 0.29796737790289746, 0.48491018619762466, 0.29796737790289746, 0.48491018619762466, 0.29796737790289746, 0.7062765364163884, 0.29796737790289746, 0.03646103516739967, 0.6892079482619913, 0.48491018619762466, 0.42280582533553307, 0.4370222884745836, 0.7402574541658936, 0.42280582533553307, 0.6831098408497168, 0.6831098408497168, 0.8671262495644286]\n",
      "all_sum before preprocessing is: [3.2548106400044245, 2.947150604079164, 2.631626935905258, 4.642809693230808, 2.631626935905258, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 4.642809693230808, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 2.947150604079164, 2.947150604079164, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 2.947150604079164, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 2.631626935905258, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 2.0011795123740237, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 5.210066032233972, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 3.2548106400044245, 5.210066032233972, 3.2548106400044245, 3.2548106400044245]\n",
      "all_sum after preprocessing is: [-0.08661712 -0.65781747 -1.2436174   2.49033617 -1.2436174  -0.08661712\n",
      " -0.08661712 -0.08661712 -0.08661712 -0.08661712 -0.08661712  2.49033617\n",
      " -0.08661712 -0.08661712 -0.08661712 -0.65781747 -0.65781747 -0.08661712\n",
      " -0.08661712 -0.08661712 -0.08661712 -0.08661712 -0.08661712 -0.08661712\n",
      " -0.08661712 -0.65781747 -0.08661712 -0.08661712 -0.08661712 -0.08661712\n",
      " -0.08661712 -0.08661712 -1.2436174  -0.08661712 -0.08661712 -0.08661712\n",
      " -0.08661712 -0.08661712 -2.41410348 -0.08661712 -0.08661712 -0.08661712\n",
      "  3.54350194 -0.08661712 -0.08661712 -0.08661712 -0.08661712  3.54350194\n",
      " -0.08661712 -0.08661712]\n",
      "P is: [0.4783592478284175, 0.3412300570192833, 0.22380695190914604, 0.9234615664375154, 0.22380695190914604, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.9234615664375154, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.3412300570192833, 0.3412300570192833, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.3412300570192833, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.22380695190914604, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.08210353881710244, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.9719005077776658, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.4783592478284175, 0.9719005077776658, 0.4783592478284175, 0.4783592478284175]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.786\n",
      "(*) epoch 2, cost 2.376\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.585\n",
      "(*) epoch 2, cost 2.741\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 2.2739219322452175, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 2.2739219322452175, 1.6947662059581332, 2.2739219322452175, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 2.2739219322452175, 2.2739219322452175, 1.6947662059581332, 2.2739219322452175, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 2.2739219322452175, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 2.2739219322452175, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 2.2739219322452175, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332, 1.6947662059581332]\n",
      "all_sum after preprocessing is: [-0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129  2.13437475\n",
      " -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129  2.13437475 -0.46852129  2.13437475 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129  2.13437475\n",
      "  2.13437475 -0.46852129  2.13437475 -0.46852129 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129  2.13437475 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129  2.13437475 -0.46852129 -0.46852129\n",
      " -0.46852129  2.13437475 -0.46852129 -0.46852129 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129]\n",
      "P is: [0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.894199602788416, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.894199602788416, 0.38496629512219666, 0.894199602788416, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.894199602788416, 0.894199602788416, 0.38496629512219666, 0.894199602788416, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.894199602788416, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.894199602788416, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.894199602788416, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666, 0.38496629512219666]\n",
      "all_sum before preprocessing is: [3.749572470356135, 4.470533829663104, 4.470533829663104, 4.470533829663104, 5.334475317272872, 3.749572470356135, 4.470533829663104, 3.2826997320659412, 4.470533829663104, 2.1443591900074455, 4.470533829663104, 3.749572470356135, 2.865320549314415, 2.865320549314415, 2.865320549314415, 4.470533829663104, 2.865320549314415, 4.470533829663104, 2.865320549314415, 3.749572470356135, 2.865320549314415, 3.749572470356135, 2.865320549314415, 3.749572470356135, 3.749572470356135, 2.865320549314415, 2.865320549314415, 4.470533829663104, 2.865320549314415, 2.865320549314415, 3.7292620369241822, 2.865320549314415, 5.334475317272872, 4.470533829663104, 4.470533829663104, 2.865320549314415, 4.470533829663104, 2.1443591900074455, 4.470533829663104, 3.749572470356135, 3.749572470356135, 3.749572470356135, 2.865320549314415, 4.470533829663104, 3.749572470356135, 3.749572470356135, 4.470533829663104, 4.470533829663104, 2.865320549314415, 3.749572470356135]\n",
      "all_sum after preprocessing is: [ 0.05792857  0.98347237  0.98347237  0.98347237  2.09256883  0.05792857\n",
      "  0.98347237 -0.54142557  0.98347237 -2.00278549  0.98347237  0.05792857\n",
      " -1.07724168 -1.07724168 -1.07724168  0.98347237 -1.07724168  0.98347237\n",
      " -1.07724168  0.05792857 -1.07724168  0.05792857 -1.07724168  0.05792857\n",
      "  0.05792857 -1.07724168 -1.07724168  0.98347237 -1.07724168 -1.07724168\n",
      "  0.03185478 -1.07724168  2.09256883  0.98347237  0.98347237 -1.07724168\n",
      "  0.98347237 -2.00278549  0.98347237  0.05792857  0.05792857  0.05792857\n",
      " -1.07724168  0.98347237  0.05792857  0.05792857  0.98347237  0.98347237\n",
      " -1.07724168  0.05792857]\n",
      "P is: [0.514478093522334, 0.7277966674450538, 0.7277966674450538, 0.7277966674450538, 0.8901788079101302, 0.514478093522334, 0.7277966674450538, 0.36785602179075616, 0.7277966674450538, 0.11891077365360658, 0.7277966674450538, 0.514478093522334, 0.2540283572461574, 0.2540283572461574, 0.2540283572461574, 0.7277966674450538, 0.2540283572461574, 0.7277966674450538, 0.2540283572461574, 0.514478093522334, 0.2540283572461574, 0.514478093522334, 0.2540283572461574, 0.514478093522334, 0.514478093522334, 0.2540283572461574, 0.2540283572461574, 0.7277966674450538, 0.2540283572461574, 0.2540283572461574, 0.5079630208872212, 0.2540283572461574, 0.8901788079101302, 0.7277966674450538, 0.7277966674450538, 0.2540283572461574, 0.7277966674450538, 0.11891077365360658, 0.7277966674450538, 0.514478093522334, 0.514478093522334, 0.514478093522334, 0.2540283572461574, 0.7277966674450538, 0.514478093522334, 0.514478093522334, 0.7277966674450538, 0.7277966674450538, 0.2540283572461574, 0.514478093522334]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.849\n",
      "(*) epoch 2, cost 1.227\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.091\n",
      "(*) epoch 2, cost 3.501\n",
      "(*) epoch 3, cost 2.838\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.074917181872443, 2.074917181872443, 2.074917181872443, 2.074917181872443, 0.2625843483465578, 2.074917181872443, 0.2625843483465578, 2.074917181872443, 3.0373903156831705, 0.2625843483465578, 0.2625843483465578, 2.074917181872443, 2.074917181872443, 3.3401070198384635, 2.074917181872443, 0.2625843483465578, 0.2625843483465578, 2.074917181872443, 0.2625843483465578, 3.3401070198384635, 2.074917181872443, 2.074917181872443, 2.074917181872443, 2.074917181872443, 2.074917181872443, 2.074917181872443, 2.074917181872443, 2.074917181872443, 2.9934511583483387, 2.074917181872443, 2.9934511583483387, 3.3401070198384635, 2.074917181872443, 2.074917181872443, 0.2625843483465578, 3.3401070198384635, 3.393018767005674, 0.2625843483465578, 2.074917181872443, 3.3401070198384635, 0.2625843483465578, 2.074917181872443, 3.3401070198384635, 2.074917181872443, 3.3401070198384635, 2.9934511583483387, 2.074917181872443, 2.074917181872443, 2.074917181872443, 2.074917181872443]\n",
      "all_sum after preprocessing is: [ 0.08557399  0.08557399  0.08557399  0.08557399 -1.74726755  0.08557399\n",
      " -1.74726755  0.08557399  1.05893866 -1.74726755 -1.74726755  0.08557399\n",
      "  0.08557399  1.36508096  0.08557399 -1.74726755 -1.74726755  0.08557399\n",
      " -1.74726755  1.36508096  0.08557399  0.08557399  0.08557399  0.08557399\n",
      "  0.08557399  0.08557399  0.08557399  0.08557399  1.01450228  0.08557399\n",
      "  1.01450228  1.36508096  0.08557399  0.08557399 -1.74726755  1.36508096\n",
      "  1.41859147 -1.74726755  0.08557399  1.36508096 -1.74726755  0.08557399\n",
      "  1.36508096  0.08557399  1.36508096  1.01450228  0.08557399  0.08557399\n",
      "  0.08557399  0.08557399]\n",
      "P is: [0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.14839217150716705, 0.5213804524768415, 0.14839217150716705, 0.5213804524768415, 0.7424876692418212, 0.14839217150716705, 0.14839217150716705, 0.5213804524768415, 0.5213804524768415, 0.7965842464461197, 0.5213804524768415, 0.14839217150716705, 0.14839217150716705, 0.5213804524768415, 0.14839217150716705, 0.7965842464461197, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.7339003271463672, 0.5213804524768415, 0.7339003271463672, 0.7965842464461197, 0.5213804524768415, 0.5213804524768415, 0.14839217150716705, 0.7965842464461197, 0.8051175083000459, 0.14839217150716705, 0.5213804524768415, 0.7965842464461197, 0.14839217150716705, 0.5213804524768415, 0.7965842464461197, 0.5213804524768415, 0.7965842464461197, 0.7339003271463672, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415, 0.5213804524768415]\n",
      "all_sum before preprocessing is: [4.299583063799596, 2.5441015402765634, 2.5441015402765634, 3.224628982394142, 4.299583063799596, 4.824854381031433, 2.695688291998693, 4.299583063799596, 3.1034173581620337, 4.299583063799596, 4.299583063799596, 2.5441015402765634, 4.299583063799596, 3.3857040513524455, 4.299583063799596, 2.5441015402765634, 4.299583063799596, 4.299583063799596, 4.299583063799596, 4.824854381031433, 4.299583063799596, 4.980110505917175, 2.5441015402765634, 2.5441015402765634, 3.1034173581620337, 4.299583063799596, 4.299583063799596, 4.299583063799596, 2.5441015402765634, 4.299583063799596, 4.299583063799596, 2.5441015402765634, 3.1034173581620337, 2.5441015402765634, 1.873207151870838, 2.5441015402765634, 4.299583063799596, 4.299583063799596, 4.299583063799596, 4.299583063799596, 2.5441015402765634, 2.5441015402765634, 1.3479358346390011, 4.299583063799596, 4.299583063799596, 4.299583063799596, 4.980110505917175, 3.628688675393871, 2.5441015402765634, 4.299583063799596]\n",
      "all_sum after preprocessing is: [ 7.27078543e-01 -1.17003851e+00 -1.17003851e+00 -4.34604844e-01\n",
      "  7.27078543e-01  1.29472973e+00 -1.00622146e+00  7.27078543e-01\n",
      " -5.65596049e-01  7.27078543e-01  7.27078543e-01 -1.17003851e+00\n",
      "  7.27078543e-01 -2.60533937e-01  7.27078543e-01 -1.17003851e+00\n",
      "  7.27078543e-01  7.27078543e-01  7.27078543e-01  1.29472973e+00\n",
      "  7.27078543e-01  1.46251221e+00 -1.17003851e+00 -1.17003851e+00\n",
      " -5.65596049e-01  7.27078543e-01  7.27078543e-01  7.27078543e-01\n",
      " -1.17003851e+00  7.27078543e-01  7.27078543e-01 -1.17003851e+00\n",
      " -5.65596049e-01 -1.17003851e+00 -1.89506192e+00 -1.17003851e+00\n",
      "  7.27078543e-01  7.27078543e-01  7.27078543e-01  7.27078543e-01\n",
      " -1.17003851e+00 -1.17003851e+00 -2.46271310e+00  7.27078543e-01\n",
      "  7.27078543e-01  7.27078543e-01  1.46251221e+00  2.05514090e-03\n",
      " -1.17003851e+00  7.27078543e-01]\n",
      "P is: [0.6741638519221531, 0.23684802297310006, 0.23684802297310006, 0.39302727514305175, 0.6741638519221531, 0.784946669594596, 0.2677199682037617, 0.6741638519221531, 0.3622536333808682, 0.6741638519221531, 0.6741638519221531, 0.23684802297310006, 0.6741638519221531, 0.4352324591720164, 0.6741638519221531, 0.23684802297310006, 0.6741638519221531, 0.6741638519221531, 0.6741638519221531, 0.784946669594596, 0.6741638519221531, 0.8119166104241982, 0.23684802297310006, 0.23684802297310006, 0.3622536333808682, 0.6741638519221531, 0.6741638519221531, 0.6741638519221531, 0.23684802297310006, 0.6741638519221531, 0.6741638519221531, 0.23684802297310006, 0.3622536333808682, 0.23684802297310006, 0.13066838965316638, 0.23684802297310006, 0.6741638519221531, 0.6741638519221531, 0.6741638519221531, 0.6741638519221531, 0.23684802297310006, 0.23684802297310006, 0.07851382106148751, 0.6741638519221531, 0.6741638519221531, 0.6741638519221531, 0.8119166104241982, 0.5005137850445832, 0.23684802297310006, 0.6741638519221531]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.267\n",
      "(*) epoch 2, cost 1.746\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.971\n",
      "(*) epoch 2, cost 1.682\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [7.61262807132081, 8.109089568919186, 6.584818641621993, 7.930406823802711, 8.685498798537466, 7.433945326204336, 7.61262807132081, 7.65768936883865, 5.829726666887237, 4.650361082210219, 7.61262807132081, 7.61262807132081, 8.109089568919186, 8.109089568919186, 5.678170511909037, 6.857536096586054, 6.584818641621993, 7.61262807132081, 6.584818641621993, 7.61262807132081, 6.584818641621993, 7.081280139220368, 6.584818641621993, 7.61262807132081, 6.584818641621993, 6.406135896505518, 8.189037300939091, 7.433945326204336, 6.584818641621993, 6.9025973941038945, 8.189037300939091, 7.61262807132081, 6.857536096586054, 7.433945326204336, 7.61262807132081, 6.584818641621993, 7.161227871240275, 7.433945326204336, 6.584818641621993, 7.161227871240275, 6.584818641621993, 6.584818641621993, 5.829726666887237, 7.61262807132081, 7.61262807132081, 7.61262807132081, 5.678170511909037, 7.161227871240275, 5.829726666887237, 7.161227871240275]\n",
      "all_sum after preprocessing is: [ 0.65754356  1.28808081 -0.6478389   1.06114251  2.0201567   0.43060526\n",
      "  0.65754356  0.71477423 -1.60685309 -3.10472138  0.65754356  0.65754356\n",
      "  1.28808081  1.28808081 -1.79933892 -0.30147063 -0.6478389   0.65754356\n",
      " -0.6478389   0.65754356 -0.6478389  -0.01730165 -0.6478389   0.65754356\n",
      " -0.6478389  -0.8747772   1.38961945  0.43060526 -0.6478389  -0.24423995\n",
      "  1.38961945  0.65754356 -0.30147063  0.43060526  0.65754356 -0.6478389\n",
      "  0.08423698  0.43060526 -0.6478389   0.08423698 -0.6478389  -0.6478389\n",
      " -1.60685309  0.65754356  0.65754356  0.65754356 -1.79933892  0.08423698\n",
      " -1.60685309  0.08423698]\n",
      "P is: [0.6587083675470341, 0.7838221694463654, 0.34347670045167583, 0.742908820650532, 0.8828972111444326, 0.6060181902193452, 0.6587083675470341, 0.6714552316744546, 0.16702597930218321, 0.04291292225869223, 0.6587083675470341, 0.6587083675470341, 0.7838221694463654, 0.7838221694463654, 0.1419315573961779, 0.42519801606944085, 0.34347670045167583, 0.6587083675470341, 0.34347670045167583, 0.6587083675470341, 0.34347670045167583, 0.49567469476183407, 0.34347670045167583, 0.6587083675470341, 0.34347670045167583, 0.2942612389361068, 0.8005314831184027, 0.6060181902193452, 0.34347670045167583, 0.4392417477501564, 0.8005314831184027, 0.6587083675470341, 0.42519801606944085, 0.6060181902193452, 0.6587083675470341, 0.34347670045167583, 0.5210468018534353, 0.6060181902193452, 0.34347670045167583, 0.5210468018534353, 0.34347670045167583, 0.34347670045167583, 0.16702597930218321, 0.6587083675470341, 0.6587083675470341, 0.6587083675470341, 0.1419315573961779, 0.5210468018534353, 0.16702597930218321, 0.5210468018534353]\n",
      "all_sum before preprocessing is: [2.0844455593040685, 1.524248782967274, 1.7781528467784087, 1.5771007818666327, 1.524248782967274, 1.5771007818666327, 1.2445276167397796, 1.7995209095148776, 1.878190010830596, 1.8995580735670647, 1.2231595540033107, 1.5771007818666327, 2.3061242349888587, 1.878190010830596, 1.2231595540033107, 1.8310048456777674, 3.173077074036147, 1.5984688446031017, 1.524248782967274, 1.5771007818666327, 1.2231595540033107, 1.2967461440975852, 1.8995580735670647, 1.878190010830596, 1.2231595540033107, 1.524248782967274, 1.524248782967274, 1.524248782967274, 1.5771007818666327, 1.2231595540033107, 1.524248782967274, 2.0050350060248956, 1.5771007818666327, 1.524248782967274, 1.524248782967274, 1.2231595540033107, 1.878190010830596, 2.1372975582034273, 2.3383496231152034, 1.524248782967274, 2.132094074641731, 1.524248782967274, 1.8310048456777674, 1.7781528467784087, 1.7781528467784087, 1.878190010830596, 1.4770636178144454, 2.1534621373781997, 2.5652317823616904, 1.524248782967274]\n",
      "all_sum after preprocessing is: [ 0.9911435  -0.49888115  0.17645889 -0.35830415 -0.49888115 -0.35830415\n",
      " -1.24289013  0.23329417  0.44254011  0.49937539 -1.29972541 -0.35830415\n",
      "  1.58076969  0.44254011 -1.29972541  0.31703589  3.88671138 -0.30146887\n",
      " -0.49888115 -0.35830415 -1.29972541 -1.10399806  0.49937539  0.44254011\n",
      " -1.29972541 -0.49888115 -0.49888115 -0.49888115 -0.35830415 -1.29972541\n",
      " -0.49888115  0.77992543 -0.35830415 -0.49888115 -0.49888115 -1.29972541\n",
      "  0.44254011  1.1317205   1.66648354 -0.49888115  1.11788015 -0.49888115\n",
      "  0.31703589  0.17645889  0.17645889  0.44254011 -0.62438537  1.17471543\n",
      "  2.26995008 -0.49888115]\n",
      "P is: [0.7293137258954149, 0.37780363843785714, 0.5440006085077526, 0.411370144601881, 0.37780363843785714, 0.411370144601881, 0.2239333169327482, 0.558060446994557, 0.608864120975555, 0.6223125337265996, 0.21421123324801716, 0.411370144601881, 0.8293134974249046, 0.608864120975555, 0.21421123324801716, 0.5786017061272464, 0.9798996193118954, 0.42519844414581437, 0.37780363843785714, 0.411370144601881, 0.21421123324801716, 0.2489915286526139, 0.6223125337265996, 0.608864120975555, 0.21421123324801716, 0.37780363843785714, 0.37780363843785714, 0.37780363843785714, 0.411370144601881, 0.21421123324801716, 0.37780363843785714, 0.685664042220653, 0.411370144601881, 0.37780363843785714, 0.37780363843785714, 0.21421123324801716, 0.608864120975555, 0.7561562712313553, 0.8411064226694438, 0.37780363843785714, 0.7535952943161771, 0.37780363843785714, 0.5786017061272464, 0.5440006085077526, 0.5440006085077526, 0.608864120975555, 0.3487847255133616, 0.7639962938099901, 0.9063575511025846, 0.37780363843785714]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.881\n",
      "(*) epoch 2, cost 5.032\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.362\n",
      "(*) epoch 2, cost 2.668\n",
      "(*) epoch 3, cost 2.153\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.8937310782895853, 2.9290793646760536, 2.9290793646760536, 1.6997557561528835, 2.9290793646760536, 1.6997557561528835, 1.7303095921797258, 1.6997557561528835, 2.9290793646760536, 2.8631772422627426, 2.9290793646760536, 1.7303095921797258, 1.6766946510609642, 2.9290793646760536, 2.9290793646760536, 1.6997557561528835, 1.6997557561528835, 2.9290793646760536, 2.9290793646760536, 2.9290793646760536, 1.6997557561528835, 1.6997557561528835, 2.9290793646760536, 1.6997557561528835, 2.9290793646760536, 2.9290793646760536, 2.9290793646760536, 2.9290793646760536, 1.6997557561528835, 1.6997557561528835, 2.9290793646760536, 0.5009859836565561, 2.9290793646760536, 2.9290793646760536, 1.6997557561528835, 2.9290793646760536, 1.6997557561528835, 1.6997557561528835, 2.9290793646760536, 2.9290793646760536, 2.9290793646760536, 1.7303095921797258, 1.7303095921797258, 1.6997557561528835, 1.6997557561528835, 2.9290793646760536, 2.9290793646760536, 1.7303095921797258, 2.9290793646760536, 1.6997557561528835]\n",
      "all_sum after preprocessing is: [ 0.844252    0.89816409  0.89816409 -0.9767612   0.89816409 -0.9767612\n",
      " -0.93016146 -0.9767612   0.89816409  0.79765227  0.89816409 -0.93016146\n",
      " -1.01193326  0.89816409  0.89816409 -0.9767612  -0.9767612   0.89816409\n",
      "  0.89816409  0.89816409 -0.9767612  -0.9767612   0.89816409 -0.9767612\n",
      "  0.89816409  0.89816409  0.89816409  0.89816409 -0.9767612  -0.9767612\n",
      "  0.89816409 -2.80508674  0.89816409  0.89816409 -0.9767612   0.89816409\n",
      " -0.9767612  -0.9767612   0.89816409  0.89816409  0.89816409 -0.93016146\n",
      " -0.93016146 -0.9767612  -0.9767612   0.89816409  0.89816409 -0.93016146\n",
      "  0.89816409 -0.9767612 ]\n",
      "P is: [0.6993599808954888, 0.7105720759088506, 0.7105720759088506, 0.27353490541341213, 0.7105720759088506, 0.27353490541341213, 0.2828919593457267, 0.27353490541341213, 0.7105720759088506, 0.6894720540458034, 0.7105720759088506, 0.2828919593457267, 0.26660167884351443, 0.7105720759088506, 0.7105720759088506, 0.27353490541341213, 0.27353490541341213, 0.7105720759088506, 0.7105720759088506, 0.7105720759088506, 0.27353490541341213, 0.27353490541341213, 0.7105720759088506, 0.27353490541341213, 0.7105720759088506, 0.7105720759088506, 0.7105720759088506, 0.7105720759088506, 0.27353490541341213, 0.27353490541341213, 0.7105720759088506, 0.0570499160974999, 0.7105720759088506, 0.7105720759088506, 0.27353490541341213, 0.7105720759088506, 0.27353490541341213, 0.27353490541341213, 0.7105720759088506, 0.7105720759088506, 0.7105720759088506, 0.2828919593457267, 0.2828919593457267, 0.27353490541341213, 0.27353490541341213, 0.7105720759088506, 0.7105720759088506, 0.2828919593457267, 0.7105720759088506, 0.27353490541341213]\n",
      "all_sum before preprocessing is: [1.1868300854957947, 1.1868300854957947, 1.6975621200278868, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.6975621200278868, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.6975621200278868, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 2.340678069272346, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.5017970590964085, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.6975621200278868, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.6975621200278868, 1.1868300854957947, 1.6975621200278868, 1.3512224463832738, 1.1868300854957947, 1.1868300854957947, 1.1868300854957947, 1.6975621200278868]\n",
      "all_sum after preprocessing is: [-0.4448974  -0.4448974   1.73644755 -0.4448974  -0.4448974  -0.4448974\n",
      " -0.4448974  -0.4448974   1.73644755 -0.4448974  -0.4448974  -0.4448974\n",
      " -0.4448974  -0.4448974  -0.4448974  -0.4448974  -0.4448974  -0.4448974\n",
      " -0.4448974  -0.4448974  -0.4448974  -0.4448974  -0.4448974   1.73644755\n",
      " -0.4448974  -0.4448974  -0.4448974  -0.4448974   4.48320638 -0.4448974\n",
      " -0.4448974  -0.4448974  -0.4448974   0.90033174 -0.4448974  -0.4448974\n",
      " -0.4448974  -0.4448974   1.73644755 -0.4448974  -0.4448974  -0.4448974\n",
      "  1.73644755 -0.4448974   1.73644755  0.25722509 -0.4448974  -0.4448974\n",
      " -0.4448974   1.73644755]\n",
      "P is: [0.39057463726589536, 0.39057463726589536, 0.8502352757733384, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.8502352757733384, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.8502352757733384, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.9888290674193146, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.7110176709368747, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.8502352757733384, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.8502352757733384, 0.39057463726589536, 0.8502352757733384, 0.5639540344528635, 0.39057463726589536, 0.39057463726589536, 0.39057463726589536, 0.8502352757733384]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.645\n",
      "(*) epoch 2, cost 2.298\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.152\n",
      "(*) epoch 2, cost 1.586\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.7376491739021613, 2.6440546583580913, 3.2191033247654293, 2.07036472900332, 2.6440546583580913, 2.925175268470923, 3.1140601000922516, 2.7170396701825172, 2.7170396701825172, 3.4272389230538347, 2.6440546583580913, 2.83293948997942, 2.925175268470923, 2.07036472900332, 3.3113391032569326, 3.4272389230538347, 2.7170396701825172, 2.6440546583580913, 2.6440546583580913, 2.83293948997942, 1.7571859060417365, 2.6440546583580913, 3.634171982297645, 1.7709421978271478, 3.0302184931441007, 2.435919060069686, 3.7083595331666666, 2.330875835396508, 2.8509877176019014, 2.7376491739021613, 2.925175268470923, 3.0302184931441007, 2.435919060069686, 2.435919060069686, 1.678706419335645, 2.0497552252836764, 2.83293948997942, 2.6440546583580913, 3.1346696038118953, 3.4260363840092394, 3.1140601000922516, 2.435919060069686, 3.813402757839844, 2.330875835396508, 2.330875835396508, 3.0302184931441007, 2.435919060069686, 4.020335817083654, 2.330875835396508, 2.925175268470923]\n",
      "all_sum after preprocessing is: [-0.06468116 -0.24880611  0.88246539 -1.37740461 -0.24880611  0.30423184\n",
      "  0.67581782 -0.10522545 -0.10522545  1.29192268 -0.24880611  0.12277988\n",
      "  0.30423184 -1.37740461  1.06391734  1.29192268 -0.10522545 -0.24880611\n",
      " -0.24880611  0.12277988 -1.99350946 -0.24880611  1.69901426 -1.96644723\n",
      "  0.5108794  -0.6582634   1.84496062 -0.86491096  0.15828547 -0.06468116\n",
      "  0.30423184  0.5108794  -0.6582634  -0.6582634  -2.14789919 -1.41794891\n",
      "  0.12277988 -0.24880611  0.71636212  1.28955697  0.67581782 -0.6582634\n",
      "  2.05160818 -0.86491096 -0.86491096  0.5108794  -0.6582634   2.45869977\n",
      " -0.86491096  0.30423184]\n",
      "P is: [0.4838353458749293, 0.4381173783866136, 0.7073328488604853, 0.20142615433284797, 0.4381173783866136, 0.5754766970358395, 0.6628046403466659, 0.47371788238201384, 0.47371788238201384, 0.7844724442684093, 0.4381173783866136, 0.5306564671503777, 0.5754766970358395, 0.20142615433284797, 0.7434384428355915, 0.7844724442684093, 0.47371788238201384, 0.4381173783866136, 0.4381173783866136, 0.5306564671503777, 0.11988607278178716, 0.4381173783866136, 0.8454059474219504, 0.12277100143560166, 0.6250126036111484, 0.341129822699325, 0.863534335670358, 0.2963143271262492, 0.5394889554032498, 0.4838353458749293, 0.5754766970358395, 0.6250126036111484, 0.341129822699325, 0.341129822699325, 0.10452769914769308, 0.19498333171703763, 0.5306564671503777, 0.4381173783866136, 0.6718054284731356, 0.7840721917321314, 0.6628046403466659, 0.341129822699325, 0.8861100159102205, 0.2963143271262492, 0.2963143271262492, 0.6250126036111484, 0.341129822699325, 0.9211953246062226, 0.2963143271262492, 0.5754766970358395]\n",
      "all_sum before preprocessing is: [4.633932267534871, 3.7498092180733105, 0.5663140716457409, 1.4438420026197472, 5.632627892547123, 6.887836059677498, 4.633932267534871, 6.894431178165052, 3.7498092180733105, 4.633932267534871, 4.633932267534871, 4.484295845211647, 4.633932267534871, 4.640527386022425, 4.633932267534871, 5.011612503691239, 3.7498092180733105, 2.4425376276319994, 4.633932267534871, 6.738199637354273, 5.632627892547123, 1.4438420026197472, 2.657391204490035, 4.633932267534871, 5.0050173852036846, 5.482991470223899, 5.889140434665245, 2.6990501697501217, 2.6990501697501217, 4.633932267534871, 5.526732916909473, 1.4438420026197472, 4.633932267534871, 6.894431178165052, 1.4438420026197472, 4.477700726724093, 1.4504371211073015, 3.7498092180733105, 3.600172795750087, 5.889140434665245, 5.895735553152799, 4.633932267534871, 4.633932267534871, 5.632627892547123, 6.887836059677498, 2.4491327461195533, 4.633932267534871, 1.4438420026197472, 5.526732916909473, 1.2876104618089692]\n",
      "all_sum after preprocessing is: [ 0.24257594 -0.2842378  -2.18115586 -1.65827189  0.83765892  1.58558751\n",
      "  0.24257594  1.58951728 -0.2842378   0.24257594  0.24257594  0.15341355\n",
      "  0.24257594  0.24650571  0.24257594  0.46762057 -0.2842378  -1.06318891\n",
      "  0.24257594  1.49642513  0.83765892 -1.65827189 -0.93516622  0.24257594\n",
      "  0.4636908   0.74849653  0.99050454 -0.9103433  -0.9103433   0.24257594\n",
      "  0.77456032 -1.65827189  0.24257594  1.58951728 -1.65827189  0.14948379\n",
      " -1.65434212 -0.2842378  -0.37340019  0.99050454  0.99443431  0.24257594\n",
      "  0.24257594  0.83765892  1.58558751 -1.05925914  0.24257594 -1.65827189\n",
      "  0.77456032 -1.75136405]\n",
      "P is: [0.5603483520188601, 0.4294151314744879, 0.10145550844911548, 0.1599941116315466, 0.6979719287702577, 0.8299943912959036, 0.5603483520188601, 0.830548177334684, 0.4294151314744879, 0.5603483520188601, 0.5603483520188601, 0.5382783423206694, 0.5603483520188601, 0.5613162514740612, 0.5603483520188601, 0.6148204217547087, 0.4294151314744879, 0.2567005213143977, 0.5603483520188601, 0.817040690902765, 0.6979719287702577, 0.1599941116315466, 0.2818777777559793, 0.5603483520188601, 0.6138893696913303, 0.6788510128472375, 0.7291875662478551, 0.28692959335230633, 0.28692959335230633, 0.5603483520188601, 0.6845065557926118, 0.1599941116315466, 0.5603483520188601, 0.830548177334684, 0.1599941116315466, 0.5373015124986946, 0.16052296274247935, 0.4294151314744879, 0.4077196731107336, 0.7291875662478551, 0.7299628903877274, 0.5603483520188601, 0.5603483520188601, 0.6979719287702577, 0.8299943912959036, 0.25745105888012587, 0.5603483520188601, 0.1599941116315466, 0.6845065557926118, 0.1478752344054365]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.410\n",
      "(*) epoch 2, cost 3.916\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.892\n",
      "(*) epoch 2, cost 3.837\n",
      "(*) epoch 3, cost 3.468\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.709544048570443, 2.565472293709327, 1.5026093038016506, 0.8450538843294202, 2.565472293709327, 1.5026093038016506, 2.4662858808759998, 2.4662858808759998, 1.5026093038016506, 2.4662858808759998, 1.5026093038016506, 0.7458674714960936, 2.4662858808759998, 1.8087304614037696, 2.4662858808759998, 1.5026093038016506, 1.8087304614037696, 2.565472293709327, 0.7458674714960936, 1.5026093038016506, 0.7458674714960936, 1.5026093038016506, 1.709544048570443, 2.4662858808759998, 1.709544048570443, 2.145977550304748, 2.565472293709327, 1.5026093038016506, 1.5026093038016506, 2.4662858808759998, 1.6017957166349772, 2.4662858808759998, 2.4662858808759998, 2.4662858808759998, 1.709544048570443, 2.4662858808759998, 0.7458674714960936, 3.109654127379097, 1.5026093038016506, 1.5026093038016506, 2.565472293709327, 2.4662858808759998, 1.5026093038016506, 1.5026093038016506, 2.565472293709327, 1.6017957166349772, 2.4662858808759998, 1.5026093038016506, 2.565472293709327, 2.4662858808759998]\n",
      "all_sum after preprocessing is: [-0.35891027  1.06476598 -0.70310744 -1.79682766  1.06476598 -0.70310744\n",
      "  0.89978797  0.89978797 -0.70310744  0.89978797 -0.70310744 -1.96180568\n",
      "  0.89978797 -0.19393226  0.89978797 -0.70310744 -0.19393226  1.06476598\n",
      " -1.96180568 -0.70310744 -1.96180568 -0.70310744 -0.35891027  0.89978797\n",
      " -0.35891027  0.36701508  1.06476598 -0.70310744 -0.70310744  0.89978797\n",
      " -0.53812943  0.89978797  0.89978797  0.89978797 -0.35891027  0.89978797\n",
      " -1.96180568  1.96991049 -0.70310744 -0.70310744  1.06476598  0.89978797\n",
      " -0.70310744 -0.70310744  1.06476598 -0.53812943  0.89978797 -0.70310744\n",
      "  1.06476598  0.89978797]\n",
      "P is: [0.4112233847780697, 0.7436002762128289, 0.3311236288078685, 0.14223767011998398, 0.7436002762128289, 0.3311236288078685, 0.7109059279904978, 0.7109059279904978, 0.3311236288078685, 0.7109059279904978, 0.3311236288078685, 0.12327176479507178, 0.7109059279904978, 0.4516683193580274, 0.7109059279904978, 0.3311236288078685, 0.4516683193580274, 0.7436002762128289, 0.12327176479507178, 0.3311236288078685, 0.12327176479507178, 0.3311236288078685, 0.4112233847780697, 0.7109059279904978, 0.4112233847780697, 0.5907375202795497, 0.7436002762128289, 0.3311236288078685, 0.3311236288078685, 0.7109059279904978, 0.3686228321037822, 0.7109059279904978, 0.7109059279904978, 0.7109059279904978, 0.4112233847780697, 0.7109059279904978, 0.12327176479507178, 0.8776014984414477, 0.3311236288078685, 0.3311236288078685, 0.7436002762128289, 0.7109059279904978, 0.3311236288078685, 0.3311236288078685, 0.7436002762128289, 0.3686228321037822, 0.7109059279904978, 0.3311236288078685, 0.7436002762128289, 0.7109059279904978]\n",
      "all_sum before preprocessing is: [1.2648938196602297, 4.69492537553385, 3.489669566659798, 4.69492537553385, 3.453297047327918, 4.69492537553385, 4.69492537553385, 4.69492537553385, 2.5065221478661615, 3.489669566659798, 2.5065221478661615, 2.5065221478661615, 4.69492537553385, 4.69492537553385, 2.5065221478661615, 2.248041238453866, 4.69492537553385, 4.69492537553385, 2.5065221478661615, 3.489669566659798, 4.69492537553385, 4.69492537553385, 4.69492537553385, 4.69492537553385, 1.2648938196602297, 4.69492537553385, 4.69492537553385, 2.5065221478661615, 3.453297047327918, 4.69492537553385, 2.5065221478661615, 4.69492537553385, 4.69492537553385, 2.5065221478661615, 4.69492537553385, 3.489669566659798, 4.69492537553385, 4.69492537553385, 3.489669566659798, 2.5065221478661615, 3.489669566659798, 4.69492537553385, 2.5065221478661615, 2.5065221478661615, 4.69492537553385, 4.69492537553385, 4.69492537553385, 4.69492537553385, 1.2648938196602297, 4.69492537553385]\n",
      "all_sum after preprocessing is: [-2.23616623  0.83243756 -0.24581857  0.83243756 -0.27835846  0.83243756\n",
      "  0.83243756  0.83243756 -1.12537022 -0.24581857 -1.12537022 -1.12537022\n",
      "  0.83243756  0.83243756 -1.12537022 -1.35661459  0.83243756  0.83243756\n",
      " -1.12537022 -0.24581857  0.83243756  0.83243756  0.83243756  0.83243756\n",
      " -2.23616623  0.83243756  0.83243756 -1.12537022 -0.27835846  0.83243756\n",
      " -1.12537022  0.83243756  0.83243756 -1.12537022  0.83243756 -0.24581857\n",
      "  0.83243756  0.83243756 -0.24581857 -1.12537022 -0.24581857  0.83243756\n",
      " -1.12537022 -1.12537022  0.83243756  0.83243756  0.83243756  0.83243756\n",
      " -2.23616623  0.83243756]\n",
      "P is: [0.09654943514487142, 0.696870091525197, 0.4388529573177815, 0.696870091525197, 0.4308562668567121, 0.696870091525197, 0.696870091525197, 0.696870091525197, 0.2450165227672542, 0.4388529573177815, 0.2450165227672542, 0.2450165227672542, 0.696870091525197, 0.696870091525197, 0.2450165227672542, 0.20479107104560157, 0.696870091525197, 0.696870091525197, 0.2450165227672542, 0.4388529573177815, 0.696870091525197, 0.696870091525197, 0.696870091525197, 0.696870091525197, 0.09654943514487142, 0.696870091525197, 0.696870091525197, 0.2450165227672542, 0.4308562668567121, 0.696870091525197, 0.2450165227672542, 0.696870091525197, 0.696870091525197, 0.2450165227672542, 0.696870091525197, 0.4388529573177815, 0.696870091525197, 0.696870091525197, 0.4388529573177815, 0.2450165227672542, 0.4388529573177815, 0.696870091525197, 0.2450165227672542, 0.2450165227672542, 0.696870091525197, 0.696870091525197, 0.696870091525197, 0.696870091525197, 0.09654943514487142, 0.696870091525197]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.258\n",
      "(*) epoch 2, cost 2.129\n",
      "(*) epoch 3, cost 1.850\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.561\n",
      "(*) epoch 2, cost 2.389\n",
      "(*) epoch 3, cost 1.969\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.8701044438595695, 3.1979246879010543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 2.6161665756976693, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 2.721031658901122, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 3.1979246879010543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 2.6161665756976693, 2.6161665756976693, 1.9439868197391543, 1.9439868197391543, 2.6161665756976693, 2.6161665756976693, 1.9439868197391543, 3.3932114148596373, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 2.6161665756976693, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 1.9439868197391543, 2.6161665756976693, 1.9439868197391543, 1.9439868197391543, 2.722382455067927, 1.9439868197391543, 1.9439868197391543]\n",
      "all_sum after preprocessing is: [ 3.69467665  2.2192555  -0.5331131  -0.5331131  -0.5331131   0.94230805\n",
      " -0.5331131  -0.5331131  -0.5331131   1.17248482 -0.5331131  -0.5331131\n",
      " -0.5331131  -0.5331131  -0.5331131   2.2192555  -0.5331131  -0.5331131\n",
      " -0.5331131  -0.5331131  -0.5331131   0.94230805  0.94230805 -0.5331131\n",
      " -0.5331131   0.94230805  0.94230805 -0.5331131   2.64790597 -0.5331131\n",
      " -0.5331131  -0.5331131  -0.5331131  -0.5331131  -0.5331131  -0.5331131\n",
      " -0.5331131  -0.5331131  -0.5331131   0.94230805 -0.5331131  -0.5331131\n",
      " -0.5331131  -0.5331131   0.94230805 -0.5331131  -0.5331131   1.17544979\n",
      " -0.5331131  -0.5331131 ]\n",
      "P is: [0.9757473228754514, 0.9019653840605126, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.7195656377483562, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.76359386478484, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.9019653840605126, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.7195656377483562, 0.7195656377483562, 0.3697911005428412, 0.3697911005428412, 0.7195656377483562, 0.7195656377483562, 0.3697911005428412, 0.9338818088222934, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.7195656377483562, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.3697911005428412, 0.7195656377483562, 0.3697911005428412, 0.3697911005428412, 0.7641286777934133, 0.3697911005428412, 0.3697911005428412]\n",
      "all_sum before preprocessing is: [0.9836745857702536, 0.9836745857702536, 2.2900001854294056, 0.9836745857702536, 0.9836745857702536, 1.46921904368686, 2.356899418270209, 0.9836745857702536, 0.9836745857702536, 1.46921904368686, 0.9836745857702536, 0.9836745857702536, 0.9836745857702536, 0.9836745857702536, 1.46921904368686, 0.9836745857702536, 1.804455727512799, 1.46921904368686, 0.9836745857702536, 1.804455727512799, 0.9836745857702536, 0.9836745857702536, 1.46921904368686, 1.46921904368686, 0.9836745857702536, 0.9836745857702536, 1.46921904368686, 0.9836745857702536, 0.9836745857702536, 0.9836745857702536, 1.804455727512799, 0.9836745857702536, 1.46921904368686, 1.46921904368686, 0.9836745857702536, 0.9836745857702536, 0.9836745857702536, 1.46921904368686, 0.9836745857702536, 0.9836745857702536, 1.46921904368686, 0.9836745857702536, 0.9836745857702536, 0.9836745857702536, 2.438357717633125, 1.46921904368686, 1.46921904368686, 0.9836745857702536, 1.804455727512799, 0.9836745857702536]\n",
      "all_sum after preprocessing is: [-0.69981188 -0.69981188  2.62946608 -0.69981188 -0.69981188  0.537638\n",
      "  2.79996426 -0.69981188 -0.69981188  0.537638   -0.69981188 -0.69981188\n",
      " -0.69981188 -0.69981188  0.537638   -0.69981188  1.39201619  0.537638\n",
      " -0.69981188  1.39201619 -0.69981188 -0.69981188  0.537638    0.537638\n",
      " -0.69981188 -0.69981188  0.537638   -0.69981188 -0.69981188 -0.69981188\n",
      "  1.39201619 -0.69981188  0.537638    0.537638   -0.69981188 -0.69981188\n",
      " -0.69981188  0.537638   -0.69981188 -0.69981188  0.537638   -0.69981188\n",
      " -0.69981188 -0.69981188  3.00756742  0.537638    0.537638   -0.69981188\n",
      "  1.39201619 -0.69981188]\n",
      "P is: [0.33185393690565146, 0.33185393690565146, 0.932734058053124, 0.33185393690565146, 0.33185393690565146, 0.6312627855180356, 0.9426738926637632, 0.33185393690565146, 0.33185393690565146, 0.6312627855180356, 0.33185393690565146, 0.33185393690565146, 0.33185393690565146, 0.33185393690565146, 0.6312627855180356, 0.33185393690565146, 0.8009139215148212, 0.6312627855180356, 0.33185393690565146, 0.8009139215148212, 0.33185393690565146, 0.33185393690565146, 0.6312627855180356, 0.6312627855180356, 0.33185393690565146, 0.33185393690565146, 0.6312627855180356, 0.33185393690565146, 0.33185393690565146, 0.33185393690565146, 0.8009139215148212, 0.33185393690565146, 0.6312627855180356, 0.6312627855180356, 0.33185393690565146, 0.33185393690565146, 0.33185393690565146, 0.6312627855180356, 0.33185393690565146, 0.33185393690565146, 0.6312627855180356, 0.33185393690565146, 0.33185393690565146, 0.33185393690565146, 0.9529148289788059, 0.6312627855180356, 0.6312627855180356, 0.33185393690565146, 0.8009139215148212, 0.33185393690565146]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.773\n",
      "(*) epoch 2, cost 2.169\n",
      "(*) epoch 3, cost 1.563\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.290\n",
      "(*) epoch 2, cost 1.588\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.184568981693325, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 2.6003771844927615, 2.184568981693325, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 2.184568981693325, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 1.3227834268071725, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914, 1.2907313835705914, 2.184568981693325, 1.2907313835705914]\n",
      "all_sum after preprocessing is: [ 1.21790093 -0.77872692  1.21790093 -0.77872692 -0.77872692  1.21790093\n",
      "  2.14672092  1.21790093  1.21790093 -0.77872692 -0.77872692 -0.77872692\n",
      "  1.21790093 -0.77872692  1.21790093 -0.77872692 -0.77872692 -0.77872692\n",
      " -0.77872692  1.21790093 -0.77872692  1.21790093 -0.77872692  1.21790093\n",
      "  1.21790093 -0.77872692 -0.77872692  1.21790093 -0.77872692 -0.77872692\n",
      "  1.21790093 -0.77872692 -0.77872692  1.21790093 -0.77872692 -0.77872692\n",
      " -0.77872692  1.21790093 -0.77872692 -0.77872692 -0.70713002  1.21790093\n",
      " -0.77872692 -0.77872692 -0.77872692  1.21790093 -0.77872692 -0.77872692\n",
      "  1.21790093 -0.77872692]\n",
      "P is: [0.7716939404426817, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.8953619618060821, 0.7716939404426817, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.7716939404426817, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.3302333111301119, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365, 0.3145943289827365, 0.7716939404426817, 0.3145943289827365]\n",
      "all_sum before preprocessing is: [3.7201862735479723, 4.763318451890521, 3.7201862735479723, 4.763318451890521, 4.763318451890521, 4.763318451890521, 3.7201862735479723, 4.763318451890521, 4.763318451890521, 3.7201862735479723, 3.7201862735479723, 3.7201862735479723, 4.763318451890521, 3.7201862735479723, 3.7201862735479723, 4.763318451890521, 4.123800067522093, 4.763318451890521, 3.7201862735479723, 3.704579486188951, 4.123800067522093, 3.7201862735479723, 4.763318451890521, 3.7201862735479723, 3.7201862735479723, 4.123800067522093, 3.7201862735479723, 3.704579486188951, 4.763318451890521, 3.7201862735479723, 4.123800067522093, 3.7201862735479723, 4.763318451890521, 4.763318451890521, 4.763318451890521, 4.763318451890521, 4.763318451890521, 3.7201862735479723, 3.7201862735479723, 4.763318451890521, 3.7201862735479723, 4.763318451890521, 4.763318451890521, 3.7201862735479723, 3.7201862735479723, 4.763318451890521, 2.8082969959391226, 5.166932245864642, 4.763318451890521, 4.123800067522093]\n",
      "all_sum after preprocessing is: [-0.90236681  1.02433123 -0.90236681  1.02433123  1.02433123  1.02433123\n",
      " -0.90236681  1.02433123  1.02433123 -0.90236681 -0.90236681 -0.90236681\n",
      "  1.02433123 -0.90236681 -0.90236681  1.02433123 -0.1568794   1.02433123\n",
      " -0.90236681 -0.93119304 -0.1568794  -0.90236681  1.02433123 -0.90236681\n",
      " -0.90236681 -0.1568794  -0.90236681 -0.93119304  1.02433123 -0.90236681\n",
      " -0.1568794  -0.90236681  1.02433123  1.02433123  1.02433123  1.02433123\n",
      "  1.02433123 -0.90236681 -0.90236681  1.02433123 -0.90236681  1.02433123\n",
      "  1.02433123 -0.90236681 -0.90236681  1.02433123 -2.58665507  1.76981863\n",
      "  1.02433123 -0.1568794 ]\n",
      "P is: [0.288564360017519, 0.7358154106345126, 0.288564360017519, 0.7358154106345126, 0.7358154106345126, 0.7358154106345126, 0.288564360017519, 0.7358154106345126, 0.7358154106345126, 0.288564360017519, 0.288564360017519, 0.288564360017519, 0.7358154106345126, 0.288564360017519, 0.288564360017519, 0.7358154106345126, 0.46086038909506877, 0.7358154106345126, 0.288564360017519, 0.2826827354331889, 0.46086038909506877, 0.288564360017519, 0.7358154106345126, 0.288564360017519, 0.288564360017519, 0.46086038909506877, 0.288564360017519, 0.2826827354331889, 0.7358154106345126, 0.288564360017519, 0.46086038909506877, 0.288564360017519, 0.7358154106345126, 0.7358154106345126, 0.7358154106345126, 0.7358154106345126, 0.7358154106345126, 0.288564360017519, 0.288564360017519, 0.7358154106345126, 0.288564360017519, 0.7358154106345126, 0.7358154106345126, 0.288564360017519, 0.288564360017519, 0.7358154106345126, 0.07000223131855442, 0.8544351149682679, 0.7358154106345126, 0.46086038909506877]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.131\n",
      "(*) epoch 2, cost 2.682\n",
      "(*) epoch 3, cost 2.125\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.591\n",
      "(*) epoch 2, cost 2.426\n",
      "(*) epoch 3, cost 1.898\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.835973287321343, 2.3245006857228905, 1.7644574670956685, 2.435696108525087, 2.435696108525087, 0.835973287321343, 2.9708965040725044, 1.2292570715482511, 2.3245006857228905, 2.435696108525087, 1.2292570715482511, 2.3245006857228905, 1.9312169014959826, 1.7644574670956685, 2.3245006857228905, 2.6444354556886576, 1.3404524943504474, 2.9708965040725044, 1.2292570715482511, 1.3404524943504474, 1.3404524943504474, 2.3245006857228905, 2.3245006857228905, 2.435696108525087, 2.9708965040725044, 1.9656262214462328, 2.859701081270308, 1.2292570715482511, 1.3404524943504474, 2.358910005673141, 2.859701081270308, 1.2292570715482511, 1.2292570715482511, 1.2292570715482511, 2.3245006857228905, 2.9708965040725044, 1.2292570715482511, 1.7644574670956685, 1.3404524943504474, 1.2292570715482511, 2.5776127198455967, 1.3404524943504474, 1.2292570715482511, 1.2292570715482511, 2.9708965040725044, 1.7644574670956685, 2.3245006857228905, 2.3245006857228905, 2.4664172970434004, 2.859701081270308]\n",
      "all_sum after preprocessing is: [-1.71403674e+00  5.42363440e-01 -3.06584063e-01  7.10920211e-01\n",
      "  7.10920211e-01 -1.71403674e+00  1.52220946e+00 -1.11787331e+00\n",
      "  5.42363440e-01  7.10920211e-01 -1.11787331e+00  5.42363440e-01\n",
      " -5.37999908e-02 -3.06584063e-01  5.42363440e-01  1.02733998e+00\n",
      " -9.49316537e-01  1.52220946e+00 -1.11787331e+00 -9.49316537e-01\n",
      " -9.49316537e-01  5.42363440e-01  5.42363440e-01  7.10920211e-01\n",
      "  1.52220946e+00 -1.64025510e-03  1.35365268e+00 -1.11787331e+00\n",
      " -9.49316537e-01  5.94523176e-01  1.35365268e+00 -1.11787331e+00\n",
      " -1.11787331e+00 -1.11787331e+00  5.42363440e-01  1.52220946e+00\n",
      " -1.11787331e+00 -3.06584063e-01 -9.49316537e-01 -1.11787331e+00\n",
      "  9.26046025e-01 -9.49316537e-01 -1.11787331e+00 -1.11787331e+00\n",
      "  1.52220946e+00 -3.06584063e-01  5.42363440e-01  5.42363440e-01\n",
      "  7.57489254e-01  1.35365268e+00]\n",
      "P is: [0.1526408649645206, 0.6323620427052691, 0.42394874852205583, 0.670604460989379, 0.670604460989379, 0.1526408649645206, 0.8208636037945934, 0.2464059762006739, 0.6323620427052691, 0.670604460989379, 0.2464059762006739, 0.6323620427052691, 0.4865532455423065, 0.42394874852205583, 0.6323620427052691, 0.7363998712688234, 0.2790222927704697, 0.8208636037945934, 0.2464059762006739, 0.2790222927704697, 0.2790222927704697, 0.6323620427052691, 0.6323620427052691, 0.670604460989379, 0.8208636037945934, 0.49958993631693377, 0.7947261558955698, 0.2464059762006739, 0.2790222927704697, 0.6444022979788168, 0.7947261558955698, 0.2464059762006739, 0.2464059762006739, 0.2464059762006739, 0.6323620427052691, 0.8208636037945934, 0.2464059762006739, 0.42394874852205583, 0.2790222927704697, 0.2464059762006739, 0.7162724215563536, 0.2790222927704697, 0.2464059762006739, 0.2464059762006739, 0.8208636037945934, 0.42394874852205583, 0.6323620427052691, 0.6323620427052691, 0.6808083755366039, 0.7947261558955698]\n",
      "all_sum before preprocessing is: [4.164297547143042, 4.164297547143042, 1.9319154329005346, 4.164297547143042, 4.164297547143042, 1.9319154329005346, 1.9319154329005346, 1.9319154329005346, 1.9319154329005346, 4.777816363052155, 4.726007466812677, 1.9319154329005346, 4.164297547143042, 4.726007466812677, 1.9319154329005346, 1.9319154329005346, 4.164297547143042, 1.9319154329005346, 4.164297547143042, 4.164297547143042, 4.164297547143042, 4.164297547143042, 1.9319154329005346, 4.164297547143042, 4.164297547143042, 2.4936253525701693, 1.9319154329005346, 4.164297547143042, 1.9319154329005346, 2.4936253525701693, 4.164297547143042, 4.164297547143042, 4.164297547143042, 1.9319154329005346, 1.9319154329005346, 1.9319154329005346, 1.9319154329005346, 4.164297547143042, 1.9319154329005346, 4.164297547143042, 2.4936253525701693, 4.164297547143042, 4.164297547143042, 4.164297547143042, 4.164297547143042, 4.164297547143042, 1.9319154329005346, 1.9319154329005346, 1.9319154329005346, 1.9319154329005346]\n",
      "all_sum after preprocessing is: [ 0.88854108  0.88854108 -1.08888806  0.88854108  0.88854108 -1.08888806\n",
      " -1.08888806 -1.08888806 -1.08888806  1.43199195  1.38609997 -1.08888806\n",
      "  0.88854108  1.38609997 -1.08888806 -1.08888806  0.88854108 -1.08888806\n",
      "  0.88854108  0.88854108  0.88854108  0.88854108 -1.08888806  0.88854108\n",
      "  0.88854108 -0.59132917 -1.08888806  0.88854108 -1.08888806 -0.59132917\n",
      "  0.88854108  0.88854108  0.88854108 -1.08888806 -1.08888806 -1.08888806\n",
      " -1.08888806  0.88854108 -1.08888806  0.88854108 -0.59132917  0.88854108\n",
      "  0.88854108  0.88854108  0.88854108  0.88854108 -1.08888806 -1.08888806\n",
      " -1.08888806 -1.08888806]\n",
      "P is: [0.7085890114600428, 0.7085890114600428, 0.2518277216821638, 0.7085890114600428, 0.7085890114600428, 0.2518277216821638, 0.2518277216821638, 0.2518277216821638, 0.2518277216821638, 0.8072114941883306, 0.7999688958588254, 0.2518277216821638, 0.7085890114600428, 0.7999688958588254, 0.2518277216821638, 0.2518277216821638, 0.7085890114600428, 0.2518277216821638, 0.7085890114600428, 0.7085890114600428, 0.7085890114600428, 0.7085890114600428, 0.2518277216821638, 0.7085890114600428, 0.7085890114600428, 0.35632993884224434, 0.2518277216821638, 0.7085890114600428, 0.2518277216821638, 0.35632993884224434, 0.7085890114600428, 0.7085890114600428, 0.7085890114600428, 0.2518277216821638, 0.2518277216821638, 0.2518277216821638, 0.2518277216821638, 0.7085890114600428, 0.2518277216821638, 0.7085890114600428, 0.35632993884224434, 0.7085890114600428, 0.7085890114600428, 0.7085890114600428, 0.7085890114600428, 0.7085890114600428, 0.2518277216821638, 0.2518277216821638, 0.2518277216821638, 0.2518277216821638]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.102\n",
      "(*) epoch 2, cost 2.705\n",
      "(*) epoch 3, cost 2.413\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.863\n",
      "(*) epoch 2, cost 1.561\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.2712536209415581, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 1.2712536209415581, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 1.9197863844101177, 1.2712536209415581, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 1.2712536209415581, 0.5210467778216257, 1.2712536209415581, 0.5210467778216257, 1.2712536209415581, 1.2712536209415581, 0.5210467778216257, 0.5210467778216257, 1.2712536209415581, 1.2712536209415581, 0.5210467778216257, 1.2712536209415581, 0.5210467778216257, 1.2712536209415581, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 0.5210467778216257, 1.2712536209415581, 1.2712536209415581, 0.5210467778216257, 0.5210467778216257]\n",
      "all_sum after preprocessing is: [ 1.43099514 -0.60539825 -0.60539825 -0.60539825 -0.60539825 -0.60539825\n",
      " -0.60539825 -0.60539825 -0.60539825 -0.60539825 -0.60539825  1.43099514\n",
      " -0.60539825 -0.60539825 -0.60539825  3.19140008  1.43099514 -0.60539825\n",
      " -0.60539825 -0.60539825 -0.60539825 -0.60539825  1.43099514 -0.60539825\n",
      "  1.43099514 -0.60539825  1.43099514  1.43099514 -0.60539825 -0.60539825\n",
      "  1.43099514  1.43099514 -0.60539825  1.43099514 -0.60539825  1.43099514\n",
      " -0.60539825 -0.60539825 -0.60539825 -0.60539825 -0.60539825 -0.60539825\n",
      " -0.60539825 -0.60539825 -0.60539825 -0.60539825  1.43099514  1.43099514\n",
      " -0.60539825 -0.60539825]\n",
      "P is: [0.807056322772595, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.807056322772595, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.9605093612389147, 0.807056322772595, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.807056322772595, 0.3531096332102536, 0.807056322772595, 0.3531096332102536, 0.807056322772595, 0.807056322772595, 0.3531096332102536, 0.3531096332102536, 0.807056322772595, 0.807056322772595, 0.3531096332102536, 0.807056322772595, 0.3531096332102536, 0.807056322772595, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.3531096332102536, 0.807056322772595, 0.807056322772595, 0.3531096332102536, 0.3531096332102536]\n",
      "all_sum before preprocessing is: [3.6757955998012415, 0.9735709915741593, 0.5531050349820583, 1.0914147092763322, 1.0914147092763322, 0.9735709915741593, 1.961184692626838, 1.961184692626838, 1.843340974924665, 0.5531050349820583, 2.5672250389349305, 1.0914147092763322, 2.3816506492189387, 0.5531050349820583, 3.97530469657971, 2.4994943669211116, 0.5531050349820583, 3.223378430931377, 0.5531050349820583, 3.6757955998012415, 1.961184692626838, 1.7179777182454918, 0.4352613172798855, 2.3816506492189387, 1.843340974924665, 1.961184692626838, 2.3816506492189387, 2.4994943669211116, 0.5531050349820583, 4.093148414281883, 1.961184692626838, 0.5531050349820583, 2.4994943669211116, 0.5531050349820583, 1.961184692626838, 2.4994943669211116, 0.5531050349820583, 1.961184692626838, 4.093148414281883, 2.4994943669211116, 1.6282255609977128, 4.986724886218762, 4.6314580885761565, 5.807759321456286, 0.5531050349820583, 2.6850687566371034, 1.961184692626838, 2.4994943669211116, 1.961184692626838, 1.0914147092763322]\n",
      "all_sum after preprocessing is: [ 1.27083642 -0.84191661 -1.17066083 -0.74977968 -0.74977968 -0.84191661\n",
      " -0.06974399 -0.06974399 -0.16188092 -1.17066083  0.40409285 -0.74977968\n",
      "  0.25900023 -1.17066083  1.50500968  0.35113715 -1.17066083  0.91711092\n",
      " -1.17066083  1.27083642 -0.06974399 -0.25989705 -1.26279775  0.25900023\n",
      " -0.16188092 -0.06974399  0.25900023  0.35113715 -1.17066083  1.5971466\n",
      " -0.06974399 -1.17066083  0.35113715 -1.17066083 -0.06974399  0.35113715\n",
      " -1.17066083 -0.06974399  1.5971466   0.35113715 -0.3300704   2.29579556\n",
      "  2.01802775  2.93772701 -1.17066083  0.49622977 -0.06974399  0.35113715\n",
      " -0.06974399 -0.74977968]\n",
      "P is: [0.7808858949464964, 0.30113127837302994, 0.2367355578195889, 0.32086930964348526, 0.32086930964348526, 0.30113127837302994, 0.4825710656759301, 0.4825710656759301, 0.4596179170582403, 0.2367355578195889, 0.5996706121524955, 0.32086930964348526, 0.564390509163419, 0.2367355578195889, 0.8183204634247724, 0.5868933081144072, 0.2367355578195889, 0.7144530701804762, 0.2367355578195889, 0.7808858949464964, 0.4825710656759301, 0.4353890154040607, 0.2204926508389447, 0.564390509163419, 0.4596179170582403, 0.4825710656759301, 0.564390509163419, 0.5868933081144072, 0.2367355578195889, 0.8316192058044707, 0.4825710656759301, 0.2367355578195889, 0.5868933081144072, 0.2367355578195889, 0.4825710656759301, 0.5868933081144072, 0.2367355578195889, 0.4825710656759301, 0.8316192058044707, 0.5868933081144072, 0.4182234945668248, 0.908528229653232, 0.882676920271431, 0.9496802170226161, 0.2367355578195889, 0.6215729057801629, 0.4825710656759301, 0.5868933081144072, 0.4825710656759301, 0.32086930964348526]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.751\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.808\n",
      "(*) epoch 2, cost 3.371\n",
      "(*) epoch 3, cost 2.883\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.5567227498783893, 2.9909857166076534, 2.9909857166076534, 3.5567227498783893, 3.8091596383309234, 3.8091596383309234, 2.9909857166076534, 3.8091596383309234, 3.8091596383309234, 4.1614832382147195, 4.46158859584472, 3.5567227498783893, 2.9909857166076534, 3.8091596383309234, 2.9909857166076534, 3.8091596383309234, 3.5567227498783893, 2.710332169369067, 3.8091596383309234, 3.64341467412145, 3.34330931649145, 2.9909857166076534, 2.9909857166076534, 3.8091596383309234, 2.87607713357854, 2.87607713357854, 2.9909857166076534, 3.8091596383309234, 3.8091596383309234, 3.8091596383309234, 2.9909857166076534, 4.374896671601659, 3.8091596383309234, 3.5567227498783893, 3.4418141668492757, 3.4418141668492757, 2.87607713357854, 2.87607713357854, 4.374896671601659, 3.8091596383309234, 3.8091596383309234, 4.46158859584472, 3.5567227498783893, 4.374896671601659, 2.9909857166076534, 3.5567227498783893, 3.64341467412145, 2.9909857166076534, 3.8091596383309234, 3.8091596383309234]\n",
      "all_sum after preprocessing is: [ 0.04880225 -1.14751839 -1.14751839  0.04880225  0.58261114  0.58261114\n",
      " -1.14751839  0.58261114  0.58261114  1.32764279  1.96225253  0.04880225\n",
      " -1.14751839  0.58261114 -1.14751839  0.58261114  0.04880225 -1.74099488\n",
      "  0.58261114  0.232123   -0.40248674 -1.14751839 -1.14751839  0.58261114\n",
      " -1.39050674 -1.39050674 -1.14751839  0.58261114  0.58261114  0.58261114\n",
      " -1.14751839  1.77893178  0.58261114  0.04880225 -0.19418611 -0.19418611\n",
      " -1.39050674 -1.39050674  1.77893178  0.58261114  0.58261114  1.96225253\n",
      "  0.04880225  1.77893178 -1.14751839  0.04880225  0.232123   -1.14751839\n",
      "  0.58261114  0.58261114]\n",
      "P is: [0.5121981406749826, 0.24094265100454218, 0.24094265100454218, 0.5121981406749826, 0.6416680077528398, 0.6416680077528398, 0.24094265100454218, 0.6416680077528398, 0.6416680077528398, 0.7904504565160738, 0.8767765208336801, 0.5121981406749826, 0.24094265100454218, 0.6416680077528398, 0.24094265100454218, 0.6416680077528398, 0.5121981406749826, 0.14918660992731642, 0.6416680077528398, 0.5577715824221492, 0.40071501979305474, 0.24094265100454218, 0.24094265100454218, 0.6416680077528398, 0.1993268706388057, 0.1993268706388057, 0.24094265100454218, 0.6416680077528398, 0.6416680077528398, 0.6416680077528398, 0.24094265100454218, 0.8555649117156535, 0.6416680077528398, 0.5121981406749826, 0.45160545092786086, 0.45160545092786086, 0.1993268706388057, 0.1993268706388057, 0.8555649117156535, 0.6416680077528398, 0.6416680077528398, 0.8767765208336801, 0.5121981406749826, 0.8555649117156535, 0.24094265100454218, 0.5121981406749826, 0.5577715824221492, 0.24094265100454218, 0.6416680077528398, 0.6416680077528398]\n",
      "all_sum before preprocessing is: [3.4734532934383857, 3.33297690460785, 4.481753814023178, 3.0286570871349805, 2.8843924184167924, 4.481753814023178, 3.4734532934383857, 3.4734532934383857, 3.0286570871349805, 3.0286570871349805, 2.8881806983044447, 2.324676384023057, 3.4734532934383857, 1.879880177719652, 3.4734532934383857, 3.0286570871349805, 3.0286570871349805, 4.481753814023178, 3.4478967326981804, 3.4734532934383857, 3.0286570871349805, 3.0286570871349805, 3.4734532934383857, 2.8843924184167924, 3.0286570871349805, 3.4734532934383857, 4.036957607719773, 4.036957607719773, 3.4734532934383857, 2.439596212113387, 2.8843924184167924, 3.4734532934383857, 3.0286570871349805, 2.439596212113387, 3.4734532934383857, 3.4734532934383857, 3.0286570871349805, 3.0286570871349805, 3.0286570871349805, 3.4734532934383857, 3.4478967326981804, 2.8843924184167924, 3.4734532934383857, 3.0286570871349805, 4.481753814023178, 1.879880177719652, 2.439596212113387, 3.4734532934383857, 3.0286570871349805, 3.4734532934383857]\n",
      "all_sum after preprocessing is: [ 0.4099186   0.16251278  2.18572893 -0.37345271 -0.62753042  2.18572893\n",
      "  0.4099186   0.4099186  -0.37345271 -0.37345271 -0.62085853 -1.61329755\n",
      "  0.4099186  -2.39666886  0.4099186  -0.37345271 -0.37345271  2.18572893\n",
      "  0.3649086   0.4099186  -0.37345271 -0.37345271  0.4099186  -0.62753042\n",
      " -0.37345271  0.4099186   1.40235762  1.40235762  0.4099186  -1.41090173\n",
      " -0.62753042  0.4099186  -0.37345271 -1.41090173  0.4099186   0.4099186\n",
      " -0.37345271 -0.37345271 -0.37345271  0.4099186   0.3649086  -0.62753042\n",
      "  0.4099186  -0.37345271  2.18572893 -2.39666886 -1.41090173  0.4099186\n",
      " -0.37345271  0.4099186 ]\n",
      "P is: [0.6010683606864867, 0.5405390122037899, 0.8989606238349744, 0.40770699004680677, 0.3480707185957064, 0.8989606238349744, 0.6010683606864867, 0.6010683606864867, 0.40770699004680677, 0.40770699004680677, 0.3495862169098677, 0.16613129489872075, 0.6010683606864867, 0.0834270654613892, 0.6010683606864867, 0.40770699004680677, 0.40770699004680677, 0.8989606238349744, 0.5902281468595362, 0.6010683606864867, 0.40770699004680677, 0.40770699004680677, 0.6010683606864867, 0.3480707185957064, 0.40770699004680677, 0.6010683606864867, 0.8025577410351854, 0.8025577410351854, 0.6010683606864867, 0.19609186943138676, 0.3480707185957064, 0.6010683606864867, 0.40770699004680677, 0.19609186943138676, 0.6010683606864867, 0.6010683606864867, 0.40770699004680677, 0.40770699004680677, 0.40770699004680677, 0.6010683606864867, 0.5902281468595362, 0.3480707185957064, 0.6010683606864867, 0.40770699004680677, 0.8989606238349744, 0.0834270654613892, 0.19609186943138676, 0.6010683606864867, 0.40770699004680677, 0.6010683606864867]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.848\n",
      "(*) epoch 2, cost 1.862\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.370\n",
      "(*) epoch 2, cost 3.483\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.9887909831164197, 3.0782050440589495, 1.5348641421403246, 1.9887909831164197, 4.273911149664357, 1.9887909831164197, 1.5348641421403246, 1.5348641421403246, 3.819984308688262, 1.5348641421403246, 1.5348641421403246, 1.9887909831164197, 1.9887909831164197, 1.9887909831164197, 1.9887909831164197, 1.5348641421403246, 1.5348641421403246, 1.9887909831164197, 1.5348641421403246, 3.532131885035045, 4.273911149664357, 1.9887909831164197, 5.363325210606887, 1.9887909831164197, 1.9887909831164197, 3.0782050440589495, 1.9887909831164197, 1.5348641421403246, 3.819984308688262, 4.273911149664357, 4.273911149664357, 1.9887909831164197, 1.5348641421403246, 4.273911149664357, 1.5348641421403246, 1.5348641421403246, 1.5348641421403246, 1.5348641421403246, 1.9887909831164197, 1.9887909831164197, 1.9887909831164197, 1.5348641421403246, 1.9887909831164197, 1.9887909831164197, 1.9887909831164197, 1.9887909831164197, 1.9887909831164197, 1.5348641421403246, 1.5348641421403246, 1.5348641421403246]\n",
      "all_sum after preprocessing is: [-0.28388137  0.81953018 -0.74364056 -0.28388137  2.03059949 -0.28388137\n",
      " -0.74364056 -0.74364056  1.5708403  -0.74364056 -0.74364056 -0.28388137\n",
      " -0.28388137 -0.28388137 -0.28388137 -0.74364056 -0.74364056 -0.28388137\n",
      " -0.74364056  1.27928936  2.03059949 -0.28388137  3.13401104 -0.28388137\n",
      " -0.28388137  0.81953018 -0.28388137 -0.74364056  1.5708403   2.03059949\n",
      "  2.03059949 -0.28388137 -0.74364056  2.03059949 -0.74364056 -0.74364056\n",
      " -0.74364056 -0.74364056 -0.28388137 -0.28388137 -0.28388137 -0.74364056\n",
      " -0.28388137 -0.28388137 -0.28388137 -0.28388137 -0.28388137 -0.74364056\n",
      " -0.74364056 -0.74364056]\n",
      "P is: [0.4295024641948352, 0.6941366013857574, 0.32220856804329795, 0.4295024641948352, 0.883972578338998, 0.4295024641948352, 0.32220856804329795, 0.32220856804329795, 0.8279033668409475, 0.32220856804329795, 0.32220856804329795, 0.4295024641948352, 0.4295024641948352, 0.4295024641948352, 0.4295024641948352, 0.32220856804329795, 0.32220856804329795, 0.4295024641948352, 0.32220856804329795, 0.7823287863175614, 0.883972578338998, 0.4295024641948352, 0.9582740689033072, 0.4295024641948352, 0.4295024641948352, 0.6941366013857574, 0.4295024641948352, 0.32220856804329795, 0.8279033668409475, 0.883972578338998, 0.883972578338998, 0.4295024641948352, 0.32220856804329795, 0.883972578338998, 0.32220856804329795, 0.32220856804329795, 0.32220856804329795, 0.32220856804329795, 0.4295024641948352, 0.4295024641948352, 0.4295024641948352, 0.32220856804329795, 0.4295024641948352, 0.4295024641948352, 0.4295024641948352, 0.4295024641948352, 0.4295024641948352, 0.32220856804329795, 0.32220856804329795, 0.32220856804329795]\n",
      "all_sum before preprocessing is: [6.637407995064874, 5.454848279147907, 6.660045420322251, 3.5866336400067214, 5.499913224297302, 3.5297969329651226, 5.2317068913534595, 6.660045420322251, 3.628532995210016, 4.049147175436493, 5.254344316610837, 5.249804063332949, 4.067244347415983, 5.254344316610837, 7.080659600548728, 5.03423409892143, 3.1091827527386457, 5.254344316610837, 6.637407995064874, 6.637407995064874, 6.660045420322251, 5.03423409892143, 5.254344316610837, 3.628532995210016, 4.7349940741394665, 6.660045420322251, 5.254344316610837, 5.254344316610837, 5.254344316610837, 6.660045420322251, 5.03423409892143, 5.03423409892143, 5.03423409892143, 4.049147175436493, 5.03423409892143, 7.080659600548728, 5.03423409892143, 5.454848279147907, 5.674958496837314, 5.674958496837314, 6.660045420322251, 5.693055668816803, 3.628532995210016, 7.080659600548728, 3.5297969329651226, 6.637407995064874, 6.637407995064874, 5.254344316610837, 5.254344316610837, 5.03423409892143]\n",
      "all_sum after preprocessing is: [ 1.19767199  0.09877094  1.21870796 -1.63727925  0.14064782 -1.69009512\n",
      " -0.1085846   1.21870796 -1.59834401 -1.20748564 -0.08754863 -0.09176769\n",
      " -1.19066873 -0.08754863  1.60956633 -0.29208743 -2.08095349 -0.08754863\n",
      "  1.19767199  1.19767199  1.21870796 -0.29208743 -0.08754863 -1.59834401\n",
      " -0.5701581   1.21870796 -0.08754863 -0.08754863 -0.08754863  1.21870796\n",
      " -0.29208743 -0.29208743 -0.29208743 -1.20748564 -0.29208743  1.60956633\n",
      " -0.29208743  0.09877094  0.30330974  0.30330974  1.21870796  0.32012665\n",
      " -1.59834401  1.60956633 -1.69009512  1.19767199  1.19767199 -0.08754863\n",
      " -0.08754863 -0.29208743]\n",
      "P is: [0.7681103842390348, 0.5246726800931631, 0.7718360940536874, 0.16283561508303232, 0.5351041064777271, 0.15576333124321376, 0.4728804919485235, 0.7718360940536874, 0.16821318897525078, 0.230146239592755, 0.4781268125782663, 0.4770741651108703, 0.2331393546909535, 0.4781268125782663, 0.833351168053433, 0.4274929066595262, 0.11096187057310407, 0.4781268125782663, 0.7681103842390348, 0.7681103842390348, 0.7718360940536874, 0.4274929066595262, 0.4781268125782663, 0.16821318897525078, 0.36120034412158264, 0.7718360940536874, 0.4781268125782663, 0.4781268125782663, 0.4781268125782663, 0.7718360940536874, 0.4274929066595262, 0.4274929066595262, 0.4274929066595262, 0.230146239592755, 0.4274929066595262, 0.833351168053433, 0.4274929066595262, 0.5246726800931631, 0.5752514110657053, 0.5752514110657053, 0.7718360940536874, 0.5793551184439462, 0.16821318897525078, 0.833351168053433, 0.15576333124321376, 0.7681103842390348, 0.7681103842390348, 0.4781268125782663, 0.4781268125782663, 0.4274929066595262]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.955\n",
      "(*) epoch 2, cost 1.724\n",
      "(*) epoch 3, cost 1.296\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.208\n",
      "(*) epoch 2, cost 3.931\n",
      "(*) epoch 3, cost 3.283\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.3962727687419392, 0.5814387210240785, 0.5814387210240785, 1.463110298977619, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 2.280717278308609, 1.463110298977619, 0.5814387210240785, 0.8790376381737437, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 1.4658832305907488, 2.2779443466954796, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 2.280717278308609, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 0.8790376381737437, 0.5814387210240785, 1.3962727687419392, 1.3962727687419392, 1.3962727687419392, 1.3962727687419392, 0.5814387210240785, 0.5814387210240785, 0.8790376381737437, 1.3962727687419392, 0.5814387210240785, 1.463110298977619, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785, 0.8790376381737437, 0.5814387210240785, 1.3962727687419392, 0.5814387210240785, 0.5814387210240785, 1.4658832305907488, 0.5814387210240785, 0.5814387210240785, 0.5814387210240785]\n",
      "all_sum after preprocessing is: [ 0.98663527 -0.66495367 -0.66495367  1.12210841 -0.66495367 -0.66495367\n",
      " -0.66495367  2.77931782  1.12210841 -0.66495367 -0.06174976 -0.66495367\n",
      " -0.66495367 -0.66495367 -0.66495367  1.12772887  2.77369736 -0.66495367\n",
      " -0.66495367 -0.66495367  2.77931782 -0.66495367 -0.66495367 -0.66495367\n",
      " -0.66495367 -0.66495367 -0.06174976 -0.66495367  0.98663527  0.98663527\n",
      "  0.98663527  0.98663527 -0.66495367 -0.66495367 -0.06174976  0.98663527\n",
      " -0.66495367  1.12210841 -0.66495367 -0.66495367 -0.66495367 -0.06174976\n",
      " -0.66495367  0.98663527 -0.66495367 -0.66495367  1.12772887 -0.66495367\n",
      " -0.66495367 -0.66495367]\n",
      "P is: [0.7284228137115814, 0.3396277173563271, 0.3396277173563271, 0.7543795957168564, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.9415479115684693, 0.7543795957168564, 0.3396277173563271, 0.48456746233671705, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.7554195271639952, 0.9412378182568971, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.9415479115684693, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.48456746233671705, 0.3396277173563271, 0.7284228137115814, 0.7284228137115814, 0.7284228137115814, 0.7284228137115814, 0.3396277173563271, 0.3396277173563271, 0.48456746233671705, 0.7284228137115814, 0.3396277173563271, 0.7543795957168564, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271, 0.48456746233671705, 0.3396277173563271, 0.7284228137115814, 0.3396277173563271, 0.3396277173563271, 0.7554195271639952, 0.3396277173563271, 0.3396277173563271, 0.3396277173563271]\n",
      "all_sum before preprocessing is: [2.358765246062333, 2.030141880991162, 2.358765246062333, 2.030141880991162, 2.030141880991162, 1.9598480653948436, 3.2139808811930637, 2.030141880991162, 3.8763050945117614, 2.030141880991162, 2.030141880991162, 2.030141880991162, 4.204928459582932, 2.358765246062333, 3.8763050945117614, 2.030141880991162, 2.358765246062333, 4.204928459582932, 3.8763050945117614, 3.8763050945117614, 2.358765246062333, 2.030141880991162, 2.358765246062333, 2.030141880991162, 2.030141880991162, 2.030141880991162, 3.8763050945117614, 2.358765246062333, 3.8060112789154426, 4.204928459582932, 2.030141880991162, 3.4773879138442716, 3.8763050945117614, 4.204928459582932, 4.204928459582932, 2.030141880991162, 4.204928459582932, 4.204928459582932, 2.030141880991162, 2.030141880991162, 4.5580180294840735, 3.4773879138442716, 3.8763050945117614, 3.8763050945117614, 3.8763050945117614, 4.204928459582932, 3.8763050945117614, 3.8763050945117614, 3.8763050945117614, 4.204928459582932]\n",
      "all_sum after preprocessing is: [-0.76061138 -1.10865996 -0.76061138 -1.10865996 -1.10865996 -1.1831089\n",
      "  0.14515677 -1.10865996  0.84663154 -1.10865996 -1.10865996 -1.10865996\n",
      "  1.19468011 -0.76061138  0.84663154 -1.10865996 -0.76061138  1.19468011\n",
      "  0.84663154  0.84663154 -0.76061138 -1.10865996 -0.76061138 -1.10865996\n",
      " -1.10865996 -1.10865996  0.84663154 -0.76061138  0.77218259  1.19468011\n",
      " -1.10865996  0.42413402  0.84663154  1.19468011  1.19468011 -1.10865996\n",
      "  1.19468011  1.19468011 -1.10865996 -1.10865996  1.5686411   0.42413402\n",
      "  0.84663154  0.84663154  0.84663154  1.19468011  0.84663154  0.84663154\n",
      "  0.84663154  1.19468011]\n",
      "P is: [0.3185135426764125, 0.24812079847330754, 0.3185135426764125, 0.24812079847330754, 0.24812079847330754, 0.23449366835159355, 0.5362256082731236, 0.24812079847330754, 0.6998600530948599, 0.24812079847330754, 0.24812079847330754, 0.24812079847330754, 0.7675770525132117, 0.3185135426764125, 0.6998600530948599, 0.24812079847330754, 0.3185135426764125, 0.7675770525132117, 0.6998600530948599, 0.6998600530948599, 0.3185135426764125, 0.24812079847330754, 0.3185135426764125, 0.24812079847330754, 0.24812079847330754, 0.24812079847330754, 0.6998600530948599, 0.3185135426764125, 0.6839928430946498, 0.7675770525132117, 0.24812079847330754, 0.6044720602842871, 0.6998600530948599, 0.7675770525132117, 0.7675770525132117, 0.24812079847330754, 0.7675770525132117, 0.7675770525132117, 0.24812079847330754, 0.24812079847330754, 0.8275898003082318, 0.6044720602842871, 0.6998600530948599, 0.6998600530948599, 0.6998600530948599, 0.7675770525132117, 0.6998600530948599, 0.6998600530948599, 0.6998600530948599, 0.7675770525132117]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.196\n",
      "(*) epoch 2, cost 1.504\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.545\n",
      "(*) epoch 2, cost 2.837\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8551955253346963, 2.9580984708703877, 1.8551955253346963, 2.0024301745100868, 2.810863821694997, 2.9580984708703877, 1.8551955253346963, 2.810863821694997, 2.8842015362544657, 1.8926957554395198, 1.8551955253346963, 1.8551955253346963, 1.7454611062641292, 1.8551955253346963, 1.8551955253346963, 1.8551955253346963, 3.476074528034998, 2.810863821694997, 2.8206083913322084, 1.8551955253346963, 1.8551955253346963, 3.5829007643688087, 1.8551955253346963, 2.7011294026244297, 1.8551955253346963, 1.8551955253346963, 1.8551955253346963, 2.0024301745100868, 2.810863821694997, 1.8551955253346963, 2.9580984708703877, 1.8551955253346963, 1.7454611062641292, 2.0024301745100868, 2.810863821694997, 1.8551955253346963, 1.8551955253346963, 2.0024301745100868, 1.8551955253346963, 1.8551955253346963, 1.8551955253346963, 1.8551955253346963, 2.810863821694997, 1.7454611062641292, 2.0024301745100868, 1.8551955253346963, 1.8551955253346963, 2.810863821694997, 1.8551955253346963, 2.0024301745100868]\n",
      "all_sum after preprocessing is: [-0.66072804  1.51078889 -0.66072804 -0.37083623  1.22089707  1.51078889\n",
      " -0.66072804  1.22089707  1.36529245 -0.58689345 -0.66072804 -0.66072804\n",
      " -0.87678526 -0.66072804 -0.66072804 -0.66072804  2.53063726  1.22089707\n",
      "  1.24008326 -0.66072804 -0.66072804  2.74096853 -0.66072804  1.00483985\n",
      " -0.66072804 -0.66072804 -0.66072804 -0.37083623  1.22089707 -0.66072804\n",
      "  1.51078889 -0.66072804 -0.87678526 -0.37083623  1.22089707 -0.66072804\n",
      " -0.66072804 -0.37083623 -0.66072804 -0.66072804 -0.66072804 -0.66072804\n",
      "  1.22089707 -0.87678526 -0.37083623 -0.66072804 -0.66072804  1.22089707\n",
      " -0.66072804 -0.37083623]\n",
      "P is: [0.34057608695843533, 0.819178090271378, 0.34057608695843533, 0.40833897523246815, 0.7722213793884645, 0.819178090271378, 0.34057608695843533, 0.7722213793884645, 0.7966185137373669, 0.3573479581746215, 0.34057608695843533, 0.34057608695843533, 0.29384439444266275, 0.34057608695843533, 0.34057608695843533, 0.34057608695843533, 0.9262618904881783, 0.7722213793884645, 0.7755785061740126, 0.34057608695843533, 0.34057608695843533, 0.9394012552748549, 0.34057608695843533, 0.7320090863592993, 0.34057608695843533, 0.34057608695843533, 0.34057608695843533, 0.40833897523246815, 0.7722213793884645, 0.34057608695843533, 0.819178090271378, 0.34057608695843533, 0.29384439444266275, 0.40833897523246815, 0.7722213793884645, 0.34057608695843533, 0.34057608695843533, 0.40833897523246815, 0.34057608695843533, 0.34057608695843533, 0.34057608695843533, 0.34057608695843533, 0.7722213793884645, 0.29384439444266275, 0.40833897523246815, 0.34057608695843533, 0.34057608695843533, 0.7722213793884645, 0.34057608695843533, 0.40833897523246815]\n",
      "all_sum before preprocessing is: [0.7806123383862639, 0.6319127234544826, 0.6319127234544826, 1.1634932603237236, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 1.0561646831469023, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 1.4177980740551348, 1.2690984591233534, 0.6319127234544826, 1.0780955709865667, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 1.0780955709865667, 1.0780955709865667, 0.6319127234544826, 0.6319127234544826, 1.0780955709865667, 1.1634932603237236, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 1.0780955709865667, 0.6319127234544826, 1.0780955709865667, 1.4177980740551348, 0.6319127234544826, 1.0780955709865667, 0.6319127234544826, 0.6319127234544826, 1.0780955709865667, 1.0780955709865667, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 0.6319127234544826, 1.0780955709865667]\n",
      "all_sum after preprocessing is: [-0.07096505 -0.67609589 -0.67609589  1.4871631  -0.67609589 -0.67609589\n",
      " -0.67609589  1.05039107 -0.67609589 -0.67609589 -0.67609589  2.5220527\n",
      "  1.91692186 -0.67609589  1.13963849 -0.67609589 -0.67609589 -0.67609589\n",
      " -0.67609589  1.13963849  1.13963849 -0.67609589 -0.67609589  1.13963849\n",
      "  1.4871631  -0.67609589 -0.67609589 -0.67609589 -0.67609589 -0.67609589\n",
      " -0.67609589 -0.67609589  1.13963849 -0.67609589  1.13963849  2.5220527\n",
      " -0.67609589  1.13963849 -0.67609589 -0.67609589  1.13963849  1.13963849\n",
      " -0.67609589 -0.67609589 -0.67609589 -0.67609589 -0.67609589 -0.67609589\n",
      " -0.67609589  1.13963849]\n",
      "P is: [0.4822661800348364, 0.3371332159019176, 0.3371332159019176, 0.8156520870266574, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.7408499880370357, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.9256734087817559, 0.8717947879408515, 0.3371332159019176, 0.7576132584807348, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.7576132584807348, 0.7576132584807348, 0.3371332159019176, 0.3371332159019176, 0.7576132584807348, 0.8156520870266574, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.7576132584807348, 0.3371332159019176, 0.7576132584807348, 0.9256734087817559, 0.3371332159019176, 0.7576132584807348, 0.3371332159019176, 0.3371332159019176, 0.7576132584807348, 0.7576132584807348, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.3371332159019176, 0.7576132584807348]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.603\n",
      "(*) epoch 2, cost 1.806\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.340\n",
      "(*) epoch 2, cost 2.554\n",
      "(*) epoch 3, cost 1.862\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 1.276011570261814, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 0.09261227587986257, 2.4007366107773924, 0.09261227587986257, 0.09261227587986257, 2.4007366107773924, 2.4007366107773924, 0.09261227587986257]\n",
      "all_sum after preprocessing is: [-0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558\n",
      " -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558\n",
      " -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558\n",
      " -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558\n",
      "  1.80149542 -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558\n",
      " -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558\n",
      " -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558 -0.28604558\n",
      " -0.28604558 -0.28604558  3.78553381 -0.28604558 -0.28604558  3.78553381\n",
      "  3.78553381 -0.28604558]\n",
      "P is: [0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.8583308738391602, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.42897224804603, 0.9778069658948454, 0.42897224804603, 0.42897224804603, 0.9778069658948454, 0.9778069658948454, 0.42897224804603]\n",
      "all_sum before preprocessing is: [4.07197469148418, 3.277701666655929, 2.879560824088733, 3.277701666655929, 4.27933082698096, 4.07197469148418, 3.277701666655929, 3.8945173940674938, 4.07197469148418, 3.277701666655929, 4.07197469148418, 3.8945173940674938, 3.1002443692392436, 4.21870069454897, 4.628160286463755, 3.277701666655929, 2.294705605726426, 3.1002443692392436, 5.012973719377221, 4.07197469148418, 3.8945173940674938, 3.277701666655929, 3.8945173940674938, 3.833887261635504, 3.1002443692392436, 4.805617583880441, 3.2664359279713624, 4.101873529564274, 3.277701666655929, 4.101873529564274, 4.07197469148418, 4.011344559052191, 3.277701666655929, 3.473792063468142, 3.2664359279713624, 3.277701666655929, 3.833887261635504, 3.277701666655929, 3.088978630554677, 3.473792063468142, 3.1002443692392436, 3.307600504736023, 3.1002443692392436, 3.1002443692392436, 3.8945173940674938, 4.101873529564274, 4.07197469148418, 3.1002443692392436, 4.07197469148418, 4.27933082698096]\n",
      "all_sum after preprocessing is: [ 0.77242732 -0.70156335 -1.4404225  -0.70156335  1.15723331  0.77242732\n",
      " -0.70156335  0.44310681  0.77242732 -0.70156335  0.77242732  0.44310681\n",
      " -1.03088387  1.04471752  1.80458171 -0.70156335 -2.52578121 -1.03088387\n",
      "  2.5187082   0.77242732  0.44310681 -0.70156335  0.44310681  0.33059103\n",
      " -1.03088387  2.13390222 -0.72247001  0.82791279 -0.70156335  0.82791279\n",
      "  0.77242732  0.65991154 -0.70156335 -0.33766403 -0.72247001 -0.70156335\n",
      "  0.33059103 -0.70156335 -1.05179053 -0.33766403 -1.03088387 -0.64607789\n",
      " -1.03088387 -1.03088387  0.44310681  0.82791279  0.77242732 -1.03088387\n",
      "  0.77242732  1.15723331]\n",
      "P is: [0.684045738574464, 0.331465703090844, 0.19147993000099076, 0.331465703090844, 0.7608296285881209, 0.684045738574464, 0.331465703090844, 0.6089990713967941, 0.684045738574464, 0.331465703090844, 0.684045738574464, 0.6089990713967941, 0.2629127832496501, 0.7397592293330031, 0.8587057484070414, 0.331465703090844, 0.07407046904156653, 0.2629127832496501, 0.9254429720236176, 0.684045738574464, 0.6089990713967941, 0.331465703090844, 0.6089990713967941, 0.5819031757520021, 0.2629127832496501, 0.8941548904861409, 0.3268493014912507, 0.695913419356472, 0.331465703090844, 0.695913419356472, 0.684045738574464, 0.6592405174043592, 0.331465703090844, 0.4163770233195815, 0.3268493014912507, 0.331465703090844, 0.5819031757520021, 0.331465703090844, 0.2588814185513661, 0.4163770233195815, 0.2629127832496501, 0.3438739194817385, 0.2629127832496501, 0.2629127832496501, 0.6089990713967941, 0.695913419356472, 0.684045738574464, 0.2629127832496501, 0.684045738574464, 0.7608296285881209]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.269\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.092\n",
      "(*) epoch 2, cost 3.835\n",
      "(*) epoch 3, cost 3.381\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.960338012078215, 2.960338012078215, 2.720692698365099, 2.659646298441055, 2.960338012078215, 2.960338012078215, 2.659646298441055, 2.960338012078215, 2.659646298441055, 2.960338012078215, 2.960338012078215, 2.960338012078215, 2.659646298441055, 2.960338012078215, 2.960338012078215, 2.659646298441055, 2.960338012078215, 2.960338012078215, 2.420000984727939, 2.720692698365099, 2.720692698365099, 2.960338012078215, 2.960338012078215, 2.659646298441055, 2.960338012078215, 2.960338012078215, 5.099466314851554, 2.659646298441055, 2.960338012078215, 2.960338012078215, 2.659646298441055, 2.659646298441055, 2.960338012078215, 2.960338012078215, 2.960338012078215, 2.960338012078215, 2.720692698365099, 2.960338012078215, 2.420000984727939, 2.960338012078215, 2.960338012078215, 2.960338012078215, 2.960338012078215, 2.659646298441055, 2.960338012078215, 2.960338012078215, 2.659646298441055, 2.420000984727939, 2.960338012078215, 2.659646298441055]\n",
      "all_sum after preprocessing is: [ 0.22565305  0.22565305 -0.44216418 -0.61228158  0.22565305  0.22565305\n",
      " -0.61228158  0.22565305 -0.61228158  0.22565305  0.22565305  0.22565305\n",
      " -0.61228158  0.22565305  0.22565305 -0.61228158  0.22565305  0.22565305\n",
      " -1.2800988  -0.44216418 -0.44216418  0.22565305  0.22565305 -0.61228158\n",
      "  0.22565305  0.22565305  6.18674073 -0.61228158  0.22565305  0.22565305\n",
      " -0.61228158 -0.61228158  0.22565305  0.22565305  0.22565305  0.22565305\n",
      " -0.44216418  0.22565305 -1.2800988   0.22565305  0.22565305  0.22565305\n",
      "  0.22565305 -0.61228158  0.22565305  0.22565305 -0.61228158 -1.2800988\n",
      "  0.22565305 -0.61228158]\n",
      "P is: [0.5561750969533348, 0.5561750969533348, 0.3912254094474974, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.3515389147626793, 0.5561750969533348, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.5561750969533348, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.21753340539460017, 0.3912254094474974, 0.3912254094474974, 0.5561750969533348, 0.5561750969533348, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.9979477019909656, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.3515389147626793, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.5561750969533348, 0.5561750969533348, 0.3912254094474974, 0.5561750969533348, 0.21753340539460017, 0.5561750969533348, 0.5561750969533348, 0.5561750969533348, 0.5561750969533348, 0.3515389147626793, 0.5561750969533348, 0.5561750969533348, 0.3515389147626793, 0.21753340539460017, 0.5561750969533348, 0.3515389147626793]\n",
      "all_sum before preprocessing is: [8.747269261060314, 9.681152352667107, 9.322610587305213, 9.382512383664995, 9.382512383664995, 8.115463635824176, 6.523102055204803, 9.382512383664995, 6.0076625253196845, 8.115463635824176, 7.202014470428519, 8.747269261060314, 9.382512383664995, 8.690804962069073, 6.523102055204803, 8.807171057420096, 5.3159551037237645, 8.630903165709292, 6.0076625253196845, 8.747269261060314, 8.055561839464394, 8.115463635824176, 8.747269261060314, 9.322610587305213, 8.690804962069073, 8.630903165709292, 8.690804962069073, 5.947760728959904, 6.0076625253196845, 8.055561839464394, 9.110495816779007, 5.947760728959904, 9.382512383664995, 8.055561839464394, 6.57020884519238, 5.256053307363984, 8.055561839464394, 8.115463635824176, 9.382512383664995, 8.115463635824176, 8.630903165709292, 8.055561839464394, 6.523102055204803, 5.891296429968663, 6.583003851564584, 8.690804962069073, 8.807171057420096, 5.947760728959904, 5.891296429968663, 8.115463635824176]\n",
      "all_sum after preprocessing is: [ 0.66560075  1.38410311  1.10825155  1.15433824  1.15433824  0.17950796\n",
      " -1.04560851  1.15433824 -1.44217262  0.17950796 -0.52327313  0.66560075\n",
      "  1.15433824  0.62215877 -1.04560851  0.71168744 -1.9743521   0.57607208\n",
      " -1.44217262  0.66560075  0.13342127  0.17950796  0.66560075  1.10825155\n",
      "  0.62215877  0.57607208  0.62215877 -1.48825931 -1.44217262  0.13342127\n",
      "  0.94505665 -1.48825931  1.15433824  0.13342127 -1.00936592 -2.02043879\n",
      "  0.13342127  0.17950796  1.15433824  0.17950796  0.57607208  0.13342127\n",
      " -1.04560851 -1.53170129 -0.99952181  0.62215877  0.71168744 -1.48825931\n",
      " -1.53170129  0.17950796]\n",
      "P is: [0.66051739442276, 0.7996491692711817, 0.7518030031096471, 0.7603024226387034, 0.7603024226387034, 0.5447568714394349, 0.26006927951340086, 0.7603024226387034, 0.19120913167839398, 0.5447568714394349, 0.3720871849429284, 0.66051739442276, 0.7603024226387034, 0.6507093670490167, 0.26006927951340086, 0.6707739151513358, 0.1219221966325258, 0.6401630909763151, 0.19120913167839398, 0.66051739442276, 0.5333059252506321, 0.5447568714394349, 0.66051739442276, 0.7518030031096471, 0.6507093670490167, 0.6401630909763151, 0.6507093670490167, 0.1841831392769181, 0.19120913167839398, 0.5333059252506321, 0.7201199438769282, 0.1841831392769181, 0.7603024226387034, 0.5333059252506321, 0.2671039599654373, 0.11707362699286833, 0.5333059252506321, 0.5447568714394349, 0.7603024226387034, 0.5447568714394349, 0.6401630909763151, 0.5333059252506321, 0.26006927951340086, 0.17774490291843192, 0.26903544883580915, 0.6507093670490167, 0.6707739151513358, 0.1841831392769181, 0.17774490291843192, 0.5447568714394349]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.283\n",
      "(*) epoch 2, cost 2.188\n",
      "(*) epoch 3, cost 1.730\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.136\n",
      "(*) epoch 2, cost 3.512\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 2.294811406192574, 0.23433638184985547, 1.4569329328081078, 3.5056987590817634, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 3.3215748448050846, 1.4569329328081078, 1.4569329328081078, 1.8707723304294395, 3.5056987590817634, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 3.5056987590817634, 2.294811406192574, 3.5056987590817634, 1.4569329328081078, 1.4569329328081078, 3.5056987590817634, 2.294811406192574, 1.4569329328081078, 2.294811406192574, 0.23433638184985547, 1.4569329328081078, 1.4569329328081078, 2.1580467106892676, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078, 1.4569329328081078]\n",
      "all_sum after preprocessing is: [-0.38505119 -0.38505119 -0.38505119 -0.38505119 -0.38505119 -0.38505119\n",
      " -0.38505119  0.7566046  -2.05090664 -0.38505119  2.40650562 -0.38505119\n",
      " -0.38505119 -0.38505119 -0.38505119 -0.38505119 -0.38505119 -0.38505119\n",
      " -0.38505119 -0.38505119  2.1556266  -0.38505119 -0.38505119  0.17882789\n",
      "  2.40650562 -0.38505119 -0.38505119 -0.38505119 -0.38505119  2.40650562\n",
      "  0.7566046   2.40650562 -0.38505119 -0.38505119  2.40650562  0.7566046\n",
      " -0.38505119  0.7566046  -2.05090664 -0.38505119 -0.38505119  0.57025513\n",
      " -0.38505119 -0.38505119 -0.38505119 -0.38505119 -0.38505119 -0.38505119\n",
      " -0.38505119 -0.38505119]\n",
      "P is: [0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.6806161011176571, 0.11396080221370143, 0.4049091917109608, 0.917322046030731, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.8961933916878839, 0.4049091917109608, 0.4049091917109608, 0.5445882104123135, 0.917322046030731, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.917322046030731, 0.6806161011176571, 0.917322046030731, 0.4049091917109608, 0.4049091917109608, 0.917322046030731, 0.6806161011176571, 0.4049091917109608, 0.6806161011176571, 0.11396080221370143, 0.4049091917109608, 0.4049091917109608, 0.6388220428745495, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608, 0.4049091917109608]\n",
      "all_sum before preprocessing is: [1.2752614481439828, 2.4678556928654602, 1.2752614481439828, 1.2752614481439828, 2.1383041767714666, 1.2752614481439828, 2.4678556928654602, 3.573112526690677, 1.2752614481439828, 2.1383041767714666, 2.710069798063193, 1.2752614481439828, 4.293274918822012, 2.710069798063193, 2.1383041767714666, 3.1861314392733364, 2.1401908224949255, 2.7838783806396368, 2.710069798063193, 3.4283455444710693, 3.332785067216403, 1.2752614481439828, 2.4678556928654602, 1.2752614481439828, 4.765706771412154, 1.2752614481439828, 2.710069798063193, 0.6307942843125505, 2.4184456030978057, 1.2752614481439828, 2.856579923179342, 1.2752614481439828, 1.2752614481439828, 1.2752614481439828, 4.765706771412154, 2.9286453628592444, 3.573112526690677, 1.2752614481439828, 1.2752614481439828, 2.1383041767714666, 2.1383041767714666, 1.2752614481439828, 2.710069798063193, 1.2752614481439828, 3.573112526690677, 2.1383041767714666, 1.3490700307204262, 1.2752614481439828, 1.2752614481439828, 1.2752614481439828]\n",
      "all_sum after preprocessing is: [-0.90136035  0.28973346 -0.90136035 -0.90136035 -0.03940344 -0.90136035\n",
      "  0.28973346  1.39359974 -0.90136035 -0.03940344  0.53164283 -0.90136035\n",
      "  2.11285607  0.53164283 -0.03940344  1.00710552 -0.03751917  0.60535855\n",
      "  0.53164283  1.24901489  1.15357464 -0.90136035  0.28973346 -0.90136035\n",
      "  2.58469355 -0.90136035  0.53164283 -1.54501669  0.24038553 -0.90136035\n",
      "  0.67796863 -0.90136035 -0.90136035 -0.90136035  2.58469355  0.7499434\n",
      "  1.39359974 -0.90136035 -0.90136035 -0.03940344 -0.03940344 -0.90136035\n",
      "  0.53164283 -0.90136035  1.39359974 -0.03940344 -0.82764463 -0.90136035\n",
      " -0.90136035 -0.90136035]\n",
      "P is: [0.2887710256763172, 0.5719308782525364, 0.2887710256763172, 0.2887710256763172, 0.49015041485465516, 0.2887710256763172, 0.5719308782525364, 0.8011662991406127, 0.2887710256763172, 0.49015041485465516, 0.6298661940922454, 0.2887710256763172, 0.8921464559303187, 0.6298661940922454, 0.49015041485465516, 0.7324533135407683, 0.490621308673591, 0.6468812990955187, 0.6298661940922454, 0.7771292876630634, 0.7601632340852967, 0.2887710256763172, 0.5719308782525364, 0.2887710256763172, 0.9298699620281299, 0.2887710256763172, 0.6298661940922454, 0.1758071788004072, 0.5598086559668717, 0.2887710256763172, 0.663285164901143, 0.2887710256763172, 0.2887710256763172, 0.2887710256763172, 0.9298699620281299, 0.6791663656056447, 0.8011662991406127, 0.2887710256763172, 0.2887710256763172, 0.49015041485465516, 0.49015041485465516, 0.2887710256763172, 0.6298661940922454, 0.2887710256763172, 0.8011662991406127, 0.49015041485465516, 0.30414333180297654, 0.2887710256763172, 0.2887710256763172, 0.2887710256763172]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.277\n",
      "(*) epoch 2, cost 1.536\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.581\n",
      "(*) epoch 2, cost 3.280\n",
      "(*) epoch 3, cost 2.396\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.6483807798367909, 0.9576873449411587, 1.0285530105828258, 1.1150855253445988, 1.0285530105828258, 0.7349132945985637, 1.0285530105828258, 1.0442198597029315, 1.0285530105828258, 1.1150855253445988, 0.7349132945985637, 1.1150855253445988, 1.0285530105828258, 1.1150855253445988, 1.0285530105828258, 0.6483807798367909, 1.0285530105828258, 1.0285530105828258, 0.6483807798367909, 0.9576873449411587, 1.0285530105828258, 0.6483807798367909, 2.411164363152218, 0.7349132945985637, 1.1150855253445988, 0.6483807798367909, 1.1150855253445988, 0.6483807798367909, 1.4243920904489666, 0.6483807798367909, 1.0285530105828258, 1.1150855253445988, 1.0285530105828258, 1.0285530105828258, 0.6483807798367909, 0.7349132945985637, 1.0285530105828258, 0.7349132945985637, 1.1150855253445988, 1.4243920904489666, 0.6483807798367909, 0.7349132945985637, 1.0285530105828258, 0.7349132945985637, 1.4243920904489666, 0.7349132945985637, 0.7349132945985637, 0.6483807798367909, 0.7349132945985637, 1.0285530105828258]\n",
      "all_sum after preprocessing is: [-1.02712500e+00  3.90081200e-03  2.40120597e-01  5.28563411e-01\n",
      "  2.40120597e-01 -7.38682184e-01  2.40120597e-01  2.92343626e-01\n",
      "  2.40120597e-01  5.28563411e-01 -7.38682184e-01  5.28563411e-01\n",
      "  2.40120597e-01  5.28563411e-01  2.40120597e-01 -1.02712500e+00\n",
      "  2.40120597e-01  2.40120597e-01 -1.02712500e+00  3.90081200e-03\n",
      "  2.40120597e-01 -1.02712500e+00  4.84884266e+00 -7.38682184e-01\n",
      "  5.28563411e-01 -1.02712500e+00  5.28563411e-01 -1.02712500e+00\n",
      "  1.55958922e+00 -1.02712500e+00  2.40120597e-01  5.28563411e-01\n",
      "  2.40120597e-01  2.40120597e-01 -1.02712500e+00 -7.38682184e-01\n",
      "  2.40120597e-01 -7.38682184e-01  5.28563411e-01  1.55958922e+00\n",
      " -1.02712500e+00 -7.38682184e-01  2.40120597e-01 -7.38682184e-01\n",
      "  1.55958922e+00 -7.38682184e-01 -7.38682184e-01 -1.02712500e+00\n",
      " -7.38682184e-01  2.40120597e-01]\n",
      "P is: [0.26364186281204777, 0.5009752017624187, 0.5597433682911627, 0.6291479881806212, 0.5597433682911627, 0.3232923811070129, 0.5597433682911627, 0.5725697943909498, 0.5597433682911627, 0.6291479881806212, 0.3232923811070129, 0.6291479881806212, 0.5597433682911627, 0.6291479881806212, 0.5597433682911627, 0.26364186281204777, 0.5597433682911627, 0.5597433682911627, 0.26364186281204777, 0.5009752017624187, 0.5597433682911627, 0.26364186281204777, 0.992223504916251, 0.3232923811070129, 0.6291479881806212, 0.26364186281204777, 0.6291479881806212, 0.26364186281204777, 0.8262944009973553, 0.26364186281204777, 0.5597433682911627, 0.6291479881806212, 0.5597433682911627, 0.5597433682911627, 0.26364186281204777, 0.3232923811070129, 0.5597433682911627, 0.3232923811070129, 0.6291479881806212, 0.8262944009973553, 0.26364186281204777, 0.3232923811070129, 0.5597433682911627, 0.3232923811070129, 0.8262944009973553, 0.3232923811070129, 0.3232923811070129, 0.26364186281204777, 0.3232923811070129, 0.5597433682911627]\n",
      "all_sum before preprocessing is: [3.095487284861551, 3.4850798695122926, 5.3139060424275915, 3.095487284861551, 3.4850798695122926, 3.095487284861551, 3.4850798695122926, 3.4850798695122926, 3.4850798695122926, 3.4850798695122926, 3.095487284861551, 3.4850798695122926, 3.095487284861551, 3.095487284861551, 3.4850798695122926, 4.308710665474631, 3.4850798695122926, 3.095487284861551, 3.4850798695122926, 3.4850798695122926, 4.308710665474631, 3.4850798695122926, 3.095487284861551, 3.4850798695122926, 3.4850798695122926, 3.4850798695122926, 3.4850798695122926, 3.095487284861551, 3.4850798695122926, 3.095487284861551, 3.095487284861551, 3.4850798695122926, 3.4850798695122926, 3.4850798695122926, 3.4850798695122926, 4.308710665474631, 3.4850798695122926, 4.308710665474631, 3.4850798695122926, 3.4850798695122926, 4.308710665474631, 4.698303250125373, 3.4850798695122926, 3.4850798695122926, 3.095487284861551, 3.4850798695122926, 3.095487284861551, 4.698303250125373, 3.095487284861551, 4.92431345777685]\n",
      "all_sum after preprocessing is: [-0.91763678 -0.16777399  3.35223316 -0.91763678 -0.16777399 -0.91763678\n",
      " -0.16777399 -0.16777399 -0.16777399 -0.16777399 -0.91763678 -0.16777399\n",
      " -0.91763678 -0.91763678 -0.16777399  1.41749766 -0.16777399 -0.91763678\n",
      " -0.16777399 -0.16777399  1.41749766 -0.16777399 -0.91763678 -0.16777399\n",
      " -0.16777399 -0.16777399 -0.16777399 -0.91763678 -0.16777399 -0.91763678\n",
      " -0.91763678 -0.16777399 -0.16777399 -0.16777399 -0.16777399  1.41749766\n",
      " -0.16777399  1.41749766 -0.16777399 -0.16777399  1.41749766  2.16736044\n",
      " -0.16777399 -0.16777399 -0.91763678 -0.16777399 -0.91763678  2.16736044\n",
      " -0.91763678  2.60237037]\n",
      "P is: [0.2854396618169796, 0.4581546112152517, 0.9661778873874478, 0.2854396618169796, 0.4581546112152517, 0.2854396618169796, 0.4581546112152517, 0.4581546112152517, 0.4581546112152517, 0.4581546112152517, 0.2854396618169796, 0.4581546112152517, 0.2854396618169796, 0.2854396618169796, 0.4581546112152517, 0.8049458287061744, 0.4581546112152517, 0.2854396618169796, 0.4581546112152517, 0.4581546112152517, 0.8049458287061744, 0.4581546112152517, 0.2854396618169796, 0.4581546112152517, 0.4581546112152517, 0.4581546112152517, 0.4581546112152517, 0.2854396618169796, 0.4581546112152517, 0.2854396618169796, 0.2854396618169796, 0.4581546112152517, 0.4581546112152517, 0.4581546112152517, 0.4581546112152517, 0.8049458287061744, 0.4581546112152517, 0.8049458287061744, 0.4581546112152517, 0.4581546112152517, 0.8049458287061744, 0.8972799371814438, 0.4581546112152517, 0.4581546112152517, 0.2854396618169796, 0.4581546112152517, 0.2854396618169796, 0.8972799371814438, 0.2854396618169796, 0.9310139772107168]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.041\n",
      "(*) epoch 2, cost 2.832\n",
      "(*) epoch 3, cost 2.290\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.097\n",
      "(*) epoch 2, cost 2.071\n",
      "(*) epoch 3, cost 1.624\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.5509514932971875, 3.5509514932971875, 4.768505270091485, 3.8052330206646676, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.8052330206646676, 3.5509514932971875, 3.5509514932971875, 4.078651736670251, 3.5509514932971875, 4.240805026718422, 3.5509514932971875, 4.240805026718422, 3.5778523511054834, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 4.240805026718422, 3.5509514932971875, 3.5509514932971875, 3.8052330206646676, 3.5509514932971875, 3.5509514932971875, 4.240805026718422, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 3.5509514932971875, 4.078651736670251, 3.8052330206646676, 4.240805026718422, 3.5509514932971875, 3.5509514932971875, 4.078651736670251, 3.5509514932971875, 3.5509514932971875]\n",
      "all_sum after preprocessing is: [-0.52282307 -0.52282307  3.84082955  0.38850937 -0.52282307 -0.52282307\n",
      " -0.52282307 -0.52282307 -0.52282307 -0.52282307 -0.52282307  0.38850937\n",
      " -0.52282307 -0.52282307  1.36842855 -0.52282307  1.94957793 -0.52282307\n",
      "  1.94957793 -0.42641173 -0.52282307 -0.52282307 -0.52282307 -0.52282307\n",
      " -0.52282307 -0.52282307  1.94957793 -0.52282307 -0.52282307  0.38850937\n",
      " -0.52282307 -0.52282307  1.94957793 -0.52282307 -0.52282307 -0.52282307\n",
      " -0.52282307 -0.52282307 -0.52282307 -0.52282307 -0.52282307 -0.52282307\n",
      "  1.36842855  0.38850937  1.94957793 -0.52282307 -0.52282307  1.36842855\n",
      " -0.52282307 -0.52282307]\n",
      "P is: [0.372192342402612, 0.372192342402612, 0.9789757337272381, 0.5959238083785392, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.5959238083785392, 0.372192342402612, 0.372192342402612, 0.7971261428033058, 0.372192342402612, 0.8754006121684046, 0.372192342402612, 0.8754006121684046, 0.39498350309427754, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.8754006121684046, 0.372192342402612, 0.372192342402612, 0.5959238083785392, 0.372192342402612, 0.372192342402612, 0.8754006121684046, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.372192342402612, 0.7971261428033058, 0.5959238083785392, 0.8754006121684046, 0.372192342402612, 0.372192342402612, 0.7971261428033058, 0.372192342402612, 0.372192342402612]\n",
      "all_sum before preprocessing is: [3.6008895106649152, 6.29374370661612, 4.094423518729425, 3.911260467924224, 4.094423518729425, 3.6008895106649152, 4.094423518729425, 3.6008895106649152, 2.4386164614782335, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 5.800209698551611, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 6.29374370661612, 3.6008895106649152, 3.6008895106649152, 4.800271054849195, 3.6008895106649152, 4.094423518729425, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 4.094423518729425, 4.094423518729425, 3.6008895106649152, 4.800271054849195, 3.6008895106649152, 3.6008895106649152, 3.6008895106649152, 4.094423518729425, 3.6008895106649152, 4.094423518729425, 3.6008895106649152, 4.800271054849195, 4.800271054849195, 3.6008895106649152, 2.936708472379578, 3.6008895106649152]\n",
      "all_sum after preprocessing is: [-0.42292104  3.42076579  0.28153231  0.02009171  0.28153231 -0.42292104\n",
      "  0.28153231 -0.42292104 -2.08190934 -0.42292104 -0.42292104 -0.42292104\n",
      " -0.42292104  2.71631243 -0.42292104 -0.42292104 -0.42292104 -0.42292104\n",
      " -0.42292104  3.42076579 -0.42292104 -0.42292104  1.28903464 -0.42292104\n",
      "  0.28153231 -0.42292104 -0.42292104 -0.42292104 -0.42292104 -0.42292104\n",
      " -0.42292104 -0.42292104 -0.42292104 -0.42292104  0.28153231  0.28153231\n",
      " -0.42292104  1.28903464 -0.42292104 -0.42292104 -0.42292104  0.28153231\n",
      " -0.42292104  0.28153231 -0.42292104  1.28903464  1.28903464 -0.42292104\n",
      " -1.37095006 -0.42292104]\n",
      "P is: [0.3958179820673706, 0.9683472520072149, 0.5699218500384627, 0.5050227595518992, 0.5699218500384627, 0.3958179820673706, 0.5699218500384627, 0.3958179820673706, 0.11086761135566153, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.9379823687618506, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.9683472520072149, 0.3958179820673706, 0.3958179820673706, 0.783983747158123, 0.3958179820673706, 0.5699218500384627, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.5699218500384627, 0.5699218500384627, 0.3958179820673706, 0.783983747158123, 0.3958179820673706, 0.3958179820673706, 0.3958179820673706, 0.5699218500384627, 0.3958179820673706, 0.5699218500384627, 0.3958179820673706, 0.783983747158123, 0.783983747158123, 0.3958179820673706, 0.20246639391277466, 0.3958179820673706]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.614\n",
      "(*) epoch 2, cost 2.204\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.517\n",
      "(*) epoch 2, cost 2.860\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.999425815444224, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.7725979442524276, 0.444135512882606, 2.999425815444224, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 1.0490294091669343, 0.7725979442524276, 2.999425815444224, 1.0490294091669343, 0.444135512882606, 0.444135512882606, 1.0490294091669343, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 0.444135512882606, 3.327888246814046, 0.444135512882606, 0.444135512882606, 0.444135512882606, 1.3069917431664397]\n",
      "all_sum after preprocessing is: [ 3.15198451 -0.38428399 -0.38428399 -0.38428399 -0.38428399 -0.38428399\n",
      " -0.38428399  0.07027546 -0.38428399  3.15198451 -0.38428399 -0.38428399\n",
      " -0.38428399 -0.38428399 -0.38428399 -0.38428399 -0.38428399 -0.38428399\n",
      " -0.38428399  0.45282921  0.07027546  3.15198451  0.45282921 -0.38428399\n",
      " -0.38428399  0.45282921 -0.38428399 -0.38428399 -0.38428399 -0.38428399\n",
      " -0.38428399 -0.38428399 -0.38428399 -0.38428399 -0.38428399 -0.38428399\n",
      " -0.38428399 -0.38428399 -0.38428399 -0.38428399 -0.38428399 -0.38428399\n",
      " -0.38428399 -0.38428399 -0.38428399  3.60654396 -0.38428399 -0.38428399\n",
      " -0.38428399  0.80982351]\n",
      "P is: [0.9589868458595507, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.5175616379034363, 0.40509406808016235, 0.9589868458595507, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.6113116923289303, 0.5175616379034363, 0.9589868458595507, 0.6113116923289303, 0.40509406808016235, 0.40509406808016235, 0.6113116923289303, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.9735719030084153, 0.40509406808016235, 0.40509406808016235, 0.40509406808016235, 0.6920718936733293]\n",
      "all_sum before preprocessing is: [2.151242205761282, 2.2005547480257723, 2.151242205761282, 2.2005547480257723, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.151242205761282, 3.8307344645737893, 2.151242205761282, 2.2005547480257723, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.400609638847741, 2.151242205761282, 2.151242205761282, 4.486422708181364, 2.151242205761282, 2.151242205761282, 4.535735250445855, 2.151242205761282, 2.151242205761282, 2.2005547480257723, 2.2005547480257723, 2.454437184269147, 2.151242205761282, 4.486422708181364, 2.2005547480257723, 2.151242205761282, 2.151242205761282, 2.151242205761282, 2.2005547480257723, 2.2005547480257723, 4.486422708181364, 2.2005547480257723, 2.151242205761282, 2.151242205761282, 2.2005547480257723, 2.151242205761282, 4.535735250445855, 2.151242205761282, 2.2005547480257723, 2.151242205761282]\n",
      "all_sum after preprocessing is: [-0.39970067 -0.33196327 -0.39970067 -0.33196327 -0.39970067 -0.39970067\n",
      " -0.39970067 -0.39970067 -0.39970067 -0.39970067 -0.39970067 -0.39970067\n",
      " -0.39970067  1.90730756 -0.39970067 -0.33196327 -0.39970067 -0.39970067\n",
      " -0.39970067 -0.39970067 -0.05716101 -0.39970067 -0.39970067  2.80798344\n",
      " -0.39970067 -0.39970067  2.87572084 -0.39970067 -0.39970067 -0.33196327\n",
      " -0.33196327  0.01677836 -0.39970067  2.80798344 -0.33196327 -0.39970067\n",
      " -0.39970067 -0.39970067 -0.33196327 -0.33196327  2.80798344 -0.33196327\n",
      " -0.39970067 -0.39970067 -0.33196327 -0.39970067  2.87572084 -0.39970067\n",
      " -0.33196327 -0.39970067]\n",
      "P is: [0.401384258197685, 0.4177630053506284, 0.401384258197685, 0.4177630053506284, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.8707163635649535, 0.401384258197685, 0.4177630053506284, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.48571363808412465, 0.401384258197685, 0.401384258197685, 0.9431057126336606, 0.401384258197685, 0.401384258197685, 0.9466330980378289, 0.401384258197685, 0.401384258197685, 0.4177630053506284, 0.4177630053506284, 0.5041944911113834, 0.401384258197685, 0.9431057126336606, 0.4177630053506284, 0.401384258197685, 0.401384258197685, 0.401384258197685, 0.4177630053506284, 0.4177630053506284, 0.9431057126336606, 0.4177630053506284, 0.401384258197685, 0.401384258197685, 0.4177630053506284, 0.401384258197685, 0.9466330980378289, 0.401384258197685, 0.4177630053506284, 0.401384258197685]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.807\n",
      "(*) epoch 2, cost 1.268\n",
      "(*) epoch 3, cost 0.818\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.947\n",
      "(*) epoch 2, cost 2.036\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.839068548360105, 2.839068548360105, 2.241088724421753, 3.91528744229521, 2.839068548360105, 3.3755543735220526, 2.3613196216565098, 4.339071087033834, 2.8978054468184573, 2.3613196216565098, 2.7188376511253485, 2.3613196216565098, 2.3613196216565098, 2.839068548360105, 2.241088724421753, 2.3613196216565098, 2.3613196216565098, 2.8978054468184573, 2.839068548360105, 2.7775745495837008, 2.3613196216565098, 2.7188376511253485, 4.81682001373743, 1.4597870502142902, 2.241088724421753, 2.839068548360105, 2.7188376511253485, 2.3613196216565098, 3.6211494719884656, 1.9375359769178857, 2.3613196216565098, 2.839068548360105, 2.839068548360105, 2.241088724421753, 4.81682001373743, 2.7188376511253485, 2.839068548360105, 2.7188376511253485, 2.7188376511253485, 2.241088724421753, 2.3613196216565098, 2.3613196216565098, 2.241088724421753, 2.839068548360105, 2.839068548360105, 2.3613196216565098, 2.7188376511253485, 2.241088724421753, 2.241088724421753, 2.241088724421753]\n",
      "all_sum after preprocessing is: [ 0.19963803  0.19963803 -0.74318438  1.89649008  0.19963803  1.04550412\n",
      " -0.55361882  2.56466098  0.29224728 -0.55361882  0.01007246 -0.55361882\n",
      " -0.55361882  0.19963803 -0.74318438 -0.55361882 -0.55361882  0.29224728\n",
      "  0.19963803  0.10268171 -0.55361882  0.01007246  3.31791783 -1.97504656\n",
      " -0.74318438  0.19963803  0.01007246 -0.55361882  1.43272883 -1.22178972\n",
      " -0.55361882  0.19963803  0.19963803 -0.74318438  3.31791783  0.01007246\n",
      "  0.19963803  0.01007246  0.01007246 -0.74318438 -0.55361882 -0.55361882\n",
      " -0.74318438  0.19963803  0.19963803 -0.55361882  0.01007246 -0.74318438\n",
      " -0.74318438 -0.74318438]\n",
      "P is: [0.5497444018032921, 0.5497444018032921, 0.3223081998537836, 0.8694937562598073, 0.5497444018032921, 0.7399106336229906, 0.3650252244468901, 0.9285522993625341, 0.5725462152308751, 0.3650252244468901, 0.5025180941223851, 0.3650252244468901, 0.3650252244468901, 0.5497444018032921, 0.3223081998537836, 0.3650252244468901, 0.3650252244468901, 0.5725462152308751, 0.5497444018032921, 0.5256478974204672, 0.3650252244468901, 0.5025180941223851, 0.9650384084528115, 0.12184786869179562, 0.3223081998537836, 0.5497444018032921, 0.5025180941223851, 0.3650252244468901, 0.8073261435078652, 0.22762164712734137, 0.3650252244468901, 0.5497444018032921, 0.5497444018032921, 0.3223081998537836, 0.9650384084528115, 0.5025180941223851, 0.5497444018032921, 0.5025180941223851, 0.5025180941223851, 0.3223081998537836, 0.3650252244468901, 0.3650252244468901, 0.3223081998537836, 0.5497444018032921, 0.5497444018032921, 0.3650252244468901, 0.5025180941223851, 0.3223081998537836, 0.3223081998537836, 0.3223081998537836]\n",
      "all_sum before preprocessing is: [2.961544417701354, 2.961544417701354, 2.961544417701354, 2.961544417701354, 4.649449694982241, 2.961544417701354, 2.961544417701354, 2.945136503183654, 2.2721113167036564, 2.961544417701354, 5.338882795979938, 2.945136503183654, 2.945136503183654, 2.961544417701354, 2.2557034021859566, 2.2557034021859566, 2.961544417701354, 2.945136503183654, 5.355290710497638, 2.961544417701354, 5.355290710497638, 2.2557034021859566, 2.961544417701354, 2.961544417701354, 2.2557034021859566, 2.2721113167036564, 2.945136503183654, 2.2557034021859566, 4.665857609499941, 2.961544417701354, 2.2721113167036564, 4.665857609499941, 2.945136503183654, 5.355290710497638, 5.338882795979938, 2.2721113167036564, 2.945136503183654, 5.355290710497638, 2.945136503183654, 2.2721113167036564, 2.961544417701354, 5.338882795979938, 2.2557034021859566, 2.961544417701354, 5.355290710497638, 2.2557034021859566, 2.961544417701354, 2.961544417701354, 2.961544417701354, 2.2721113167036564]\n",
      "all_sum after preprocessing is: [-0.28297341 -0.28297341 -0.28297341 -0.28297341  1.31035274 -0.28297341\n",
      " -0.28297341 -0.29846193 -0.9337752  -0.28297341  1.96115453 -0.29846193\n",
      " -0.29846193 -0.28297341 -0.94926373 -0.94926373 -0.28297341 -0.29846193\n",
      "  1.97664306 -0.28297341  1.97664306 -0.94926373 -0.28297341 -0.28297341\n",
      " -0.94926373 -0.9337752  -0.29846193 -0.94926373  1.32584126 -0.28297341\n",
      " -0.9337752   1.32584126 -0.29846193  1.97664306  1.96115453 -0.9337752\n",
      " -0.29846193  1.97664306 -0.29846193 -0.9337752  -0.28297341  1.96115453\n",
      " -0.94926373 -0.28297341  1.97664306 -0.94926373 -0.28297341 -0.28297341\n",
      " -0.28297341 -0.9337752 ]\n",
      "P is: [0.42972495651170994, 0.42972495651170994, 0.42972495651170994, 0.42972495651170994, 0.7875721755482993, 0.42972495651170994, 0.42972495651170994, 0.42593351978190014, 0.2821594353795936, 0.42972495651170994, 0.8766578450536839, 0.42593351978190014, 0.42593351978190014, 0.42972495651170994, 0.27903291645166417, 0.27903291645166417, 0.42972495651170994, 0.42593351978190014, 0.8783228547349128, 0.42972495651170994, 0.8783228547349128, 0.27903291645166417, 0.42972495651170994, 0.42972495651170994, 0.27903291645166417, 0.2821594353795936, 0.42593351978190014, 0.27903291645166417, 0.790151898317033, 0.42972495651170994, 0.2821594353795936, 0.790151898317033, 0.42593351978190014, 0.8783228547349128, 0.8766578450536839, 0.2821594353795936, 0.42593351978190014, 0.8783228547349128, 0.42593351978190014, 0.2821594353795936, 0.42972495651170994, 0.8766578450536839, 0.27903291645166417, 0.42972495651170994, 0.8783228547349128, 0.27903291645166417, 0.42972495651170994, 0.42972495651170994, 0.42972495651170994, 0.2821594353795936]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.139\n",
      "(*) epoch 2, cost 3.264\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.577\n",
      "(*) epoch 2, cost 2.154\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.173823053644946, 1.173823053644946, 3.23827957985314, 1.173823053644946, 3.23827957985314, 1.173823053644946, 1.173823053644946, 3.23827957985314, 1.173823053644946, 3.23827957985314, 1.173823053644946, 1.173823053644946, 1.173823053644946, 3.23827957985314, 1.173823053644946, 2.3346487301345555, 1.173823053644946, 1.173823053644946, 3.23827957985314, 1.173823053644946, 4.399105256342749, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 3.23827957985314, 1.173823053644946, 1.173823053644946, 1.173823053644946, 2.2971302673747522, 1.173823053644946, 3.23827957985314, 3.23827957985314, 2.3346487301345555, 1.173823053644946, 1.173823053644946, 3.23827957985314, 2.3346487301345555, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 1.173823053644946, 3.23827957985314]\n",
      "all_sum after preprocessing is: [-0.65160085 -0.65160085  1.55075302 -0.65160085  1.55075302 -0.65160085\n",
      " -0.65160085  1.55075302 -0.65160085  1.55075302 -0.65160085 -0.65160085\n",
      " -0.65160085  1.55075302 -0.65160085  0.58676328 -0.65160085 -0.65160085\n",
      "  1.55075302 -0.65160085  2.78911715 -0.65160085 -0.65160085 -0.65160085\n",
      " -0.65160085 -0.65160085 -0.65160085  1.55075302 -0.65160085 -0.65160085\n",
      " -0.65160085  0.54673874 -0.65160085  1.55075302  1.55075302  0.58676328\n",
      " -0.65160085 -0.65160085  1.55075302  0.58676328 -0.65160085 -0.65160085\n",
      " -0.65160085 -0.65160085 -0.65160085 -0.65160085 -0.65160085 -0.65160085\n",
      " -0.65160085  1.55075302]\n",
      "P is: [0.34262888004247927, 0.34262888004247927, 0.825022464191287, 0.34262888004247927, 0.825022464191287, 0.34262888004247927, 0.34262888004247927, 0.825022464191287, 0.34262888004247927, 0.825022464191287, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.825022464191287, 0.34262888004247927, 0.6426221484088724, 0.34262888004247927, 0.34262888004247927, 0.825022464191287, 0.34262888004247927, 0.9420848943901128, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.825022464191287, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.6333786230311397, 0.34262888004247927, 0.825022464191287, 0.825022464191287, 0.6426221484088724, 0.34262888004247927, 0.34262888004247927, 0.825022464191287, 0.6426221484088724, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.34262888004247927, 0.825022464191287]\n",
      "all_sum before preprocessing is: [1.9875947264894223, 3.1924282479749397, 1.9875947264894223, 1.9875947264894223, 1.9875947264894223, 3.153120883752437, 3.153120883752437, 1.9875947264894223, 3.650212624415271, 2.9054033437156592, 1.9875947264894223, 4.132939906974835, 2.670393601192873, 3.254438653971101, 3.153120883752437, 2.274619630748703, 3.153120883752437, 3.153120883752437, 1.9875947264894223, 1.9875947264894223, 2.9674137497118203, 1.9875947264894223, 2.9101657614650898, 3.153120883752437, 2.274619630748703, 1.9875947264894223, 3.254438653971101, 3.0958728955057064, 3.885222366938057, 3.153120883752437, 1.9875947264894223, 2.274619630748703, 2.9674137497118203, 2.9674137497118203, 2.9054033437156592, 3.1351802597282092, 4.132939906974835, 2.9054033437156592, 3.650212624415271, 2.9674137497118203, 3.153120883752437, 3.153120883752437, 3.885222366938057, 2.274619630748703, 2.9101657614650898, 2.9101657614650898, 3.153120883752437, 3.4401457880117183, 2.9674137497118203, 1.9875947264894223]\n",
      "all_sum after preprocessing is: [-1.38976685  0.56797524 -1.38976685 -1.38976685 -1.38976685  0.50410444\n",
      "  0.50410444 -1.38976685  1.31183215  0.10158654 -1.38976685  2.09621895\n",
      " -0.28028237  0.66873636  0.50410444 -0.92337815  0.50410444  0.50410444\n",
      " -1.38976685 -1.38976685  0.20234767 -1.38976685  0.10932503  0.50410444\n",
      " -0.92337815 -1.38976685  0.66873636  0.4110818   1.69370106  0.50410444\n",
      " -1.38976685 -0.92337815  0.20234767  0.20234767  0.10158654  0.4749526\n",
      "  2.09621895  0.10158654  1.31183215  0.20234767  0.50410444  0.50410444\n",
      "  1.69370106 -0.92337815  0.10932503  0.10932503  0.50410444  0.97049313\n",
      "  0.20234767 -1.38976685]\n",
      "P is: [0.19944498063268148, 0.6382958403493031, 0.19944498063268148, 0.19944498063268148, 0.19944498063268148, 0.6234234029844797, 0.6234234029844797, 0.19944498063268148, 0.7878195786896611, 0.5253748169155223, 0.19944498063268148, 0.890535137359494, 0.43038455080875115, 0.6612201517339377, 0.6234234029844797, 0.28427007254247183, 0.6234234029844797, 0.6234234029844797, 0.19944498063268148, 0.19944498063268148, 0.5504150153031612, 0.19944498063268148, 0.5273040669407341, 0.6234234029844797, 0.28427007254247183, 0.19944498063268148, 0.6612201517339377, 0.6013472446596096, 0.8447102648733299, 0.6234234029844797, 0.19944498063268148, 0.28427007254247183, 0.5504150153031612, 0.5504150153031612, 0.5253748169155223, 0.6165552974531883, 0.890535137359494, 0.5253748169155223, 0.7878195786896611, 0.5504150153031612, 0.6234234029844797, 0.6234234029844797, 0.8447102648733299, 0.28427007254247183, 0.5273040669407341, 0.5273040669407341, 0.6234234029844797, 0.7252177785040447, 0.5504150153031612, 0.19944498063268148]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.589\n",
      "(*) epoch 2, cost 2.332\n",
      "(*) epoch 3, cost 1.745\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.716\n",
      "(*) epoch 2, cost 2.377\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.261183677294898, 2.6993711061564403, 2.6993711061564403, 2.6993711061564403, 2.6993711061564403, 2.233686025877154, 2.6993711061564403, 2.6993711061564403, 4.226352468048755, 1.7268687575741846, 1.7268687575741846, 2.6993711061564403, 2.6993711061564403, 2.6993711061564403, 3.2538501194664993, 2.6993711061564403, 3.2538501194664993, 2.6993711061564403, 2.6993711061564403, 2.6993711061564403, 1.7268687575741846, 4.226352468048755, 1.7268687575741846, 4.226352468048755, 2.6993711061564403, 1.7268687575741846, 2.6993711061564403, 1.7268687575741846, 4.226352468048755, 2.6993711061564403, 2.6993711061564403, 2.8646707383631203, 1.7268687575741846, 2.6993711061564403, 4.226352468048755, 2.6993711061564403, 1.7268687575741846, 4.226352468048755, 3.2538501194664993, 3.2538501194664993, 2.788165039187213, 4.226352468048755, 3.2538501194664993, 1.7268687575741846, 3.2538501194664993, 4.226352468048755, 2.6993711061564403, 4.226352468048755, 1.7268687575741846, 2.233686025877154]\n",
      "all_sum after preprocessing is: [-1.86329009 -0.12631229 -0.12631229 -0.12631229 -0.12631229 -0.68874569\n",
      " -0.12631229 -0.12631229  1.71790682 -1.30085669 -1.30085669 -0.12631229\n",
      " -0.12631229 -0.12631229  0.54336242 -0.12631229  0.54336242 -0.12631229\n",
      " -0.12631229 -0.12631229 -1.30085669  1.71790682 -1.30085669  1.71790682\n",
      " -0.12631229 -1.30085669 -0.12631229 -1.30085669  1.71790682 -0.12631229\n",
      " -0.12631229  0.07332914 -1.30085669 -0.12631229  1.71790682 -0.12631229\n",
      " -1.30085669  1.71790682  0.54336242  0.54336242 -0.01907098  1.71790682\n",
      "  0.54336242 -1.30085669  0.54336242  1.71790682 -0.12631229  1.71790682\n",
      " -1.30085669 -0.68874569]\n",
      "P is: [0.13432002599517726, 0.4684638469587303, 0.4684638469587303, 0.4684638469587303, 0.4684638469587303, 0.33431215949485843, 0.4684638469587303, 0.4684638469587303, 0.8478590249606727, 0.214020873214252, 0.214020873214252, 0.4684638469587303, 0.4684638469587303, 0.4684638469587303, 0.6325942544791697, 0.4684638469587303, 0.6325942544791697, 0.4684638469587303, 0.4684638469587303, 0.4684638469587303, 0.214020873214252, 0.8478590249606727, 0.214020873214252, 0.8478590249606727, 0.4684638469587303, 0.214020873214252, 0.4684638469587303, 0.214020873214252, 0.8478590249606727, 0.4684638469587303, 0.4684638469587303, 0.5183240754914248, 0.214020873214252, 0.4684638469587303, 0.8478590249606727, 0.4684638469587303, 0.214020873214252, 0.8478590249606727, 0.6325942544791697, 0.6325942544791697, 0.4952323984219999, 0.8478590249606727, 0.6325942544791697, 0.214020873214252, 0.6325942544791697, 0.8478590249606727, 0.4684638469587303, 0.8478590249606727, 0.214020873214252, 0.33431215949485843]\n",
      "all_sum before preprocessing is: [6.1012104293320615, 3.6002917036128954, 4.939349082310873, 3.684052992736265, 3.976801456762224, 2.5629334172814295, 7.848452588321591, 3.7100961237268373, 3.6263348346034685, 5.0231103714342416, 4.175317903264139, 4.845914339757453, 6.158928587464858, 5.289815704469628, 5.0231103714342416, 4.939349082310873, 2.3710387450288604, 3.7100961237268373, 6.712634372290975, 4.939349082310873, 7.874495719312163, 4.939349082310873, 2.9619603566208994, 4.060562745885592, 3.684052992736265, 6.1012104293320615, 3.684052992736265, 3.684052992736265, 3.976801456762224, 5.514375281962116, 2.287277455905491, 5.0231103714342416, 8.066390391564731, 7.414224677039466, 5.0231103714342416, 3.684052992736265, 2.287277455905491, 4.939349082310873, 3.684052992736265, 7.414224677039466, 2.287277455905491, 6.753376143857327, 3.684052992736265, 6.376866390708, 5.0231103714342416, 4.939349082310873, 5.373576993592997, 5.399620124583571, 5.0231103714342416, 7.874495719312163]\n",
      "all_sum after preprocessing is: [ 8.14245813e-01 -8.07487722e-01  6.08308821e-02 -7.53172286e-01\n",
      " -5.63338047e-01 -1.48016801e+00  1.94725392e+00 -7.36284484e-01\n",
      " -7.90599920e-01  1.15146318e-01 -4.34609042e-01  2.42645565e-04\n",
      "  8.51673448e-01  2.88092755e-01  1.15146318e-01  6.08308821e-02\n",
      " -1.60460309e+00 -7.36284484e-01  1.21072680e+00  6.08308821e-02\n",
      "  1.96414173e+00  6.08308821e-02 -1.22141695e+00 -5.09022611e-01\n",
      " -7.53172286e-01  8.14245813e-01 -7.53172286e-01 -7.53172286e-01\n",
      " -5.63338047e-01  4.33709561e-01 -1.65891852e+00  1.15146318e-01\n",
      "  2.08857681e+00  1.66567662e+00  1.15146318e-01 -7.53172286e-01\n",
      " -1.65891852e+00  6.08308821e-02 -7.53172286e-01  1.66567662e+00\n",
      " -1.65891852e+00  1.23714601e+00 -7.53172286e-01  9.92996331e-01\n",
      "  1.15146318e-01  6.08308821e-02  3.42408191e-01  3.59295993e-01\n",
      "  1.15146318e-01  1.96414173e+00]\n",
      "P is: [0.6930135226280499, 0.30842610518894026, 0.5152030327123387, 0.32013046894132297, 0.3627754523603569, 0.18540204423916887, 0.8751469014328915, 0.3238171585218794, 0.31203986941641093, 0.5287548157012553, 0.3930262735389362, 0.5000606613910757, 0.700918068507246, 0.5715291438411627, 0.5287548157012553, 0.5152030327123387, 0.16733925270616337, 0.3238171585218794, 0.770427521825618, 0.5152030327123387, 0.8769804836542424, 0.5152030327123387, 0.22768719026590592, 0.37542267626429476, 0.32013046894132297, 0.6930135226280499, 0.32013046894132297, 0.32013046894132297, 0.3627754523603569, 0.6067591286638274, 0.1599072256355519, 0.5287548157012553, 0.8897879371717388, 0.8409985501921481, 0.5287548157012553, 0.32013046894132297, 0.1599072256355519, 0.5152030327123387, 0.32013046894132297, 0.8409985501921481, 0.1599072256355519, 0.7750668445207705, 0.32013046894132297, 0.7296793473729782, 0.5287548157012553, 0.5152030327123387, 0.5847753825559064, 0.5888700031019944, 0.5287548157012553, 0.8769804836542424]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.419\n",
      "(*) epoch 2, cost 3.085\n",
      "(*) epoch 3, cost 2.690\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.422\n",
      "(*) epoch 2, cost 4.446\n",
      "(*) epoch 3, cost 3.893\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.9666824096999094, 1.9666824096999094, 1.9666824096999094, 1.8715182171281022, 1.8715182171281022, 2.6776249499604767, 1.8715182171281022, 3.0275047692958186, 2.6776249499604767, 2.7727891425322837, 1.9666824096999094, 1.8715182171281022, 2.6776249499604767, 1.8715182171281022, 3.715754383375995, 1.8715182171281022, 1.9666824096999094, 1.8715182171281022, 1.8715182171281022, 1.9666824096999094, 1.9666824096999094, 1.9666824096999094, 1.8715182171281022, 1.9666824096999094, 1.9666824096999094, 1.8715182171281022, 1.9666824096999094, 1.9666824096999094, 1.9666824096999094, 2.7727891425322837, 1.9666824096999094, 2.6776249499604767, 2.7727891425322837, 2.6776249499604767, 2.6776249499604767, 2.7727891425322837, 2.7727891425322837, 1.9666824096999094, 1.9666824096999094, 1.9666824096999094, 2.6776249499604767, 2.9323405767240116, 1.8715182171281022, 1.9666824096999094, 1.9666824096999094, 1.8715182171281022, 1.9666824096999094, 1.8715182171281022, 1.8715182171281022, 1.9666824096999094]\n",
      "all_sum after preprocessing is: [-0.52792071 -0.52792071 -0.52792071 -0.74729826 -0.74729826  1.11098176\n",
      " -0.74729826  1.91754328  1.11098176  1.3303593  -0.52792071 -0.74729826\n",
      "  1.11098176 -0.74729826  3.50413281 -0.74729826 -0.52792071 -0.74729826\n",
      " -0.74729826 -0.52792071 -0.52792071 -0.52792071 -0.74729826 -0.52792071\n",
      " -0.52792071 -0.74729826 -0.52792071 -0.52792071 -0.52792071  1.3303593\n",
      " -0.52792071  1.11098176  1.3303593   1.11098176  1.11098176  1.3303593\n",
      "  1.3303593  -0.52792071 -0.52792071 -0.52792071  1.11098176  1.69816573\n",
      " -0.74729826 -0.52792071 -0.52792071 -0.74729826 -0.52792071 -0.74729826\n",
      " -0.74729826 -0.52792071]\n",
      "P is: [0.3710019789828912, 0.3710019789828912, 0.3710019789828912, 0.3214102811642723, 0.3214102811642723, 0.7523120957399242, 0.3214102811642723, 0.8718642270906185, 0.7523120957399242, 0.7909000613764064, 0.3710019789828912, 0.3214102811642723, 0.7523120957399242, 0.3214102811642723, 0.9708051318093494, 0.3214102811642723, 0.3710019789828912, 0.3214102811642723, 0.3214102811642723, 0.3710019789828912, 0.3710019789828912, 0.3710019789828912, 0.3214102811642723, 0.3710019789828912, 0.3710019789828912, 0.3214102811642723, 0.3710019789828912, 0.3710019789828912, 0.3710019789828912, 0.7909000613764064, 0.3710019789828912, 0.7523120957399242, 0.7909000613764064, 0.7523120957399242, 0.7523120957399242, 0.7909000613764064, 0.7909000613764064, 0.3710019789828912, 0.3710019789828912, 0.3710019789828912, 0.7523120957399242, 0.8452950174712646, 0.3214102811642723, 0.3710019789828912, 0.3710019789828912, 0.3214102811642723, 0.3710019789828912, 0.3214102811642723, 0.3214102811642723, 0.3710019789828912]\n",
      "all_sum before preprocessing is: [0.7057825243286966, 1.905051514706348, 0.7057825243286966, 0.8210609393443875, 1.905051514706348, 1.905051514706348, 0.7057825243286966, 0.592321106712859, 0.7057825243286966, 2.122148793479581, 1.905051514706348, 0.7057825243286966, 1.9648311322316714, 1.905051514706348, 0.7057825243286966, 0.7057825243286966, 0.7057825243286966, 0.7057825243286966, 0.9228798031019293, 0.7057825243286966, 1.905051514706348, 1.905051514706348, 3.164100122609323, 0.7057825243286966, 0.7057825243286966, 0.7057825243286966, 0.7057825243286966, 0.7057825243286966, 1.7915900970905105, 0.7057825243286966, 1.905051514706348, 0.7057825243286966, 2.020329929722039, 1.905051514706348, 0.7057825243286966, 0.7057825243286966, 1.905051514706348, 0.9228798031019293, 0.7057825243286966, 1.7915900970905105, 0.7057825243286966, 0.7057825243286966, 0.7057825243286966, 0.7057825243286966, 1.905051514706348, 3.164100122609323, 0.7057825243286966, 1.905051514706348, 0.7057825243286966, 0.7057825243286966]\n",
      "all_sum after preprocessing is: [-0.75220357  0.98892493 -0.75220357 -0.58483951  0.98892493  0.98892493\n",
      " -0.75220357 -0.91692967 -0.75220357  1.30411215  0.98892493 -0.75220357\n",
      "  1.07571446  0.98892493 -0.75220357 -0.75220357 -0.75220357 -0.75220357\n",
      " -0.43701635 -0.75220357  0.98892493  0.98892493  2.81684296 -0.75220357\n",
      " -0.75220357 -0.75220357 -0.75220357 -0.75220357  0.82419882 -0.75220357\n",
      "  0.98892493 -0.75220357  1.15628899  0.98892493 -0.75220357 -0.75220357\n",
      "  0.98892493 -0.43701635 -0.75220357  0.82419882 -0.75220357 -0.75220357\n",
      " -0.75220357 -0.75220357  0.98892493  2.81684296 -0.75220357  0.98892493\n",
      " -0.75220357 -0.75220357]\n",
      "P is: [0.32034134340589737, 0.7288755231606979, 0.32034134340589737, 0.35781978533496733, 0.7288755231606979, 0.7288755231606979, 0.32034134340589737, 0.28558390710738524, 0.32034134340589737, 0.7865262373031603, 0.7288755231606979, 0.32034134340589737, 0.7456821284705303, 0.7288755231606979, 0.32034134340589737, 0.32034134340589737, 0.32034134340589737, 0.32034134340589737, 0.39245214223960734, 0.32034134340589737, 0.7288755231606979, 0.7288755231606979, 0.9435792287754534, 0.32034134340589737, 0.32034134340589737, 0.32034134340589737, 0.32034134340589737, 0.32034134340589737, 0.6951269063504996, 0.32034134340589737, 0.7288755231606979, 0.32034134340589737, 0.7606577517395662, 0.7288755231606979, 0.32034134340589737, 0.32034134340589737, 0.7288755231606979, 0.39245214223960734, 0.32034134340589737, 0.6951269063504996, 0.32034134340589737, 0.32034134340589737, 0.32034134340589737, 0.32034134340589737, 0.7288755231606979, 0.9435792287754534, 0.32034134340589737, 0.7288755231606979, 0.32034134340589737, 0.32034134340589737]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.477\n",
      "(*) epoch 2, cost 2.379\n",
      "(*) epoch 3, cost 1.880\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.402\n",
      "(*) epoch 2, cost 2.442\n",
      "(*) epoch 3, cost 1.761\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.212926171393872, 4.268130732520237, 3.5017030392611628, 3.8466104255522793, 3.8466104255522793, 3.8466104255522793, 3.8466104255522793, 3.8466104255522793, 3.080182732293206, 3.8466104255522793, 3.8466104255522793, 4.268130732520237, 3.8466104255522793, 2.355655861619912, 2.355655861619912, 3.8466104255522793, 4.268130732520237, 3.8466104255522793, 3.5017030392611628, 3.080182732293206, 4.268130732520237, 3.8466104255522793, 3.8466104255522793, 4.268130732520237, 2.0107484753287954, 3.8466104255522793, 1.5892281683608385, 3.080182732293206, 2.355655861619912, 3.8466104255522793, 3.8466104255522793, 3.080182732293206, 4.268130732520237, 4.268130732520237, 2.777176168587869, 3.5017030392611628, 2.355655861619912, 4.268130732520237, 3.080182732293206, 4.268130732520237, 1.5892281683608385, 3.8466104255522793, 3.8466104255522793, 4.268130732520237, 3.8466104255522793, 2.0107484753287954, 3.8466104255522793, 3.8466104255522793, 3.5017030392611628, 3.8466104255522793]\n",
      "all_sum after preprocessing is: [-0.40463203  1.03450494 -0.01078473  0.45961597  0.45961597  0.45961597\n",
      "  0.45961597  0.45961597 -0.58567369  0.45961597  0.45961597  1.03450494\n",
      "  0.45961597 -1.57381707 -1.57381707  0.45961597  1.03450494  0.45961597\n",
      " -0.01078473 -0.58567369  1.03450494  0.45961597  0.45961597  1.03450494\n",
      " -2.04421778  0.45961597 -2.61910674 -0.58567369 -1.57381707  0.45961597\n",
      "  0.45961597 -0.58567369  1.03450494  1.03450494 -0.99892811 -0.01078473\n",
      " -1.57381707  1.03450494 -0.58567369  1.03450494 -2.61910674  0.45961597\n",
      "  0.45961597  1.03450494  0.45961597 -2.04421778  0.45961597  0.45961597\n",
      " -0.01078473  0.45961597]\n",
      "P is: [0.40019995591891894, 0.7377883392158174, 0.49730384365762653, 0.6129230707124171, 0.6129230707124171, 0.6129230707124171, 0.6129230707124171, 0.6129230707124171, 0.35762812471969774, 0.6129230707124171, 0.6129230707124171, 0.7377883392158174, 0.6129230707124171, 0.17167291855149774, 0.17167291855149774, 0.6129230707124171, 0.7377883392158174, 0.6129230707124171, 0.49730384365762653, 0.35762812471969774, 0.7377883392158174, 0.6129230707124171, 0.6129230707124171, 0.7377883392158174, 0.11463794789779523, 0.6129230707124171, 0.06791882039788687, 0.35762812471969774, 0.17167291855149774, 0.6129230707124171, 0.6129230707124171, 0.35762812471969774, 0.7377883392158174, 0.7377883392158174, 0.26915221994646843, 0.49730384365762653, 0.17167291855149774, 0.7377883392158174, 0.35762812471969774, 0.7377883392158174, 0.06791882039788687, 0.6129230707124171, 0.6129230707124171, 0.7377883392158174, 0.6129230707124171, 0.11463794789779523, 0.6129230707124171, 0.6129230707124171, 0.49730384365762653, 0.6129230707124171]\n",
      "all_sum before preprocessing is: [2.27815671803298, 3.3440474881891262, 2.6587540936591267, 2.27815671803298, 3.23517583387978, 2.6512535548426195, 3.9204692284097797, 3.3440474881891262, 3.5398718527836324, 3.0318509304687664, 3.5398718527836324, 2.346557535938767, 2.6587540936591267, 3.9204692284097797, 3.3440474881891262, 2.9634501125629793, 3.3440474881891262, 3.3440474881891262, 2.6587540936591267, 3.3440474881891262, 3.0318509304687664, 2.6512535548426195, 2.6512535548426195, 3.2276752950632726, 3.0318509304687664, 3.9204692284097797, 3.0318509304687664, 3.3440474881891262, 3.3440474881891262, 2.6587540936591267, 3.0318509304687664, 3.23517583387978, 3.0318509304687664, 3.3440474881891262, 3.3440474881891262, 2.9634501125629793, 3.3440474881891262, 3.3440474881891262, 3.3440474881891262, 3.3440474881891262, 2.6512535548426195, 3.3440474881891262, 2.9634501125629793, 3.0318509304687664, 2.6512535548426195, 3.3440474881891262, 2.346557535938767, 3.3440474881891262, 2.346557535938767, 2.9634501125629793]\n",
      "all_sum after preprocessing is: [-1.95436275  0.64668611 -1.02560682 -1.95436275  0.38101115 -1.04391007\n",
      "  2.05330408  0.64668611  1.12454815 -0.11515415  1.12454815 -1.78744708\n",
      " -1.02560682  2.05330408  0.64668611 -0.28206981  0.64668611  0.64668611\n",
      " -1.02560682  0.64668611 -0.11515415 -1.04391007 -1.04391007  0.3627079\n",
      " -0.11515415  2.05330408 -0.11515415  0.64668611  0.64668611 -1.02560682\n",
      " -0.11515415  0.38101115 -0.11515415  0.64668611  0.64668611 -0.28206981\n",
      "  0.64668611  0.64668611  0.64668611  0.64668611 -1.04391007  0.64668611\n",
      " -0.28206981 -0.11515415 -1.04391007  0.64668611 -1.78744708  0.64668611\n",
      " -1.78744708 -0.28206981]\n",
      "P is: [0.12407842370467914, 0.6562632976580072, 0.26393669965498123, 0.12407842370467914, 0.5941169564552661, 0.2603962475724781, 0.8862810522810406, 0.6562632976580072, 0.7548313776106614, 0.47124323373775034, 0.7548313776106614, 0.14338600425702633, 0.26393669965498123, 0.8862810522810406, 0.6562632976580072, 0.42994640680063245, 0.6562632976580072, 0.6562632976580072, 0.26393669965498123, 0.6562632976580072, 0.47124323373775034, 0.2603962475724781, 0.2603962475724781, 0.5896957808654385, 0.47124323373775034, 0.8862810522810406, 0.47124323373775034, 0.6562632976580072, 0.6562632976580072, 0.26393669965498123, 0.47124323373775034, 0.5941169564552661, 0.47124323373775034, 0.6562632976580072, 0.6562632976580072, 0.42994640680063245, 0.6562632976580072, 0.6562632976580072, 0.6562632976580072, 0.6562632976580072, 0.2603962475724781, 0.6562632976580072, 0.42994640680063245, 0.47124323373775034, 0.2603962475724781, 0.6562632976580072, 0.14338600425702633, 0.6562632976580072, 0.14338600425702633, 0.42994640680063245]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.650\n",
      "(*) epoch 2, cost 2.083\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.475\n",
      "(*) epoch 2, cost 3.000\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.516162049482909, 2.768770001128728, 1.294923209617375, 1.294923209617375, 1.5664979025084702, 1.7877367423740043, 1.5664979025084702, 1.5664979025084702, 1.7400602623729367, 2.586297169137827, 1.5664979025084702, 2.586297169137827, 2.011634955264032, 1.5664979025084702, 2.586297169137827, 1.5664979025084702, 3.0314342218933885, 1.5664979025084702, 2.307556401480932, 2.011634955264032, 1.8624193487253704, 1.5664979025084702, 3.740892787757017, 1.5664979025084702, 1.294923209617375, 1.5664979025084702, 1.5664979025084702, 2.3147224762467316, 1.5664979025084702, 1.5664979025084702, 1.812083495699809, 1.5664979025084702, 1.294923209617375, 1.5664979025084702, 1.5664979025084702, 2.3147224762467316, 2.011634955264032, 1.5664979025084702, 1.5664979025084702, 1.294923209617375, 2.011634955264032, 1.7400602623729367, 1.7877367423740043, 1.7877367423740043, 2.232873795129566, 1.7400602623729367, 1.5664979025084702, 1.5664979025084702, 1.5664979025084702, 1.5664979025084702]\n",
      "all_sum after preprocessing is: [-0.63559562  1.94597348 -1.091559   -1.091559   -0.53185568 -0.0758923\n",
      " -0.53185568 -0.53185568 -0.1741514   1.56990511 -0.53185568  1.56990511\n",
      "  0.38555193 -0.53185568  1.56990511 -0.53185568  2.48731272 -0.53185568\n",
      "  0.99543283  0.38555193  0.07802522 -0.53185568  3.94947517 -0.53185568\n",
      " -1.091559   -0.53185568 -0.53185568  1.01020179 -0.53185568 -0.53185568\n",
      " -0.02571473 -0.53185568 -1.091559   -0.53185568 -0.53185568  1.01020179\n",
      "  0.38555193 -0.53185568 -0.53185568 -1.091559    0.38555193 -0.1741514\n",
      " -0.0758923  -0.0758923   0.84151531 -0.1741514  -0.53185568 -0.53185568\n",
      " -0.53185568 -0.53185568]\n",
      "P is: [0.3462428320914087, 0.8750069262852805, 0.25132482188803823, 0.25132482188803823, 0.3700841850137163, 0.4810360265846326, 0.3700841850137163, 0.3700841850137163, 0.45657185531805233, 0.8277700807098824, 0.3700841850137163, 0.8277700807098824, 0.595211459579648, 0.3700841850137163, 0.8277700807098824, 0.3700841850137163, 0.9232475942153129, 0.3700841850137163, 0.7301596706373038, 0.595211459579648, 0.5194964151360825, 0.3700841850137163, 0.9810993082918763, 0.3700841850137163, 0.25132482188803823, 0.3700841850137163, 0.3700841850137163, 0.733059637256396, 0.3700841850137163, 0.3700841850137163, 0.4935716726205938, 0.3700841850137163, 0.25132482188803823, 0.3700841850137163, 0.3700841850137163, 0.733059637256396, 0.595211459579648, 0.3700841850137163, 0.3700841850137163, 0.25132482188803823, 0.595211459579648, 0.45657185531805233, 0.4810360265846326, 0.4810360265846326, 0.6987842609987822, 0.45657185531805233, 0.3700841850137163, 0.3700841850137163, 0.3700841850137163, 0.3700841850137163]\n",
      "all_sum before preprocessing is: [1.8147623334920027, 0.8083183960563618, 0.5618326225445813, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 0.5618326225445813, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 1.6090412754774197, 1.8947864315600973, 0.8083183960563618, 0.8083183960563618, 1.5050958498655074, 2.1195744546300945, 1.1980089777509517, 0.8083183960563618, 0.8083183960563618, 1.1980089777509517, 0.8083183960563618, 0.5618326225445813, 1.4250717517974127, 1.5050958498655074, 0.8083183960563618, 1.1980089777509517, 2.255259929055695, 0.8083183960563618, 0.8083183960563618, 2.262779262812904, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 1.8947864315600973, 0.5618326225445813, 1.5050958498655074, 1.6090412754774197, 1.5050958498655074, 2.0087741555439145, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618, 0.5618326225445813, 0.8083183960563618, 0.8083183960563618, 0.8083183960563618]\n",
      "all_sum after preprocessing is: [ 1.53792044 -0.56581065 -1.08103039 -0.56581065 -0.56581065 -0.56581065\n",
      " -0.56581065 -1.08103039 -0.56581065 -0.56581065 -0.56581065  1.10790962\n",
      "  1.70519173 -0.56581065 -0.56581065  0.89063649  2.1750575   0.2487446\n",
      " -0.56581065 -0.56581065  0.2487446  -0.56581065 -1.08103039  0.72336519\n",
      "  0.89063649 -0.56581065  0.2487446   2.45867563 -0.56581065 -0.56581065\n",
      "  2.47439301 -0.56581065 -0.56581065 -0.56581065 -0.56581065 -0.56581065\n",
      " -0.56581065  1.70519173 -1.08103039  0.89063649  1.10790962  0.89063649\n",
      "  1.94345589 -0.56581065 -0.56581065 -0.56581065 -1.08103039 -0.56581065\n",
      " -0.56581065 -0.56581065]\n",
      "P is: [0.8231622145517586, 0.3622040567271465, 0.2533110747411278, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.2533110747411278, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.7517391936978245, 0.8462115894296384, 0.3622040567271465, 0.3622040567271465, 0.7090215035556316, 0.897987198271902, 0.561867479796083, 0.3622040567271465, 0.3622040567271465, 0.561867479796083, 0.3622040567271465, 0.2533110747411278, 0.6733476238595603, 0.7090215035556316, 0.3622040567271465, 0.561867479796083, 0.9211935727089509, 0.3622040567271465, 0.3622040567271465, 0.9223270637068185, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.8462115894296384, 0.2533110747411278, 0.7090215035556316, 0.7517391936978245, 0.7090215035556316, 0.8747313185613753, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465, 0.2533110747411278, 0.3622040567271465, 0.3622040567271465, 0.3622040567271465]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.132\n",
      "(*) epoch 2, cost 2.456\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.457\n",
      "(*) epoch 2, cost 1.966\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [5.110458655045474, 6.10552784484784, 3.9680951610428115, 4.975478875122955, 4.10307494096533, 6.171015713188009, 5.7318149523115975, 4.242858958150938, 4.28459098003693, 4.817039498949868, 5.6846391958444045, 7.4595040590859805, 5.7318149523115975, 3.3939146202438812, 3.621502660884815, 7.4595040590859805, 4.419570759959449, 6.380291641955968, 4.88287061440454, 4.126534537215898, 6.305995493110528, 4.88287061440454, 6.305995493110528, 7.869247636116627, 6.171015713188009, 7.112911558927984, 4.747890834482021, 7.131183984563408, 5.7318149523115975, 3.3939146202438812, 4.747890834482021, 5.596835172389079, 4.368151114310335, 6.305995493110528, 6.515271421878487, 7.594483839008499, 8.308448396993038, 4.242858958150938, 4.952019278872387, 4.952019278872387, 7.4595040590859805, 7.869247636116627, 5.7318149523115975, 7.020303298209569, 7.869247636116627, 6.09218228842561, 4.747890834482021, 5.012969871295597, 7.594483839008499, 4.817039498949868]\n",
      "all_sum after preprocessing is: [-4.33892372e-01  3.20955587e-01 -1.30047608e+00 -5.36286469e-01\n",
      " -1.19808199e+00  3.70633925e-01  3.74613160e-02 -1.09204345e+00\n",
      " -1.06038602e+00 -6.56476745e-01  1.67433373e-03  1.34806626e+00\n",
      "  3.74613160e-02 -1.73604279e+00 -1.56339714e+00  1.34806626e+00\n",
      " -9.57991925e-01  5.29388220e-01 -6.06538023e-01 -1.18028581e+00\n",
      "  4.73028022e-01 -6.06538023e-01  4.73028022e-01  1.65889299e+00\n",
      "  3.70633925e-01  1.08514520e+00 -7.08932120e-01  1.09900645e+00\n",
      "  3.74613160e-02 -1.73604279e+00 -7.08932120e-01 -6.49327812e-02\n",
      " -9.96998273e-01  4.73028022e-01  6.31782317e-01  1.45046035e+00\n",
      "  1.99206560e+00 -1.09204345e+00 -5.54082647e-01 -5.54082647e-01\n",
      "  1.34806626e+00  1.65889299e+00  3.74613160e-02  1.01489365e+00\n",
      "  1.65889299e+00  3.10831802e-01 -7.08932120e-01 -5.07846234e-01\n",
      "  1.45046035e+00 -6.56476745e-01]\n",
      "P is: [0.39319725306042597, 0.5795571182527685, 0.2140849037438426, 0.3690518661739274, 0.2318165961499437, 0.5916121481247033, 0.5093642339225178, 0.2512336786613722, 0.25723569224813736, 0.34153150552367717, 0.5004185833341033, 0.7938133049006689, 0.5093642339225178, 0.14981627161229522, 0.17315972001812166, 0.7938133049006689, 0.2772804250137604, 0.6293404126368172, 0.35284932553570003, 0.23500081097712008, 0.6161001977290929, 0.35284932553570003, 0.6161001977290929, 0.8400893436706551, 0.5916121481247033, 0.7474664293743386, 0.32983484548147946, 0.7500738982027064, 0.5093642339225178, 0.14981627161229522, 0.32983484548147946, 0.48377250591949217, 0.26953200598277927, 0.6161001977290929, 0.6528934872387061, 0.8100692726786863, 0.8799614961206224, 0.2512336786613722, 0.364917723335958, 0.364917723335958, 0.7938133049006689, 0.8400893436706551, 0.5093642339225178, 0.7339767511384986, 0.8400893436706551, 0.5770882815935708, 0.32983484548147946, 0.37569855408599756, 0.8100692726786863, 0.34153150552367717]\n",
      "all_sum before preprocessing is: [2.3592176368860063, 0.7936729146074746, 2.932824239162422, 1.3672795168838903, 2.3592176368860063, 0.7936729146074746, 2.3592176368860063, 0.31306340876277605, 0.31306340876277605, 2.932824239162422, 0.7936729146074746, 2.3592176368860063, 1.3672795168838903, 2.4522147333177235, 2.3592176368860063, 2.932824239162422, 1.3672795168838903, 2.3592176368860063, 0.7936729146074746, 2.3592176368860063, 0.7936729146074746, 1.3672795168838903, 1.3672795168838903, 0.8866700110391917, 0.31306340876277605, 2.4522147333177235, 2.3592176368860063, 0.31306340876277605, 2.4522147333177235, 1.3672795168838903, 0.7936729146074746, 0.31306340876277605, 0.7936729146074746, 0.7936729146074746, 2.3592176368860063, 2.3592176368860063, 0.7936729146074746, 0.7936729146074746, 0.7936729146074746, 1.3672795168838903, 0.31306340876277605, 0.31306340876277605, 2.932824239162422, 1.8786081310413079, 2.3592176368860063, 2.3592176368860063, 0.7936729146074746, 2.932824239162422, 2.3592176368860063, 0.7936729146074746]\n",
      "all_sum after preprocessing is: [ 0.91027621 -0.85234967  1.55609222 -0.20653367  0.91027621 -0.85234967\n",
      "  0.91027621 -1.39346149 -1.39346149  1.55609222 -0.85234967  0.91027621\n",
      " -0.20653367  1.0149804   0.91027621  1.55609222 -0.20653367  0.91027621\n",
      " -0.85234967  0.91027621 -0.85234967 -0.20653367 -0.20653367 -0.74764549\n",
      " -1.39346149  1.0149804   0.91027621 -1.39346149  1.0149804  -0.20653367\n",
      " -0.85234967 -1.39346149 -0.85234967 -0.85234967  0.91027621  0.91027621\n",
      " -0.85234967 -0.85234967 -0.85234967 -0.20653367 -1.39346149 -1.39346149\n",
      "  1.55609222  0.36916439  0.91027621  0.91027621 -0.85234967  1.55609222\n",
      "  0.91027621 -0.85234967]\n",
      "P is: [0.7130566802720933, 0.298940192091309, 0.8257918962960005, 0.4485493442573821, 0.7130566802720933, 0.298940192091309, 0.7130566802720933, 0.1988557238449016, 0.1988557238449016, 0.8257918962960005, 0.298940192091309, 0.7130566802720933, 0.4485493442573821, 0.7339936890944122, 0.7130566802720933, 0.8257918962960005, 0.4485493442573821, 0.7130566802720933, 0.298940192091309, 0.7130566802720933, 0.298940192091309, 0.4485493442573821, 0.4485493442573821, 0.32133455387588367, 0.1988557238449016, 0.7339936890944122, 0.7130566802720933, 0.1988557238449016, 0.7339936890944122, 0.4485493442573821, 0.298940192091309, 0.1988557238449016, 0.298940192091309, 0.298940192091309, 0.7130566802720933, 0.7130566802720933, 0.298940192091309, 0.298940192091309, 0.298940192091309, 0.4485493442573821, 0.1988557238449016, 0.1988557238449016, 0.8257918962960005, 0.5912570497519964, 0.7130566802720933, 0.7130566802720933, 0.298940192091309, 0.8257918962960005, 0.7130566802720933, 0.298940192091309]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.905\n",
      "(*) epoch 2, cost 4.471\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.917\n",
      "(*) epoch 2, cost 2.471\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.969551552791891, 2.583283199754222, 2.5040930988933114, 4.318194711927335, 2.5040930988933114, 2.583283199754222, 2.583283199754222, 2.7400827628175124, 2.583283199754222, 2.5040930988933114, 2.5040930988933114, 2.583283199754222, 2.583283199754222, 2.583283199754222, 2.5040930988933114, 2.583283199754222, 2.583283199754222, 2.583283199754222, 2.583283199754222, 2.5040930988933114, 2.583283199754222, 2.5040930988933114, 4.4749942749906255, 2.5040930988933114, 2.583283199754222, 2.583283199754222, 2.7400827628175124, 2.583283199754222, 4.397384812788245, 2.583283199754222, 2.583283199754222, 2.583283199754222, 4.318194711927335, 4.318194711927335, 2.583283199754222, 2.5040930988933114, 2.583283199754222, 2.5040930988933114, 4.554184375851536, 4.397384812788245, 4.397384812788245, 4.397384812788245, 2.583283199754222, 2.5040930988933114, 2.583283199754222, 2.5040930988933114, 2.583283199754222, 2.5040930988933114, 3.0051214625479936, 4.397384812788245]\n",
      "all_sum after preprocessing is: [ 0.02961709 -0.49839204 -0.60664087  1.8731435  -0.60664087 -0.49839204\n",
      " -0.49839204 -0.28405504 -0.49839204 -0.60664087 -0.60664087 -0.49839204\n",
      " -0.49839204 -0.49839204 -0.60664087 -0.49839204 -0.49839204 -0.49839204\n",
      " -0.49839204 -0.60664087 -0.49839204 -0.60664087  2.0874805  -0.60664087\n",
      " -0.49839204 -0.49839204 -0.28405504 -0.49839204  1.98139233 -0.49839204\n",
      " -0.49839204 -0.49839204  1.8731435   1.8731435  -0.49839204 -0.60664087\n",
      " -0.49839204 -0.60664087  2.19572933  1.98139233  1.98139233  1.98139233\n",
      " -0.49839204 -0.60664087 -0.49839204 -0.60664087 -0.49839204 -0.60664087\n",
      "  0.07823934  1.98139233]\n",
      "P is: [0.507403731906473, 0.3779186190590959, 0.3528258408825329, 0.866821587430317, 0.3528258408825329, 0.3779186190590959, 0.3779186190590959, 0.4294599110258276, 0.3779186190590959, 0.3528258408825329, 0.3528258408825329, 0.3779186190590959, 0.3779186190590959, 0.3779186190590959, 0.3528258408825329, 0.3779186190590959, 0.3779186190590959, 0.3779186190590959, 0.3779186190590959, 0.3528258408825329, 0.3779186190590959, 0.3528258408825329, 0.8896803815347173, 0.3528258408825329, 0.3779186190590959, 0.3779186190590959, 0.4294599110258276, 0.3779186190590959, 0.8788295065536537, 0.3779186190590959, 0.3779186190590959, 0.3779186190590959, 0.866821587430317, 0.866821587430317, 0.3779186190590959, 0.3528258408825329, 0.3779186190590959, 0.3528258408825329, 0.8998653472038904, 0.8788295065536537, 0.8788295065536537, 0.8788295065536537, 0.3779186190590959, 0.3528258408825329, 0.3779186190590959, 0.3528258408825329, 0.3779186190590959, 0.3528258408825329, 0.5195498644636536, 0.8788295065536537]\n",
      "all_sum before preprocessing is: [2.190632043429871, 2.3973078016303617, 2.3671465917009593, 2.190632043429871, 2.3671465917009593, 4.292892694401031, 4.292892694401031, 2.3671465917009593, 2.3671465917009593, 4.469407242672119, 2.190632043429871, 2.3671465917009593, 2.840956021606309, 2.190632043429871, 3.285304341600555, 2.8711172315357114, 4.439246032742716, 2.3973078016303617, 1.548437656030627, 3.285304341600555, 2.3973078016303617, 2.3973078016303617, 3.4741837587306987, 3.620537097072384, 2.2207932533592736, 1.548437656030627, 1.3719231077595389, 3.2551431316711525, 2.190632043429871, 1.548437656030627, 3.0786285834000644, 4.292892694401031, 2.3671465917009593, 2.190632043429871, 2.3973078016303617, 4.439246032742716, 1.3719231077595389, 2.3973078016303617, 2.3671465917009593, 2.3671465917009593, 2.3973078016303617, 2.3671465917009593, 2.190632043429871, 2.3671465917009593, 2.3671465917009593, 4.439246032742716, 2.3671465917009593, 2.3671465917009593, 2.3671465917009593, 2.3671465917009593]\n",
      "all_sum after preprocessing is: [-0.58170482 -0.33205025 -0.36848357 -0.58170482 -0.36848357  1.95772692\n",
      "  1.95772692 -0.36848357 -0.36848357  2.17094817 -0.58170482 -0.36848357\n",
      "  0.20385588 -0.58170482  0.7406077   0.2402892   2.13451486 -0.33205025\n",
      " -1.35744536  0.7406077  -0.33205025 -0.33205025  0.96876513  1.14555306\n",
      " -0.5452715  -1.35744536 -1.57066661  0.70417438 -0.58170482 -1.35744536\n",
      "  0.49095313  1.95772692 -0.36848357 -0.58170482 -0.33205025  2.13451486\n",
      " -1.57066661 -0.33205025 -0.36848357 -0.36848357 -0.33205025 -0.36848357\n",
      " -0.58170482 -0.36848357 -0.36848357  2.13451486 -0.36848357 -0.36848357\n",
      " -0.36848357 -0.36848357]\n",
      "P is: [0.35854040963730105, 0.41774185037376554, 0.40890749624473893, 0.35854040963730105, 0.40890749624473893, 0.8762867428150913, 0.8762867428150913, 0.40890749624473893, 0.40890749624473893, 0.8976101425483385, 0.35854040963730105, 0.40890749624473893, 0.5507882080568257, 0.35854040963730105, 0.6771287298740728, 0.5597849177664026, 0.8942128573698128, 0.41774185037376554, 0.20465581248031, 0.6771287298740728, 0.41774185037376554, 0.41774185037376554, 0.7248732941843204, 0.7586977289815247, 0.3669621518333362, 0.20465581248031, 0.1721213822596779, 0.6691126360878189, 0.35854040963730105, 0.20465581248031, 0.6203309402407277, 0.8762867428150913, 0.40890749624473893, 0.35854040963730105, 0.41774185037376554, 0.8942128573698128, 0.1721213822596779, 0.41774185037376554, 0.40890749624473893, 0.40890749624473893, 0.41774185037376554, 0.40890749624473893, 0.35854040963730105, 0.40890749624473893, 0.40890749624473893, 0.8942128573698128, 0.40890749624473893, 0.40890749624473893, 0.40890749624473893, 0.40890749624473893]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.070\n",
      "(*) epoch 2, cost 1.947\n",
      "(*) epoch 3, cost 1.720\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.581\n",
      "(*) epoch 2, cost 2.629\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.7977406748969624, 3.0699803825085965, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 3.6896158030687625, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 3.6896158030687625, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 3.6896158030687625, 2.7977406748969624, 3.6896158030687625, 2.7977406748969624, 2.763626347488949, 3.6896158030687625, 3.6896158030687625, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 3.6896158030687625, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624, 2.763626347488949, 2.7977406748969624, 3.6896158030687625, 2.7977406748969624, 3.6555014756607487, 2.763626347488949, 3.6896158030687625, 3.6896158030687625, 2.7977406748969624, 2.7977406748969624, 2.7977406748969624]\n",
      "all_sum after preprocessing is: [-0.53985058  0.19895257 -0.53985058 -0.53985058 -0.53985058 -0.53985058\n",
      " -0.53985058 -0.53985058 -0.53985058 -0.53985058 -0.53985058 -0.53985058\n",
      " -0.53985058  1.88051699 -0.53985058 -0.53985058 -0.53985058 -0.53985058\n",
      "  1.88051699 -0.53985058 -0.53985058 -0.53985058  1.88051699 -0.53985058\n",
      "  1.88051699 -0.53985058 -0.63242992  1.88051699  1.88051699 -0.53985058\n",
      " -0.53985058 -0.53985058  1.88051699 -0.53985058 -0.53985058 -0.53985058\n",
      " -0.53985058 -0.53985058 -0.53985058 -0.63242992 -0.53985058  1.88051699\n",
      " -0.53985058  1.78793764 -0.63242992  1.88051699  1.88051699 -0.53985058\n",
      " -0.53985058 -0.53985058]\n",
      "P is: [0.36822234178970104, 0.5495747286427237, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.867670497176004, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.867670497176004, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.867670497176004, 0.36822234178970104, 0.867670497176004, 0.36822234178970104, 0.34695976490349584, 0.867670497176004, 0.867670497176004, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.867670497176004, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104, 0.34695976490349584, 0.36822234178970104, 0.867670497176004, 0.36822234178970104, 0.8566742395291349, 0.34695976490349584, 0.867670497176004, 0.867670497176004, 0.36822234178970104, 0.36822234178970104, 0.36822234178970104]\n",
      "all_sum before preprocessing is: [1.586212236134957, 2.8448759491211604, 2.5390739921609757, 5.233985254275736, 1.5366467390896466, 2.5915682682787295, 3.899797478310243, 1.2804102791747722, 1.2804102791747722, 3.53056347956801, 2.5390739921609757, 2.5390739921609757, 3.399416579677736, 1.586212236134957, 1.3299757762200828, 2.5390739921609757, 2.0156633066669327, 2.79531045207585, 2.64113376532404, 3.2743270196531356, 3.899797478310243, 2.5915682682787295, 3.922827265171779, 1.5366467390896466, 3.448350805900836, 1.3299757762200828, 2.6641635521855758, 3.448350805900836, 2.7137290492308863, 1.2804102791747722, 1.2804102791747722, 1.2804102791747722, 2.8478047281936036, 1.2804102791747722, 2.5390739921609757, 3.8502319812649324, 1.5366467390896466, 2.2021119723653966, 2.5390739921609757, 1.3299757762200828, 3.8502319812649324, 1.5366467390896466, 2.7137290492308863, 1.2804102791747722, 1.2804102791747722, 1.2804102791747722, 1.2804102791747722, 1.2804102791747722, 1.2804102791747722, 2.5886394892062863]\n",
      "all_sum after preprocessing is: [-0.76542362  0.51687182  0.20532836  2.95083727 -0.81591972  0.25880823\n",
      "  1.59159978 -1.07696709 -1.07696709  1.21543331  0.20532836  0.20532836\n",
      "  1.0818241  -0.76542362 -1.02647099  0.20532836 -0.3279095   0.46637572\n",
      "  0.30930433  0.95438595  1.59159978  0.25880823  1.61506195 -0.81591972\n",
      "  1.13167708 -1.02647099  0.33276651  1.13167708  0.38326261 -1.07696709\n",
      " -1.07696709 -1.07696709  0.51985559 -1.07696709  0.20532836  1.54110367\n",
      " -0.81591972 -0.13796021  0.20532836 -1.02647099  1.54110367 -0.81591972\n",
      "  0.38326261 -1.07696709 -1.07696709 -1.07696709 -1.07696709 -1.07696709\n",
      " -1.07696709  0.25582446]\n",
      "P is: [0.3174698990369546, 0.6264160038387243, 0.5511525008751266, 0.9503030452362302, 0.3066304749373542, 0.5643433050985629, 0.8308410613288959, 0.2540803957701948, 0.2540803957701948, 0.7712588992597708, 0.5511525008751266, 0.5511525008751266, 0.7468390216756419, 0.3174698990369546, 0.2637688486226265, 0.5511525008751266, 0.4187493612974193, 0.6145255806221944, 0.5767154466788632, 0.7219963718412141, 0.8308410613288959, 0.5643433050985629, 0.8341129864467705, 0.3066304749373542, 0.7561482648435274, 0.2637688486226265, 0.5824323577451904, 0.7561482648435274, 0.5946597627016644, 0.2540803957701948, 0.2540803957701948, 0.2540803957701948, 0.627113998344044, 0.2540803957701948, 0.5511525008751266, 0.8236251096945213, 0.3066304749373542, 0.46556454757530374, 0.5511525008751266, 0.2637688486226265, 0.8236251096945213, 0.3066304749373542, 0.5946597627016644, 0.2540803957701948, 0.2540803957701948, 0.2540803957701948, 0.2540803957701948, 0.2540803957701948, 0.2540803957701948, 0.5636095758446836]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.740\n",
      "(*) epoch 2, cost 2.277\n",
      "(*) epoch 3, cost 1.705\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.477\n",
      "(*) epoch 2, cost 3.022\n",
      "(*) epoch 3, cost 2.334\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.2872728959472282, 0.29352197220433374, 0.2872728959472282, 0.29352197220433374, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282, 1.574493565870897, 0.29352197220433374, 0.2872728959472282, 0.29352197220433374, 0.29352197220433374, 0.29352197220433374, 0.2872728959472282, 0.2872728959472282, 0.29352197220433374, 0.2872728959472282, 0.29352197220433374, 0.29352197220433374, 0.29352197220433374, 0.2872728959472282, 0.051867397846094745, 0.2872728959472282, 0.2872728959472282, 1.5807426421280024, 0.29352197220433374, 0.29352197220433374, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282, 0.29352197220433374, 0.2872728959472282, 0.29352197220433374, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282, 0.05811647410320025, 0.29352197220433374, 0.2872728959472282, 2.5966015341627346, 0.2872728959472282, 0.2872728959472282, 0.051867397846094745, 0.2872728959472282, 0.2872728959472282, 0.2872728959472282]\n",
      "all_sum after preprocessing is: [-0.20828596 -0.19309386 -0.20828596 -0.19309386 -0.20828596 -0.20828596\n",
      " -0.20828596 -0.20828596  2.92107067 -0.19309386 -0.20828596 -0.19309386\n",
      " -0.19309386 -0.19309386 -0.20828596 -0.20828596 -0.19309386 -0.20828596\n",
      " -0.19309386 -0.19309386 -0.19309386 -0.20828596 -0.78057925 -0.20828596\n",
      " -0.20828596  2.93626277 -0.19309386 -0.19309386 -0.20828596 -0.20828596\n",
      " -0.20828596 -0.20828596 -0.20828596 -0.20828596 -0.19309386 -0.20828596\n",
      " -0.19309386 -0.20828596 -0.20828596 -0.20828596 -0.76538715 -0.19309386\n",
      " -0.20828596  5.40591295 -0.20828596 -0.20828596 -0.78057925 -0.20828596\n",
      " -0.20828596 -0.20828596]\n",
      "P is: [0.44811594832726626, 0.4518759689083088, 0.44811594832726626, 0.4518759689083088, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626, 0.9488782604550815, 0.4518759689083088, 0.44811594832726626, 0.4518759689083088, 0.4518759689083088, 0.4518759689083088, 0.44811594832726626, 0.44811594832726626, 0.4518759689083088, 0.44811594832726626, 0.4518759689083088, 0.4518759689083088, 0.4518759689083088, 0.44811594832726626, 0.3141950569719748, 0.44811594832726626, 0.44811594832726626, 0.949610198169589, 0.4518759689083088, 0.4518759689083088, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626, 0.4518759689083088, 0.44811594832726626, 0.4518759689083088, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626, 0.3174778016633174, 0.4518759689083088, 0.44811594832726626, 0.9955301161587248, 0.44811594832726626, 0.44811594832726626, 0.3141950569719748, 0.44811594832726626, 0.44811594832726626, 0.44811594832726626]\n",
      "all_sum before preprocessing is: [2.792168479435202, 3.1604476551162874, 2.792168479435202, 2.5464373000284986, 3.110267810788688, 3.5982312811893866, 3.5982312811893866, 2.9842209261015977, 3.5480514368617877, 2.792168479435202, 3.5982312811893866, 3.5480514368617877, 2.792168479435202, 3.5982312811893866, 2.792168479435202, 2.792168479435202, 2.741988635107603, 3.5982312811893866, 2.792168479435202, 2.792168479435202, 3.5982312811893866, 2.127978280019814, 3.5982312811893866, 2.9842209261015977, 3.5982312811893866, 2.792168479435202, 2.792168479435202, 3.5982312811893866, 2.178158124347413, 3.5982312811893866, 2.9842209261015977, 3.312155386585972, 3.1604476551162874, 1.7403744982743143, 2.792168479435202, 2.792168479435202, 2.9340410817739984, 4.472767577220279, 3.5149970439964098, 2.3543848533621032, 2.3543848533621032, 3.312155386585972, 3.5982312811893866, 3.312155386585972, 2.792168479435202, 2.792168479435202, 2.3543848533621032, 2.178158124347413, 4.1980514892708065, 3.5982312811893866]\n",
      "all_sum after preprocessing is: [-0.50764203  0.17104494 -0.50764203 -0.96049019  0.07857051  0.97781889\n",
      "  0.97781889 -0.15371625  0.88534446 -0.50764203  0.97781889  0.88534446\n",
      " -0.50764203  0.97781889 -0.50764203 -0.50764203 -0.60011646  0.97781889\n",
      " -0.50764203 -0.50764203  0.97781889 -1.73165159  0.97781889 -0.15371625\n",
      "  0.97781889 -0.50764203 -0.50764203  0.97781889 -1.63917716  0.97781889\n",
      " -0.15371625  0.45062106  0.17104494 -2.44595111 -0.50764203 -0.50764203\n",
      " -0.24619068  2.58946686  0.82442984 -1.31441597 -1.31441597  0.45062106\n",
      "  0.97781889  0.45062106 -0.50764203 -0.50764203 -1.31441597 -1.63917716\n",
      "  2.08320357  0.97781889]\n",
      "P is: [0.37574645195047857, 0.5426572867018813, 0.37574645195047857, 0.2767800606607614, 0.5196325297557957, 0.7266752214154123, 0.7266752214154123, 0.4616464280033553, 0.7079284985006644, 0.37574645195047857, 0.7266752214154123, 0.7079284985006644, 0.37574645195047857, 0.7266752214154123, 0.37574645195047857, 0.37574645195047857, 0.3543170509520882, 0.7266752214154123, 0.37574645195047857, 0.37574645195047857, 0.7266752214154123, 0.15037644480483403, 0.7266752214154123, 0.4616464280033553, 0.7266752214154123, 0.37574645195047857, 0.37574645195047857, 0.7266752214154123, 0.16257705713472304, 0.7266752214154123, 0.4616464280033553, 0.6107868856035644, 0.5426572867018813, 0.07973514153691036, 0.37574645195047857, 0.37574645195047857, 0.4387613236737692, 0.9301806007874279, 0.6951758618579379, 0.2117488307716184, 0.2117488307716184, 0.6107868856035644, 0.7266752214154123, 0.6107868856035644, 0.37574645195047857, 0.37574645195047857, 0.2117488307716184, 0.16257705713472304, 0.8892599038813244, 0.7266752214154123]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.143\n",
      "(*) epoch 2, cost 1.359\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.531\n",
      "(*) epoch 2, cost 3.838\n",
      "(*) epoch 3, cost 3.246\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.159054452068188, 1.159054452068188, 1.159054452068188, 1.8388856571707497, 1.685850696586499, 1.685850696586499, 1.685850696586499, 1.159054452068188, 1.685850696586499, 1.685850696586499, 1.685850696586499, 1.685850696586499, 1.159054452068188, 1.159054452068188, 1.159054452068188, 1.685850696586499, 1.8388856571707497, 1.685850696586499, 1.159054452068188, 1.159054452068188, 1.685850696586499, 1.159054452068188, 1.685850696586499, 1.159054452068188, 1.685850696586499, 1.3120894126524387, 1.685850696586499, 1.159054452068188, 1.159054452068188, 2.380947929863318, 1.685850696586499, 1.685850696586499, 1.685850696586499, 1.685850696586499, 1.685850696586499, 1.159054452068188, 1.685850696586499, 2.380947929863318, 3.163460832125988, 1.685850696586499, 1.159054452068188, 1.685850696586499, 1.685850696586499, 1.159054452068188, 3.8432920372285495, 1.685850696586499, 1.685850696586499, 1.685850696586499, 1.8388856571707497, 1.159054452068188]\n",
      "all_sum after preprocessing is: [-0.90209856 -0.90209856 -0.90209856  0.46104528  0.15419167  0.15419167\n",
      "  0.15419167 -0.90209856  0.15419167  0.15419167  0.15419167  0.15419167\n",
      " -0.90209856 -0.90209856 -0.90209856  0.15419167  0.46104528  0.15419167\n",
      " -0.90209856 -0.90209856  0.15419167 -0.90209856  0.15419167 -0.90209856\n",
      "  0.15419167 -0.59524494  0.15419167 -0.90209856 -0.90209856  1.54794574\n",
      "  0.15419167  0.15419167  0.15419167  0.15419167  0.15419167 -0.90209856\n",
      "  0.15419167  1.54794574  3.1169788   0.15419167 -0.90209856  0.15419167\n",
      "  0.15419167 -0.90209856  4.48012264  0.15419167  0.15419167  0.15419167\n",
      "  0.46104528 -0.90209856]\n",
      "P is: [0.28861943434915177, 0.28861943434915177, 0.28861943434915177, 0.6132621166239611, 0.5384717242217539, 0.5384717242217539, 0.5384717242217539, 0.28861943434915177, 0.5384717242217539, 0.5384717242217539, 0.5384717242217539, 0.5384717242217539, 0.28861943434915177, 0.28861943434915177, 0.28861943434915177, 0.5384717242217539, 0.6132621166239611, 0.5384717242217539, 0.28861943434915177, 0.28861943434915177, 0.5384717242217539, 0.28861943434915177, 0.5384717242217539, 0.28861943434915177, 0.5384717242217539, 0.3554323283688087, 0.5384717242217539, 0.28861943434915177, 0.28861943434915177, 0.8246168344207458, 0.5384717242217539, 0.5384717242217539, 0.5384717242217539, 0.5384717242217539, 0.5384717242217539, 0.28861943434915177, 0.5384717242217539, 0.8246168344207458, 0.9575876963155636, 0.5384717242217539, 0.28861943434915177, 0.5384717242217539, 0.5384717242217539, 0.28861943434915177, 0.9887949525734347, 0.5384717242217539, 0.5384717242217539, 0.5384717242217539, 0.6132621166239611, 0.28861943434915177]\n",
      "all_sum before preprocessing is: [3.9360611412030826, 3.9071677795953224, 4.2456748215765865, 4.4410749979106905, 2.6437222743593645, 4.2456748215765865, 5.065545118552831, 4.2456748215765865, 4.2456748215765865, 3.663116310064538, 3.972729990438043, 2.9455604671056688, 3.9360611412030826, 3.972729990438043, 3.177629492674732, 3.711767603261219, 3.4021539228877145, 5.823976767081181, 3.9360611412030826, 4.168130166772146, 4.4410749979106905, 3.2551741474791727, 5.290069548765813, 5.514363086707677, 6.019376943415285, 3.9360611412030826, 4.4410749979106905, 2.9455604671056688, 3.972729990438043, 4.4410749979106905, 3.711767603261219, 4.216781459968827, 3.663116310064538, 4.518562617760949, 3.663116310064538, 4.750688678284194, 5.823976767081181, 3.9360611412030826, 3.711767603261219, 3.9360611412030826, 5.823976767081181, 5.823976767081181, 4.4410749979106905, 4.2456748215765865, 2.721266929163805, 3.9360611412030826, 4.750688678284194, 3.663116310064538, 3.9360611412030826, 4.2456748215765865]\n",
      "all_sum after preprocessing is: [-0.31884224 -0.35522863  0.07106474  0.31713879 -1.94632828  0.07106474\n",
      "  1.10355513  0.07106474  0.07106474 -0.6625709  -0.27266392 -1.56621324\n",
      " -0.31884224 -0.27266392 -1.27396086 -0.60130268 -0.99120966  2.05867376\n",
      " -0.31884224 -0.02658987  0.31713879 -1.17630626  1.38630634  1.66876678\n",
      "  2.30474781 -0.31884224  0.31713879 -1.56621324 -0.27266392  0.31713879\n",
      " -0.60130268  0.03467835 -0.6625709   0.41472157 -0.6625709   0.70704577\n",
      "  2.05867376 -0.31884224 -0.60130268 -0.31884224  2.05867376  2.05867376\n",
      "  0.31713879  0.07106474 -1.84867367 -0.31884224  0.70704577 -0.6625709\n",
      " -0.31884224  0.07106474]\n",
      "P is: [0.42095792909752977, 0.41211506978152573, 0.5177587119963352, 0.5786267957725271, 0.12495427401932248, 0.5177587119963352, 0.7509256377367287, 0.5177587119963352, 0.5177587119963352, 0.3401623322459455, 0.43225322468174926, 0.1727568950795038, 0.42095792909752977, 0.43225322468174926, 0.21857997153113595, 0.3540457185137921, 0.27067321428975283, 0.8868211241706643, 0.42095792909752977, 0.4933529251535747, 0.5786267957725271, 0.23571699082502837, 0.8000019169562641, 0.8414113316668681, 0.9092694879337537, 0.42095792909752977, 0.5786267957725271, 0.1727568950795038, 0.43225322468174926, 0.5786267957725271, 0.3540457185137921, 0.5086687195295846, 0.3401623322459455, 0.6022194808752357, 0.3401623322459455, 0.6697480546553142, 0.8868211241706643, 0.42095792909752977, 0.3540457185137921, 0.42095792909752977, 0.8868211241706643, 0.8868211241706643, 0.5786267957725271, 0.5177587119963352, 0.13602869805256756, 0.42095792909752977, 0.6697480546553142, 0.3401623322459455, 0.42095792909752977, 0.5177587119963352]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.276\n",
      "(*) epoch 2, cost 1.843\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.998\n",
      "(*) epoch 2, cost 4.642\n",
      "(*) epoch 3, cost 3.992\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.9354853399440937, 1.9354853399440937, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 1.9354853399440937, 3.386198272418634, 3.386198272418634, 1.9354853399440937, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 3.386198272418634, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 3.386198272418634, 1.9354853399440937, 1.9354853399440937, 1.9354853399440937, 3.386198272418634, 1.9354853399440937, 1.9354853399440937, 1.9354853399440937, 1.9354853399440937, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 3.386198272418634, 1.9354853399440937, 1.9354853399440937, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 0.7078061864843456, 1.9354853399440937, 1.9354853399440937, 2.1585191189588864, 1.9354853399440937, 1.9354853399440937, 1.9354853399440937, 2.1585191189588864]\n",
      "all_sum after preprocessing is: [ 0.05244137  0.05244137  0.05244137 -1.64290026  0.05244137 -1.64290026\n",
      "  0.05244137  0.05244137 -1.64290026  0.05244137  0.05244137  2.05577753\n",
      "  2.05577753  0.05244137  0.05244137 -1.64290026  0.05244137  2.05577753\n",
      "  0.05244137 -1.64290026  0.05244137  2.05577753  0.05244137  0.05244137\n",
      "  0.05244137  2.05577753  0.05244137  0.05244137  0.05244137  0.05244137\n",
      "  0.05244137 -1.64290026  0.05244137  2.05577753  0.05244137  0.05244137\n",
      "  0.05244137 -1.64290026  0.05244137  0.05244137 -1.64290026  0.05244137\n",
      " -1.64290026  0.05244137  0.05244137  0.36043589  0.05244137  0.05244137\n",
      "  0.05244137  0.36043589]\n",
      "P is: [0.5131073399655202, 0.5131073399655202, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.5131073399655202, 0.8865301051066198, 0.8865301051066198, 0.5131073399655202, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.8865301051066198, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.8865301051066198, 0.5131073399655202, 0.5131073399655202, 0.5131073399655202, 0.8865301051066198, 0.5131073399655202, 0.5131073399655202, 0.5131073399655202, 0.5131073399655202, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.8865301051066198, 0.5131073399655202, 0.5131073399655202, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.16207081036228885, 0.5131073399655202, 0.5131073399655202, 0.589145947656086, 0.5131073399655202, 0.5131073399655202, 0.5131073399655202, 0.589145947656086]\n",
      "all_sum before preprocessing is: [1.5607990162629335, 1.5607990162629335, 0.9872507246078628, 1.5607990162629335, 2.0652265843683644, 0.9872507246078628, 1.5607990162629335, 0.9872507246078628, 1.5607990162629335, 1.5607990162629335, 2.6387748760234353, 1.5607990162629335, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 2.6387748760234353, 1.5607990162629335, 0.9872507246078628, 1.5607990162629335, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 1.5607990162629335, 1.5607990162629335, 1.5607990162629335, 0.9872507246078628, 1.5607990162629335, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 1.5607990162629335, 1.5607990162629335, 2.0652265843683644, 1.5607990162629335, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 0.9872507246078628, 2.0652265843683644, 1.5607990162629335, 2.0652265843683644, 2.6387748760234353, 0.9872507246078628, 1.5607990162629335, 1.5607990162629335, 2.0652265843683644, 2.6387748760234353]\n",
      "all_sum after preprocessing is: [ 0.23146889  0.23146889 -0.91616336  0.23146889  1.24079513 -0.91616336\n",
      "  0.23146889 -0.91616336  0.23146889  0.23146889  2.38842738  0.23146889\n",
      " -0.91616336 -0.91616336 -0.91616336  2.38842738  0.23146889 -0.91616336\n",
      "  0.23146889 -0.91616336 -0.91616336 -0.91616336 -0.91616336  0.23146889\n",
      "  0.23146889  0.23146889 -0.91616336  0.23146889 -0.91616336 -0.91616336\n",
      " -0.91616336 -0.91616336 -0.91616336  0.23146889  0.23146889  1.24079513\n",
      "  0.23146889 -0.91616336 -0.91616336 -0.91616336 -0.91616336  1.24079513\n",
      "  0.23146889  1.24079513  2.38842738 -0.91616336  0.23146889  0.23146889\n",
      "  1.24079513  2.38842738]\n",
      "P is: [0.5576102313379855, 0.5576102313379855, 0.2857402800343533, 0.5576102313379855, 0.7757023880138931, 0.2857402800343533, 0.5576102313379855, 0.2857402800343533, 0.5576102313379855, 0.5576102313379855, 0.9159405657955668, 0.5576102313379855, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.9159405657955668, 0.5576102313379855, 0.2857402800343533, 0.5576102313379855, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.5576102313379855, 0.5576102313379855, 0.5576102313379855, 0.2857402800343533, 0.5576102313379855, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.5576102313379855, 0.5576102313379855, 0.7757023880138931, 0.5576102313379855, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.2857402800343533, 0.7757023880138931, 0.5576102313379855, 0.7757023880138931, 0.9159405657955668, 0.2857402800343533, 0.5576102313379855, 0.5576102313379855, 0.7757023880138931, 0.9159405657955668]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.959\n",
      "(*) epoch 2, cost 1.450\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.993\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.33940719326706287, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 0.33940719326706287, 1.6739682879415148, 1.6739682879415148, 1.985297133435709, 0.33940719326706287, 1.6739682879415148, 1.6739682879415148, 2.725589410954878, 1.985297133435709, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 2.725589410954878, 1.6739682879415148, 2.725589410954878, 0.6507360387612571, 2.725589410954878, 2.725589410954878, 1.6739682879415148, 1.8659708932330192, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 1.985297133435709, 1.6739682879415148, 1.6739682879415148, 1.6739682879415148, 2.5766864840679227, 2.725589410954878, 1.985297133435709, 1.985297133435709, 2.5766864840679227, 1.6739682879415148, 1.6739682879415148, 1.985297133435709, 2.725589410954878, 2.8618735646608164, 1.6739682879415148]\n",
      "all_sum after preprocessing is: [-2.56493891 -0.25566917 -0.25566917 -0.25566917 -0.25566917 -0.25566917\n",
      " -0.25566917 -2.56493891 -0.25566917 -0.25566917  0.28304148 -2.56493891\n",
      " -0.25566917 -0.25566917  1.56401284  0.28304148 -0.25566917 -0.25566917\n",
      " -0.25566917 -0.25566917 -0.25566917 -0.25566917  1.56401284 -0.25566917\n",
      "  1.56401284 -2.02622825  1.56401284  1.56401284 -0.25566917  0.07656425\n",
      " -0.25566917 -0.25566917 -0.25566917 -0.25566917 -0.25566917  0.28304148\n",
      " -0.25566917 -0.25566917 -0.25566917  1.30635733  1.56401284  0.28304148\n",
      "  0.28304148  1.30635733 -0.25566917 -0.25566917  0.28304148  1.56401284\n",
      "  1.79983335 -0.25566917]\n",
      "P is: [0.07142926469947743, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.07142926469947743, 0.43642861735832056, 0.43642861735832056, 0.5702917245879232, 0.07142926469947743, 0.43642861735832056, 0.43642861735832056, 0.8269284160730276, 0.5702917245879232, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.8269284160730276, 0.43642861735832056, 0.8269284160730276, 0.11647651052898594, 0.8269284160730276, 0.8269284160730276, 0.43642861735832056, 0.5191317176672745, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.5702917245879232, 0.43642861735832056, 0.43642861735832056, 0.43642861735832056, 0.786902967349288, 0.8269284160730276, 0.5702917245879232, 0.5702917245879232, 0.786902967349288, 0.43642861735832056, 0.43642861735832056, 0.5702917245879232, 0.8269284160730276, 0.8581286475174378, 0.43642861735832056]\n",
      "all_sum before preprocessing is: [1.5293946164369745, 3.1051283576136943, 3.1051283576136943, 4.284808113517638, 5.686940340334618, 3.9050550610655077, 1.949568267436658, 3.484881410065824, 3.1051283576136943, 1.1496415639848447, 1.1496415639848447, 3.484881410065824, 3.484881410065824, 3.484881410065824, 2.3293213198887877, 6.053505050429421, 3.484881410065824, 4.873825294525478, 3.1051283576136943, 1.1496415639848447, 4.284808113517638, 3.9050550610655077, 6.524437167105581, 2.3293213198887877, 5.673751997977291, 3.484881410065824, 1.949568267436658, 4.7002237801657385, 3.484881410065824, 3.1051283576136943, 3.586991797659434, 4.284808113517638, 1.5293946164369745, 1.1496415639848447, 1.949568267436658, 5.673751997977291, 3.1051283576136943, 1.5293946164369745, 3.484881410065824, 5.307187287882488, 1.1496415639848447, 5.673751997977291, 3.484881410065824, 2.3293213198887877, 3.1051283576136943, 5.673751997977291, 3.9050550610655077, 3.9050550610655077, 4.887013636882805, 3.9050550610655077]\n",
      "all_sum after preprocessing is: [-1.35025538 -0.24782677 -0.24782677  0.57751109  1.55848309  0.31182494\n",
      " -1.05628982  0.01785938 -0.24782677 -1.61594153 -1.61594153  0.01785938\n",
      "  0.01785938  0.01785938 -0.79060367  1.8149423   0.01785938  0.98960444\n",
      " -0.24782677 -1.61594153  0.57751109  0.31182494  2.14441994 -0.79060367\n",
      "  1.54925615  0.01785938 -1.05628982  0.86814783  0.01785938 -0.24782677\n",
      "  0.08929874  0.57751109 -1.35025538 -1.61594153 -1.05628982  1.54925615\n",
      " -0.24782677 -1.35025538  0.01785938  1.29279695 -1.61594153  1.54925615\n",
      "  0.01785938 -0.79060367 -0.24782677  1.54925615  0.31182494  0.31182494\n",
      "  0.99883138  0.31182494]\n",
      "P is: [0.20582862296291524, 0.4383584770542885, 0.4383584770542885, 0.640494507592239, 0.8261355791912954, 0.577330646020307, 0.2580191129609169, 0.504464726147465, 0.4383584770542885, 0.16576534322099634, 0.16576534322099634, 0.504464726147465, 0.504464726147465, 0.504464726147465, 0.3120390642502875, 0.8599581358354499, 0.504464726147465, 0.7290097846719319, 0.4383584770542885, 0.16576534322099634, 0.640494507592239, 0.577330646020307, 0.8951461893719469, 0.3120390642502875, 0.8248062710257847, 0.504464726147465, 0.2580191129609169, 0.7043601540020793, 0.504464726147465, 0.4383584770542885, 0.522309861853615, 0.640494507592239, 0.20582862296291524, 0.16576534322099634, 0.2580191129609169, 0.8248062710257847, 0.4383584770542885, 0.20582862296291524, 0.504464726147465, 0.7846202248951745, 0.16576534322099634, 0.8248062710257847, 0.504464726147465, 0.3120390642502875, 0.4383584770542885, 0.8248062710257847, 0.577330646020307, 0.577330646020307, 0.7308287525291659, 0.577330646020307]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.675\n",
      "(*) epoch 2, cost 1.367\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.294\n",
      "(*) epoch 2, cost 3.788\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.323759597657885, 4.323759597657885, 2.52899861372012, 2.52899861372012, 2.52899861372012, 2.52899861372012, 2.52899861372012, 2.52899861372012, 4.323759597657885, 4.323759597657885, 2.52899861372012, 4.323759597657885, 2.52899861372012, 2.52899861372012, 2.52899861372012, 4.323759597657885, 2.5961737142045958, 2.52899861372012, 2.52899861372012, 2.52899861372012, 2.52899861372012, 6.584229276513482, 2.52899861372012, 2.52899861372012, 2.52899861372012, 4.323759597657885, 4.323759597657885, 2.52899861372012, 6.584229276513482, 2.52899861372012, 4.323759597657885, 4.323759597657885, 2.52899861372012, 2.52899861372012, 2.52899861372012, 2.52899861372012, 2.52899861372012, 4.789468292575718, 4.323759597657885, 2.52899861372012, 4.323759597657885, 4.323759597657885, 2.52899861372012, 4.323759597657885, 2.52899861372012, 2.52899861372012, 2.5961737142045958, 2.52899861372012, 2.5961737142045958, 2.52899861372012]\n",
      "all_sum after preprocessing is: [ 1.00677388  1.00677388 -0.66509321 -0.66509321 -0.66509321 -0.66509321\n",
      " -0.66509321 -0.66509321  1.00677388  1.00677388 -0.66509321  1.00677388\n",
      " -0.66509321 -0.66509321 -0.66509321  1.00677388 -0.60251784 -0.66509321\n",
      " -0.66509321 -0.66509321 -0.66509321  3.11246089 -0.66509321 -0.66509321\n",
      " -0.66509321  1.00677388  1.00677388 -0.66509321  3.11246089 -0.66509321\n",
      "  1.00677388  1.00677388 -0.66509321 -0.66509321 -0.66509321 -0.66509321\n",
      " -0.66509321  1.44059379  1.00677388 -0.66509321  1.00677388  1.00677388\n",
      " -0.66509321  1.00677388 -0.66509321 -0.66509321 -0.60251784 -0.66509321\n",
      " -0.60251784 -0.66509321]\n",
      "P is: [0.7323883187980006, 0.7323883187980006, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.7323883187980006, 0.7323883187980006, 0.339596421317889, 0.7323883187980006, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.7323883187980006, 0.35376786309305247, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.9574038282491629, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.7323883187980006, 0.7323883187980006, 0.339596421317889, 0.9574038282491629, 0.339596421317889, 0.7323883187980006, 0.7323883187980006, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.339596421317889, 0.8085465867402769, 0.7323883187980006, 0.339596421317889, 0.7323883187980006, 0.7323883187980006, 0.339596421317889, 0.7323883187980006, 0.339596421317889, 0.339596421317889, 0.35376786309305247, 0.339596421317889, 0.35376786309305247, 0.339596421317889]\n",
      "all_sum before preprocessing is: [1.222456583499675, 1.222456583499675, 1.222456583499675, 1.6205610022077521, 1.222456583499675, 1.6205610022077521, 1.6205610022077521, 1.222456583499675, 1.6205610022077521, 1.6205610022077521, 2.0731935518331244, 1.222456583499675, 1.6205610022077521, 1.6205610022077521, 1.6205610022077521, 1.222456583499675, 1.222456583499675, 2.0731935518331244, 1.6205610022077521, 1.967752874744561, 1.6205610022077521, 1.222456583499675, 1.6205610022077521, 1.6205610022077521, 1.6205610022077521, 1.820590307760983, 1.222456583499675, 1.222456583499675, 1.222456583499675, 1.6205610022077521, 1.6205610022077521, 1.6205610022077521, 1.6205610022077521, 1.967752874744561, 1.222456583499675, 1.222456583499675, 1.222456583499675, 1.422485889052906, 1.6205610022077521, 1.222456583499675, 1.6205610022077521, 1.222456583499675, 1.6205610022077521, 1.6205610022077521, 1.222456583499675, 1.6205610022077521, 1.222456583499675, 1.222456583499675, 1.222456583499675, 1.6205610022077521]\n",
      "all_sum after preprocessing is: [-1.04842415 -1.04842415 -1.04842415  0.53898741 -1.04842415  0.53898741\n",
      "  0.53898741 -1.04842415  0.53898741  0.53898741  2.34382581 -1.04842415\n",
      "  0.53898741  0.53898741  0.53898741 -1.04842415 -1.04842415  2.34382581\n",
      "  0.53898741  1.923389    0.53898741 -1.04842415  0.53898741  0.53898741\n",
      "  0.53898741  1.33658929 -1.04842415 -1.04842415 -1.04842415  0.53898741\n",
      "  0.53898741  0.53898741  0.53898741  1.923389   -1.04842415 -1.04842415\n",
      " -1.04842415 -0.25082227  0.53898741 -1.04842415  0.53898741 -1.04842415\n",
      "  0.53898741  0.53898741 -1.04842415  0.53898741 -1.04842415 -1.04842415\n",
      " -1.04842415  0.53898741]\n",
      "P is: [0.25952782260589313, 0.25952782260589313, 0.25952782260589313, 0.6315768322809127, 0.25952782260589313, 0.6315768322809127, 0.6315768322809127, 0.25952782260589313, 0.6315768322809127, 0.6315768322809127, 0.9124422170575794, 0.25952782260589313, 0.6315768322809127, 0.6315768322809127, 0.6315768322809127, 0.25952782260589313, 0.25952782260589313, 0.9124422170575794, 0.6315768322809127, 0.8725158752178361, 0.6315768322809127, 0.25952782260589313, 0.6315768322809127, 0.6315768322809127, 0.6315768322809127, 0.7919284915230601, 0.25952782260589313, 0.25952782260589313, 0.25952782260589313, 0.6315768322809127, 0.6315768322809127, 0.6315768322809127, 0.6315768322809127, 0.8725158752178361, 0.25952782260589313, 0.25952782260589313, 0.25952782260589313, 0.4376211207445758, 0.6315768322809127, 0.25952782260589313, 0.6315768322809127, 0.25952782260589313, 0.6315768322809127, 0.6315768322809127, 0.25952782260589313, 0.6315768322809127, 0.25952782260589313, 0.25952782260589313, 0.25952782260589313, 0.6315768322809127]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.310\n",
      "(*) epoch 2, cost 2.461\n",
      "(*) epoch 3, cost 2.153\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.496\n",
      "(*) epoch 2, cost 1.275\n",
      "(*) epoch 3, cost 0.799\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 0.1681959279838877, 0.1681959279838877, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053, 1.1515228822646053]\n",
      "all_sum after preprocessing is: [ 0.20412415  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415 -4.89897949 -4.89897949  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415  0.20412415\n",
      "  0.20412415  0.20412415]\n",
      "P is: [0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.007399032528496906, 0.007399032528496906, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624, 0.5508545804061624]\n",
      "all_sum before preprocessing is: [6.167407543771498, 5.005429685832961, 5.005429685832961, 5.120222313389592, 4.6209710062743525, 4.245474626461387, 4.314872004914377, 6.167407543771498, 4.4329141319021375, 3.8840738453937718, 5.861308542411523, 5.551020472910196, 5.426321314749567, 5.1261182042683355, 4.190172846753748, 5.005429685832961, 3.5737857758924454, 4.986560855483319, 5.371019535041928, 5.426321314749567, 5.064920533681951, 4.986560855483319, 5.426321314749567, 5.005429685832961, 5.861308542411523, 6.563951630580862, 5.426321314749567, 5.064920533681951, 5.371019535041928, 5.857119474270172, 5.55691636378894, 5.631696197718258, 4.245474626461387, 4.699330684472985, 3.9393756251014116, 5.495718693202557, 4.6209710062743525, 5.064920533681951, 5.0607314655406, 6.222709323479139, 5.210804568801652, 6.465450608627529, 3.9393756251014116, 5.371019535041928, 5.861308542411523, 5.551020472910196, 5.120222313389592, 6.167407543771498, 5.861308542411523, 5.132307720640346]\n",
      "all_sum after preprocessing is: [ 1.43202172 -0.26445443 -0.26445443 -0.09685833 -0.82576029 -1.37398128\n",
      " -1.2726618   1.43202172 -1.10032146 -1.90162284  0.98512021  0.53210271\n",
      "  0.35004318 -0.08825039 -1.45472133 -0.26445443 -2.35464034 -0.29200273\n",
      "  0.26930313  0.35004318 -0.17759838 -0.29200273  0.35004318 -0.26445443\n",
      "  0.98512021  2.01097216  0.35004318 -0.17759838  0.26930313  0.97900422\n",
      "  0.54071065  0.64988847 -1.37398128 -0.71135594 -1.82088279  0.45136266\n",
      " -0.82576029 -0.17759838 -0.18371438  1.51276177  0.03539086  1.86716164\n",
      " -1.82088279  0.26930313  0.98512021  0.53210271 -0.09685833  1.43202172\n",
      "  0.98512021 -0.07921376]\n",
      "P is: [0.8072161279788179, 0.434269027702781, 0.434269027702781, 0.4758043301772852, 0.3045422801635485, 0.20197737205617305, 0.2188019368848656, 0.8072161279788179, 0.24967966698789215, 0.12992491133621206, 0.7281229966095489, 0.62997340197564, 0.5866280487768929, 0.47795171036789696, 0.18927601181549122, 0.434269027702781, 0.08669763932292118, 0.4275136352531666, 0.5669218152400716, 0.5866280487768929, 0.4557167389796881, 0.4275136352531666, 0.5866280487768929, 0.434269027702781, 0.7281229966095489, 0.881944279331427, 0.5866280487768929, 0.4557167389796881, 0.5669218152400716, 0.7269105865013696, 0.6319777180181235, 0.6569853287757202, 0.20197737205617305, 0.32929929701624994, 0.13932797909114222, 0.6109631696277431, 0.3045422801635485, 0.4557167389796881, 0.454200148483216, 0.8194701406638549, 0.5088467924035429, 0.866129513967053, 0.13932797909114222, 0.5669218152400716, 0.7281229966095489, 0.62997340197564, 0.4758043301772852, 0.8072161279788179, 0.7281229966095489, 0.48020690953366146]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.256\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.093\n",
      "(*) epoch 2, cost 5.717\n",
      "(*) epoch 3, cost 5.019\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.220619072748556, 3.188207626289767, 3.188207626289767, 4.081758897555849, 3.188207626289767, 3.188207626289767, 4.081758897555849, 3.188207626289767, 6.220619072748556, 3.188207626289767, 3.188207626289767, 3.188207626289767, 3.188207626289767, 4.081758897555849, 4.081758897555849, 3.188207626289767, 3.4983775713248804, 3.188207626289767, 3.188207626289767, 4.081758897555849, 3.188207626289767, 3.188207626289767, 3.188207626289767, 4.081758897555849, 4.081758897555849, 3.188207626289767, 3.188207626289767, 3.188207626289767, 3.188207626289767, 4.081758897555849, 4.081758897555849, 6.220619072748556, 3.188207626289767, 4.081758897555849, 3.188207626289767, 4.081758897555849, 4.081758897555849, 4.081758897555849, 4.081758897555849, 4.081758897555849, 6.220619072748556, 3.188207626289767, 4.081758897555849, 3.188207626289767, 4.081758897555849, 4.081758897555849, 3.188207626289767, 3.188207626289767, 4.081758897555849, 4.081758897555849]\n",
      "all_sum after preprocessing is: [ 2.92198031 -0.73009544 -0.73009544  0.34605039 -0.73009544 -0.73009544\n",
      "  0.34605039 -0.73009544  2.92198031 -0.73009544 -0.73009544 -0.73009544\n",
      " -0.73009544  0.34605039  0.34605039 -0.73009544 -0.35654318 -0.73009544\n",
      " -0.73009544  0.34605039 -0.73009544 -0.73009544 -0.73009544  0.34605039\n",
      "  0.34605039 -0.73009544 -0.73009544 -0.73009544 -0.73009544  0.34605039\n",
      "  0.34605039  2.92198031 -0.73009544  0.34605039 -0.73009544  0.34605039\n",
      "  0.34605039  0.34605039  0.34605039  0.34605039  2.92198031 -0.73009544\n",
      "  0.34605039 -0.73009544  0.34605039  0.34605039 -0.73009544 -0.73009544\n",
      "  0.34605039  0.34605039]\n",
      "P is: [0.9489223677031563, 0.32517378484400955, 0.32517378484400955, 0.5856594827860707, 0.32517378484400955, 0.32517378484400955, 0.5856594827860707, 0.32517378484400955, 0.9489223677031563, 0.32517378484400955, 0.32517378484400955, 0.32517378484400955, 0.32517378484400955, 0.5856594827860707, 0.5856594827860707, 0.32517378484400955, 0.4117966210543528, 0.32517378484400955, 0.32517378484400955, 0.5856594827860707, 0.32517378484400955, 0.32517378484400955, 0.32517378484400955, 0.5856594827860707, 0.5856594827860707, 0.32517378484400955, 0.32517378484400955, 0.32517378484400955, 0.32517378484400955, 0.5856594827860707, 0.5856594827860707, 0.9489223677031563, 0.32517378484400955, 0.5856594827860707, 0.32517378484400955, 0.5856594827860707, 0.5856594827860707, 0.5856594827860707, 0.5856594827860707, 0.5856594827860707, 0.9489223677031563, 0.32517378484400955, 0.5856594827860707, 0.32517378484400955, 0.5856594827860707, 0.5856594827860707, 0.32517378484400955, 0.32517378484400955, 0.5856594827860707, 0.5856594827860707]\n",
      "all_sum before preprocessing is: [1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 2.53409551746116, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 2.53409551746116, 1.6780257854857803, 1.6780257854857803, 2.53409551746116, 1.6780257854857803, 1.7688507677890173, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.7688507677890173, 2.53409551746116, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 2.53409551746116, 2.53409551746116, 1.6780257854857803, 1.6780257854857803, 1.7688507677890173, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 2.0506909875203743, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803, 1.6780257854857803]\n",
      "all_sum after preprocessing is: [-0.41443901 -0.41443901 -0.41443901 -0.41443901 -0.41443901 -0.41443901\n",
      " -0.41443901 -0.41443901  2.65384001 -0.41443901 -0.41443901 -0.41443901\n",
      " -0.41443901 -0.41443901  2.65384001 -0.41443901 -0.41443901  2.65384001\n",
      " -0.41443901 -0.088909   -0.41443901 -0.41443901 -0.41443901 -0.088909\n",
      "  2.65384001 -0.41443901 -0.41443901 -0.41443901 -0.41443901  2.65384001\n",
      "  2.65384001 -0.41443901 -0.41443901 -0.088909   -0.41443901 -0.41443901\n",
      " -0.41443901 -0.41443901 -0.41443901 -0.41443901 -0.41443901  0.92124753\n",
      " -0.41443901 -0.41443901 -0.41443901 -0.41443901 -0.41443901 -0.41443901\n",
      " -0.41443901 -0.41443901]\n",
      "P is: [0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.9342472732008565, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.9342472732008565, 0.3978482080309135, 0.3978482080309135, 0.9342472732008565, 0.3978482080309135, 0.47778737911614616, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.47778737911614616, 0.9342472732008565, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.9342472732008565, 0.9342472732008565, 0.3978482080309135, 0.3978482080309135, 0.47778737911614616, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.7152962302427838, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135, 0.3978482080309135]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.840\n",
      "(*) epoch 2, cost 2.151\n",
      "(*) epoch 3, cost 1.483\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.853\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.7674905149117635, 4.9494951872934685, 3.1447305852608873, 3.1447305852608873, 3.1447305852608873, 4.7674905149117635, 3.1447305852608873, 4.9494951872934685, 3.1447305852608873, 3.1447305852608873, 2.6057337661710047, 4.7674905149117635, 3.3742284937661102, 5.178993095798692, 3.1447305852608873, 2.6057337661710047, 2.6057337661710047, 3.1447305852608873, 3.1447305852608873, 2.6057337661710047, 4.9494951872934685, 2.9627259128791823, 3.1447305852608873, 3.1447305852608873, 3.642959744786032, 3.1447305852608873, 3.1447305852608873, 4.410498368203585, 2.9627259128791823, 2.6057337661710047, 4.7674905149117635, 3.1447305852608873, 2.6057337661710047, 3.1447305852608873, 4.9494951872934685, 3.1447305852608873, 3.1447305852608873, 2.6057337661710047, 3.1447305852608873, 4.9494951872934685, 3.1447305852608873, 3.642959744786032, 3.1447305852608873, 3.1447305852608873, 4.410498368203585, 2.6057337661710047, 3.1447305852608873, 3.1447305852608873, 3.1447305852608873, 2.6057337661710047]\n",
      "all_sum after preprocessing is: [ 1.62077221  1.84752441 -0.40095828 -0.40095828 -0.40095828  1.62077221\n",
      " -0.40095828  1.84752441 -0.40095828 -0.40095828 -1.07247246  1.62077221\n",
      " -0.11503619  2.13344651 -0.40095828 -1.07247246 -1.07247246 -0.40095828\n",
      " -0.40095828 -1.07247246  1.84752441 -0.62771049 -0.40095828 -0.40095828\n",
      "  0.21976513 -0.40095828 -0.40095828  1.17601023 -0.62771049 -1.07247246\n",
      "  1.62077221 -0.40095828 -1.07247246 -0.40095828  1.84752441 -0.40095828\n",
      " -0.40095828 -1.07247246 -0.40095828  1.84752441 -0.40095828  0.21976513\n",
      " -0.40095828 -0.40095828  1.17601023 -1.07247246 -0.40095828 -0.40095828\n",
      " -0.40095828 -1.07247246]\n",
      "P is: [0.8349015989597363, 0.8638361786483897, 0.4010821238632371, 0.4010821238632371, 0.4010821238632371, 0.8349015989597363, 0.4010821238632371, 0.8638361786483897, 0.4010821238632371, 0.4010821238632371, 0.25493317455515546, 0.8349015989597363, 0.47127262589340657, 0.8941117531827616, 0.4010821238632371, 0.25493317455515546, 0.25493317455515546, 0.4010821238632371, 0.4010821238632371, 0.25493317455515546, 0.8638361786483897, 0.34802985832255473, 0.4010821238632371, 0.4010821238632371, 0.5547212216996296, 0.4010821238632371, 0.4010821238632371, 0.7642296749812144, 0.34802985832255473, 0.25493317455515546, 0.8349015989597363, 0.4010821238632371, 0.25493317455515546, 0.4010821238632371, 0.8638361786483897, 0.4010821238632371, 0.4010821238632371, 0.25493317455515546, 0.4010821238632371, 0.8638361786483897, 0.4010821238632371, 0.5547212216996296, 0.4010821238632371, 0.4010821238632371, 0.7642296749812144, 0.25493317455515546, 0.4010821238632371, 0.4010821238632371, 0.4010821238632371, 0.25493317455515546]\n",
      "all_sum before preprocessing is: [3.0176511877884105, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 1.849304714327413, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.362229231386637, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 1.849304714327413, 3.4711487287311495, 2.2289616557000906, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 1.849304714327413, 2.9582242116719257, 3.0176511877884105, 2.9582242116719257, 3.4711487287311495, 2.9582242116719257, 3.4711487287311495, 1.849304714327413, 2.9582242116719257, 3.4711487287311495, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 1.849304714327413, 1.849304714327413, 2.9582242116719257, 2.9582242116719257, 2.9582242116719257, 1.849304714327413, 3.325154720110387, 1.849304714327413, 2.9582242116719257, 1.849304714327413, 2.9582242116719257]\n",
      "all_sum after preprocessing is: [ 0.48722423  0.36390335  0.36390335  0.36390335 -1.93728958  0.36390335\n",
      "  0.36390335  0.36390335  0.36390335  0.36390335 -0.87288565  0.36390335\n",
      "  0.36390335  0.36390335  0.36390335  0.36390335  0.36390335 -1.93728958\n",
      "  1.42830728 -1.1494381   0.36390335  0.36390335  0.36390335 -1.93728958\n",
      "  0.36390335  0.48722423  0.36390335  1.42830728  0.36390335  1.42830728\n",
      " -1.93728958  0.36390335  1.42830728  0.36390335  0.36390335  0.36390335\n",
      "  0.36390335  0.36390335  0.36390335 -1.93728958 -1.93728958  0.36390335\n",
      "  0.36390335  0.36390335 -1.93728958  1.12534536 -1.93728958  0.36390335\n",
      " -1.93728958  0.36390335]\n",
      "P is: [0.6194523150480384, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.12594592667040733, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.2946542129108365, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.12594592667040733, 0.8066374326110242, 0.2405917312871783, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.12594592667040733, 0.5899849944683158, 0.6194523150480384, 0.5899849944683158, 0.8066374326110242, 0.5899849944683158, 0.8066374326110242, 0.12594592667040733, 0.5899849944683158, 0.8066374326110242, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.12594592667040733, 0.12594592667040733, 0.5899849944683158, 0.5899849944683158, 0.5899849944683158, 0.12594592667040733, 0.7549788782994445, 0.12594592667040733, 0.5899849944683158, 0.12594592667040733, 0.5899849944683158]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.817\n",
      "(*) epoch 2, cost 2.290\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.741\n",
      "(*) epoch 2, cost 2.980\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 3.687558698070032, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 2.5421834873083444, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 2.5421834873083444, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 2.5421834873083444, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 2.5421834873083444, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 1.1006866863575822, 2.5421834873083444]\n",
      "all_sum after preprocessing is: [-0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132\n",
      "  4.34181117 -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132\n",
      " -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132   2.26191393\n",
      " -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132   2.26191393\n",
      " -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132\n",
      "  2.26191393 -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132\n",
      " -0.3557132  -0.3557132  -0.3557132  -0.3557132   2.26191393 -0.3557132\n",
      " -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132  -0.3557132\n",
      " -0.3557132   2.26191393]\n",
      "P is: [0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.9871542230691118, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.9056732631991653, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.9056732631991653, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.9056732631991653, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.9056732631991653, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.4119976740125255, 0.9056732631991653]\n",
      "all_sum before preprocessing is: [2.153941266147879, 1.697763907911161, 1.7047033036149934, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.697763907911161, 1.697763907911161, 1.7047033036149934, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.697763907911161, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.697763907911161, 1.697763907911161, 1.7047033036149934, 1.2485259453782753, 1.697763907911161, 1.7047033036149934, 1.697763907911161, 1.7047033036149934, 1.2485259453782753, 1.697763907911161, 1.2485259453782753, 1.2485259453782753, 1.7047033036149934, 1.7047033036149934, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.2485259453782753, 1.697763907911161, 1.2485259453782753, 1.697763907911161, 2.153941266147879, 1.2485259453782753, 1.2485259453782753, 1.697763907911161, 1.2485259453782753]\n",
      "all_sum after preprocessing is: [ 2.69196152  0.93141331  0.95819487 -0.80235334 -0.80235334 -0.80235334\n",
      " -0.80235334  0.93141331  0.93141331  0.95819487 -0.80235334 -0.80235334\n",
      " -0.80235334 -0.80235334 -0.80235334 -0.80235334 -0.80235334  0.93141331\n",
      " -0.80235334 -0.80235334 -0.80235334 -0.80235334 -0.80235334 -0.80235334\n",
      "  0.93141331  0.93141331  0.95819487 -0.80235334  0.93141331  0.95819487\n",
      "  0.93141331  0.95819487 -0.80235334  0.93141331 -0.80235334 -0.80235334\n",
      "  0.95819487  0.95819487 -0.80235334 -0.80235334 -0.80235334 -0.80235334\n",
      "  0.93141331 -0.80235334  0.93141331  2.69196152 -0.80235334 -0.80235334\n",
      "  0.93141331 -0.80235334]\n",
      "P is: [0.9365506417464635, 0.7173619273411637, 0.7227602421010588, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.7173619273411637, 0.7173619273411637, 0.7227602421010588, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.7173619273411637, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.7173619273411637, 0.7173619273411637, 0.7227602421010588, 0.3095223421047262, 0.7173619273411637, 0.7227602421010588, 0.7173619273411637, 0.7227602421010588, 0.3095223421047262, 0.7173619273411637, 0.3095223421047262, 0.3095223421047262, 0.7227602421010588, 0.7227602421010588, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.3095223421047262, 0.7173619273411637, 0.3095223421047262, 0.7173619273411637, 0.9365506417464635, 0.3095223421047262, 0.3095223421047262, 0.7173619273411637, 0.3095223421047262]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.817\n",
      "(*) epoch 2, cost 1.962\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.760\n",
      "(*) epoch 2, cost 2.321\n",
      "(*) epoch 3, cost 1.631\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1831224318452411, 3.3230245044530395, 2.762781196744897, 2.128973893108778, 3.36885980723179, 1.2742498431528846, 1.1831224318452411, 1.8803284536397775, 1.789201042332134, 1.789201042332134, 2.762781196744897, 1.1831224318452411, 2.735052503595671, 1.1831224318452411, 1.7433657395533835, 1.1372871290664905, 1.1831224318452411, 3.36885980723179, 2.128973893108778, 2.938560772683244, 1.2284145403741342, 1.7433657395533835, 1.789201042332134, 1.789201042332134, 1.789201042332134, 1.1831224318452411, 1.789201042332134, 1.1831224318452411, 2.716945893966147, 2.6892172008169206, 1.1831224318452411, 1.789201042332134, 1.1831224318452411, 2.762781196744897, 1.1831224318452411, 1.1831224318452411, 2.762781196744897, 2.762781196744897, 1.1372871290664905, 1.1831224318452411, 1.1831224318452411, 2.762781196744897, 2.938560772683244, 1.789201042332134, 1.1831224318452411, 2.6892172008169206, 3.36885980723179, 1.1831224318452411, 1.789201042332134, 1.358902007783588]\n",
      "all_sum after preprocessing is: [-0.99392255  1.86723123  1.11815851  0.27072714  1.92851527 -0.87208074\n",
      " -0.99392255 -0.06172398 -0.18356579 -0.18356579  1.11815851 -0.99392255\n",
      "  1.08108389 -0.99392255 -0.24484983 -1.05520659 -0.99392255  1.92851527\n",
      "  0.27072714  1.35318441 -0.93336478 -0.24484983 -0.18356579 -0.18356579\n",
      " -0.18356579 -0.99392255 -0.18356579 -0.99392255  1.05687447  1.01979985\n",
      " -0.99392255 -0.18356579 -0.99392255  1.11815851 -0.99392255 -0.99392255\n",
      "  1.11815851  1.11815851 -1.05520659 -0.99392255 -0.99392255  1.11815851\n",
      "  1.35318441 -0.18356579 -0.99392255  1.01979985  1.92851527 -0.99392255\n",
      " -0.18356579 -0.75889665]\n",
      "P is: [0.2701379979913267, 0.8661375823014194, 0.75364697989574, 0.5672714073824852, 0.8730849916976517, 0.2948215282002574, 0.2701379979913267, 0.4845739019708681, 0.4542369847278601, 0.4542369847278601, 0.75364697989574, 0.2701379979913267, 0.7466990454364381, 0.2701379979913267, 0.4390915343858382, 0.25822654701125297, 0.2701379979913267, 0.8730849916976517, 0.5672714073824852, 0.794649752224641, 0.2822425723504593, 0.4390915343858382, 0.4542369847278601, 0.4542369847278601, 0.4542369847278601, 0.2701379979913267, 0.4542369847278601, 0.2701379979913267, 0.742092799752667, 0.7349336111653128, 0.2701379979913267, 0.4542369847278601, 0.2701379979913267, 0.75364697989574, 0.2701379979913267, 0.2701379979913267, 0.75364697989574, 0.75364697989574, 0.25822654701125297, 0.2701379979913267, 0.2701379979913267, 0.75364697989574, 0.794649752224641, 0.4542369847278601, 0.2701379979913267, 0.7349336111653128, 0.8730849916976517, 0.2701379979913267, 0.4542369847278601, 0.3188858628963212]\n",
      "all_sum before preprocessing is: [1.3713732929501792, 0.9563549773569501, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.9563549773569501, 0.12726919423082958, 0.9563549773569501, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.9563549773569501, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958, 0.12726919423082958]\n",
      "all_sum after preprocessing is: [ 4.13791961  2.64835447 -0.32736306 -0.32736306 -0.32736306 -0.32736306\n",
      " -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306  2.64835447\n",
      " -0.32736306  2.64835447 -0.32736306 -0.32736306 -0.32736306 -0.32736306\n",
      " -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306\n",
      " -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306\n",
      " -0.32736306  2.64835447 -0.32736306 -0.32736306 -0.32736306 -0.32736306\n",
      " -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306\n",
      " -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306 -0.32736306\n",
      " -0.32736306 -0.32736306]\n",
      "P is: [0.9842945840437615, 0.9339094968849412, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.9339094968849412, 0.4188823703450454, 0.9339094968849412, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.9339094968849412, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454, 0.4188823703450454]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.907\n",
      "(*) epoch 2, cost 2.130\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.997\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.1459286709068874, 2.570368823829667, 0.8516486365721341, 0.8516486365721341, 2.1459286709068874, 1.2760887894949138, 1.2760887894949138, 0.8516486365721341, 2.1459286709068874, 1.2760887894949138, 1.2760887894949138, 2.1459286709068874, 2.570368823829667, 2.1459286709068874, 2.1459286709068874, 1.2760887894949138, 1.564997545935112, 2.570368823829667, 0.8516486365721341, 2.1459286709068874, 1.2760887894949138, 0.8516486365721341, 0.8516486365721341, 2.570368823829667, 0.8516486365721341, 2.1459286709068874, 0.8516486365721341, 2.570368823829667, 2.1459286709068874, 0.8516486365721341, 0.8516486365721341, 1.2760887894949138, 1.2760887894949138, 0.8516486365721341, 0.8516486365721341, 0.8516486365721341, 2.1459286709068874, 2.1459286709068874, 0.8516486365721341, 2.1459286709068874, 1.8899147118476214, 0.8516486365721341, 0.8516486365721341, 0.8516486365721341, 0.8516486365721341, 2.570368823829667, 0.8516486365721341, 2.1459286709068874, 2.1459286709068874, 0.8516486365721341]\n",
      "all_sum after preprocessing is: [ 0.94624036  1.59121748 -1.02054107 -1.02054107  0.94624036 -0.37556395\n",
      " -0.37556395 -1.02054107  0.94624036 -0.37556395 -0.37556395  0.94624036\n",
      "  1.59121748  0.94624036  0.94624036 -0.37556395  0.06346034  1.59121748\n",
      " -1.02054107  0.94624036 -0.37556395 -1.02054107 -1.02054107  1.59121748\n",
      " -1.02054107  0.94624036 -1.02054107  1.59121748  0.94624036 -1.02054107\n",
      " -1.02054107 -0.37556395 -0.37556395 -1.02054107 -1.02054107 -1.02054107\n",
      "  0.94624036  0.94624036 -1.02054107  0.94624036  0.55720283 -1.02054107\n",
      " -1.02054107 -1.02054107 -1.02054107  1.59121748 -1.02054107  0.94624036\n",
      "  0.94624036 -1.02054107]\n",
      "P is: [0.7203584556351544, 0.8307873251950041, 0.2649220193215021, 0.2649220193215021, 0.7203584556351544, 0.4071972620085116, 0.4071972620085116, 0.2649220193215021, 0.7203584556351544, 0.4071972620085116, 0.4071972620085116, 0.7203584556351544, 0.8307873251950041, 0.7203584556351544, 0.7203584556351544, 0.4071972620085116, 0.5158597633569981, 0.8307873251950041, 0.2649220193215021, 0.7203584556351544, 0.4071972620085116, 0.2649220193215021, 0.2649220193215021, 0.8307873251950041, 0.2649220193215021, 0.7203584556351544, 0.2649220193215021, 0.8307873251950041, 0.7203584556351544, 0.2649220193215021, 0.2649220193215021, 0.4071972620085116, 0.4071972620085116, 0.2649220193215021, 0.2649220193215021, 0.2649220193215021, 0.7203584556351544, 0.7203584556351544, 0.2649220193215021, 0.7203584556351544, 0.6358050833166047, 0.2649220193215021, 0.2649220193215021, 0.2649220193215021, 0.2649220193215021, 0.8307873251950041, 0.2649220193215021, 0.7203584556351544, 0.7203584556351544, 0.2649220193215021]\n",
      "all_sum before preprocessing is: [2.268003330142769, 2.0741787361398307, 4.706893205437127, 4.768541410984249, 2.268003330142769, 4.768541410984249, 4.706893205437127, 3.0144024612543663, 2.2063551245956465, 3.7666694803225904, 3.8988458687784067, 5.228758348490279, 3.597915809854641, 3.4386289312723766, 5.290406554037402, 4.768541410984249, 5.228758348490279, 3.0760506668014886, 3.8988458687784067, 3.8988458687784067, 3.244804337269438, 3.7666694803225904, 5.228758348490279, 5.554975817660429, 5.228758348490279, 1.8532436520104434, 3.960494074325529, 4.706893205437127, 4.768541410984249, 3.8988458687784067, 3.597915809854641, 1.7461381870896164, 6.660070175751253, 3.244804337269438, 2.277099794215735, 3.0760506668014886, 3.0760506668014886, 3.960494074325529, 4.768541410984249, 2.268003330142769, 3.597915809854641, 4.706893205437127, 3.376980725725254, 3.597915809854641, 5.290406554037402, 4.768541410984249, 3.960494074325529, 4.768541410984249, 5.228758348490279, 4.706893205437127]\n",
      "all_sum after preprocessing is: [-1.5193226  -1.69385241  0.67678158  0.73229285 -1.5193226   0.73229285\n",
      "  0.67678158 -0.84722573 -1.57483387 -0.16984511 -0.05082657  1.14669628\n",
      " -0.32179975 -0.46523     1.20220755  0.73229285  1.14669628 -0.79171446\n",
      " -0.05082657 -0.05082657 -0.63975981 -0.16984511  1.14669628  1.44043957\n",
      "  1.14669628 -1.89279393  0.00468471  0.67678158  0.73229285 -0.05082657\n",
      " -0.32179975 -1.9892373   2.43552441 -0.63975981 -1.51113166 -0.79171446\n",
      " -0.79171446  0.00468471  0.73229285 -1.5193226  -0.32179975  0.67678158\n",
      " -0.52074127 -0.32179975  1.20220755  0.73229285  0.00468471  0.73229285\n",
      "  1.14669628  0.67678158]\n",
      "P is: [0.1795612921830286, 0.15526988207483458, 0.6630200002661512, 0.6753082205573226, 0.1795612921830286, 0.6753082205573226, 0.6630200002661512, 0.3000151478507366, 0.171528376917305, 0.4576405041622147, 0.4872960934825427, 0.7589069619393571, 0.42023719764040834, 0.38574585872211276, 0.7689172622573734, 0.6753082205573226, 0.7589069619393571, 0.3118006610838017, 0.4872960934825427, 0.4872960934825427, 0.3453008359739528, 0.4576405041622147, 0.7589069619393571, 0.8085227128805305, 0.7589069619393571, 0.13092623515760132, 0.5011711748027223, 0.6630200002661512, 0.6753082205573226, 0.4872960934825427, 0.42023719764040834, 0.1203375755809752, 0.9194964137112566, 0.3453008359739528, 0.1807711411890416, 0.3118006610838017, 0.3118006610838017, 0.5011711748027223, 0.6753082205573226, 0.1795612921830286, 0.42023719764040834, 0.6630200002661512, 0.3726789161407608, 0.42023719764040834, 0.7689172622573734, 0.6753082205573226, 0.5011711748027223, 0.6753082205573226, 0.7589069619393571, 0.6630200002661512]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.229\n",
      "(*) epoch 2, cost 2.724\n",
      "(*) epoch 3, cost 2.360\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.430\n",
      "(*) epoch 2, cost 3.540\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.925317116839948, 2.5823861040643883, 2.302972693245202, 1.7329859381583632, 3.4216631612966735, 2.5823861040643883, 4.073855636343552, 5.147366243262858, 2.1996140348737634, 3.8044352304872984, 3.4216631612966735, 2.1996140348737634, 2.5823861040643883, 1.569660646209343, 3.4216631612966735, 2.1996140348737634, 4.619952997483197, 3.925317116839948, 2.302972693245202, 3.8044352304872984, 3.061130178488507, 3.4216631612966735, 4.456627705534177, 2.1996140348737634, 2.1996140348737634, 2.1996140348737634, 3.4216631612966735, 5.530138312453483, 3.8044352304872984, 2.302972693245202, 3.4216631612966735, 3.4216631612966735, 4.073855636343552, 2.5823861040643883, 2.1996140348737634, 3.5250218196681127, 2.8518065099206424, 2.7917097726322533, 2.5823861040643883, 2.1996140348737634, 2.7457113960134087, 2.1996140348737634, 2.5823861040643883, 2.1996140348737634, 6.728428148640007, 3.925317116839948, 2.9550350645812733, 3.8044352304872984, 5.147366243262858, 5.147366243262858]\n",
      "all_sum after preprocessing is: [ 0.64599833 -0.6017766  -0.86139161 -1.3909908   0.17803179 -0.6017766\n",
      "  0.78401185  1.7814567  -0.95742658  0.53368177  0.17803179 -0.95742658\n",
      " -0.6017766  -1.54274335  0.17803179 -0.95742658  1.29141438  0.64599833\n",
      " -0.86139161  0.53368177 -0.1569549   0.17803179  1.13966183 -0.95742658\n",
      " -0.95742658 -0.95742658  0.17803179  2.13710668  0.53368177 -0.86139161\n",
      "  0.17803179  0.17803179  0.78401185 -0.6017766  -0.95742658  0.27406676\n",
      " -0.35144652 -0.40728498 -0.6017766  -0.95742658 -0.45002405 -0.95742658\n",
      " -0.6017766  -0.95742658  3.25048927  0.64599833 -0.25553243  0.53368177\n",
      "  1.7814567   1.7814567 ]\n",
      "P is: [0.6561081289804632, 0.35393734100906765, 0.2970486805490498, 0.1992496278796052, 0.5443907606812974, 0.35393734100906765, 0.6865441146095862, 0.855876645235617, 0.2773937318231933, 0.6303414162653237, 0.5443907606812974, 0.2773937318231933, 0.35393734100906765, 0.17613682595522592, 0.5443907606812974, 0.2773937318231933, 0.7843864915215363, 0.6561081289804632, 0.2970486805490498, 0.6303414162653237, 0.46084162970615067, 0.5443907606812974, 0.757617545458216, 0.2773937318231933, 0.2773937318231933, 0.2773937318231933, 0.5443907606812974, 0.8944577836470484, 0.6303414162653237, 0.2970486805490498, 0.5443907606812974, 0.5443907606812974, 0.6865441146095862, 0.35393734100906765, 0.2773937318231933, 0.5680910149905255, 0.4130316876741886, 0.39956330984505545, 0.35393734100906765, 0.2773937318231933, 0.38935504775072394, 0.2773937318231933, 0.35393734100906765, 0.2773937318231933, 0.9626906899273094, 0.6561081289804632, 0.4364622504685468, 0.6303414162653237, 0.855876645235617, 0.855876645235617]\n",
      "all_sum before preprocessing is: [4.445753570207612, 3.4347096116069507, 3.4347096116069507, 3.4347096116069507, 3.8306157854158807, 3.4347096116069507, 3.4347096116069507, 3.632435852310656, 4.445753570207612, 4.445753570207612, 3.4347096116069507, 3.8306157854158807, 4.445753570207612, 4.445753570207612, 3.4347096116069507, 3.4347096116069507, 4.445753570207612, 3.0172980675189254, 4.445753570207612, 2.8195718268152206, 3.4347096116069507, 4.445753570207612, 3.4347096116069507, 4.445753570207612, 4.445753570207612, 4.445753570207612, 3.4347096116069507, 3.4347096116069507, 3.8306157854158807, 3.490238498042742, 3.8306157854158807, 2.8195718268152206, 4.445753570207612, 4.445753570207612, 4.445753570207612, 3.4347096116069507, 4.445753570207612, 3.4347096116069507, 3.4347096116069507, 3.8306157854158807, 3.4347096116069507, 3.8306157854158807, 4.445753570207612, 4.445753570207612, 2.8195718268152206, 4.445753570207612, 4.445753570207612, 3.4347096116069507, 2.8195718268152206, 4.445753570207612]\n",
      "all_sum after preprocessing is: [ 1.11156828 -0.72594437 -0.72594437 -0.72594437 -0.0064083  -0.72594437\n",
      " -0.72594437 -0.36658861  1.11156828  1.11156828 -0.72594437 -0.0064083\n",
      "  1.11156828  1.11156828 -0.72594437 -0.72594437  1.11156828 -1.48456519\n",
      "  1.11156828 -1.84392095 -0.72594437  1.11156828 -0.72594437  1.11156828\n",
      "  1.11156828  1.11156828 -0.72594437 -0.72594437 -0.0064083  -0.6250239\n",
      " -0.0064083  -1.84392095  1.11156828  1.11156828  1.11156828 -0.72594437\n",
      "  1.11156828 -0.72594437 -0.72594437 -0.0064083  -0.72594437 -0.0064083\n",
      "  1.11156828  1.11156828 -1.84392095  1.11156828  1.11156828 -0.72594437\n",
      " -1.84392095  1.11156828]\n",
      "P is: [0.7524213718962349, 0.3260853369932776, 0.3260853369932776, 0.3260853369932776, 0.49839793160662266, 0.3260853369932776, 0.3260853369932776, 0.4093655891909206, 0.7524213718962349, 0.7524213718962349, 0.3260853369932776, 0.49839793160662266, 0.7524213718962349, 0.7524213718962349, 0.3260853369932776, 0.3260853369932776, 0.7524213718962349, 0.18473886425926378, 0.7524213718962349, 0.13658822834803244, 0.3260853369932776, 0.7524213718962349, 0.3260853369932776, 0.7524213718962349, 0.7524213718962349, 0.7524213718962349, 0.3260853369932776, 0.3260853369932776, 0.49839793160662266, 0.34863970715590475, 0.49839793160662266, 0.13658822834803244, 0.7524213718962349, 0.7524213718962349, 0.7524213718962349, 0.3260853369932776, 0.7524213718962349, 0.3260853369932776, 0.3260853369932776, 0.49839793160662266, 0.3260853369932776, 0.49839793160662266, 0.7524213718962349, 0.7524213718962349, 0.13658822834803244, 0.7524213718962349, 0.7524213718962349, 0.3260853369932776, 0.13658822834803244, 0.7524213718962349]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.168\n",
      "(*) epoch 2, cost 4.022\n",
      "(*) epoch 3, cost 3.277\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.059\n",
      "(*) epoch 2, cost 2.354\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 2.725833816566544, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.595709741732726, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.595709741732726, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.595709741732726, 2.8030070568850936, 4.385008736481462, 4.385008736481462, 4.595709741732726, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.672882982051275, 4.385008736481462, 4.385008736481462, 4.385008736481462, 4.595709741732726, 4.385008736481462, 4.595709741732726, 4.462181976800011, 4.385008736481462, 3.0551914940324543, 5.017174670853007, 4.385008736481462, 4.385008736481462, 4.385008736481462]\n",
      "all_sum after preprocessing is: [ 0.11792024  0.11792024  0.11792024  0.11792024  0.11792024  0.11792024\n",
      "  0.11792024  0.11792024  0.11792024 -4.11771511  0.11792024  0.11792024\n",
      "  0.11792024  0.11792024  0.11792024  0.11792024  0.65580965  0.11792024\n",
      "  0.11792024  0.11792024  0.11792024  0.11792024  0.65580965  0.11792024\n",
      "  0.11792024  0.11792024  0.11792024  0.11792024  0.65580965 -3.9207029\n",
      "  0.11792024  0.11792024  0.65580965  0.11792024  0.11792024  0.11792024\n",
      "  0.85282185  0.11792024  0.11792024  0.11792024  0.65580965  0.11792024\n",
      "  0.65580965  0.31493244  0.11792024 -3.27691225  1.7317491   0.11792024\n",
      "  0.11792024  0.11792024]\n",
      "P is: [0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.016020827981898682, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.6583184570986031, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.6583184570986031, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.6583184570986031, 0.019441680092457857, 0.5294459459841379, 0.5294459459841379, 0.6583184570986031, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.7011587549405851, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379, 0.6583184570986031, 0.5294459459841379, 0.6583184570986031, 0.5780887544182967, 0.5294459459841379, 0.03637178392440598, 0.8496360124040434, 0.5294459459841379, 0.5294459459841379, 0.5294459459841379]\n",
      "all_sum before preprocessing is: [2.730905707220531, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.936615446487927, 2.3285985059423813, 2.730905707220531, 3.8929028966284482, 2.730905707220531, 2.730905707220531, 2.3285985059423813, 2.3285985059423813, 2.730905707220531, 2.3285985059423813, 2.730905707220531, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 4.2952100979065975, 2.3285985059423813, 2.936615446487927, 2.730905707220531, 2.730905707220531, 4.2952100979065975, 2.3285985059423813, 2.730905707220531, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.730905707220531, 2.3285985059423813, 3.8929028966284482, 2.3285985059423813, 2.730905707220531, 2.3285985059423813, 2.730905707220531, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 2.3285985059423813, 3.8929028966284482, 2.3285985059423813, 2.730905707220531, 2.730905707220531]\n",
      "all_sum after preprocessing is: [ 0.18001763 -0.60024653 -0.60024653 -0.60024653  0.57898622 -0.60024653\n",
      "  0.18001763  2.43368039  0.18001763  0.18001763 -0.60024653 -0.60024653\n",
      "  0.18001763 -0.60024653  0.18001763 -0.60024653 -0.60024653 -0.60024653\n",
      " -0.60024653 -0.60024653 -0.60024653 -0.60024653 -0.60024653  3.21394455\n",
      " -0.60024653  0.57898622  0.18001763  0.18001763  3.21394455 -0.60024653\n",
      "  0.18001763 -0.60024653 -0.60024653 -0.60024653  0.18001763 -0.60024653\n",
      "  2.43368039 -0.60024653  0.18001763 -0.60024653  0.18001763 -0.60024653\n",
      " -0.60024653 -0.60024653 -0.60024653 -0.60024653  2.43368039 -0.60024653\n",
      "  0.18001763  0.18001763]\n",
      "P is: [0.5448832633429841, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.6408341012831085, 0.35428729275589194, 0.5448832633429841, 0.9193598088539735, 0.5448832633429841, 0.5448832633429841, 0.35428729275589194, 0.35428729275589194, 0.5448832633429841, 0.35428729275589194, 0.5448832633429841, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.9613556763684811, 0.35428729275589194, 0.6408341012831085, 0.5448832633429841, 0.5448832633429841, 0.9613556763684811, 0.35428729275589194, 0.5448832633429841, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.5448832633429841, 0.35428729275589194, 0.9193598088539735, 0.35428729275589194, 0.5448832633429841, 0.35428729275589194, 0.5448832633429841, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.35428729275589194, 0.9193598088539735, 0.35428729275589194, 0.5448832633429841, 0.5448832633429841]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.879\n",
      "(*) epoch 2, cost 3.617\n",
      "(*) epoch 3, cost 2.565\n",
      "(*) epoch 4, cost 2.316\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.001\n",
      "(*) epoch 2, cost 2.183\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0773079700323993, 0.40733643105940315, 1.9593259519185429, 2.3226256157286223, 2.419165124423936, 1.9593259519185429, 1.9593259519185429, 2.9925971547016186, 0.6174687975270061, 2.9925971547016186, 0.6174687975270061, 2.629297490891539, 0.6174687975270061, 1.0773079700323993, 1.9593259519185429, 0.8830926197023492, 1.9593259519185429, 1.9593259519185429, 1.6507400003100816, 1.9593259519185429, 0.40733643105940315, 1.74919358545094, 0.6136591714692576, 1.9593259519185429, 1.8608723667776847, 0.40733643105940315, 2.629297490891539, 1.74919358545094, 1.74919358545094, 1.74919358545094, 2.3226256157286223, 1.2874403365000022, 2.629297490891539, 0.6174687975270061, 0.6174687975270061, 2.419165124423936, 2.684788946599279, 2.629297490891539, 0.9807684613370855, 1.6005817322523954, 1.9593259519185429, 1.8608723667776847, 2.3226256157286223, 0.40733643105940315, 0.6174687975270061, 1.74919358545094, 0.6174687975270061, 0.6174687975270061, 2.629297490891539, 0.40733643105940315]\n",
      "all_sum after preprocessing is: [-0.64992745 -1.48709696  0.45220677  0.90617142  1.02680331  0.45220677\n",
      "  0.45220677  1.74334093 -1.224524    1.74334093 -1.224524    1.28937627\n",
      " -1.224524   -0.64992745  0.45220677 -0.89261115  0.45220677  0.45220677\n",
      "  0.06661016  0.45220677 -1.48709696  0.18963381 -1.22928436  0.45220677\n",
      "  0.32918312 -1.48709696  1.28937627  0.18963381  0.18963381  0.18963381\n",
      "  0.90617142 -0.38735449  1.28937627 -1.224524   -1.224524    1.02680331\n",
      "  1.35871617  1.28937627 -0.77055934  0.00393441  0.45220677  0.32918312\n",
      "  0.90617142 -1.48709696 -1.224524    0.18963381 -1.224524   -1.224524\n",
      "  1.28937627 -1.48709696]\n",
      "P is: [0.3430058859595637, 0.18435785790943687, 0.6111637840734053, 0.7122160791384321, 0.7362956822552816, 0.6111637840734053, 0.6111637840734053, 0.8511109286460387, 0.22714129072945305, 0.8511109286460387, 0.22714129072945305, 0.7840415981034096, 0.22714129072945305, 0.3430058859595637, 0.6111637840734053, 0.2905712722363186, 0.6111637840734053, 0.6111637840734053, 0.5166463866283374, 0.6111637840734053, 0.18435785790943687, 0.5472668895931797, 0.22630670485432625, 0.6111637840734053, 0.5815606048984605, 0.18435785790943687, 0.7840415981034096, 0.5472668895931797, 0.5472668895931797, 0.5472668895931797, 0.7122160791384321, 0.4043543144819927, 0.7840415981034096, 0.22714129072945305, 0.22714129072945305, 0.7362956822552816, 0.7955509616699936, 0.7840415981034096, 0.3163581217532555, 0.5009836008592764, 0.6111637840734053, 0.5815606048984605, 0.7122160791384321, 0.18435785790943687, 0.22714129072945305, 0.5472668895931797, 0.22714129072945305, 0.22714129072945305, 0.7840415981034096, 0.18435785790943687]\n",
      "all_sum before preprocessing is: [2.094790120751033, 1.735852263945371, 1.6282330503225966, 1.6282330503225966, 2.5316714932318365, 2.998228563660273, 2.4783250043733815, 2.094790120751033, 1.6282330503225966, 2.094790120751033, 1.6282330503225966, 1.6282330503225966, 2.094790120751033, 2.944882074801818, 2.944882074801818, 2.4783250043733815, 1.6282330503225966, 2.094790120751033, 1.6282330503225966, 2.094790120751033, 1.6282330503225966, 2.094790120751033, 2.094790120751033, 2.944882074801818, 2.4783250043733815, 2.094790120751033, 1.6282330503225966, 2.094790120751033, 2.094790120751033, 2.094790120751033, 2.998228563660273, 2.094790120751033, 1.6282330503225966, 2.4783250043733815, 2.094790120751033, 1.6282330503225966, 2.944882074801818, 2.4783250043733815, 2.094790120751033, 2.4783250043733815, 1.6282330503225966, 2.4783250043733815, 2.094790120751033, 2.094790120751033, 2.998228563660273, 2.094790120751033, 2.944882074801818, 2.094790120751033, 1.6282330503225966, 2.4783250043733815]\n",
      "all_sum after preprocessing is: [-0.18020005 -0.98035502 -1.22026298 -1.22026298  0.79370893  1.83377185\n",
      "  0.67478735 -0.18020005 -1.22026298 -0.18020005 -1.22026298 -1.22026298\n",
      " -0.18020005  1.71485027  1.71485027  0.67478735 -1.22026298 -0.18020005\n",
      " -1.22026298 -0.18020005 -1.22026298 -0.18020005 -0.18020005  1.71485027\n",
      "  0.67478735 -0.18020005 -1.22026298 -0.18020005 -0.18020005 -0.18020005\n",
      "  1.83377185 -0.18020005 -1.22026298  0.67478735 -0.18020005 -1.22026298\n",
      "  1.71485027  0.67478735 -0.18020005  0.67478735 -1.22026298  0.67478735\n",
      " -0.18020005 -0.18020005  1.83377185 -0.18020005  1.71485027 -0.18020005\n",
      " -1.22026298  0.67478735]\n",
      "P is: [0.4550714988923259, 0.27282134626618487, 0.22789017512964552, 0.22789017512964552, 0.688627154040269, 0.86221044924925, 0.6625742956597203, 0.4550714988923259, 0.22789017512964552, 0.4550714988923259, 0.22789017512964552, 0.22789017512964552, 0.4550714988923259, 0.8474643290252756, 0.8474643290252756, 0.6625742956597203, 0.22789017512964552, 0.4550714988923259, 0.22789017512964552, 0.4550714988923259, 0.22789017512964552, 0.4550714988923259, 0.4550714988923259, 0.8474643290252756, 0.6625742956597203, 0.4550714988923259, 0.22789017512964552, 0.4550714988923259, 0.4550714988923259, 0.4550714988923259, 0.86221044924925, 0.4550714988923259, 0.22789017512964552, 0.6625742956597203, 0.4550714988923259, 0.22789017512964552, 0.8474643290252756, 0.6625742956597203, 0.4550714988923259, 0.6625742956597203, 0.22789017512964552, 0.6625742956597203, 0.4550714988923259, 0.4550714988923259, 0.86221044924925, 0.4550714988923259, 0.8474643290252756, 0.4550714988923259, 0.22789017512964552, 0.6625742956597203]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.481\n",
      "(*) epoch 2, cost 2.645\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.395\n",
      "(*) epoch 2, cost 2.202\n",
      "(*) epoch 3, cost 1.764\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.872594912344994, 1.872594912344994, 1.872594912344994, 1.872594912344994, 2.769369402643204, 1.6963030580251846, 2.9456612569630134, 1.3041090283239416, 1.6963030580251846, 1.6963030580251846, 2.9456612569630134, 3.421277095206382, 1.6963030580251846, 2.769369402643204, 1.6963030580251846, 2.9456612569630134, 1.872594912344994, 1.872594912344994, 1.6963030580251846, 3.984284902654014, 2.9456612569630134, 3.6358010442091597, 1.872594912344994, 1.6963030580251846, 1.872594912344994, 2.9456612569630134, 3.4939518888163694, 1.872594912344994, 2.348210750588362, 1.4804008826437511, 2.9456612569630134, 1.872594912344994, 1.6963030580251846, 2.2445936898785406, 3.0875104123558037, 2.028691514497107, 2.9456612569630134, 2.4737686308304174, 2.9456612569630134, 2.9456612569630134, 2.9456612569630134, 2.695316382654561, 3.5190532245319424, 1.872594912344994, 2.0815746011291743, 1.6963030580251846, 2.769369402643204, 2.42088554419835, 1.4804008826437511, 1.6963030580251846]\n",
      "all_sum after preprocessing is: [-0.69793567 -0.69793567 -0.69793567 -0.69793567  0.63964497 -0.96088312\n",
      "  0.90259242 -1.54585866 -0.96088312 -0.96088312  0.90259242  1.61199544\n",
      " -0.96088312  0.63964497 -0.96088312  0.90259242 -0.69793567 -0.69793567\n",
      " -0.96088312  2.45174763  0.90259242  1.93196784 -0.69793567 -0.96088312\n",
      " -0.69793567  0.90259242  1.72039326 -0.69793567  0.01146736 -1.2829112\n",
      "  0.90259242 -0.69793567 -0.96088312 -0.14308228  1.114167   -0.46511036\n",
      "  0.90259242  0.19874274  0.90259242  0.90259242  0.90259242  0.52919146\n",
      "  1.75783306 -0.69793567 -0.38623279 -0.96088312  0.63964497  0.11986517\n",
      " -1.2829112  -0.96088312]\n",
      "P is: [0.3322700758987186, 0.3322700758987186, 0.3322700758987186, 0.3322700758987186, 0.6546732001669152, 0.27670141403759346, 0.7114819543628711, 0.17568521170552598, 0.27670141403759346, 0.27670141403759346, 0.7114819543628711, 0.8336882431122606, 0.27670141403759346, 0.6546732001669152, 0.27670141403759346, 0.7114819543628711, 0.3322700758987186, 0.3322700758987186, 0.27670141403759346, 0.9206891576646156, 0.7114819543628711, 0.8734670695466737, 0.3322700758987186, 0.27670141403759346, 0.3322700758987186, 0.7114819543628711, 0.8481794836391376, 0.3322700758987186, 0.5028668074478997, 0.2170550799480091, 0.7114819543628711, 0.3322700758987186, 0.27670141403759346, 0.4642903306850385, 0.7529051520364194, 0.38577420577441757, 0.7114819543628711, 0.5495227855306146, 0.7114819543628711, 0.7114819543628711, 0.7114819543628711, 0.6292945133266046, 0.8529380587712628, 0.3322700758987186, 0.4046245066928992, 0.27670141403759346, 0.6546732001669152, 0.5299304656001793, 0.2170550799480091, 0.27670141403759346]\n",
      "all_sum before preprocessing is: [0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 2.1984080867844096, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.8095809570708942, 0.7723072321306671, 0.7723072321306671, 0.8016855655927256, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.8389592905329527, 0.7723072321306671, 2.2273150478626618, 0.7723072321306671, 0.8016855655927256, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.8016855655927256, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.8016855655927256, 0.8016855655927256, 0.8095809570708942, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.8095809570708942, 2.1690297533223513, 0.7723072321306671, 0.7723072321306671, 2.190041322922435, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.7723072321306671, 0.8095809570708942]\n",
      "all_sum after preprocessing is: [-0.31512367 -0.31512367 -0.31512367 -0.31512367  3.39388105 -0.31512367\n",
      " -0.31512367 -0.31512367 -0.21818213 -0.31512367 -0.31512367 -0.23871647\n",
      " -0.31512367 -0.31512367 -0.31512367 -0.31512367 -0.31512367 -0.14177492\n",
      " -0.31512367  3.4690623  -0.31512367 -0.23871647 -0.31512367 -0.31512367\n",
      " -0.31512367 -0.31512367 -0.31512367 -0.31512367 -0.23871647 -0.31512367\n",
      " -0.31512367 -0.31512367 -0.31512367 -0.23871647 -0.23871647 -0.21818213\n",
      " -0.31512367 -0.31512367 -0.31512367 -0.21818213  3.31747384 -0.31512367\n",
      " -0.31512367  3.37212076 -0.31512367 -0.31512367 -0.31512367 -0.31512367\n",
      " -0.31512367 -0.21818213]\n",
      "P is: [0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.9675127546467336, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4456698230592849, 0.4218646039323092, 0.4218646039323092, 0.44060268103185496, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.46461551886015456, 0.4218646039323092, 0.9697945625996511, 0.4218646039323092, 0.44060268103185496, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.44060268103185496, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.44060268103185496, 0.44060268103185496, 0.4456698230592849, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4456698230592849, 0.9650234256542132, 0.4218646039323092, 0.4218646039323092, 0.9668217869734184, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4218646039323092, 0.4456698230592849]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.519\n",
      "(*) epoch 2, cost 4.153\n",
      "(*) epoch 3, cost 3.350\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.770\n",
      "(*) epoch 2, cost 1.551\n",
      "(*) epoch 3, cost 1.100\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.7954913398328961, 1.3970923415251457, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 1.1218893865998663, 1.3970923415251457, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 1.3970923415251457, 0.7954913398328961, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 1.3970923415251457, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961, 0.7954913398328961]\n",
      "all_sum after preprocessing is: [-0.74331704  1.3752948   1.3752948  -0.74331704 -0.74331704  1.3752948\n",
      "  1.3752948  -0.74331704 -0.74331704  1.3752948  -0.74331704 -0.74331704\n",
      " -0.74331704 -0.74331704  1.3752948  -0.74331704 -0.74331704  1.3752948\n",
      " -0.74331704 -0.74331704  1.3752948   0.40613378  1.3752948   1.3752948\n",
      " -0.74331704 -0.74331704 -0.74331704 -0.74331704 -0.74331704  1.3752948\n",
      "  1.3752948  -0.74331704 -0.74331704  1.3752948   1.3752948  -0.74331704\n",
      "  1.3752948  -0.74331704 -0.74331704  1.3752948  -0.74331704 -0.74331704\n",
      " -0.74331704  1.3752948  -0.74331704 -0.74331704 -0.74331704 -0.74331704\n",
      " -0.74331704 -0.74331704]\n",
      "P is: [0.32227922446926155, 0.7982342607004338, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.6001604705861253, 0.7982342607004338, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.7982342607004338, 0.32227922446926155, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.7982342607004338, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155, 0.32227922446926155]\n",
      "all_sum before preprocessing is: [5.812584718407505, 8.633388496038528, 5.812584718407505, 5.812584718407505, 3.3296227748268117, 5.862307434581876, 4.806069042128264, 5.816703711125234, 4.585119129320919, 4.806069042128264, 4.5570883639133974, 5.812584718407505, 5.812584718407505, 4.585119129320919, 4.5570883639133974, 2.9958999334942114, 2.017415022622493, 6.061565396622372, 6.150426552457834, 6.061565396622372, 4.5570883639133974, 8.633388496038528, 4.052138325947823, 1.7404035790001042, 4.585119129320919, 5.812584718407505, 1.7684343444076258, 6.061565396622372, 4.5570883639133974, 5.812584718407505, 5.613326756367009, 5.812584718407505, 6.065868472695819, 3.2448806117090783, 3.2448806117090783, 4.5570883639133974, 5.613326756367009, 4.5570883639133974, 2.017415022622493, 5.812584718407505, 5.812584718407505, 3.3296227748268117, 6.061565396622372, 6.868823110861117, 0.7619186681283855, 6.061565396622372, 5.812584718407505, 4.834099807535786, 4.585119129320919, 6.061565396622372]\n",
      "all_sum after preprocessing is: [ 0.53905393  2.3308222   0.53905393  0.53905393 -1.03811797  0.57063769\n",
      " -0.10028259  0.5416703  -0.24062948 -0.10028259 -0.25843456  0.53905393\n",
      "  0.53905393 -0.24062948 -0.25843456 -1.25009797 -1.87162941  0.6972059\n",
      "  0.75365031  0.6972059  -0.25843456  2.3308222  -0.5791777  -2.04758646\n",
      " -0.24062948  0.53905393 -2.02978138  0.6972059  -0.25843456  0.53905393\n",
      "  0.41248571  0.53905393  0.6999392  -1.091946   -1.091946   -0.25843456\n",
      "  0.41248571 -0.25843456 -1.87162941  0.53905393  0.53905393 -1.03811797\n",
      "  0.6972059   1.2099742  -2.6691179   0.6972059   0.53905393 -0.08247751\n",
      " -0.24062948  0.6972059 ]\n",
      "P is: [0.6315923096799251, 0.9113977536235829, 0.6315923096799251, 0.6315923096799251, 0.26151329651919625, 0.6389103048026851, 0.4749503423517135, 0.6322008870004805, 0.4401312310328732, 0.4749503423517135, 0.4357485668651719, 0.6315923096799251, 0.6315923096799251, 0.4401312310328732, 0.4357485668651719, 0.2226831796790381, 0.13335329893721024, 0.667567993247128, 0.6799735621661088, 0.667567993247128, 0.4357485668651719, 0.9113977536235829, 0.3591218269922627, 0.114296483284498, 0.4401312310328732, 0.6315923096799251, 0.11611135697717899, 0.667567993247128, 0.4357485668651719, 0.6315923096799251, 0.6016837563297482, 0.6315923096799251, 0.6681742927187919, 0.2512520108776218, 0.2512520108776218, 0.4357485668651719, 0.6016837563297482, 0.4357485668651719, 0.13335329893721024, 0.6315923096799251, 0.6315923096799251, 0.26151329651919625, 0.667567993247128, 0.7702943841943319, 0.06482042011428026, 0.667567993247128, 0.6315923096799251, 0.47939230367538355, 0.4401312310328732, 0.667567993247128]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.637\n",
      "(*) epoch 2, cost 2.068\n",
      "(*) epoch 3, cost 1.093\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.312\n",
      "(*) epoch 2, cost 3.817\n",
      "(*) epoch 3, cost 3.083\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [5.444900986994079, 5.5102606984280875, 2.4314992687084334, 4.252567576950161, 5.444900986994079, 4.252567576950161, 4.252567576950161, 1.7032743120960405, 2.4314992687084334, 2.4314992687084334, 5.444900986994079, 4.252567576950161, 3.524342620337768, 3.9600033312447795, 4.252567576950161, 4.252567576950161, 2.4314992687084334, 3.524342620337768, 2.4314992687084334, 2.4314992687084334, 5.444900986994079, 2.496858980142442, 4.716676030381686, 3.6238326787523514, 4.716676030381686, 2.4314992687084334, 2.4314992687084334, 4.252567576950161, 4.252567576950161, 4.252567576950161, 5.444900986994079, 3.524342620337768, 4.252567576950161, 2.4314992687084334, 4.252567576950161, 4.252567576950161, 4.252567576950161, 4.588738229442589, 3.68919239018636, 2.4314992687084334, 4.252567576950161, 4.252567576950161, 2.4314992687084334, 4.716676030381686, 3.524342620337768, 4.252567576950161, 3.524342620337768, 4.317927288384169, 3.524342620337768, 2.4314992687084334]\n",
      "all_sum after preprocessing is: [ 1.61661908  1.68056714 -1.33169843  0.45003799  1.61661908  0.45003799\n",
      "  0.45003799 -2.044195   -1.33169843 -1.33169843  1.61661908  0.45003799\n",
      " -0.26245858  0.16379262  0.45003799  0.45003799 -1.33169843 -0.26245858\n",
      " -1.33169843 -1.33169843  1.61661908 -1.26775037  0.90412251 -0.16511733\n",
      "  0.90412251 -1.33169843 -1.33169843  0.45003799  0.45003799  0.45003799\n",
      "  1.61661908 -0.26245858  0.45003799 -1.33169843  0.45003799  0.45003799\n",
      "  0.45003799  0.77894795 -0.10116928 -1.33169843  0.45003799  0.45003799\n",
      " -1.33169843  0.90412251 -0.26245858  0.45003799 -0.26245858  0.51398605\n",
      " -0.26245858 -1.33169843]\n",
      "P is: [0.8343283322351948, 0.8429796151779081, 0.20887856443500682, 0.6106482665810512, 0.8343283322351948, 0.6106482665810512, 0.6106482665810512, 0.11464026001591318, 0.20887856443500682, 0.20887856443500682, 0.8343283322351948, 0.6106482665810512, 0.43475943113079024, 0.5408568537706466, 0.6106482665810512, 0.6106482665810512, 0.20887856443500682, 0.43475943113079024, 0.20887856443500682, 0.20887856443500682, 0.8343283322351948, 0.21964259486619012, 0.7117959430463433, 0.45881419753553715, 0.7117959430463433, 0.20887856443500682, 0.20887856443500682, 0.6106482665810512, 0.6106482665810512, 0.6106482665810512, 0.8343283322351948, 0.43475943113079024, 0.6106482665810512, 0.20887856443500682, 0.6106482665810512, 0.6106482665810512, 0.6106482665810512, 0.6854533277242381, 0.4747292314362788, 0.20887856443500682, 0.6106482665810512, 0.6106482665810512, 0.20887856443500682, 0.7117959430463433, 0.43475943113079024, 0.6106482665810512, 0.43475943113079024, 0.6257404310257433, 0.43475943113079024, 0.20887856443500682]\n",
      "all_sum before preprocessing is: [2.692600403952639, 5.596665560203302, 3.4041295566365486, 2.692600403952639, 2.692600403952639, 1.3115113749325056, 1.3115113749325056, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 5.596665560203302, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 5.596665560203302, 5.596665560203302, 2.692600403952639, 6.308194712887211, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 2.692600403952639, 5.596665560203302, 2.692600403952639, 1.3115113749325056, 2.692600403952639, 7.5892619242458235, 2.692600403952639, 3.4041295566365486, 2.692600403952639, 2.692600403952639, 3.4041295566365486, 5.596665560203302, 5.596665560203302, 2.692600403952639, 2.692600403952639, 3.4041295566365486]\n",
      "all_sum after preprocessing is: [-0.41368793  1.76717875  0.12064933 -0.41368793 -0.41368793 -1.45084477\n",
      " -1.45084477 -0.41368793 -0.41368793 -0.41368793 -0.41368793 -0.41368793\n",
      " -0.41368793 -0.41368793  1.76717875 -0.41368793 -0.41368793 -0.41368793\n",
      " -0.41368793 -0.41368793 -0.41368793 -0.41368793 -0.41368793 -0.41368793\n",
      "  1.76717875  1.76717875 -0.41368793  2.30151601 -0.41368793 -0.41368793\n",
      " -0.41368793 -0.41368793 -0.41368793 -0.41368793 -0.41368793  1.76717875\n",
      " -0.41368793 -1.45084477 -0.41368793  3.26355944 -0.41368793  0.12064933\n",
      " -0.41368793 -0.41368793  0.12064933  1.76717875  1.76717875 -0.41368793\n",
      " -0.41368793  0.12064933]\n",
      "P is: [0.3980281547623583, 0.8541064700967161, 0.5301257979189282, 0.3980281547623583, 0.3980281547623583, 0.18987158841158003, 0.18987158841158003, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.8541064700967161, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.8541064700967161, 0.8541064700967161, 0.3980281547623583, 0.9090025165694458, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.3980281547623583, 0.8541064700967161, 0.3980281547623583, 0.18987158841158003, 0.3980281547623583, 0.9631573069465276, 0.3980281547623583, 0.5301257979189282, 0.3980281547623583, 0.3980281547623583, 0.5301257979189282, 0.8541064700967161, 0.8541064700967161, 0.3980281547623583, 0.3980281547623583, 0.5301257979189282]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.932\n",
      "(*) epoch 2, cost 4.333\n",
      "(*) epoch 3, cost 3.363\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.083\n",
      "(*) epoch 2, cost 1.625\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0356823563166975, 1.4710460728404766, 1.4710460728404766, 2.4901755948471687, 2.0014751067667262, 0.5052533223904476, 1.4710460728404766, 1.4710460728404766, 1.4710460728404766, 1.52438284439714, 1.4710460728404766, 1.4710460728404766, 1.4710460728404766, 1.0356823563166975, 1.0356823563166975, 1.4710460728404766, 1.4710460728404766, 1.4710460728404766, 1.4710460728404766, 2.0014751067667262, 1.4710460728404766, 1.4710460728404766, 0.5052533223904476, 1.4710460728404766, 1.52438284439714, 2.0014751067667262, 1.4710460728404766, 1.4710460728404766, 0.5052533223904476, 1.0356823563166975, 2.0014751067667262, 1.4710460728404766, 1.4710460728404766, 1.4710460728404766, 1.4710460728404766, 0.5052533223904476, 1.4710460728404766, 2.4901755948471687, 1.4710460728404766, 1.4710460728404766, 2.0014751067667262, 3.0206046287734187, 1.4710460728404766, 0.5052533223904476, 3.0206046287734187, 1.4710460728404766, 2.4901755948471687, 1.0356823563166975, 0.5052533223904476, 2.0014751067667262]\n",
      "all_sum after preprocessing is: [-0.81886189 -0.05193742 -0.05193742  1.74333247  0.88245144 -1.75325076\n",
      " -0.05193742 -0.05193742 -0.05193742  0.04201913 -0.05193742 -0.05193742\n",
      " -0.05193742 -0.81886189 -0.81886189 -0.05193742 -0.05193742 -0.05193742\n",
      " -0.05193742  0.88245144 -0.05193742 -0.05193742 -1.75325076 -0.05193742\n",
      "  0.04201913  0.88245144 -0.05193742 -0.05193742 -1.75325076 -0.81886189\n",
      "  0.88245144 -0.05193742 -0.05193742 -0.05193742 -0.05193742 -1.75325076\n",
      " -0.05193742  1.74333247 -0.05193742 -0.05193742  0.88245144  2.67772133\n",
      " -0.05193742 -1.75325076  2.67772133 -0.05193742  1.74333247 -0.81886189\n",
      " -1.75325076  0.88245144]\n",
      "P is: [0.3060053014317046, 0.48701856256729653, 0.48701856256729653, 0.8511098564527294, 0.7073299619482882, 0.1476376516024262, 0.48701856256729653, 0.48701856256729653, 0.48701856256729653, 0.5105032382533888, 0.48701856256729653, 0.48701856256729653, 0.48701856256729653, 0.3060053014317046, 0.3060053014317046, 0.48701856256729653, 0.48701856256729653, 0.48701856256729653, 0.48701856256729653, 0.7073299619482882, 0.48701856256729653, 0.48701856256729653, 0.1476376516024262, 0.48701856256729653, 0.5105032382533888, 0.7073299619482882, 0.48701856256729653, 0.48701856256729653, 0.1476376516024262, 0.3060053014317046, 0.7073299619482882, 0.48701856256729653, 0.48701856256729653, 0.48701856256729653, 0.48701856256729653, 0.1476376516024262, 0.48701856256729653, 0.8511098564527294, 0.48701856256729653, 0.48701856256729653, 0.7073299619482882, 0.9356991606391789, 0.48701856256729653, 0.1476376516024262, 0.9356991606391789, 0.48701856256729653, 0.8511098564527294, 0.3060053014317046, 0.1476376516024262, 0.7073299619482882]\n",
      "all_sum before preprocessing is: [2.4878897668326063, 2.4878897668326063, 3.1556985985284047, 2.4878897668326063, 1.655817173674222, 2.4878897668326063, 4.01334998730156, 1.655817173674222, 1.655817173674222, 2.4878897668326063, 2.4878897668326063, 2.4878897668326063, 4.490111142148631, 1.655817173674222, 2.4878897668326063, 2.132578328521293, 1.655817173674222, 2.4878897668326063, 2.4878897668326063, 2.4878897668326063, 4.01334998730156, 2.4878897668326063, 2.4878897668326063, 2.4878897668326063, 1.655817173674222, 3.049872003392796, 2.9646509216796773, 2.4878897668326063, 2.4878897668326063, 2.4878897668326063, 2.132578328521293, 2.4878897668326063, 2.9646509216796773, 2.4878897668326063, 3.049872003392796, 2.4878897668326063, 2.4878897668326063, 2.4878897668326063, 4.01334998730156, 2.4878897668326063, 2.4878897668326063, 2.9646509216796773, 2.4878897668326063, 4.01334998730156, 2.4878897668326063, 2.4878897668326063, 2.4878897668326063, 1.655817173674222, 2.4878897668326063, 2.132578328521293]\n",
      "all_sum after preprocessing is: [-0.14059153 -0.14059153  0.9177393  -0.14059153 -1.45924446 -0.14059153\n",
      "  2.27692903 -1.45924446 -1.45924446 -0.14059153 -0.14059153 -0.14059153\n",
      "  3.0324911  -1.45924446 -0.14059153 -0.70368239 -1.45924446 -0.14059153\n",
      " -0.14059153 -0.14059153  2.27692903 -0.14059153 -0.14059153 -0.14059153\n",
      " -1.45924446  0.75002731  0.61497055 -0.14059153 -0.14059153 -0.14059153\n",
      " -0.70368239 -0.14059153  0.61497055 -0.14059153  0.75002731 -0.14059153\n",
      " -0.14059153 -0.14059153  2.27692903 -0.14059153 -0.14059153  0.61497055\n",
      " -0.14059153  2.27692903 -0.14059153 -0.14059153 -0.14059153 -1.45924446\n",
      " -0.14059153 -0.70368239]\n",
      "P is: [0.4649098978558143, 0.4649098978558143, 0.7145812482398538, 0.4649098978558143, 0.18858290967932648, 0.4649098978558143, 0.9069482012942195, 0.18858290967932648, 0.18858290967932648, 0.4649098978558143, 0.4649098978558143, 0.4649098978558143, 0.9540205695975772, 0.18858290967932648, 0.4649098978558143, 0.3309963013098353, 0.18858290967932648, 0.4649098978558143, 0.4649098978558143, 0.4649098978558143, 0.9069482012942195, 0.4649098978558143, 0.4649098978558143, 0.4649098978558143, 0.18858290967932648, 0.6791846494686085, 0.6490738155626665, 0.4649098978558143, 0.4649098978558143, 0.4649098978558143, 0.3309963013098353, 0.4649098978558143, 0.6490738155626665, 0.4649098978558143, 0.6791846494686085, 0.4649098978558143, 0.4649098978558143, 0.4649098978558143, 0.9069482012942195, 0.4649098978558143, 0.4649098978558143, 0.6490738155626665, 0.4649098978558143, 0.9069482012942195, 0.4649098978558143, 0.4649098978558143, 0.4649098978558143, 0.18858290967932648, 0.4649098978558143, 0.3309963013098353]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.109\n",
      "(*) epoch 2, cost 2.566\n",
      "(*) epoch 3, cost 2.186\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.062\n",
      "(*) epoch 2, cost 2.933\n",
      "(*) epoch 3, cost 2.309\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.9321853885061566, 1.419325615921165, 1.8583376039470862, 0.9321853885061566, 1.419325615921165, 0.544857215302419, 0.9321853885061566, 3.144776291529702, 0.05771698788741087, 1.419325615921165, 0.07973500725959032, 3.144776291529702, 2.2703078909109564, 0.9321853885061566, 3.9712481539865943, 0.9321853885061566, 0.9321853885061566, 3.144776291529702, 0.05771698788741087, 0.954203407878336, 0.07973500725959032, 3.144776291529702, 1.419325615921165, 0.9321853885061566, 3.144776291529702, 1.419325615921165, 1.419325615921165, 3.144776291529702, 0.9321853885061566, 1.419325615921165, 0.9321853885061566, 0.9321853885061566, 2.292325910283136, 0.954203407878336, 1.419325615921165, 0.954203407878336, 1.419325615921165, 3.144776291529702, 0.9321853885061566, 0.9321853885061566, 0.9321853885061566, 1.349179357159899, 0.544857215302419, 0.9321853885061566, 1.419325615921165, 1.4413436352933442, 3.144776291529702, 0.954203407878336, 1.4423902722530995, 1.4413436352933442]\n",
      "all_sum after preprocessing is: [-0.57079693 -0.05664949  0.40670148 -0.57079693 -0.05664949 -0.97959871\n",
      " -0.57079693  1.76446076 -1.49374616 -0.05664949 -1.47050746  1.76446076\n",
      "  0.84151154 -0.57079693  2.63675251 -0.57079693 -0.57079693  1.76446076\n",
      " -1.49374616 -0.54755823 -1.47050746  1.76446076 -0.05664949 -0.57079693\n",
      "  1.76446076 -0.05664949 -0.05664949  1.76446076 -0.57079693 -0.05664949\n",
      " -0.57079693 -0.57079693  0.86475024 -0.54755823 -0.05664949 -0.54755823\n",
      " -0.05664949  1.76446076 -0.57079693 -0.57079693 -0.57079693 -0.13068468\n",
      " -0.97959871 -0.57079693 -0.05664949 -0.03341078  1.76446076 -0.54755823\n",
      " -0.03230612 -0.03341078]\n",
      "P is: [0.3610529568252805, 0.4858414146576194, 0.6002966915829027, 0.3610529568252805, 0.4858414146576194, 0.27297141498162875, 0.3610529568252805, 0.853767459482402, 0.1833601148185966, 0.4858414146576194, 0.18686549554818316, 0.853767459482402, 0.698783467461294, 0.3610529568252805, 0.9331897788631662, 0.3610529568252805, 0.3610529568252805, 0.853767459482402, 0.1833601148185966, 0.3664311040469544, 0.18686549554818316, 0.853767459482402, 0.4858414146576194, 0.3610529568252805, 0.853767459482402, 0.4858414146576194, 0.4858414146576194, 0.853767459482402, 0.3610529568252805, 0.4858414146576194, 0.3610529568252805, 0.3610529568252805, 0.7036521596748216, 0.3664311040469544, 0.4858414146576194, 0.3664311040469544, 0.4858414146576194, 0.853767459482402, 0.3610529568252805, 0.3610529568252805, 0.3610529568252805, 0.46737524917345635, 0.27297141498162875, 0.3610529568252805, 0.4858414146576194, 0.4916480818020518, 0.853767459482402, 0.3664311040469544, 0.491924172983383, 0.4916480818020518]\n",
      "all_sum before preprocessing is: [0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 0.8759758401903596, 0.8759758401903596, 1.4940414412781886, 0.9397052765183325, 0.8759758401903596, 0.8759758401903596, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 0.8759758401903596, 0.8759758401903596, 0.8759758401903596, 1.4940414412781886, 1.4940414412781886, 0.8759758401903596, 1.4940414412781886, 1.4940414412781886, 1.4940414412781886, 0.8759758401903596, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 0.9397052765183325, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 0.8759758401903596, 0.8759758401903596, 1.5577708776061616, 0.8759758401903596, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 1.4940414412781886, 0.8759758401903596, 0.8759758401903596]\n",
      "all_sum after preprocessing is: [-0.7624428   1.31967233 -0.7624428   1.31967233 -0.7624428   1.31967233\n",
      " -0.7624428  -0.7624428  -0.7624428   1.31967233 -0.54775358 -0.7624428\n",
      " -0.7624428  -0.7624428   1.31967233 -0.7624428   1.31967233 -0.7624428\n",
      " -0.7624428  -0.7624428  -0.7624428   1.31967233  1.31967233 -0.7624428\n",
      "  1.31967233  1.31967233  1.31967233 -0.7624428  -0.7624428   1.31967233\n",
      " -0.7624428  -0.54775358 -0.7624428   1.31967233 -0.7624428  -0.7624428\n",
      " -0.7624428   1.53436155 -0.7624428  -0.7624428   1.31967233 -0.7624428\n",
      "  1.31967233 -0.7624428  -0.7624428   1.31967233 -0.7624428   1.31967233\n",
      " -0.7624428  -0.7624428 ]\n",
      "P is: [0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.31811614301980273, 0.31811614301980273, 0.7891271855096769, 0.3663857531483666, 0.31811614301980273, 0.31811614301980273, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.31811614301980273, 0.31811614301980273, 0.31811614301980273, 0.7891271855096769, 0.7891271855096769, 0.31811614301980273, 0.7891271855096769, 0.7891271855096769, 0.7891271855096769, 0.31811614301980273, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.3663857531483666, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.31811614301980273, 0.31811614301980273, 0.8226435653618389, 0.31811614301980273, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.7891271855096769, 0.31811614301980273, 0.31811614301980273]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.402\n",
      "(*) epoch 2, cost 2.569\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.922\n",
      "(*) epoch 2, cost 1.045\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.173971141169098, 4.231962576303005, 3.1455170099565595, 4.173971141169098, 3.987413441481809, 3.987413441481809, 3.987413441481809, 4.173971141169098, 4.418520275990291, 2.8784160056107706, 3.987413441481809, 4.173971141169098, 3.987413441481809, 3.987413441481809, 3.987413441481809, 3.987413441481809, 3.987413441481809, 4.418520275990291, 3.987413441481809, 4.231962576303005, 4.418520275990291, 4.173971141169098, 4.173971141169098, 4.231962576303005, 4.418520275990291, 4.173971141169098, 4.173971141169098, 4.231962576303005, 3.987413441481809, 4.173971141169098, 2.633866870789576, 4.173971141169098, 4.173971141169098, 4.173971141169098, 4.418520275990291, 4.173971141169098, 4.173971141169098, 4.173971141169098, 3.987413441481809, 4.173971141169098, 4.173971141169098, 4.231962576303005, 4.173971141169098, 4.231962576303005, 4.173971141169098, 3.987413441481809, 3.987413441481809, 3.987413441481809, 4.418520275990291, 4.173971141169098]\n",
      "all_sum after preprocessing is: [ 0.29126191  0.46549211 -2.79863862  0.29126191 -0.26923439 -0.26923439\n",
      " -0.26923439  0.29126191  1.02598841 -3.60112023 -0.26923439  0.29126191\n",
      " -0.26923439 -0.26923439 -0.26923439 -0.26923439 -0.26923439  1.02598841\n",
      " -0.26923439  0.46549211  1.02598841  0.29126191  0.29126191  0.46549211\n",
      "  1.02598841  0.29126191  0.29126191  0.46549211 -0.26923439  0.29126191\n",
      " -4.33584673  0.29126191  0.29126191  0.29126191  1.02598841  0.29126191\n",
      "  0.29126191  0.29126191 -0.26923439  0.29126191  0.29126191  0.46549211\n",
      "  0.29126191  0.46549211  0.29126191 -0.26923439 -0.26923439 -0.26923439\n",
      "  1.02598841  0.29126191]\n",
      "P is: [0.5723050420167728, 0.6143162458839078, 0.05739778687709524, 0.5723050420167728, 0.4330950616294071, 0.4330950616294071, 0.4330950616294071, 0.5723050420167728, 0.7361374265908287, 0.02656800656721524, 0.4330950616294071, 0.5723050420167728, 0.4330950616294071, 0.4330950616294071, 0.4330950616294071, 0.4330950616294071, 0.4330950616294071, 0.7361374265908287, 0.4330950616294071, 0.6143162458839078, 0.7361374265908287, 0.5723050420167728, 0.5723050420167728, 0.6143162458839078, 0.7361374265908287, 0.5723050420167728, 0.5723050420167728, 0.6143162458839078, 0.4330950616294071, 0.5723050420167728, 0.012921630726046183, 0.5723050420167728, 0.5723050420167728, 0.5723050420167728, 0.7361374265908287, 0.5723050420167728, 0.5723050420167728, 0.5723050420167728, 0.4330950616294071, 0.5723050420167728, 0.5723050420167728, 0.6143162458839078, 0.5723050420167728, 0.6143162458839078, 0.5723050420167728, 0.4330950616294071, 0.4330950616294071, 0.4330950616294071, 0.7361374265908287, 0.5723050420167728]\n",
      "all_sum before preprocessing is: [5.901271654272077, 5.901271654272077, 4.5615983159949085, 4.908148733909001, 4.5615983159949085, 4.5615983159949085, 5.901271654272077, 3.542421328877278, 4.908148733909001, 4.908148733909001, 4.908148733909001, 5.901271654272077, 4.882094667154447, 5.432445194975911, 3.5684753956318316, 4.882094667154447, 4.882094667154447, 4.882094667154447, 4.5615983159949085, 4.5615983159949085, 5.901271654272077, 3.542421328877278, 3.0996489363356665, 4.5615983159949085, 5.432445194975911, 5.901271654272077, 2.5492984085142014, 4.918327196544166, 4.882094667154447, 5.911450116907242, 5.901271654272077, 5.901271654272077, 2.5492984085142014, 3.5684753956318316, 3.542421328877278, 3.5684753956318316, 2.0804719492180364, 4.882094667154447, 4.5615983159949085, 4.092771856698743, 2.5492984085142014, 3.542421328877278, 4.5615983159949085, 5.901271654272077, 5.901271654272077, 4.908148733909001, 4.908148733909001, 4.908148733909001, 3.073594869581113, 4.413268207858281]\n",
      "all_sum after preprocessing is: [ 1.263753    1.263753   -0.03995028  0.29729531 -0.03995028 -0.03995028\n",
      "  1.263753   -1.03176249  0.29729531  0.29729531  0.29729531  1.263753\n",
      "  0.27194079  0.80751447 -1.00640797  0.27194079  0.27194079  0.27194079\n",
      " -0.03995028 -0.03995028  1.263753   -1.03176249 -1.4626465  -0.03995028\n",
      "  0.80751447  1.263753   -1.99822019  0.30720048  0.27194079  1.27365817\n",
      "  1.263753    1.263753   -1.99822019 -1.00640797 -1.03176249 -1.00640797\n",
      " -2.45445872  0.27194079 -0.03995028 -0.49618881 -1.99822019 -1.03176249\n",
      " -0.03995028  1.263753    1.263753    0.29729531  0.29729531  0.29729531\n",
      " -1.48800102 -0.18429774]\n",
      "P is: [0.779671489438321, 0.779671489438321, 0.49001375867140723, 0.5737811989430079, 0.49001375867140723, 0.49001375867140723, 0.779671489438321, 0.26274255099074456, 0.5737811989430079, 0.5737811989430079, 0.5737811989430079, 0.779671489438321, 0.5675693031258383, 0.6915796007738458, 0.2676834041848253, 0.5675693031258383, 0.5675693031258383, 0.5675693031258383, 0.49001375867140723, 0.49001375867140723, 0.779671489438321, 0.26274255099074456, 0.1880628832875459, 0.49001375867140723, 0.6915796007738458, 0.779671489438321, 0.11938991753231674, 0.5762017827609047, 0.5675693031258383, 0.7813683236998535, 0.779671489438321, 0.779671489438321, 0.11938991753231674, 0.2676834041848253, 0.26274255099074456, 0.2676834041848253, 0.07911310267216208, 0.5675693031258383, 0.49001375867140723, 0.37843673059320915, 0.11938991753231674, 0.26274255099074456, 0.49001375867140723, 0.779671489438321, 0.779671489438321, 0.5737811989430079, 0.5737811989430079, 0.5737811989430079, 0.1842219528793381, 0.45405553556579187]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.520\n",
      "(*) epoch 2, cost 3.164\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.523\n",
      "(*) epoch 2, cost 3.081\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.2892641821661304, 5.183065510826967, 2.785292980518671, 4.822558042098631, 5.687036712474427, 5.687036712474427, 4.793515434346311, 2.785292980518671, 3.2892641821661304, 3.2892641821661304, 4.822558042098631, 4.822558042098631, 4.793515434346311, 3.2892641821661304, 3.2892641821661304, 4.822558042098631, 3.145800449247008, 3.2892641821661304, 2.785292980518671, 2.785292980518671, 3.145800449247008, 4.822558042098631, 3.6497716508944675, 2.785292980518671, 2.785292980518671, 3.145800449247008, 3.145800449247008, 4.822558042098631, 2.785292980518671, 2.785292980518671, 2.785292980518671, 2.785292980518671, 4.793515434346311, 2.785292980518671, 2.785292980518671, 3.2892641821661304, 2.785292980518671, 3.145800449247008, 2.785292980518671, 3.2892641821661304, 3.6497716508944675, 2.785292980518671, 3.2892641821661304, 2.785292980518671, 3.2892641821661304, 2.785292980518671, 4.822558042098631, 4.822558042098631, 2.785292980518671, 4.822558042098631]\n",
      "all_sum after preprocessing is: [-0.34408452  1.700692   -0.88823267  1.31144462  2.24484014  2.24484014\n",
      "  1.28008671 -0.88823267 -0.34408452 -0.34408452  1.31144462  1.31144462\n",
      "  1.28008671 -0.34408452 -0.34408452  1.31144462 -0.49898529 -0.34408452\n",
      " -0.88823267 -0.88823267 -0.49898529  1.31144462  0.04516286 -0.88823267\n",
      " -0.88823267 -0.49898529 -0.49898529  1.31144462 -0.88823267 -0.88823267\n",
      " -0.88823267 -0.88823267  1.28008671 -0.88823267 -0.88823267 -0.34408452\n",
      " -0.88823267 -0.49898529 -0.88823267 -0.34408452  0.04516286 -0.88823267\n",
      " -0.34408452 -0.88823267 -0.34408452 -0.88823267  1.31144462  1.31144462\n",
      " -0.88823267  1.31144462]\n",
      "P is: [0.4148176401358782, 0.8456250920704932, 0.29147467743737965, 0.7877547919901379, 0.9042045260738497, 0.9042045260738497, 0.7824645361569614, 0.29147467743737965, 0.4148176401358782, 0.4148176401358782, 0.7877547919901379, 0.7877547919901379, 0.7824645361569614, 0.4148176401358782, 0.4148176401358782, 0.7877547919901379, 0.37777915984948235, 0.4148176401358782, 0.29147467743737965, 0.29147467743737965, 0.37777915984948235, 0.7877547919901379, 0.511288795839248, 0.29147467743737965, 0.29147467743737965, 0.37777915984948235, 0.37777915984948235, 0.7877547919901379, 0.29147467743737965, 0.29147467743737965, 0.29147467743737965, 0.29147467743737965, 0.7824645361569614, 0.29147467743737965, 0.29147467743737965, 0.4148176401358782, 0.29147467743737965, 0.37777915984948235, 0.29147467743737965, 0.4148176401358782, 0.511288795839248, 0.29147467743737965, 0.4148176401358782, 0.29147467743737965, 0.4148176401358782, 0.29147467743737965, 0.7877547919901379, 0.7877547919901379, 0.29147467743737965, 0.7877547919901379]\n",
      "all_sum before preprocessing is: [1.0474848654770617, 2.1776244425346567, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 2.1776244425346567, 1.0474848654770617, 1.1580715042237535, 1.0474848654770617, 2.1776244425346567, 2.1776244425346567, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 2.1776244425346567, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0592687152046008, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 2.1776244425346567, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617, 1.1580715042237535, 1.0474848654770617, 2.1776244425346567, 1.0474848654770617, 1.0474848654770617, 1.0474848654770617]\n",
      "all_sum after preprocessing is: [-0.41671721  2.47469009 -0.41671721 -0.41671721 -0.41671721 -0.41671721\n",
      " -0.41671721  2.47469009 -0.41671721 -0.13378666 -0.41671721  2.47469009\n",
      "  2.47469009 -0.41671721 -0.41671721 -0.41671721 -0.41671721  2.47469009\n",
      " -0.41671721 -0.41671721 -0.41671721 -0.41671721 -0.41671721 -0.41671721\n",
      " -0.41671721 -0.41671721 -0.41671721 -0.41671721 -0.41671721 -0.3865688\n",
      " -0.41671721 -0.41671721 -0.41671721 -0.41671721 -0.41671721 -0.41671721\n",
      " -0.41671721 -0.41671721 -0.41671721 -0.41671721  2.47469009 -0.41671721\n",
      " -0.41671721 -0.41671721 -0.13378666 -0.41671721  2.47469009 -0.41671721\n",
      " -0.41671721 -0.41671721]\n",
      "P is: [0.3973025584497627, 0.9223483442179595, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.9223483442179595, 0.3973025584497627, 0.46660313390360375, 0.3973025584497627, 0.9223483442179595, 0.9223483442179595, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.9223483442179595, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.404543563205296, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.9223483442179595, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627, 0.46660313390360375, 0.3973025584497627, 0.9223483442179595, 0.3973025584497627, 0.3973025584497627, 0.3973025584497627]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.120\n",
      "(*) epoch 2, cost 2.962\n",
      "(*) epoch 3, cost 2.459\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.451\n",
      "(*) epoch 2, cost 1.203\n",
      "(*) epoch 3, cost 0.748\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.8242002735132563, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.8242002735132563, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 3.190132667375341, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 3.190132667375341, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 1.23796600278408, 3.190132667375341]\n",
      "all_sum after preprocessing is: [-0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292\n",
      " -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292\n",
      "  0.94448612 -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292\n",
      " -0.29793292 -0.29793292  0.94448612 -0.29793292 -0.29793292 -0.29793292\n",
      " -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292\n",
      " -0.29793292  3.83933635 -0.29793292 -0.29793292 -0.29793292 -0.29793292\n",
      " -0.29793292 -0.29793292 -0.29793292 -0.29793292  3.83933635 -0.29793292\n",
      " -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292 -0.29793292\n",
      " -0.29793292  3.83933635]\n",
      "P is: [0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.7200049418559453, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.7200049418559453, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.9789449784090232, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.9789449784090232, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.4260628762053745, 0.9789449784090232]\n",
      "all_sum before preprocessing is: [0.4143825057246089, 0.7432153127774772, 0.4143825057246089, 2.643833899499924, 1.1842796219112248, 1.2973802999581285, 1.2973802999581285, 1.2973802999581285, 0.7432153127774772, 1.2973802999581285, 1.6262131070109969, 1.5131124289640931, 1.2973802999581285, 1.2973802999581285, 1.2973802999581285, 0.4143825057246089, 0.4143825057246089, 1.2973802999581285, 1.2973802999581285, 1.1842796219112248, 1.6262131070109969, 0.7432153127774772, 1.2973802999581285, 1.2973802999581285, 1.2973802999581285, 1.6262131070109969, 1.2973802999581285, 1.2973802999581285, 0.4143825057246089, 1.2973802999581285, 0.4143825057246089, 1.1842796219112248, 1.2973802999581285, 0.4143825057246089, 0.4143825057246089, 1.2973802999581285, 1.2973802999581285, 1.6262131070109969, 1.2973802999581285, 0.4143825057246089, 0.4143825057246089, 1.6262131070109969, 1.2973802999581285, 1.2973802999581285, 1.2973802999581285, 1.2973802999581285, 1.6262131070109969, 1.6262131070109969, 1.6262131070109969, 1.2973802999581285]\n",
      "all_sum after preprocessing is: [-1.62940734 -0.91521268 -1.62940734  3.21275636  0.0427385   0.28838279\n",
      "  0.28838279  0.28838279 -0.91521268  0.28838279  1.00257745  0.75693316\n",
      "  0.28838279  0.28838279  0.28838279 -1.62940734 -1.62940734  0.28838279\n",
      "  0.28838279  0.0427385   1.00257745 -0.91521268  0.28838279  0.28838279\n",
      "  0.28838279  1.00257745  0.28838279  0.28838279 -1.62940734  0.28838279\n",
      " -1.62940734  0.0427385   0.28838279 -1.62940734 -1.62940734  0.28838279\n",
      "  0.28838279  1.00257745  0.28838279 -1.62940734 -1.62940734  1.00257745\n",
      "  0.28838279  0.28838279  0.28838279  0.28838279  1.00257745  1.00257745\n",
      "  1.00257745  0.28838279]\n",
      "P is: [0.16391156577898017, 0.28593434722801514, 0.16391156577898017, 0.9613115098019307, 0.5106829985577109, 0.5716001660358956, 0.5716001660358956, 0.5716001660358956, 0.28593434722801514, 0.5716001660358956, 0.7315650335326814, 0.6806875195625472, 0.5716001660358956, 0.5716001660358956, 0.5716001660358956, 0.16391156577898017, 0.16391156577898017, 0.5716001660358956, 0.5716001660358956, 0.5106829985577109, 0.7315650335326814, 0.28593434722801514, 0.5716001660358956, 0.5716001660358956, 0.5716001660358956, 0.7315650335326814, 0.5716001660358956, 0.5716001660358956, 0.16391156577898017, 0.5716001660358956, 0.16391156577898017, 0.5106829985577109, 0.5716001660358956, 0.16391156577898017, 0.16391156577898017, 0.5716001660358956, 0.5716001660358956, 0.7315650335326814, 0.5716001660358956, 0.16391156577898017, 0.16391156577898017, 0.7315650335326814, 0.5716001660358956, 0.5716001660358956, 0.5716001660358956, 0.5716001660358956, 0.7315650335326814, 0.7315650335326814, 0.7315650335326814, 0.5716001660358956]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.609\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.809\n",
      "(*) epoch 2, cost 2.309\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396, 0.9097201422118396]\n",
      "all_sum after preprocessing is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "P is: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "all_sum before preprocessing is: [3.008390347828878, 2.862847263678831, 3.5375107897458227, 2.9583869217972234, 2.333726821761887, 2.9583869217972234, 2.862847263678831, 2.862847263678831, 2.862847263678831, 1.754602953813288, 3.5375107897458227, 2.7681235353165947, 2.862847263678831, 2.862847263678831, 2.9583869217972234, 2.817748011177062, 2.9583869217972234, 2.862847263678831, 2.7681235353165947, 2.283723395730232, 3.008390347828878, 2.9583869217972234, 2.283723395730232, 2.862847263678831, 2.0934600092496036, 3.475473696207943, 2.862847263678831, 2.7681235353165947, 2.862847263678831, 3.008390347828878, 2.4292664798802788, 3.475473696207943, 2.9053319334293155, 3.5375107897458227, 3.579995459496306, 2.8441107696475916, 2.0934600092496036, 2.862847263678831, 2.1889996673679954, 2.862847263678831, 2.9583869217972234, 3.5375107897458227, 2.9583869217972234, 2.283723395730232, 1.5643395673326592, 3.5375107897458227, 3.5375107897458227, 3.579995459496306, 2.283723395730232, 2.333726821761887]\n",
      "all_sum after preprocessing is: [ 3.44965552e-01  3.87272089e-02  1.45829202e+00  2.39752952e-01\n",
      " -1.07459926e+00  2.39752952e-01  3.87272089e-02  3.87272089e-02\n",
      "  3.87272089e-02 -2.29313832e+00  1.45829202e+00 -1.60581730e-01\n",
      "  3.87272089e-02  3.87272089e-02  2.39752952e-01 -5.61664815e-02\n",
      "  2.39752952e-01  3.87272089e-02 -1.60581730e-01 -1.17981186e+00\n",
      "  3.44965552e-01  2.39752952e-01 -1.17981186e+00  3.87272089e-02\n",
      " -1.58014654e+00  1.32775928e+00  3.87272089e-02 -1.60581730e-01\n",
      "  3.87272089e-02  3.44965552e-01 -8.73573514e-01  1.32775928e+00\n",
      "  1.28119535e-01  1.45829202e+00  1.54768434e+00 -6.96394939e-04\n",
      " -1.58014654e+00  3.87272089e-02 -1.37912080e+00  3.87272089e-02\n",
      "  2.39752952e-01  1.45829202e+00  2.39752952e-01 -1.17981186e+00\n",
      " -2.69347300e+00  1.45829202e+00  1.45829202e+00  1.54768434e+00\n",
      " -1.17981186e+00 -1.07459926e+00]\n",
      "P is: [0.5853962083815785, 0.5096805923418534, 0.8112713043351775, 0.559652767211435, 0.25452941710016047, 0.559652767211435, 0.5096805923418534, 0.5096805923418534, 0.5096805923418534, 0.09169283876266283, 0.8112713043351775, 0.45994061316810825, 0.5096805923418534, 0.5096805923418534, 0.559652767211435, 0.4859620698561292, 0.559652767211435, 0.5096805923418534, 0.45994061316810825, 0.23508602652541127, 0.5853962083815785, 0.559652767211435, 0.23508602652541127, 0.5096805923418534, 0.1707747295864008, 0.7904697524316688, 0.5096805923418534, 0.45994061316810825, 0.5096805923418534, 0.5853962083815785, 0.29451127253331305, 0.7904697524316688, 0.531986142419751, 0.8112713043351775, 0.8245790274949969, 0.499825901272368, 0.1707747295864008, 0.5096805923418534, 0.20115024092936143, 0.5096805923418534, 0.559652767211435, 0.8112713043351775, 0.559652767211435, 0.23508602652541127, 0.06335959952503668, 0.8112713043351775, 0.8112713043351775, 0.8245790274949969, 0.23508602652541127, 0.25452941710016047]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.235\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:191: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 9.591\n",
      "(*) epoch 2, cost 5.568\n",
      "(*) epoch 3, cost 3.827\n",
      "(*) epoch 4, cost 3.320\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 1\n",
      "all_sum before preprocessing is: [1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 2.2305350085109135, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 2.2305350085109135, 2.2569547872000584, 2.2305350085109135, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 1.1997490577297196, 1.8151892030742243, 1.8151892030742243, 2.6723005926367476, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243, 2.2305350085109135, 2.2305350085109135, 1.8151892030742243, 2.2305350085109135, 2.2305350085109135, 1.8151892030742243, 1.8151892030742243, 2.2305350085109135, 1.8151892030742243, 1.8151892030742243, 2.2305350085109135, 2.2305350085109135, 1.8151892030742243, 1.8151892030742243, 2.2569547872000584, 2.2305350085109135, 1.8151892030742243, 2.2305350085109135, 1.8151892030742243, 1.8151892030742243, 1.8151892030742243]\n",
      "all_sum after preprocessing is: [-0.51382815 -0.51382815 -0.51382815  1.23280852 -0.51382815 -0.51382815\n",
      " -0.51382815 -0.51382815 -0.51382815 -0.51382815  1.23280852  1.34391053\n",
      "  1.23280852 -0.51382815 -0.51382815 -0.51382815 -0.51382815 -0.51382815\n",
      " -0.51382815 -0.51382815 -0.51382815 -0.51382815 -3.10191334 -0.51382815\n",
      " -0.51382815  3.0905472  -0.51382815 -0.51382815 -0.51382815  1.23280852\n",
      "  1.23280852 -0.51382815  1.23280852  1.23280852 -0.51382815 -0.51382815\n",
      "  1.23280852 -0.51382815 -0.51382815  1.23280852  1.23280852 -0.51382815\n",
      " -0.51382815  1.34391053  1.23280852 -0.51382815  1.23280852 -0.51382815\n",
      " -0.51382815 -0.51382815]\n",
      "P is: [0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.7743097525771262, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.7743097525771262, 0.7931322909955327, 0.7743097525771262, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.04302840067071967, 0.3742965471951653, 0.3742965471951653, 0.9565011378583502, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653, 0.7743097525771262, 0.7743097525771262, 0.3742965471951653, 0.7743097525771262, 0.7743097525771262, 0.3742965471951653, 0.3742965471951653, 0.7743097525771262, 0.3742965471951653, 0.3742965471951653, 0.7743097525771262, 0.7743097525771262, 0.3742965471951653, 0.3742965471951653, 0.7931322909955327, 0.7743097525771262, 0.3742965471951653, 0.7743097525771262, 0.3742965471951653, 0.3742965471951653, 0.3742965471951653]\n",
      "all_sum before preprocessing is: [1.920537851634658, 1.920537851634658, 1.9263585572096593, 1.920537851634658, 1.9263585572096593, 1.9313134332753732, 1.9313134332753732, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.9263585572096593, 1.920537851634658, 1.9263585572096593, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.301049518925077, 1.9313134332753732, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.301049518925077, 1.9313134332753732, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.301049518925077, 1.301049518925077, 1.9313134332753732, 1.920537851634658, 1.920537851634658, 1.920537851634658, 1.920537851634658]\n",
      "all_sum after preprocessing is: [ 0.2848712   0.2848712   0.31940461  0.2848712   0.31940461  0.34880118\n",
      "  0.34880118  0.2848712   0.2848712   0.2848712   0.2848712   0.2848712\n",
      "  0.2848712   0.2848712   0.2848712   0.2848712   0.2848712   0.31940461\n",
      "  0.2848712   0.31940461  0.2848712   0.2848712   0.2848712   0.2848712\n",
      "  0.2848712  -3.39046466  0.34880118  0.2848712   0.2848712   0.2848712\n",
      "  0.2848712   0.2848712   0.2848712   0.2848712   0.2848712   0.2848712\n",
      " -3.39046466  0.34880118  0.2848712   0.2848712   0.2848712   0.2848712\n",
      "  0.2848712  -3.39046466 -3.39046466  0.34880118  0.2848712   0.2848712\n",
      "  0.2848712   0.2848712 ]\n",
      "P is: [0.5707400557592899, 0.5707400557592899, 0.5791791445375865, 0.5707400557592899, 0.5791791445375865, 0.5863268389659527, 0.5863268389659527, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5791791445375865, 0.5707400557592899, 0.5791791445375865, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.03259480044531601, 0.5863268389659527, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.03259480044531601, 0.5863268389659527, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.03259480044531601, 0.03259480044531601, 0.5863268389659527, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899, 0.5707400557592899]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.949\n",
      "(*) epoch 2, cost 1.683\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.134\n",
      "(*) epoch 2, cost 1.039\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.8710260464908615, 3.8911125682529053, 4.1678122496685726, 2.9529982781845057, 4.1678122496685726, 4.1678122496685726, 2.9529982781845057, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 3.8911125682529053, 4.1678122496685726, 2.9529982781845057, 7.147725727906529, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 6.8710260464908615, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 6.8710260464908615, 4.1678122496685726, 4.1678122496685726, 3.8911125682529053, 3.8911125682529053, 4.1678122496685726, 4.1678122496685726, 3.8911125682529053, 4.1678122496685726, 4.1678122496685726, 7.147725727906529, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 3.8911125682529053, 4.1678122496685726, 4.1678122496685726, 4.1678122496685726, 7.147725727906529, 7.147725727906529, 4.1678122496685726, 4.1678122496685726, 7.147725727906529, 4.1678122496685726, 3.8911125682529053]\n",
      "all_sum after preprocessing is: [ 2.06183975 -0.54750233 -0.30521203 -1.36895608 -0.30521203 -0.30521203\n",
      " -1.36895608 -0.30521203 -0.30521203 -0.30521203 -0.30521203 -0.54750233\n",
      " -0.30521203 -1.36895608  2.30413005 -0.30521203 -0.30521203 -0.30521203\n",
      "  2.06183975 -0.30521203 -0.30521203 -0.30521203 -0.30521203  2.06183975\n",
      " -0.30521203 -0.30521203 -0.54750233 -0.54750233 -0.30521203 -0.30521203\n",
      " -0.54750233 -0.30521203 -0.30521203  2.30413005 -0.30521203 -0.30521203\n",
      " -0.30521203 -0.30521203 -0.30521203 -0.54750233 -0.30521203 -0.30521203\n",
      " -0.30521203  2.30413005  2.30413005 -0.30521203 -0.30521203  2.30413005\n",
      " -0.30521203 -0.54750233]\n",
      "P is: [0.8871385041235327, 0.3664440818983511, 0.42428385600013757, 0.20278856054543637, 0.42428385600013757, 0.42428385600013757, 0.20278856054543637, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.3664440818983511, 0.42428385600013757, 0.20278856054543637, 0.9092185107797107, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.8871385041235327, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.8871385041235327, 0.42428385600013757, 0.42428385600013757, 0.3664440818983511, 0.3664440818983511, 0.42428385600013757, 0.42428385600013757, 0.3664440818983511, 0.42428385600013757, 0.42428385600013757, 0.9092185107797107, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.3664440818983511, 0.42428385600013757, 0.42428385600013757, 0.42428385600013757, 0.9092185107797107, 0.9092185107797107, 0.42428385600013757, 0.42428385600013757, 0.9092185107797107, 0.42428385600013757, 0.3664440818983511]\n",
      "all_sum before preprocessing is: [2.019500759219002, 3.086541136249843, 3.086541136249843, 1.9653557999777969, 2.798782435342061, 2.019500759219002, 2.019500759219002, 1.1860741238547376, 2.2531145008855784, 2.019500759219002, 3.086541136249843, 1.1860741238547376, 3.086541136249843, 2.019500759219002, 2.019500759219002, 2.019500759219002, 2.798782435342061, 3.086541136249843, 2.4451165811562676, 2.2531145008855784, 3.086541136249843, 2.2531145008855784, 2.2531145008855784, 3.086541136249843, 2.390971621915062, 2.019500759219002, 1.1860741238547376, 3.086541136249843, 3.086541136249843, 2.798782435342061, 2.2531145008855784, 2.798782435342061, 2.019500759219002, 1.1860741238547376, 2.2531145008855784, 3.086541136249843, 1.1860741238547376, 1.1860741238547376, 2.019500759219002, 2.019500759219002, 1.7317420583112209, 2.2531145008855784, 2.2531145008855784, 3.086541136249843, 3.5121569581871084, 3.086541136249843, 2.798782435342061, 2.2531145008855784, 1.1860741238547376, 2.798782435342061]\n",
      "all_sum after preprocessing is: [-0.49189752  1.18004467  1.18004467 -0.57673709  0.72915647 -0.49189752\n",
      " -0.49189752 -1.79779109 -0.12584889 -0.49189752  1.18004467 -1.79779109\n",
      "  1.18004467 -0.49189752 -0.49189752 -0.49189752  0.72915647  1.18004467\n",
      "  0.17499856 -0.12584889  1.18004467 -0.12584889 -0.12584889  1.18004467\n",
      "  0.090159   -0.49189752 -1.79779109  1.18004467  1.18004467  0.72915647\n",
      " -0.12584889  0.72915647 -0.49189752 -1.79779109 -0.12584889  1.18004467\n",
      " -1.79779109 -1.79779109 -0.49189752 -0.49189752 -0.94278572 -0.12584889\n",
      " -0.12584889  1.18004467  1.84694076  1.18004467  0.72915647 -0.12584889\n",
      " -1.79779109  0.72915647]\n",
      "P is: [0.37944666127685683, 0.7649558358577281, 0.7649558358577281, 0.3596837341719103, 0.6746201389961292, 0.37944666127685683, 0.37944666127685683, 0.14212016709614902, 0.4685792363837276, 0.37944666127685683, 0.7649558358577281, 0.14212016709614902, 0.7649558358577281, 0.37944666127685683, 0.37944666127685683, 0.37944666127685683, 0.6746201389961292, 0.7649558358577281, 0.5436383305889911, 0.4685792363837276, 0.7649558358577281, 0.4685792363837276, 0.4685792363837276, 0.7649558358577281, 0.5225244934686677, 0.37944666127685683, 0.14212016709614902, 0.7649558358577281, 0.7649558358577281, 0.6746201389961292, 0.4685792363837276, 0.6746201389961292, 0.37944666127685683, 0.14212016709614902, 0.4685792363837276, 0.7649558358577281, 0.14212016709614902, 0.14212016709614902, 0.37944666127685683, 0.37944666127685683, 0.28033798279863176, 0.4685792363837276, 0.4685792363837276, 0.7649558358577281, 0.8637675128413045, 0.7649558358577281, 0.6746201389961292, 0.4685792363837276, 0.14212016709614902, 0.6746201389961292]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.733\n",
      "(*) epoch 2, cost 2.429\n",
      "(*) epoch 3, cost 1.966\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.874\n",
      "(*) epoch 2, cost 4.361\n",
      "(*) epoch 3, cost 2.877\n",
      "(*) epoch 4, cost 2.383\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8388922579774296, 1.8388922579774296, 1.311879903104161, 1.311879903104161, 1.611418367713973, 1.611418367713973, 1.8388922579774296, 1.311879903104161, 1.311879903104161, 1.611418367713973, 1.311879903104161, 1.8388922579774296, 1.8388922579774296, 1.8388922579774296, 1.311879903104161, 2.1384307225872417, 1.311879903104161, 1.311879903104161, 1.311879903104161, 1.8388922579774296, 1.311879903104161, 1.311879903104161, 1.311879903104161, 1.311879903104161, 1.311879903104161, 1.311879903104161, 1.311879903104161, 1.6597452710420426, 1.8388922579774296, 1.6597452710420426, 1.311879903104161, 1.8388922579774296, 1.311879903104161, 1.8388922579774296, 1.311879903104161, 1.311879903104161, 1.611418367713973, 1.611418367713973, 1.6597452710420426, 1.6597452710420426, 1.6597452710420426, 2.186757625915311, 2.335250647900404, 2.1384307225872417, 1.8388922579774296, 1.8388922579774296, 1.611418367713973, 1.311879903104161, 2.4862960905251232, 1.311879903104161]\n",
      "all_sum after preprocessing is: [ 0.76101371  0.76101371 -0.94358789 -0.94358789  0.02525798  0.02525798\n",
      "  0.76101371 -0.94358789 -0.94358789  0.02525798 -0.94358789  0.76101371\n",
      "  0.76101371  0.76101371 -0.94358789  1.72985958 -0.94358789 -0.94358789\n",
      " -0.94358789  0.76101371 -0.94358789 -0.94358789 -0.94358789 -0.94358789\n",
      " -0.94358789 -0.94358789 -0.94358789  0.18156953  0.76101371  0.18156953\n",
      " -0.94358789  0.76101371 -0.94358789  0.76101371 -0.94358789 -0.94358789\n",
      "  0.02525798  0.02525798  0.18156953  0.18156953  0.18156953  1.88617112\n",
      "  2.36646621  1.72985958  0.76101371  0.76101371  0.02525798 -0.94358789\n",
      "  2.855017   -0.94358789]\n",
      "P is: [0.6815737799499925, 0.6815737799499925, 0.280176176141104, 0.280176176141104, 0.506314160336056, 0.506314160336056, 0.6815737799499925, 0.280176176141104, 0.280176176141104, 0.506314160336056, 0.280176176141104, 0.6815737799499925, 0.6815737799499925, 0.6815737799499925, 0.280176176141104, 0.8493944578155238, 0.280176176141104, 0.280176176141104, 0.280176176141104, 0.6815737799499925, 0.280176176141104, 0.280176176141104, 0.280176176141104, 0.280176176141104, 0.280176176141104, 0.280176176141104, 0.280176176141104, 0.545268086405962, 0.6815737799499925, 0.545268086405962, 0.280176176141104, 0.6815737799499925, 0.280176176141104, 0.6815737799499925, 0.280176176141104, 0.280176176141104, 0.506314160336056, 0.506314160336056, 0.545268086405962, 0.545268086405962, 0.545268086405962, 0.8683183479061847, 0.9142341809217555, 0.8493944578155238, 0.6815737799499925, 0.6815737799499925, 0.506314160336056, 0.280176176141104, 0.9455774390261249, 0.280176176141104]\n",
      "all_sum before preprocessing is: [2.5030163058909936, 3.12997637892546, 4.149934413143345, 2.862613186542676, 3.7903375324916624, 1.457601486692953, 2.8050357309658365, 3.7903375324916624, 3.77270121436349, 2.862613186542676, 2.208266782340028, 3.12997637892546, 3.940094546744697, 1.7249646790757374, 4.810295566709547, 2.7449227132936223, 3.12997637892546, 3.12997637892546, 4.149934413143345, 1.457601486692953, 2.7449227132936223, 2.5030163058909936, 2.862613186542676, 3.405283866859824, 4.149934413143345, 3.7903375324916624, 1.7249646790757374, 4.207457739127481, 4.149934413143345, 3.5229743401088784, 4.149934413143345, 4.633236516407636, 2.7449227132936223, 1.8426551523247912, 2.1179626402591554, 4.149934413143345, 1.8426551523247912, 2.7449227132936223, 3.405283866859824, 4.149934413143345, 1.457601486692953, 3.5229743401088784, 4.149934413143345, 3.228224816557913, 4.149934413143345, 4.810295566709547, 1.0980046060412707, 1.7249646790757374, 5.227415773345366, 1.6170242188666926]\n",
      "all_sum after preprocessing is: [-0.62441665 -0.01706152  0.97100258 -0.27606431  0.62265024 -1.6371415\n",
      " -0.33184133  0.62265024  0.6055654  -0.27606431 -0.9099494  -0.01706152\n",
      "  0.76772437 -1.37813872  1.61071433 -0.39007462 -0.01706152 -0.01706152\n",
      "  0.97100258 -1.6371415  -0.39007462 -0.62441665 -0.27606431  0.24963714\n",
      "  0.97100258  0.62265024 -1.37813872  1.02672716  0.97100258  0.36364745\n",
      "  0.97100258  1.43919189 -0.39007462 -1.26412841 -0.99742975  0.97100258\n",
      " -1.26412841 -0.39007462  0.24963714  0.97100258 -1.6371415   0.36364745\n",
      "  0.97100258  0.0781147   0.97100258  1.61071433 -1.98549384 -1.37813872\n",
      "  2.01479126 -1.4827039 ]\n",
      "P is: [0.3487776209991734, 0.4957347224033406, 0.7253192872036021, 0.4314189258919144, 0.6508210629575157, 0.16285439390646053, 0.41779266752030303, 0.6508210629575157, 0.646928547893977, 0.4314189258919144, 0.28701019167016617, 0.4957347224033406, 0.6830284238200313, 0.20130809598265975, 0.8335105387814995, 0.40369933769634, 0.4957347224033406, 0.4957347224033406, 0.7253192872036021, 0.16285439390646053, 0.40369933769634, 0.3487776209991734, 0.4314189258919144, 0.5620871866211359, 0.7253192872036021, 0.6508210629575157, 0.20130809598265975, 0.7362808948569598, 0.7253192872036021, 0.5899230911277963, 0.7253192872036021, 0.8083294804510724, 0.40369933769634, 0.22026402827764108, 0.2694470641517284, 0.7253192872036021, 0.22026402827764108, 0.40369933769634, 0.5620871866211359, 0.7253192872036021, 0.16285439390646053, 0.5899230911277963, 0.7253192872036021, 0.5195187507466454, 0.7253192872036021, 0.8335105387814995, 0.12073440819782343, 0.20130809598265975, 0.8823413387272164, 0.18501935891396026]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.302\n",
      "(*) epoch 2, cost 2.327\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.479\n",
      "(*) epoch 2, cost 3.135\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.4245577306657893, 5.73804539056515, 5.27586884514397, 3.4245577306657893, 3.4245577306657893, 5.086100074080345, 3.4245577306657893, 3.886734276086969, 5.935507550598334, 5.27586884514397, 6.207915324955889, 3.886734276086969, 5.73804539056515, 3.4245577306657893, 5.73804539056515, 6.397684096019514, 5.548276619501524, 6.609734917559143, 5.27586884514397, 3.4245577306657893, 5.73804539056515, 5.9727259635278545, 5.745738779534709, 4.601683186252909, 5.27586884514397, 4.084196436120154, 3.886734276086969, 4.546372981541333, 5.294890534145926, 3.2347889596021644, 3.4245577306657893, 5.935507550598334, 7.149851419114974, 5.27586884514397, 3.4617761435953094, 4.171818892474801, 3.886734276086969, 5.548276619501524, 5.99081775530991, 3.886734276086969, 5.73804539056515, 3.886734276086969, 5.27586884514397, 5.73804539056515, 5.261321891707273, 3.886734276086969, 3.4245577306657893, 5.560953461531803, 3.886734276086969, 3.2347889596021644]\n",
      "all_sum after preprocessing is: [-1.28012392  0.86821082  0.43902767 -1.28012392 -1.28012392  0.26280592\n",
      " -1.28012392 -0.85094077  1.05157675  0.43902767  1.30453816 -0.85094077\n",
      "  0.86821082 -1.28012392  0.86821082  1.48075991  0.69198907  1.67767306\n",
      "  0.43902767 -1.28012392  0.86821082  1.08613825  0.875355   -0.18702991\n",
      "  0.43902767 -0.66757484 -0.85094077 -0.23839168  0.45669145 -1.45634567\n",
      " -1.28012392  1.05157675  2.17923227  0.43902767 -1.24556242 -0.58620749\n",
      " -0.85094077  0.69198907  1.10293853 -0.85094077  0.86821082 -0.85094077\n",
      "  0.43902767  0.86821082  0.42551918 -0.85094077 -1.28012392  0.70376095\n",
      " -0.85094077 -1.45634567]\n",
      "P is: [0.21752912977910377, 0.7043732705987608, 0.6080273187553856, 0.21752912977910377, 0.21752912977910377, 0.5653259226758798, 0.21752912977910377, 0.2992355468570992, 0.7410775637861333, 0.6080273187553856, 0.7865977564046748, 0.2992355468570992, 0.7043732705987608, 0.21752912977910377, 0.7043732705987608, 0.8146873324933035, 0.6664092591715008, 0.8425961596554913, 0.6080273187553856, 0.21752912977910377, 0.7043732705987608, 0.7476538323878252, 0.7058587393986407, 0.45337834646829167, 0.6080273187553856, 0.33904008753111814, 0.2992355468570992, 0.44068273275446135, 0.6122290042838762, 0.18902688129914758, 0.21752912977910377, 0.7410775637861333, 0.8983689980340585, 0.6080273187553856, 0.22346925014316782, 0.3575055055986739, 0.2992355468570992, 0.6664092591715008, 0.7508102921024596, 0.2992355468570992, 0.7043732705987608, 0.2992355468570992, 0.6080273187553856, 0.7043732705987608, 0.6048031830379075, 0.2992355468570992, 0.21752912977910377, 0.6690210952659886, 0.2992355468570992, 0.18902688129914758]\n",
      "all_sum before preprocessing is: [1.7686519731986396, 1.7686519731986396, 0.9307663636029221, 0.9307663636029221, 1.7686519731986396, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 1.7686519731986396, 3.5276399454251304, 0.9307663636029221, 0.9307663636029221, 1.7686519731986396, 3.5276399454251304, 0.9307663636029221, 3.5276399454251304, 1.7686519731986396, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 1.7686519731986396, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 1.7686519731986396, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 3.5276399454251304, 0.9307663636029221, 4.365525555020848, 3.5276399454251304, 0.9592018869007944, 0.9307663636029221, 0.9307663636029221, 1.7686519731986396, 0.9307663636029221, 3.5276399454251304, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221, 0.9307663636029221]\n",
      "all_sum after preprocessing is: [ 0.32475302  0.32475302 -0.56396644 -0.56396644  0.32475302 -0.56396644\n",
      " -0.56396644 -0.56396644  0.32475302  2.1904574  -0.56396644 -0.56396644\n",
      "  0.32475302  2.1904574  -0.56396644  2.1904574   0.32475302 -0.56396644\n",
      " -0.56396644 -0.56396644  0.32475302 -0.56396644 -0.56396644 -0.56396644\n",
      "  0.32475302 -0.56396644 -0.56396644 -0.56396644 -0.56396644  2.1904574\n",
      " -0.56396644  3.07917686  2.1904574  -0.53380576 -0.56396644 -0.56396644\n",
      "  0.32475302 -0.56396644  2.1904574  -0.56396644 -0.56396644 -0.56396644\n",
      " -0.56396644 -0.56396644 -0.56396644 -0.56396644 -0.56396644 -0.56396644\n",
      " -0.56396644 -0.56396644]\n",
      "P is: [0.5804821608105364, 0.5804821608105364, 0.3626301987555972, 0.3626301987555972, 0.5804821608105364, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.5804821608105364, 0.8993893028925892, 0.3626301987555972, 0.3626301987555972, 0.5804821608105364, 0.8993893028925892, 0.3626301987555972, 0.8993893028925892, 0.5804821608105364, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.5804821608105364, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.5804821608105364, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.8993893028925892, 0.3626301987555972, 0.9560255922283891, 0.8993893028925892, 0.3696296931680503, 0.3626301987555972, 0.3626301987555972, 0.5804821608105364, 0.3626301987555972, 0.8993893028925892, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972, 0.3626301987555972]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.882\n",
      "(*) epoch 2, cost 4.293\n",
      "(*) epoch 3, cost 3.436\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.077\n",
      "(*) epoch 2, cost 1.598\n",
      "(*) epoch 3, cost 1.006\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.2526607050649163, 2.3456685146878997, 0.2526607050649163, 0.2526607050649163, 0.4143543785163498, 2.3456685146878997, 2.1839748412364663, 0.2526607050649163, 0.4143543785163498, 2.617522195799717, 0.2526607050649163, 2.1839748412364663, 0.686208059628167, 1.776967018419567, 2.3456685146878997, 2.617522195799717, 2.1839748412364663, 0.2526607050649163, 2.4558285223482836, 0.2526607050649163, 2.3456685146878997, 0.2526607050649163, 0.2526607050649163, 0.686208059628167, 0.4143543785163498, 0.2526607050649163, 2.617522195799717, 2.4558285223482836, 0.686208059628167, 0.4143543785163498, 2.617522195799717, 0.4143543785163498, 2.3456685146878997, 0.4143543785163498, 2.1839748412364663, 0.2526607050649163, 2.3456685146878997, 2.3456685146878997, 2.3456685146878997, 2.617522195799717, 2.4558285223482836, 0.4143543785163498, 0.686208059628167, 2.617522195799717, 0.686208059628167, 0.2526607050649163, 0.4143543785163498, 0.5245143861767334, 2.1839748412364663, 2.4558285223482836]\n",
      "all_sum after preprocessing is: [-1.08821715  0.99525371 -1.08821715 -1.08821715 -0.92726024  0.99525371\n",
      "  0.8342968  -1.08821715 -0.92726024  1.26586867 -1.08821715  0.8342968\n",
      " -0.65664528  0.42914355  0.99525371  1.26586867  0.8342968  -1.08821715\n",
      "  1.10491176 -1.08821715  0.99525371 -1.08821715 -1.08821715 -0.65664528\n",
      " -0.92726024 -1.08821715  1.26586867  1.10491176 -0.65664528 -0.92726024\n",
      "  1.26586867 -0.92726024  0.99525371 -0.92726024  0.8342968  -1.08821715\n",
      "  0.99525371  0.99525371  0.99525371  1.26586867  1.10491176 -0.92726024\n",
      " -0.65664528  1.26586867 -0.65664528 -1.08821715 -0.92726024 -0.81760219\n",
      "  0.8342968   1.10491176]\n",
      "P is: [0.2519541502320797, 0.7301243782246178, 0.2519541502320797, 0.2519541502320797, 0.28348088247905867, 0.7301243782246178, 0.6972626992845433, 0.2519541502320797, 0.28348088247905867, 0.7800347114879376, 0.2519541502320797, 0.6972626992845433, 0.34149360419124286, 0.6056691364246674, 0.7301243782246178, 0.7800347114879376, 0.6972626992845433, 0.2519541502320797, 0.7511792902755705, 0.2519541502320797, 0.7301243782246178, 0.2519541502320797, 0.2519541502320797, 0.34149360419124286, 0.28348088247905867, 0.2519541502320797, 0.7800347114879376, 0.7511792902755705, 0.34149360419124286, 0.28348088247905867, 0.7800347114879376, 0.28348088247905867, 0.7301243782246178, 0.28348088247905867, 0.6972626992845433, 0.2519541502320797, 0.7301243782246178, 0.7301243782246178, 0.7301243782246178, 0.7800347114879376, 0.7511792902755705, 0.28348088247905867, 0.34149360419124286, 0.7800347114879376, 0.34149360419124286, 0.2519541502320797, 0.28348088247905867, 0.3062728859748818, 0.6972626992845433, 0.7511792902755705]\n",
      "all_sum before preprocessing is: [5.4742458072822116, 5.4742458072822116, 6.135423095339621, 5.4742458072822116, 6.135423095339621, 4.679204594445984, 4.679204594445984, 4.679204594445984, 6.1577857446316555, 4.679204594445984, 5.4742458072822116, 6.135423095339621, 5.4742458072822116, 5.4742458072822116, 6.135423095339621, 6.135423095339621, 2.2059058741468234, 4.018027306388573, 5.4742458072822116, 5.4742458072822116, 5.4742458072822116, 6.135423095339621, 4.679204594445984, 6.135423095339621, 4.679204594445984, 4.018027306388573, 5.4742458072822116, 5.4742458072822116, 6.135423095339621, 6.135423095339621, 5.4742458072822116, 6.135423095339621, 5.4742458072822116, 5.120810423138138, 4.018027306388573, 3.6645919222445005, 5.4742458072822116, 5.4742458072822116, 5.4742458072822116, 4.679204594445984, 4.018027306388573, 6.6937038700972105, 0.7496873732531861, 4.679204594445984, 2.2059058741468234, 6.952826957467884, 5.120810423138138, 2.2059058741468234, 6.135423095339621, 4.679204594445984]\n",
      "all_sum after preprocessing is: [ 0.31953639  0.31953639  0.86483935  0.31953639  0.86483935 -0.33617024\n",
      " -0.33617024 -0.33617024  0.88328284 -0.33617024  0.31953639  0.86483935\n",
      "  0.31953639  0.31953639  0.86483935  0.86483935 -2.37601213 -0.88147321\n",
      "  0.31953639  0.31953639  0.31953639  0.86483935 -0.33617024  0.86483935\n",
      " -0.33617024 -0.88147321  0.31953639  0.31953639  0.86483935  0.86483935\n",
      "  0.31953639  0.86483935  0.31953639  0.02804216 -0.88147321 -1.17296743\n",
      "  0.31953639  0.31953639  0.31953639 -0.33617024 -0.88147321  1.32527888\n",
      " -3.57702172 -0.33617024 -2.37601213  1.53898947  0.02804216 -2.37601213\n",
      "  0.86483935 -0.33617024]\n",
      "P is: [0.5792112616896755, 0.5792112616896755, 0.7036707407823549, 0.5792112616896755, 0.7036707407823549, 0.4167400698144819, 0.4167400698144819, 0.4167400698144819, 0.707502044857019, 0.4167400698144819, 0.5792112616896755, 0.7036707407823549, 0.5792112616896755, 0.5792112616896755, 0.7036707407823549, 0.7036707407823549, 0.08502027674471864, 0.2928725871712731, 0.5792112616896755, 0.5792112616896755, 0.5792112616896755, 0.7036707407823549, 0.4167400698144819, 0.7036707407823549, 0.4167400698144819, 0.2928725871712731, 0.5792112616896755, 0.5792112616896755, 0.7036707407823549, 0.7036707407823549, 0.5792112616896755, 0.7036707407823549, 0.5792112616896755, 0.507010080236445, 0.2928725871712731, 0.23631902536066723, 0.5792112616896755, 0.5792112616896755, 0.5792112616896755, 0.4167400698144819, 0.2928725871712731, 0.7900586344590486, 0.027198407616470608, 0.4167400698144819, 0.08502027674471864, 0.823317776268529, 0.507010080236445, 0.08502027674471864, 0.7036707407823549, 0.4167400698144819]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.611\n",
      "(*) epoch 2, cost 1.542\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.949\n",
      "(*) epoch 2, cost 2.321\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.6575746479722415, 1.1523227002209804, 0.19055736312323743, 0.19055736312323743, 1.1523227002209804, 1.2691965047633467, 1.1523227002209804, 0.19055736312323743, 0.19055736312323743, 0.19055736312323743, 1.1523227002209804, 1.1523227002209804, 0.19055736312323743, 1.1523227002209804, 1.1523227002209804, 1.2691965047633467, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 1.6575746479722415, 0.19055736312323743, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 0.19055736312323743, 1.1523227002209804, 0.19055736312323743, 0.19055736312323743, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 0.19055736312323743, 1.1523227002209804, 1.6575746479722415, 1.1523227002209804, 0.19055736312323743, 1.6575746479722415, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 1.2691965047633467, 1.1523227002209804, 1.1523227002209804, 1.1523227002209804, 1.2691965047633467, 1.1523227002209804]\n",
      "all_sum after preprocessing is: [ 1.49503489  0.39440373 -1.70068743 -1.70068743  0.39440373  0.64899939\n",
      "  0.39440373 -1.70068743 -1.70068743 -1.70068743  0.39440373  0.39440373\n",
      " -1.70068743  0.39440373  0.39440373  0.64899939  0.39440373  0.39440373\n",
      "  0.39440373  1.49503489 -1.70068743  0.39440373  0.39440373  0.39440373\n",
      "  0.39440373 -1.70068743  0.39440373 -1.70068743 -1.70068743  0.39440373\n",
      "  0.39440373  0.39440373  0.39440373 -1.70068743  0.39440373  1.49503489\n",
      "  0.39440373 -1.70068743  1.49503489  0.39440373  0.39440373  0.39440373\n",
      "  0.39440373  0.39440373  0.64899939  0.39440373  0.39440373  0.39440373\n",
      "  0.64899939  0.39440373]\n",
      "P is: [0.8168327791596621, 0.5973423577493153, 0.1543755043111031, 0.1543755043111031, 0.5973423577493153, 0.6567849418013224, 0.5973423577493153, 0.1543755043111031, 0.1543755043111031, 0.1543755043111031, 0.5973423577493153, 0.5973423577493153, 0.1543755043111031, 0.5973423577493153, 0.5973423577493153, 0.6567849418013224, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.8168327791596621, 0.1543755043111031, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.1543755043111031, 0.5973423577493153, 0.1543755043111031, 0.1543755043111031, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.1543755043111031, 0.5973423577493153, 0.8168327791596621, 0.5973423577493153, 0.1543755043111031, 0.8168327791596621, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.6567849418013224, 0.5973423577493153, 0.5973423577493153, 0.5973423577493153, 0.6567849418013224, 0.5973423577493153]\n",
      "all_sum before preprocessing is: [2.7036630180274672, 4.516907267140962, 2.7036630180274672, 2.1586578719383094, 3.9719021210518033, 4.65314574445609, 2.839901495342596, 4.516907267140962, 2.294896349253438, 2.839901495342596, 2.1586578719383094, 4.516907267140962, 4.108140598366932, 4.65314574445609, 4.516907267140962, 3.9719021210518033, 4.516907267140962, 4.516907267140962, 4.516907267140962, 2.1586578719383094, 4.516907267140962, 2.7036630180274672, 4.516907267140962, 4.663238483168465, 3.9719021210518033, 2.7036630180274672, 4.108140598366932, 3.9719021210518033, 4.516907267140962, 4.516907267140962, 2.1586578719383094, 3.9719021210518033, 6.089698262933288, 3.9719021210518033, 2.839901495342596, 2.1586578719383094, 2.294896349253438, 3.9719021210518033, 3.9719021210518033, 2.7036630180274672, 4.516907267140962, 2.1586578719383094, 4.516907267140962, 2.1586578719383094, 4.65314574445609, 6.089698262933288, 4.65314574445609, 2.1586578719383094, 4.516907267140962, 4.65314574445609]\n",
      "all_sum after preprocessing is: [-0.97331969  0.72202112 -0.97331969 -1.48288671  0.2124541   0.8494009\n",
      " -0.84593991  0.72202112 -1.35550693 -0.84593991 -1.48288671  0.72202112\n",
      "  0.33983388  0.8494009   0.72202112  0.2124541   0.72202112  0.72202112\n",
      "  0.72202112 -1.48288671  0.72202112 -0.97331969  0.72202112  0.85883738\n",
      "  0.2124541  -0.97331969  0.33983388  0.2124541   0.72202112  0.72202112\n",
      " -1.48288671  0.2124541   2.19254379  0.2124541  -0.84593991 -1.48288671\n",
      " -1.35550693  0.2124541   0.2124541  -0.97331969  0.72202112 -1.48288671\n",
      "  0.72202112 -1.48288671  0.8494009   2.19254379  0.8494009  -1.48288671\n",
      "  0.72202112  0.8494009 ]\n",
      "P is: [0.2742193118485033, 0.673051926741478, 0.2742193118485033, 0.18499179433087065, 0.5529146423755942, 0.7004414528092068, 0.3002852462495314, 0.673051926741478, 0.20497151374083555, 0.3002852462495314, 0.18499179433087065, 0.673051926741478, 0.584150170207554, 0.7004414528092068, 0.673051926741478, 0.5529146423755942, 0.673051926741478, 0.673051926741478, 0.673051926741478, 0.18499179433087065, 0.673051926741478, 0.2742193118485033, 0.673051926741478, 0.7024176915257848, 0.5529146423755942, 0.2742193118485033, 0.584150170207554, 0.5529146423755942, 0.673051926741478, 0.673051926741478, 0.18499179433087065, 0.5529146423755942, 0.8995779396592191, 0.5529146423755942, 0.3002852462495314, 0.18499179433087065, 0.20497151374083555, 0.5529146423755942, 0.5529146423755942, 0.2742193118485033, 0.673051926741478, 0.18499179433087065, 0.673051926741478, 0.18499179433087065, 0.7004414528092068, 0.8995779396592191, 0.7004414528092068, 0.18499179433087065, 0.673051926741478, 0.7004414528092068]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.918\n",
      "(*) epoch 2, cost 2.574\n",
      "(*) epoch 3, cost 1.814\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.839\n",
      "(*) epoch 2, cost 1.759\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8631639940088844, 2.259188183303987, 3.347204827497234, 2.259188183303987, 1.8839800025001234, 1.2090993352168362, 2.259188183303987, 2.2971159794100835, 1.2090993352168362, 1.2090993352168362, 1.8631639940088844, 2.3179319879013223, 1.2090993352168362, 1.2090993352168362, 1.2090993352168362, 2.259188183303987, 2.2971159794100835, 1.2090993352168362, 1.2090993352168362, 1.2090993352168362, 1.8631639940088844, 2.9132528420960355, 1.7374973905289401, 2.9132528420960355, 1.2090993352168362, 1.2299153437080754, 2.259188183303987, 3.347204827497234, 1.2090993352168362, 2.259188183303987, 2.259188183303987, 2.259188183303987, 2.9132528420960355, 2.259188183303987, 1.2090993352168362, 2.9132528420960355, 2.9132528420960355, 1.2090993352168362, 2.259188183303987, 2.280004191795226, 2.951180638202132, 1.2090993352168362, 4.001269486289282, 1.2299153437080754, 1.2090993352168362, 3.347204827497234, 1.2090993352168362, 2.259188183303987, 2.2971159794100835, 1.5758533772188583]\n",
      "all_sum after preprocessing is: [-0.19883161  0.33794459  1.81265613  0.33794459 -0.17061733 -1.08535913\n",
      "  0.33794459  0.3893524  -1.08535913 -1.08535913 -0.19883161  0.41756669\n",
      " -1.08535913 -1.08535913 -1.08535913  0.33794459  0.3893524  -1.08535913\n",
      " -1.08535913 -1.08535913 -0.19883161  1.22447211 -0.36916172  1.22447211\n",
      " -1.08535913 -1.05714485  0.33794459  1.81265613 -1.08535913  0.33794459\n",
      "  0.33794459  0.33794459  1.22447211  0.33794459 -1.08535913  1.22447211\n",
      "  1.22447211 -1.08535913  0.33794459  0.36615887  1.27587993 -1.08535913\n",
      "  2.69918365 -1.05714485 -1.08535913  1.81265613 -1.08535913  0.33794459\n",
      "  0.3893524  -0.58825606]\n",
      "P is: [0.4504552150263324, 0.5836911529087193, 0.8596825848391856, 0.5836911529087193, 0.457448840458491, 0.25249319100366774, 0.5836911529087193, 0.5961267941716385, 0.25249319100366774, 0.25249319100366774, 0.4504552150263324, 0.6029008328491758, 0.25249319100366774, 0.25249319100366774, 0.25249319100366774, 0.5836911529087193, 0.5961267941716385, 0.25249319100366774, 0.25249319100366774, 0.25249319100366774, 0.4504552150263324, 0.7728496000676491, 0.4087435957938271, 0.7728496000676491, 0.25249319100366774, 0.2578554553964587, 0.5836911529087193, 0.8596825848391856, 0.25249319100366774, 0.5836911529087193, 0.5836911529087193, 0.5836911529087193, 0.7728496000676491, 0.5836911529087193, 0.25249319100366774, 0.7728496000676491, 0.7728496000676491, 0.25249319100366774, 0.5836911529087193, 0.5905305012039752, 0.7817476324688002, 0.25249319100366774, 0.9369784556351919, 0.2578554553964587, 0.25249319100366774, 0.8596825848391856, 0.25249319100366774, 0.5836911529087193, 0.5961267941716385, 0.35703509518541476]\n",
      "all_sum before preprocessing is: [4.720164919902468, 6.487866446611375, 4.720164919902468, 4.720164919902468, 3.9964341146742015, 4.075455546367473, 4.720164919902468, 3.351724741139207, 3.351724741139207, 3.9964341146742015, 4.588354187669229, 3.351724741139207, 5.95679436643249, 3.9964341146742015, 4.720164919902468, 6.566887878304645, 3.9964341146742015, 6.566887878304645, 3.351724741139207, 3.351724741139207, 4.075455546367473, 6.487866446611375, 6.487866446611375, 3.9964341146742015, 3.9964341146742015, 6.487866446611375, 4.720164919902468, 3.351724741139207, 3.351724741139207, 2.8206526609603224, 6.20847443691065, 7.21159725183964, 3.351724741139207, 3.351724741139207, 5.84315707307638, 7.21159725183964, 6.566887878304645, 3.351724741139207, 3.9964341146742015, 6.566887878304645, 3.351724741139207, 3.351724741139207, 6.487866446611375, 7.21159725183964, 7.909171569464275, 3.9964341146742015, 3.351724741139207, 3.351724741139207, 5.84315707307638, 3.9964341146742015]\n",
      "all_sum after preprocessing is: [-0.04063977  1.21215677 -0.04063977 -0.04063977 -0.55355863 -0.49755496\n",
      " -0.04063977 -1.01047381 -1.01047381 -0.55355863 -0.13405601 -1.01047381\n",
      "  0.83577803 -0.55355863 -0.04063977  1.26816044 -0.55355863  1.26816044\n",
      " -1.01047381 -1.01047381 -0.49755496  1.21215677  1.21215677 -0.55355863\n",
      " -0.55355863  1.21215677 -0.04063977 -1.01047381 -1.01047381 -1.38685255\n",
      "  1.01414747  1.72507563 -1.01047381 -1.01047381  0.75524158  1.72507563\n",
      "  1.26816044 -1.01047381 -0.55355863  1.26816044 -1.01047381 -1.01047381\n",
      "  1.21215677  1.72507563  2.21945699 -0.55355863 -1.01047381 -1.01047381\n",
      "  0.75524158 -0.55355863]\n",
      "P is: [0.4898414555296702, 0.7706803419823588, 0.4898414555296702, 0.4898414555296702, 0.3650391748312785, 0.3781154349286057, 0.4898414555296702, 0.26688713477710796, 0.26688713477710796, 0.3650391748312785, 0.46653609756312786, 0.26688713477710796, 0.697575276832237, 0.3650391748312785, 0.4898414555296702, 0.7804276830902294, 0.3650391748312785, 0.7804276830902294, 0.26688713477710796, 0.26688713477710796, 0.3781154349286057, 0.7706803419823588, 0.7706803419823588, 0.3650391748312785, 0.3650391748312785, 0.7706803419823588, 0.4898414555296702, 0.26688713477710796, 0.26688713477710796, 0.19991070487324428, 0.7338310306612549, 0.8487814545731927, 0.26688713477710796, 0.26688713477710796, 0.6803197395965238, 0.8487814545731927, 0.7804276830902294, 0.26688713477710796, 0.3650391748312785, 0.7804276830902294, 0.26688713477710796, 0.26688713477710796, 0.7706803419823588, 0.8487814545731927, 0.9019831989692961, 0.3650391748312785, 0.26688713477710796, 0.26688713477710796, 0.6803197395965238, 0.3650391748312785]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.325\n",
      "(*) epoch 2, cost 3.488\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.729\n",
      "(*) epoch 2, cost 4.674\n",
      "(*) epoch 3, cost 3.477\n",
      "(*) epoch 4, cost 3.094\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.8693317087162895, 4.9207228453360985, 3.396836635405398, 2.8693317087162895, 3.396836635405398, 3.396836635405398, 3.396836635405398, 4.311556609181469, 3.396836635405398, 2.8693317087162895, 2.8693317087162895, 3.7840516824923602, 2.8693317087162895, 3.396836635405398, 3.396836635405398, 4.311556609181469, 4.3932179186469895, 4.9207228453360985, 3.396836635405398, 4.9207228453360985, 2.8693317087162895, 3.396836635405398, 3.396836635405398, 2.8693317087162895, 2.8693317087162895, 2.8693317087162895, 2.8693317087162895, 3.396836635405398, 2.8693317087162895, 2.8693317087162895, 3.396836635405398, 3.396836635405398, 3.396836635405398, 3.396836635405398, 3.396836635405398, 3.396836635405398, 3.396836635405398, 3.396836635405398, 3.396836635405398, 3.4003401714764006, 3.396836635405398, 3.396836635405398, 2.8693317087162895, 5.83544281911217, 2.8693317087162895, 2.8693317087162895, 3.396836635405398, 2.8693317087162895, 3.396836635405398, 3.396836635405398]\n",
      "all_sum after preprocessing is: [-0.88794479  2.34606537 -0.05633533 -0.88794479 -0.05633533 -0.05633533\n",
      " -0.05633533  1.38571716 -0.05633533 -0.88794479 -0.88794479  0.55410769\n",
      " -0.88794479 -0.05633533 -0.05633533  1.38571716  1.5144559   2.34606537\n",
      " -0.05633533  2.34606537 -0.88794479 -0.05633533 -0.05633533 -0.88794479\n",
      " -0.88794479 -0.88794479 -0.88794479 -0.05633533 -0.88794479 -0.88794479\n",
      " -0.05633533 -0.05633533 -0.05633533 -0.05633533 -0.05633533 -0.05633533\n",
      " -0.05633533 -0.05633533 -0.05633533 -0.05081201 -0.05633533 -0.05633533\n",
      " -0.88794479  3.78811785 -0.88794479 -0.88794479 -0.05633533 -0.88794479\n",
      " -0.05633533 -0.05633533]\n",
      "P is: [0.2915341317524662, 0.9126209734161375, 0.48591989217129533, 0.2915341317524662, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.7999076319881693, 0.48591989217129533, 0.2915341317524662, 0.2915341317524662, 0.6350880808978638, 0.2915341317524662, 0.48591989217129533, 0.48591989217129533, 0.7999076319881693, 0.8197206321332672, 0.9126209734161375, 0.48591989217129533, 0.9126209734161375, 0.2915341317524662, 0.48591989217129533, 0.48591989217129533, 0.2915341317524662, 0.2915341317524662, 0.2915341317524662, 0.2915341317524662, 0.48591989217129533, 0.2915341317524662, 0.2915341317524662, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.48591989217129533, 0.4872997287312215, 0.48591989217129533, 0.48591989217129533, 0.2915341317524662, 0.9778629716834422, 0.2915341317524662, 0.2915341317524662, 0.48591989217129533, 0.2915341317524662, 0.48591989217129533, 0.48591989217129533]\n",
      "all_sum before preprocessing is: [5.075044879584688, 5.075044879584688, 6.769070488598608, 4.969933260234356, 5.921279595382595, 5.075044879584688, 6.769070488598608, 5.847099327377013, 5.075044879584688, 5.075044879584688, 5.817724153450369, 4.227253986368675, 6.769070488598608, 5.075044879584688, 4.969933260234356, 4.153073718363092, 6.769070488598608, 5.075044879584688, 7.652358593611411, 7.511749762464289, 3.445891656294201, 3.3052828251470787, 5.075044879584688, 5.921279595382595, 5.075044879584688, 6.769070488598608, 4.153073718363092, 5.075044879584688, 5.075044879584688, 5.817724153450369, 6.769070488598608, 6.769070488598608, 5.075044879584688, 4.895752992228773, 5.731714450601126, 6.769070488598608, 5.075044879584688, 6.769070488598608, 5.817724153450369, 4.227253986368675, 5.731714450601126, 5.075044879584688, 5.075044879584688, 5.075044879584688, 6.769070488598608, 6.663958869248276, 4.227253986368675, 5.075044879584688, 6.769070488598608, 6.769070488598608]\n",
      "all_sum after preprocessing is: [-0.48786284 -0.48786284  1.18096908 -0.59141123  0.34578661 -0.48786284\n",
      "  1.18096908  0.27270955 -0.48786284 -0.48786284  0.24377125 -1.32304531\n",
      "  1.18096908 -0.48786284 -0.59141123 -1.39612236  1.18096908 -0.48786284\n",
      "  2.05112085  1.91260317 -2.09278715 -2.23130484 -0.48786284  0.34578661\n",
      " -0.48786284  1.18096908 -1.39612236 -0.48786284 -0.48786284  0.24377125\n",
      "  1.18096908  1.18096908 -0.48786284 -0.66448828  0.15904069  1.18096908\n",
      " -0.48786284  1.18096908  0.24377125 -1.32304531  0.15904069 -0.48786284\n",
      " -0.48786284 -0.48786284  1.18096908  1.07742069 -1.32304531 -0.48786284\n",
      "  1.18096908  1.18096908]\n",
      "P is: [0.380397158117062, 0.380397158117062, 0.7651220024577434, 0.35631111913831676, 0.585595470384563, 0.380397158117062, 0.7651220024577434, 0.5677579750662972, 0.380397158117062, 0.380397158117062, 0.5606428040942889, 0.21031207933721124, 0.7651220024577434, 0.380397158117062, 0.35631111913831676, 0.1984321548900485, 0.7651220024577434, 0.380397158117062, 0.8860608255012632, 0.8713113176881384, 0.10979985079401271, 0.09697431576579633, 0.380397158117062, 0.585595470384563, 0.380397158117062, 0.7651220024577434, 0.1984321548900485, 0.380397158117062, 0.380397158117062, 0.5606428040942889, 0.7651220024577434, 0.7651220024577434, 0.380397158117062, 0.3397321038954634, 0.5396765763905589, 0.7651220024577434, 0.380397158117062, 0.7651220024577434, 0.5606428040942889, 0.21031207933721124, 0.5396765763905589, 0.380397158117062, 0.380397158117062, 0.380397158117062, 0.7651220024577434, 0.7460055628064333, 0.21031207933721124, 0.380397158117062, 0.7651220024577434, 0.7651220024577434]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.955\n",
      "(*) epoch 2, cost 3.652\n",
      "(*) epoch 3, cost 2.558\n",
      "(*) epoch 4, cost 2.183\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.279\n",
      "(*) epoch 2, cost 3.971\n",
      "(*) epoch 3, cost 3.516\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0078078881057924, 1.1096782566869714, 1.1096782566869714, 1.0057225307089326, 1.1096782566869714, 1.1096782566869714, 1.1096782566869714, 1.1096782566869714, 1.1096782566869714, 1.1096782566869714, 0.819216379632032, 1.7906204951800955, 1.1096782566869714, 1.0078078881057924, 1.1096782566869714, 0.8431442201688485, 0.8431442201688485, 1.1096782566869714, 1.1096782566869714, 1.1096782566869714, 0.819216379632032, 0.8431442201688485, 1.1096782566869714, 1.0623239123616783, 1.7906204951800955, 0.8431442201688485, 1.1096782566869714, 1.1096782566869714, 1.1075928992901118, 1.3527857894166178, 2.145785840092137, 1.1096782566869714, 1.1096782566869714, 0.819216379632032, 1.1096782566869714, 1.1096782566869714, 1.1075928992901118, 1.0078078881057924, 1.1096782566869714, 0.819216379632032, 1.1096782566869714, 1.1096782566869714, 1.1096782566869714, 0.8431442201688485, 1.1096782566869714, 1.1096782566869714, 0.8431442201688485, 1.1096782566869714, 1.1096782566869714, 1.1096782566869714]\n",
      "all_sum after preprocessing is: [-0.37727701  0.04857968  0.04857968 -0.3859946   0.04857968  0.04857968\n",
      "  0.04857968  0.04857968  0.04857968  0.04857968 -1.16566089  2.89517592\n",
      "  0.04857968 -0.37727701  0.04857968 -1.06563346 -1.06563346  0.04857968\n",
      "  0.04857968  0.04857968 -1.16566089 -1.06563346  0.04857968 -0.1493794\n",
      "  2.89517592 -1.06563346  0.04857968  0.04857968  0.0398621   1.06486116\n",
      "  4.37990147  0.04857968  0.04857968 -1.16566089  0.04857968  0.04857968\n",
      "  0.0398621  -0.37727701  0.04857968 -1.16566089  0.04857968  0.04857968\n",
      "  0.04857968 -1.06563346  0.04857968  0.04857968 -1.06563346  0.04857968\n",
      "  0.04857968  0.04857968]\n",
      "P is: [0.4067838159522469, 0.512142531611809, 0.512142531611809, 0.4046818908811808, 0.512142531611809, 0.512142531611809, 0.512142531611809, 0.512142531611809, 0.512142531611809, 0.512142531611809, 0.23764019481411072, 0.9476074496348448, 0.512142531611809, 0.4067838159522469, 0.512142531611809, 0.25623436626496604, 0.25623436626496604, 0.512142531611809, 0.512142531611809, 0.512142531611809, 0.23764019481411072, 0.25623436626496604, 0.512142531611809, 0.4627244384669349, 0.9476074496348448, 0.25623436626496604, 0.512142531611809, 0.512142531611809, 0.5099642043853398, 0.7436184233941627, 0.9876283813827009, 0.512142531611809, 0.512142531611809, 0.23764019481411072, 0.512142531611809, 0.512142531611809, 0.5099642043853398, 0.4067838159522469, 0.512142531611809, 0.23764019481411072, 0.512142531611809, 0.512142531611809, 0.512142531611809, 0.25623436626496604, 0.512142531611809, 0.512142531611809, 0.25623436626496604, 0.512142531611809, 0.512142531611809, 0.512142531611809]\n",
      "all_sum before preprocessing is: [4.674479920766061, 4.674479920766061, 3.822860584702731, 5.379227464930612, 4.674479920766061, 4.695777568786517, 4.695777568786517, 4.695777568786517, 4.695777568786517, 4.695777568786517, 5.357929816910156, 4.48168326068361, 4.692742467000646, 4.695777568786517, 5.005359033677707, 3.3763391843470694, 5.530063296344959, 4.695777568786517, 4.5063104808468255, 5.357929816910156, 4.502980908704067, 4.674479920766061, 5.856978369741038, 4.674479920766061, 4.502980908704067, 3.608766276599824, 5.379227464930612, 5.357929816910156, 5.379227464930612, 2.905076570033416, 4.695777568786517, 4.674479920766061, 5.357929816910156, 5.2565566711954705, 5.397490011165198, 4.674479920766061, 5.194826121617399, 4.674479920766061, 3.822860584702731, 3.801562936682274, 5.379227464930612, 5.277854319215927, 4.674479920766061, 5.379227464930612, 4.695777568786517, 5.277854319215927, 3.5672288181570537, 5.940006567339566, 5.1651331568277055, 4.692742467000646]\n",
      "all_sum after preprocessing is: [-0.16494513 -0.16494513 -1.53607481  0.96971708 -0.16494513 -0.13065535\n",
      " -0.13065535 -0.13065535 -0.13065535 -0.13065535  0.9354273  -0.47535286\n",
      " -0.13554195 -0.13065535  0.367779   -2.25498609  1.21256676 -0.13065535\n",
      " -0.43570238  0.9354273  -0.44106308 -0.16494513  1.73890869 -0.16494513\n",
      " -0.44106308 -1.88077232  0.96971708  0.9354273   0.96971708 -3.01373138\n",
      " -0.13065535 -0.16494513  0.9354273   0.77221385  0.99912026 -0.16494513\n",
      "  0.67282603 -0.16494513 -1.53607481 -1.57036459  0.96971708  0.80650363\n",
      " -0.16494513  0.96971708 -0.13065535  0.80650363 -1.94764872  1.87258628\n",
      "  0.62501957 -0.13554195]\n",
      "P is: [0.45885695678309885, 0.45885695678309885, 0.17710660656132482, 0.7250631019874545, 0.45885695678309885, 0.4673825495208615, 0.4673825495208615, 0.4673825495208615, 0.4673825495208615, 0.4673825495208615, 0.7181750689084484, 0.3833500793195723, 0.46616629607513144, 0.4673825495208615, 0.5909221988343641, 0.09492024208611463, 0.7707527927681125, 0.4673825495208615, 0.39276548118049054, 0.7181750689084484, 0.3914876879327059, 0.45885695678309885, 0.8505483952541677, 0.45885695678309885, 0.3914876879327059, 0.1323001890237216, 0.7250631019874545, 0.7181750689084484, 0.7250631019874545, 0.04680937636675313, 0.4673825495208615, 0.45885695678309885, 0.7181750689084484, 0.6839995998178527, 0.7308855764357587, 0.45885695678309885, 0.6621356662029415, 0.45885695678309885, 0.17710660656132482, 0.172164423153158, 0.7250631019874545, 0.6913639489939766, 0.45885695678309885, 0.7250631019874545, 0.4673825495208615, 0.6913639489939766, 0.1248099674106893, 0.86675724839494, 0.6513593096576531, 0.46616629607513144]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.416\n",
      "(*) epoch 2, cost 2.450\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.827\n",
      "(*) epoch 2, cost 4.842\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.053290186916592, 3.750168965353423, 3.4617931038962024, 4.053290186916592, 3.4617931038962024, 3.4617931038962024, 3.750168965353423, 4.053290186916592, 3.750168965353423, 3.4617931038962024, 3.4617931038962024, 3.4617931038962024, 4.1676553441038005, 3.4617931038962024, 3.750168965353423, 3.750168965353423, 2.059197339460349, 4.332415090542197, 3.7649143254593715, 4.053290186916592, 3.8645341225406318, 3.4617931038962024, 3.750168965353423, 3.4617931038962024, 3.7649143254593715, 3.4617931038962024, 2.044451979354401, 3.4617931038962024, 3.750168965353423, 3.750168965353423, 2.059197339460349, 3.4617931038962024, 3.4617931038962024, 2.044451979354401, 2.3475732009175703, 3.4617931038962024, 4.053290186916592, 3.750168965353423, 4.152909983997853, 1.7560761178971802, 4.253864688179525, 3.4617931038962024, 1.7560761178971802, 3.4617931038962024, 3.7649143254593715, 3.4617931038962024, 3.750168965353423, 3.750168965353423, 3.750168965353423, 1.7560761178971802]\n",
      "all_sum after preprocessing is: [ 0.89538285  0.45271802  0.03158666  0.89538285  0.03158666  0.03158666\n",
      "  0.45271802  0.89538285  0.45271802  0.03158666  0.03158666  0.03158666\n",
      "  1.06239666  0.03158666  0.45271802  0.45271802 -2.01670217  1.30300451\n",
      "  0.47425149  0.89538285  0.61973184  0.03158666  0.45271802  0.03158666\n",
      "  0.47425149  0.03158666 -2.03823564  0.03158666  0.45271802  0.45271802\n",
      " -2.01670217  0.03158666  0.03158666 -2.03823564 -1.59557081  0.03158666\n",
      "  0.89538285  0.45271802  1.04086319 -2.45936699  1.18829298  0.03158666\n",
      " -2.45936699  0.03158666  0.47425149  0.03158666  0.45271802  0.45271802\n",
      "  0.45271802 -2.45936699]\n",
      "P is: [0.70999975284848, 0.6112852726814142, 0.5078960093707171, 0.70999975284848, 0.5078960093707171, 0.5078960093707171, 0.6112852726814142, 0.70999975284848, 0.6112852726814142, 0.5078960093707171, 0.5078960093707171, 0.5078960093707171, 0.7431482846143921, 0.5078960093707171, 0.6112852726814142, 0.6112852726814142, 0.11746042472143611, 0.786340203348795, 0.6163895323895693, 0.70999975284848, 0.6501575567049585, 0.5078960093707171, 0.6112852726814142, 0.5078960093707171, 0.6163895323895693, 0.5078960093707171, 0.11524651267470097, 0.5078960093707171, 0.6112852726814142, 0.6112852726814142, 0.11746042472143611, 0.5078960093707171, 0.5078960093707171, 0.11524651267470097, 0.1686015658376719, 0.5078960093707171, 0.70999975284848, 0.6112852726814142, 0.7390165254230037, 0.07875625186365492, 0.7664356258224929, 0.5078960093707171, 0.07875625186365492, 0.5078960093707171, 0.6163895323895693, 0.5078960093707171, 0.6112852726814142, 0.6112852726814142, 0.6112852726814142, 0.07875625186365492]\n",
      "all_sum before preprocessing is: [2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 1.1382510439990254, 2.5493535461969032, 2.5493535461969032, 1.1382510439990254, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 1.1382510439990254, 1.1382510439990254, 3.7999641478189976, 2.3274303212702527, 1.1382510439990254, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 1.1382510439990254, 2.5493535461969032, 2.3274303212702527, 2.5493535461969032, 1.1382510439990254, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 1.1382510439990254, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 3.7999641478189976, 2.5493535461969032, 1.8059716791136147, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032, 2.5493535461969032]\n",
      "all_sum after preprocessing is: [ 0.33512119  0.33512119  0.33512119  0.33512119  0.33512119  0.33512119\n",
      "  0.33512119  0.33512119  0.33512119 -2.03529758  0.33512119  0.33512119\n",
      " -2.03529758  0.33512119  0.33512119  0.33512119  0.33512119  0.33512119\n",
      "  0.33512119 -2.03529758 -2.03529758  2.43594012 -0.03767312 -2.03529758\n",
      "  0.33512119  0.33512119  0.33512119 -2.03529758  0.33512119 -0.03767312\n",
      "  0.33512119 -2.03529758  0.33512119  0.33512119  0.33512119  0.33512119\n",
      " -2.03529758  0.33512119  0.33512119  0.33512119  0.33512119  2.43594012\n",
      "  0.33512119 -0.91363737  0.33512119  0.33512119  0.33512119  0.33512119\n",
      "  0.33512119  0.33512119]\n",
      "P is: [0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.11554642990508535, 0.5830049168961512, 0.5830049168961512, 0.11554642990508535, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.11554642990508535, 0.11554642990508535, 0.9195271799931655, 0.49058283468884484, 0.11554642990508535, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.11554642990508535, 0.5830049168961512, 0.49058283468884484, 0.5830049168961512, 0.11554642990508535, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.11554642990508535, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.9195271799931655, 0.5830049168961512, 0.28625609552367703, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512, 0.5830049168961512]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.029\n",
      "(*) epoch 2, cost 2.446\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.541\n",
      "(*) epoch 2, cost 2.370\n",
      "(*) epoch 3, cost 1.894\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.9825941760395827, 4.4930743613436785, 4.4930743613436785, 2.8319800836242814, 2.9825941760395827, 4.4930743613436785, 3.188850774811553, 2.9825941760395827, 4.4930743613436785, 2.8319800836242814, 2.9825941760395827, 2.9825941760395827, 4.64368845375898, 2.9825941760395827, 2.8319800836242814, 4.4930743613436785, 3.188850774811553, 2.9825941760395827, 4.4930743613436785, 2.9825941760395827, 2.9825941760395827, 2.9825941760395827, 4.64368845375898, 2.8319800836242814, 2.9825941760395827, 2.8319800836242814, 4.64368845375898, 2.9825941760395827, 4.64368845375898, 4.64368845375898, 4.64368845375898, 2.8319800836242814, 4.4930743613436785, 3.188850774811553, 2.8319800836242814, 2.8319800836242814, 2.8319800836242814, 2.8319800836242814, 2.9825941760395827, 4.504312569924021, 4.4930743613436785, 2.8319800836242814, 4.64368845375898, 4.64368845375898, 2.9825941760395827, 2.8319800836242814, 2.9825941760395827, 2.9825941760395827, 2.9825941760395827, 3.3394648672268543]\n",
      "all_sum after preprocessing is: [-0.67764858  1.28603756  1.28603756 -0.87345308 -0.67764858  1.28603756\n",
      " -0.40950655 -0.67764858  1.28603756 -0.87345308 -0.67764858 -0.67764858\n",
      "  1.48184205 -0.67764858 -0.87345308  1.28603756 -0.40950655 -0.67764858\n",
      "  1.28603756 -0.67764858 -0.67764858 -0.67764858  1.48184205 -0.87345308\n",
      " -0.67764858 -0.87345308  1.48184205 -0.67764858  1.48184205  1.48184205\n",
      "  1.48184205 -0.87345308  1.28603756 -0.40950655 -0.87345308 -0.87345308\n",
      " -0.87345308 -0.87345308 -0.67764858  1.30064769  1.28603756 -0.87345308\n",
      "  1.48184205  1.48184205 -0.67764858 -0.87345308 -0.67764858 -0.67764858\n",
      " -0.67764858 -0.21370206]\n",
      "P is: [0.3367863163946546, 0.7834757494201028, 0.7834757494201028, 0.2945362972072961, 0.3367863163946546, 0.7834757494201028, 0.39903044654321923, 0.3367863163946546, 0.7834757494201028, 0.2945362972072961, 0.3367863163946546, 0.3367863163946546, 0.8148506500961054, 0.3367863163946546, 0.2945362972072961, 0.7834757494201028, 0.39903044654321923, 0.3367863163946546, 0.7834757494201028, 0.3367863163946546, 0.3367863163946546, 0.3367863163946546, 0.8148506500961054, 0.2945362972072961, 0.3367863163946546, 0.2945362972072961, 0.8148506500961054, 0.3367863163946546, 0.8148506500961054, 0.8148506500961054, 0.8148506500961054, 0.2945362972072961, 0.7834757494201028, 0.39903044654321923, 0.2945362972072961, 0.2945362972072961, 0.2945362972072961, 0.2945362972072961, 0.3367863163946546, 0.7859439677459054, 0.7834757494201028, 0.2945362972072961, 0.8148506500961054, 0.8148506500961054, 0.3367863163946546, 0.2945362972072961, 0.3367863163946546, 0.3367863163946546, 0.3367863163946546, 0.44677688294271956]\n",
      "all_sum before preprocessing is: [0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.9606983995038281, 0.9606983995038281, 0.26107101513134023, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.9565976000911889, 0.003908507756279907, 0.9606983995038281, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 1.913387491838737, 0.9606983995038281, 0.003908507756279907, 0.003908507756279907, 0.9565976000911889, 0.003908507756279907, 0.9565976000911889, 0.003908507756279907, 0.003908507756279907, 0.9565976000911889, 0.003908507756279907, 0.9606983995038281, 1.913387491838737, 0.003908507756279907, 0.003908507756279907, 0.9565976000911889, 0.9606983995038281, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.9606983995038281, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907, 0.003908507756279907]\n",
      "all_sum after preprocessing is: [-0.59854344 -0.59854344 -0.59854344 -0.59854344 -0.59854344  1.2444018\n",
      "  1.2444018  -0.10320332 -0.59854344 -0.59854344 -0.59854344 -0.59854344\n",
      "  1.23650294 -0.59854344  1.2444018  -0.59854344 -0.59854344 -0.59854344\n",
      "  3.07944817  1.2444018  -0.59854344 -0.59854344  1.23650294 -0.59854344\n",
      "  1.23650294 -0.59854344 -0.59854344  1.23650294 -0.59854344  1.2444018\n",
      "  3.07944817 -0.59854344 -0.59854344  1.23650294  1.2444018  -0.59854344\n",
      " -0.59854344 -0.59854344 -0.59854344 -0.59854344 -0.59854344  1.2444018\n",
      " -0.59854344 -0.59854344 -0.59854344 -0.59854344 -0.59854344 -0.59854344\n",
      " -0.59854344 -0.59854344]\n",
      "P is: [0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.7763292812312654, 0.7763292812312654, 0.47422204599107626, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.7749547133882272, 0.354677003133279, 0.7763292812312654, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.9560369969313802, 0.7763292812312654, 0.354677003133279, 0.354677003133279, 0.7749547133882272, 0.354677003133279, 0.7749547133882272, 0.354677003133279, 0.354677003133279, 0.7749547133882272, 0.354677003133279, 0.7763292812312654, 0.9560369969313802, 0.354677003133279, 0.354677003133279, 0.7749547133882272, 0.7763292812312654, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.7763292812312654, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279, 0.354677003133279]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.689\n",
      "(*) epoch 2, cost 2.805\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.515\n",
      "(*) epoch 2, cost 1.297\n",
      "(*) epoch 3, cost 0.932\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.1155578052687534, 3.985685191843482, 3.1155578052687534, 2.2093550722029542, 3.1155578052687534, 3.1155578052687534, 3.985685191843482, 3.1155578052687534, 3.1686911741025194, 3.1686911741025194, 3.985685191843482, 2.2985637875277907, 3.1155578052687534, 3.985685191843482, 3.1686911741025194, 2.2985637875277907, 3.1155578052687534, 3.985685191843482, 3.985685191843482, 3.1155578052687534, 3.1155578052687534, 3.1155578052687534, 3.1155578052687534, 2.2985637875277907, 1.3923610544619915, 3.985685191843482, 2.2093550722029542, 2.2985637875277907, 3.1155578052687534, 3.985685191843482, 3.1686911741025194, 2.2093550722029542, 3.985685191843482, 3.985685191843482, 3.1155578052687534, 3.1155578052687534, 3.1155578052687534, 3.1155578052687534, 3.1155578052687534, 1.3923610544619915, 3.1155578052687534, 1.3923610544619915, 3.1155578052687534, 2.26248844103672, 3.1155578052687534, 2.2985637875277907, 2.4156455862007538, 3.1155578052687534, 3.985685191843482, 3.985685191843482]\n",
      "all_sum after preprocessing is: [ 0.08146562  1.31550622  0.08146562 -1.20373811  0.08146562  0.08146562\n",
      "  1.31550622  0.08146562  0.15682094  0.15682094  1.31550622 -1.07721966\n",
      "  0.08146562  1.31550622  0.15682094 -1.07721966  0.08146562  1.31550622\n",
      "  1.31550622  0.08146562  0.08146562  0.08146562  0.08146562 -1.07721966\n",
      " -2.36242339  1.31550622 -1.20373811 -1.07721966  0.08146562  1.31550622\n",
      "  0.15682094 -1.20373811  1.31550622  1.31550622  0.08146562  0.08146562\n",
      "  0.08146562  0.08146562  0.08146562 -2.36242339  0.08146562 -2.36242339\n",
      "  0.08146562 -1.12838279  0.08146562 -1.07721966 -0.91117076  0.08146562\n",
      "  1.31550622  1.31550622]\n",
      "P is: [0.5203551479367534, 0.7884330864611822, 0.5203551479367534, 0.2308108942550671, 0.5203551479367534, 0.5203551479367534, 0.7884330864611822, 0.5203551479367534, 0.5391250859731807, 0.5391250859731807, 0.7884330864611822, 0.2540325315857036, 0.5203551479367534, 0.7884330864611822, 0.5391250859731807, 0.2540325315857036, 0.5203551479367534, 0.7884330864611822, 0.7884330864611822, 0.5203551479367534, 0.5203551479367534, 0.5203551479367534, 0.5203551479367534, 0.2540325315857036, 0.08608334802507343, 0.7884330864611822, 0.2308108942550671, 0.2540325315857036, 0.5203551479367534, 0.7884330864611822, 0.5391250859731807, 0.2308108942550671, 0.7884330864611822, 0.7884330864611822, 0.5203551479367534, 0.5203551479367534, 0.5203551479367534, 0.5203551479367534, 0.5203551479367534, 0.08608334802507343, 0.5203551479367534, 0.08608334802507343, 0.5203551479367534, 0.24445967527350335, 0.5203551479367534, 0.2540325315857036, 0.2867603237033535, 0.5203551479367534, 0.7884330864611822, 0.7884330864611822]\n",
      "all_sum before preprocessing is: [2.261084682090573, 2.573417251502115, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.9766116471447535, 2.261084682090573, 3.6964731623088376, 2.069037149144808, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.38136971855635, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.573417251502115, 2.261084682090573, 2.664279077733211, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.069037149144808, 2.261084682090573, 2.261084682090573, 2.573417251502115, 2.261084682090573, 2.261084682090573, 2.261084682090573, 2.573417251502115, 2.573417251502115, 2.261084682090573, 2.573417251502115, 2.261084682090573, 2.261084682090573, 2.261084682090573]\n",
      "all_sum after preprocessing is: [-0.33657531  0.92562425 -0.33657531 -0.33657531 -0.33657531 -0.33657531\n",
      " -0.33657531 -0.33657531 -0.33657531 -0.33657531 -0.33657531  2.55501497\n",
      " -0.33657531  5.46412206 -1.11267853 -0.33657531 -0.33657531 -0.33657531\n",
      " -0.33657531 -0.33657531 -0.33657531  0.14952103 -0.33657531 -0.33657531\n",
      " -0.33657531 -0.33657531  0.92562425 -0.33657531  1.29281541 -0.33657531\n",
      " -0.33657531 -0.33657531 -0.33657531 -0.33657531 -0.33657531 -0.33657531\n",
      " -1.11267853 -0.33657531 -0.33657531  0.92562425 -0.33657531 -0.33657531\n",
      " -0.33657531  0.92562425  0.92562425 -0.33657531  0.92562425 -0.33657531\n",
      " -0.33657531 -0.33657531]\n",
      "P is: [0.41664161342535383, 0.7161866983807483, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.9279097034671898, 0.41664161342535383, 0.9957818100872768, 0.24737186452955487, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.5373107723238847, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.7161866983807483, 0.41664161342535383, 0.7846233450746876, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.24737186452955487, 0.41664161342535383, 0.41664161342535383, 0.7161866983807483, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383, 0.7161866983807483, 0.7161866983807483, 0.41664161342535383, 0.7161866983807483, 0.41664161342535383, 0.41664161342535383, 0.41664161342535383]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.867\n",
      "(*) epoch 2, cost 2.963\n",
      "(*) epoch 3, cost 2.114\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.397\n",
      "(*) epoch 2, cost 2.804\n",
      "(*) epoch 3, cost 2.040\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.6682204479805112, 3.083785019926755, 3.046323331886688, 2.0078214974443993, 2.0078214974443993, 1.6682204479805112, 0.74744211716164, 4.3441644002095146, 3.9671016627055593, 4.3067027121694474, 2.0452831854844664, 2.0078214974443993, 0.7849038052017072, 2.0078214974443993, 4.3067027121694474, 1.5377079880540232, 3.083785019926755, 2.9285998282632706, 0.74744211716164, 5.264942731028386, 2.0452831854844664, 0.74744211716164, 2.0078214974443993, 2.0078214974443993, 4.665038454246924, 1.6682204479805112, 2.0078214974443993, 0.74744211716164, 1.5751696760940905, 2.0452831854844664, 3.083785019926755, 5.227481042988319, 2.0452831854844664, 0.7849038052017072, 1.6682204479805112, 0.74744211716164, 4.3067027121694474, 2.0452831854844664, 0.74744211716164, 0.74744211716164, 2.026556190057987, 2.0078214974443993, 2.9285998282632706, 0.74744211716164, 0.74744211716164, 4.3441644002095146, 4.3441644002095146, 2.0078214974443993, 4.3067027121694474, 1.6682204479805112]\n",
      "all_sum after preprocessing is: [-0.51565562  0.55145581  0.52321563 -0.25965023 -0.25965023 -0.51565562\n",
      " -1.2097766   1.50158219  1.21733662  1.47334201 -0.23141005 -0.25965023\n",
      " -1.18153642 -0.25965023  1.47334201 -0.61404133  0.55145581  0.43447076\n",
      " -1.2097766   2.19570317 -0.23141005 -1.2097766  -0.25965023 -0.25965023\n",
      "  1.74347039 -0.51565562 -0.25965023 -1.2097766  -0.58580116 -0.23141005\n",
      "  0.55145581  2.16746299 -0.23141005 -1.18153642 -0.51565562 -1.2097766\n",
      "  1.47334201 -0.23141005 -1.2097766  -1.2097766  -0.24552724 -0.25965023\n",
      "  0.43447076 -1.2097766  -1.2097766   1.50158219  1.50158219 -0.25965023\n",
      "  1.47334201 -0.51565562]\n",
      "P is: [0.3738686559178446, 0.6344732839654672, 0.627899380607867, 0.4354496923684975, 0.4354496923684975, 0.3738686559178446, 0.22974058106142498, 0.817810335008554, 0.7715945040791068, 0.8135648233711368, 0.44240428271609733, 0.4354496923684975, 0.23477605557370784, 0.4354496923684975, 0.8135648233711368, 0.35113786714087913, 0.6344732839654672, 0.6069407378862757, 0.22974058106142498, 0.8998629901633034, 0.44240428271609733, 0.22974058106142498, 0.4354496923684975, 0.4354496923684975, 0.8511273329286342, 0.3738686559178446, 0.4354496923684975, 0.22974058106142498, 0.3575988429840375, 0.44240428271609733, 0.6344732839654672, 0.8972893887480249, 0.44240428271609733, 0.23477605557370784, 0.3738686559178446, 0.22974058106142498, 0.8135648233711368, 0.44240428271609733, 0.22974058106142498, 0.22974058106142498, 0.43892470326243194, 0.4354496923684975, 0.6069407378862757, 0.22974058106142498, 0.22974058106142498, 0.817810335008554, 0.817810335008554, 0.4354496923684975, 0.8135648233711368, 0.3738686559178446]\n",
      "all_sum before preprocessing is: [0.8140619432919336, 1.0011420530401594, 1.0011420530401594, 0.6711590665860809, 0.6711590665860809, 0.701473246382479, 0.6711590665860809, 0.8279249965379087, 0.701473246382479, 0.701473246382479, 0.8443761230883315, 0.701473246382479, 0.8443761230883315, 0.3167835069714949, 0.701473246382479, 0.8443761230883315, 0.9708278732437614, 0.8443761230883315, 0.8582391763343068, 0.701473246382479, 0.8140619432919336, 0.6711590665860809, 0.701473246382479, 0.701473246382479, 1.0509535222241762, 0.9708278732437614, 0.8443761230883315, 0.6711590665860809, 0.6711590665860809, 0.6711590665860809, 0.8443761230883315, 0.701473246382479, 0.701473246382479, 1.081267702020574, 0.701473246382479, 0.6711590665860809, 0.8140619432919336, 0.6711590665860809, 0.701473246382479, 0.8140619432919336, 1.0011420530401594, 0.6711590665860809, 0.701473246382479, 0.8140619432919336, 0.9708278732437614, 0.701473246382479, 0.6711590665860809, 0.6711590665860809, 0.6711590665860809, 0.6711590665860809]\n",
      "all_sum after preprocessing is: [ 0.33911715  1.7191329   1.7191329  -0.71502067 -0.71502067 -0.491405\n",
      " -0.71502067  0.4413794  -0.491405   -0.491405    0.56273283 -0.491405\n",
      "  0.56273283 -3.32910859 -0.491405    0.56273283  1.49551723  0.56273283\n",
      "  0.66499508 -0.491405    0.33911715 -0.71502067 -0.491405   -0.491405\n",
      "  2.08657235  1.49551723  0.56273283 -0.71502067 -0.71502067 -0.71502067\n",
      "  0.56273283 -0.491405   -0.491405    2.31018803 -0.491405   -0.71502067\n",
      "  0.33911715 -0.71502067 -0.491405    0.33911715  1.7191329  -0.71502067\n",
      " -0.491405    0.33911715  1.49551723 -0.491405   -0.71502067 -0.71502067\n",
      " -0.71502067 -0.71502067]\n",
      "P is: [0.5839760529953696, 0.8480171150923785, 0.8480171150923785, 0.3284904052293011, 0.3284904052293011, 0.37956264220443336, 0.3284904052293011, 0.6085876643771937, 0.37956264220443336, 0.37956264220443336, 0.6370846285976292, 0.37956264220443336, 0.6370846285976292, 0.034585982009139614, 0.37956264220443336, 0.6370846285976292, 0.816904934210712, 0.6370846285976292, 0.6603815685547451, 0.37956264220443336, 0.5839760529953696, 0.3284904052293011, 0.37956264220443336, 0.37956264220443336, 0.8895912156509234, 0.816904934210712, 0.6370846285976292, 0.3284904052293011, 0.3284904052293011, 0.3284904052293011, 0.6370846285976292, 0.37956264220443336, 0.37956264220443336, 0.9097172995371385, 0.37956264220443336, 0.3284904052293011, 0.5839760529953696, 0.3284904052293011, 0.37956264220443336, 0.5839760529953696, 0.8480171150923785, 0.3284904052293011, 0.37956264220443336, 0.5839760529953696, 0.816904934210712, 0.37956264220443336, 0.3284904052293011, 0.3284904052293011, 0.3284904052293011, 0.3284904052293011]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.839\n",
      "(*) epoch 2, cost 2.601\n",
      "(*) epoch 3, cost 2.161\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.392\n",
      "(*) epoch 2, cost 2.515\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 3.6738019697902837, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 1.4185563704460222, 3.6738019697902837, 1.4185563704460222]\n",
      "all_sum after preprocessing is: [-0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      "  4.89897949 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      "  4.89897949 -0.20412415]\n",
      "P is: [0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.9926009674715031, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.4491454195938373, 0.9926009674715031, 0.4491454195938373]\n",
      "all_sum before preprocessing is: [4.053160279060332, 3.860863356277112, 3.4365229067456906, 3.860863356277112, 3.4365229067456906, 3.617261929456654, 3.6801243335661487, 3.617261929456654, 3.617261929456654, 3.4365229067456906, 3.4365229067456906, 3.6801243335661487, 3.617261929456654, 3.860863356277112, 3.617261929456654, 3.617261929456654, 3.6801243335661487, 3.4365229067456906, 3.617261929456654, 3.4365229067456906, 3.617261929456654, 3.617261929456654, 3.617261929456654, 3.617261929456654, 3.8724212563493694, 3.617261929456654, 3.4365229067456906, 3.617261929456654, 3.8724212563493694, 3.4365229067456906, 3.617261929456654, 3.6801243335661487, 3.617261929456654, 3.617261929456654, 4.053160279060332, 2.6407544502791045, 3.4365229067456906, 3.617261929456654, 3.860863356277112, 3.860863356277112, 3.617261929456654, 3.6801243335661487, 3.617261929456654, 3.4365229067456906, 4.053160279060332, 4.053160279060332, 3.617261929456654, 4.29676170588079, 3.860863356277112, 3.860863356277112]\n",
      "all_sum after preprocessing is: [ 1.60963876  0.82106633 -0.91907166  0.82106633 -0.91907166 -0.17789594\n",
      "  0.0798906  -0.17789594 -0.17789594 -0.91907166 -0.91907166  0.0798906\n",
      " -0.17789594  0.82106633 -0.17789594 -0.17789594  0.0798906  -0.91907166\n",
      " -0.17789594 -0.91907166 -0.17789594 -0.17789594 -0.17789594 -0.17789594\n",
      "  0.86846304 -0.17789594 -0.91907166 -0.17789594  0.86846304 -0.91907166\n",
      " -0.17789594  0.0798906  -0.17789594 -0.17789594  1.60963876 -4.18236397\n",
      " -0.91907166 -0.17789594  0.82106633  0.82106633 -0.17789594  0.0798906\n",
      " -0.17789594 -0.91907166  1.60963876  1.60963876 -0.17789594  2.60860103\n",
      "  0.82106633  0.82106633]\n",
      "P is: [0.8333612268971965, 0.6944626446663359, 0.2851470867764524, 0.6944626446663359, 0.2851470867764524, 0.4556429336917497, 0.5199620343863969, 0.4556429336917497, 0.4556429336917497, 0.2851470867764524, 0.2851470867764524, 0.5199620343863969, 0.4556429336917497, 0.6944626446663359, 0.4556429336917497, 0.4556429336917497, 0.5199620343863969, 0.2851470867764524, 0.4556429336917497, 0.2851470867764524, 0.4556429336917497, 0.4556429336917497, 0.4556429336917497, 0.4556429336917497, 0.7044257870823916, 0.4556429336917497, 0.2851470867764524, 0.4556429336917497, 0.7044257870823916, 0.2851470867764524, 0.4556429336917497, 0.5199620343863969, 0.4556429336917497, 0.4556429336917497, 0.8333612268971965, 0.015032946476568821, 0.2851470867764524, 0.4556429336917497, 0.6944626446663359, 0.6944626446663359, 0.4556429336917497, 0.5199620343863969, 0.4556429336917497, 0.2851470867764524, 0.8333612268971965, 0.8333612268971965, 0.4556429336917497, 0.931413079916639, 0.6944626446663359, 0.6944626446663359]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.604\n",
      "(*) epoch 2, cost 1.124\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.947\n",
      "(*) epoch 2, cost 2.656\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.749469375826298, 3.8582176218230146, 3.8582176218230146, 5.131563965754261, 2.524109896677278, 2.524109896677278, 3.8582176218230146, 4.240312211750979, 6.84780409781425, 4.749469375826298, 5.322365423202797, 5.322365423202797, 4.749469375826298, 4.622444618665231, 4.749469375826298, 3.731192864661948, 3.8582176218230146, 1.6328581426739954, 2.524109896677278, 4.749469375826298, 1.6328581426739954, 3.9882576980570597, 4.749469375826298, 7.229898687742215, 4.749469375826298, 3.8582176218230146, 4.749469375826298, 4.749469375826298, 6.84780409781425, 4.749469375826298, 1.6328581426739954, 4.749469375826298, 4.749469375826298, 3.8582176218230146, 4.749469375826298, 4.749469375826298, 6.338646933738932, 4.749469375826298, 3.8582176218230146, 4.749469375826298, 4.749469375826298, 2.524109896677278, 3.8582176218230146, 4.749469375826298, 6.84780409781425, 4.749469375826298, 4.749469375826298, 4.749469375826298, 5.940600668567152, 3.8582176218230146]\n",
      "all_sum after preprocessing is: [ 0.25111975 -0.46601247 -0.46601247  0.55856638 -1.53948203 -1.53948203\n",
      " -0.46601247 -0.15856584  1.93951299  0.25111975  0.71209188  0.71209188\n",
      "  0.25111975  0.14891121  0.25111975 -0.56822101 -0.46601247 -2.25661425\n",
      " -1.53948203  0.25111975 -2.25661425 -0.36137769  0.25111975  2.24695961\n",
      "  0.25111975 -0.46601247  0.25111975  0.25111975  1.93951299  0.25111975\n",
      " -2.25661425  0.25111975  0.25111975 -0.46601247  0.25111975  0.25111975\n",
      "  1.5298274   0.25111975 -0.46601247  0.25111975  0.25111975 -1.53948203\n",
      " -0.46601247  0.25111975  1.93951299  0.25111975  0.25111975  0.25111975\n",
      "  1.2095455  -0.46601247]\n",
      "P is: [0.5624520910177008, 0.3855604725043149, 0.3855604725043149, 0.6361207622855152, 0.17661058459743154, 0.17661058459743154, 0.3855604725043149, 0.46044138981122623, 0.8742986308366623, 0.5624520910177008, 0.6708632232173946, 0.6708632232173946, 0.5624520910177008, 0.5371591614181187, 0.5624520910177008, 0.3616474181602796, 0.3855604725043149, 0.0947804581123641, 0.17661058459743154, 0.5624520910177008, 0.0947804581123641, 0.4106261071138603, 0.5624520910177008, 0.9043879548489315, 0.5624520910177008, 0.3855604725043149, 0.5624520910177008, 0.5624520910177008, 0.8742986308366623, 0.5624520910177008, 0.0947804581123641, 0.5624520910177008, 0.5624520910177008, 0.3855604725043149, 0.5624520910177008, 0.5624520910177008, 0.8219810586618506, 0.5624520910177008, 0.3855604725043149, 0.5624520910177008, 0.5624520910177008, 0.17661058459743154, 0.3855604725043149, 0.5624520910177008, 0.8742986308366623, 0.5624520910177008, 0.5624520910177008, 0.5624520910177008, 0.7702185204880478, 0.3855604725043149]\n",
      "all_sum before preprocessing is: [2.269956244537436, 1.1539324434516385, 1.1539324434516385, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 1.1539324434516385, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 1.1539324434516385, 2.269956244537436, 1.1539324434516385, 2.269956244537436, 2.269956244537436, 1.2745947883334154, 1.1539324434516385, 1.1539324434516385, 1.1539324434516385, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436, 1.1539324434516385, 2.269956244537436, 2.269956244537436, 1.1539324434516385, 2.269956244537436, 2.269956244537436, 2.269956244537436, 1.1539324434516385, 1.1539324434516385, 2.269956244537436, 2.269956244537436, 2.269956244537436, 2.269956244537436]\n",
      "all_sum after preprocessing is: [ 0.59241124 -1.70520226 -1.70520226  0.59241124  0.59241124  0.59241124\n",
      "  0.59241124  0.59241124  0.59241124  0.59241124  0.59241124  0.59241124\n",
      "  0.59241124  0.59241124 -1.70520226  0.59241124  0.59241124  0.59241124\n",
      "  0.59241124  0.59241124  0.59241124 -1.70520226  0.59241124 -1.70520226\n",
      "  0.59241124  0.59241124 -1.45678871 -1.70520226 -1.70520226 -1.70520226\n",
      "  0.59241124  0.59241124  0.59241124  0.59241124  0.59241124  0.59241124\n",
      "  0.59241124 -1.70520226  0.59241124  0.59241124 -1.70520226  0.59241124\n",
      "  0.59241124  0.59241124 -1.70520226 -1.70520226  0.59241124  0.59241124\n",
      "  0.59241124  0.59241124]\n",
      "P is: [0.6439182041966608, 0.15378704098252732, 0.15378704098252732, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.15378704098252732, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.15378704098252732, 0.6439182041966608, 0.15378704098252732, 0.6439182041966608, 0.6439182041966608, 0.18895897509025447, 0.15378704098252732, 0.15378704098252732, 0.15378704098252732, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.15378704098252732, 0.6439182041966608, 0.6439182041966608, 0.15378704098252732, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.15378704098252732, 0.15378704098252732, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608, 0.6439182041966608]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.721\n",
      "(*) epoch 2, cost 3.589\n",
      "(*) epoch 3, cost 3.063\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 0.629\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.5784446678549515, 3.5784446678549515, 0.8445279586129131, 1.6452509797479853, 2.2055742827911615, 1.6452509797479853, 4.3381391697278335, 2.7777216467198795, 1.6452509797479853, 2.2055742827911615, 3.5784446678549515, 1.6452509797479853, 4.138767970898128, 1.6452509797479853, 0.8445279586129131, 4.138767970898128, 1.6452509797479853, 1.6452509797479853, 3.5784446678549515, 1.6452509797479853, 1.6452509797479853, 1.6452509797479853, 1.6452509797479853, 1.6452509797479853, 1.6452509797479853, 0.8445279586129131, 0.8445279586129131, 4.138767970898128, 1.6452509797479853, 1.6042224604857949, 2.404945481620867, 3.5784446678549515, 1.6452509797479853, 2.2055742827911615, 1.4048512616560895, 4.097739451635937, 3.3380449497630558, 1.6452509797479853, 1.6452509797479853, 2.2055742827911615, 1.6452509797479853, 3.5784446678549515, 2.2055742827911615, 3.5784446678549515, 0.8445279586129131, 1.6452509797479853, 2.7777216467198795, 4.898462472771009, 3.5784446678549515, 1.4048512616560895]\n",
      "all_sum after preprocessing is: [ 1.1405046   1.1405046  -1.3610799  -0.62840348 -0.11569726 -0.62840348\n",
      "  1.83563916  0.40782819 -0.62840348 -0.11569726  1.1405046  -0.62840348\n",
      "  1.65321082 -0.62840348 -1.3610799   1.65321082 -0.62840348 -0.62840348\n",
      "  1.1405046  -0.62840348 -0.62840348 -0.62840348 -0.62840348 -0.62840348\n",
      " -0.62840348 -1.3610799  -1.3610799   1.65321082 -0.62840348 -0.66594534\n",
      "  0.06673108  1.1405046  -0.62840348 -0.11569726 -0.84837368  1.61566896\n",
      "  0.9205344  -0.62840348 -0.62840348 -0.11569726 -0.62840348  1.1405046\n",
      " -0.11569726  1.1405046  -1.3610799  -0.62840348  0.40782819  2.34834538\n",
      "  1.1405046  -0.84837368]\n",
      "P is: [0.757772272382204, 0.757772272382204, 0.2040648470179273, 0.3478726320356672, 0.4711079054533716, 0.3478726320356672, 0.8624321419369646, 0.6005670043121869, 0.3478726320356672, 0.4711079054533716, 0.757772272382204, 0.3478726320356672, 0.8393245293848766, 0.3478726320356672, 0.2040648470179273, 0.8393245293848766, 0.3478726320356672, 0.3478726320356672, 0.757772272382204, 0.3478726320356672, 0.3478726320356672, 0.3478726320356672, 0.3478726320356672, 0.3478726320356672, 0.3478726320356672, 0.2040648470179273, 0.2040648470179273, 0.8393245293848766, 0.3478726320356672, 0.33940534164206376, 0.5166765820640802, 0.757772272382204, 0.3478726320356672, 0.4711079054533716, 0.29977412639127154, 0.8341969600890186, 0.7151509809672045, 0.3478726320356672, 0.3478726320356672, 0.4711079054533716, 0.3478726320356672, 0.757772272382204, 0.4711079054533716, 0.757772272382204, 0.2040648470179273, 0.3478726320356672, 0.6005670043121869, 0.9128026193648264, 0.757772272382204, 0.29977412639127154]\n",
      "all_sum before preprocessing is: [5.891752319789307, 6.355222008822134, 3.9055312764622405, 4.911665669760381, 6.355222008822134, 5.958806091455813, 4.911665669760381, 4.885617926491168, 4.911665669760381, 3.9055312764622405, 6.355222008822134, 3.9055312764622405, 7.833583824830946, 6.355222008822134, 8.408496823815705, 6.964940484753952, 5.3490876155239935, 6.355222008822134, 5.3490876155239935, 7.833583824830946, 5.3490876155239935, 5.3490876155239935, 4.448195980727554, 6.355222008822134, 6.355222008822134, 6.355222008822134, 4.911665669760381, 6.938892741484739, 5.958806091455813, 6.355222008822134, 6.355222008822134, 4.448195980727554, 6.938242615290787, 5.891105678519161, 3.9055312764622405, 6.964940484753952, 5.383893092471053, 6.355222008822134, 4.911665669760381, 8.408496823815705, 8.408496823815705, 7.402362430517566, 8.408496823815705, 3.9055312764622405, 3.9055312764622405, 8.408496823815705, 4.60965355306218, 5.031216587196209, 5.3490876155239935, 3.9055312764622405]\n",
      "all_sum after preprocessing is: [ 0.0091111   0.35443465 -1.47078913 -0.72113515  0.35443465  0.05907175\n",
      " -0.72113515 -0.74054289 -0.72113515 -1.47078913  0.35443465 -1.47078913\n",
      "  1.45593742  0.35443465  1.88429553  0.80872573 -0.39521934  0.35443465\n",
      " -0.39521934  1.45593742 -0.39521934 -0.39521934 -1.0664587   0.35443465\n",
      "  0.35443465  0.35443465 -0.72113515  0.78931799  0.05907175  0.35443465\n",
      "  0.35443465 -1.0664587   0.78883359  0.0086293  -1.47078913  0.80872573\n",
      " -0.36928636  0.35443465 -0.72113515  1.88429553  1.88429553  1.13464154\n",
      "  1.88429553 -1.47078913 -1.47078913  1.88429553 -0.94615935 -0.63205975\n",
      " -0.39521934 -1.47078913]\n",
      "P is: [0.5022777588234729, 0.5876925546668763, 0.18682269932953238, 0.32714306476892685, 0.5876925546668763, 0.5147636439443916, 0.32714306476892685, 0.3228854407163317, 0.32714306476892685, 0.18682269932953238, 0.5876925546668763, 0.18682269932953238, 0.8109105277257979, 0.5876925546668763, 0.8681037409197426, 0.6918378991919611, 0.40246148526417796, 0.5876925546668763, 0.40246148526417796, 0.8109105277257979, 0.40246148526417796, 0.40246148526417796, 0.25607712536926547, 0.5876925546668763, 0.5876925546668763, 0.5876925546668763, 0.32714306476892685, 0.687684871647603, 0.5147636439443916, 0.5876925546668763, 0.5876925546668763, 0.25607712536926547, 0.6875808258622915, 0.5021573107821706, 0.18682269932953238, 0.6918378991919611, 0.40871347421064746, 0.5876925546668763, 0.32714306476892685, 0.8681037409197426, 0.8681037409197426, 0.7566944616843009, 0.8681037409197426, 0.18682269932953238, 0.18682269932953238, 0.8681037409197426, 0.27965786381815105, 0.3470436427788479, 0.40246148526417796, 0.18682269932953238]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.791\n",
      "(*) epoch 2, cost 2.385\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.879\n",
      "(*) epoch 2, cost 3.684\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.6185483712222393, 1.4602059813295853, 2.4481244055958915, 2.6185483712222393, 0.8047557378003511, 2.4481244055958915, 2.614515155155544, 2.4481244055958915, 2.4481244055958915, 2.4481244055958915, 0.9751797034266988, 2.1335220933193524, 2.929117467432083, 2.4481244055958915, 1.9630981276930048, 1.9630981276930048, 2.4481244055958915, 1.2897820157032378, 1.4602059813295853, 5.066358401314782, 2.4481244055958915, 1.9630981276930048, 1.4602059813295853, 1.2897820157032378, 1.9630981276930048, 2.6185483712222393, 0.8047557378003511, 2.1335220933193524, 2.4481244055958915, 2.4481244055958915, 2.614515155155544, 1.2897820157032378, 2.4481244055958915, 2.6185483712222393, 2.4481244055958915, 1.2897820157032378, 2.1335220933193524, 2.6185483712222393, 2.4481244055958915, 2.6185483712222393, 2.6185483712222393, 2.4481244055958915, 2.4481244055958915, 2.4481244055958915, 2.6185483712222393, 2.4481244055958915, 1.2897820157032378, 1.4602059813295853, 2.614515155155544, 2.6185483712222393]\n",
      "all_sum after preprocessing is: [ 0.60164726 -1.07556386  0.35488346  0.60164726 -2.02461696  0.35488346\n",
      "  0.5958074   0.35488346  0.35488346  0.35488346 -1.77785316 -0.10064204\n",
      "  1.0513329   0.35488346 -0.34740584 -0.34740584  0.35488346 -1.32232766\n",
      " -1.07556386  4.14593108  0.35488346 -0.34740584 -1.07556386 -1.32232766\n",
      " -0.34740584  0.60164726 -2.02461696 -0.10064204  0.35488346  0.35488346\n",
      "  0.5958074  -1.32232766  0.35488346  0.60164726  0.35488346 -1.32232766\n",
      " -0.10064204  0.60164726  0.35488346  0.60164726  0.60164726  0.35488346\n",
      "  0.35488346  0.35488346  0.60164726  0.35488346 -1.32232766 -1.07556386\n",
      "  0.5958074   0.60164726]\n",
      "P is: [0.6460330823668048, 0.2543464328603099, 0.5878013016976492, 0.6460330823668048, 0.11664243092475589, 0.5878013016976492, 0.644696520711272, 0.5878013016976492, 0.5878013016976492, 0.5878013016976492, 0.14456842812779266, 0.47486070540555947, 0.7410307702593306, 0.5878013016976492, 0.4140116389108549, 0.4140116389108549, 0.5878013016976492, 0.21043129246185271, 0.2543464328603099, 0.9844179521159635, 0.5878013016976492, 0.4140116389108549, 0.2543464328603099, 0.21043129246185271, 0.4140116389108549, 0.6460330823668048, 0.11664243092475589, 0.47486070540555947, 0.5878013016976492, 0.5878013016976492, 0.644696520711272, 0.21043129246185271, 0.5878013016976492, 0.6460330823668048, 0.5878013016976492, 0.21043129246185271, 0.47486070540555947, 0.6460330823668048, 0.5878013016976492, 0.6460330823668048, 0.6460330823668048, 0.5878013016976492, 0.5878013016976492, 0.5878013016976492, 0.6460330823668048, 0.5878013016976492, 0.21043129246185271, 0.2543464328603099, 0.644696520711272, 0.6460330823668048]\n",
      "all_sum before preprocessing is: [3.0492899087105565, 3.0492899087105565, 4.384047076809567, 2.1252327242572466, 2.1252327242572466, 3.0492899087105565, 2.1252327242572466, 3.0492899087105565, 2.1252327242572466, 4.384047076809567, 2.1252327242572466, 3.0492899087105565, 4.384047076809567, 2.758334949867824, 3.0492899087105565, 3.0492899087105565, 2.1252327242572466, 2.1252327242572466, 2.1252327242572466, 3.0492899087105565, 2.1252327242572466, 3.080337709891203, 4.004394894344513, 4.384047076809567, 2.4945420982066686, 4.004394894344513, 3.0492899087105565, 2.1252327242572466, 2.1252327242572466, 4.384047076809567, 4.384047076809567, 3.0492899087105565, 2.758334949867824, 4.384047076809567, 3.0492899087105565, 3.0492899087105565, 3.682392134321134, 3.0492899087105565, 2.1252327242572466, 2.9052420818523688, 2.1252327242572466, 3.0492899087105565, 2.1252327242572466, 3.0492899087105565, 3.682392134321134, 4.384047076809567, 2.1252327242572466, 4.384047076809567, 2.758334949867824, 3.682392134321134]\n",
      "all_sum after preprocessing is: [-0.01044844 -0.01044844  1.64640941 -1.15749708 -1.15749708 -0.01044844\n",
      " -1.15749708 -0.01044844 -1.15749708  1.64640941 -1.15749708 -0.01044844\n",
      "  1.64640941 -0.37161601 -0.01044844 -0.01044844 -1.15749708 -1.15749708\n",
      " -1.15749708 -0.01044844 -1.15749708  0.02809175  1.17514039  1.64640941\n",
      " -0.69906678  1.17514039 -0.01044844 -1.15749708 -1.15749708  1.64640941\n",
      "  1.64640941 -0.01044844 -0.37161601  1.64640941 -0.01044844 -0.01044844\n",
      "  0.77543263 -0.01044844 -1.15749708 -0.18925757 -1.15749708 -0.01044844\n",
      " -1.15749708 -0.01044844  0.77543263  1.64640941 -1.15749708  1.64640941\n",
      " -0.37161601  0.77543263]\n",
      "P is: [0.49738791445932296, 0.49738791445932296, 0.8384051814918532, 0.23912237607124673, 0.23912237607124673, 0.49738791445932296, 0.23912237607124673, 0.49738791445932296, 0.23912237607124673, 0.8384051814918532, 0.23912237607124673, 0.49738791445932296, 0.8384051814918532, 0.408150594253388, 0.49738791445932296, 0.49738791445932296, 0.23912237607124673, 0.23912237607124673, 0.23912237607124673, 0.49738791445932296, 0.23912237607124673, 0.5070224760552539, 0.7640729091018592, 0.8384051814918532, 0.33201916801810255, 0.7640729091018592, 0.49738791445932296, 0.23912237607124673, 0.23912237607124673, 0.8384051814918532, 0.8384051814918532, 0.49738791445932296, 0.408150594253388, 0.8384051814918532, 0.49738791445932296, 0.49738791445932296, 0.6846949079743022, 0.49738791445932296, 0.23912237607124673, 0.452826330574132, 0.23912237607124673, 0.49738791445932296, 0.23912237607124673, 0.49738791445932296, 0.6846949079743022, 0.8384051814918532, 0.23912237607124673, 0.8384051814918532, 0.408150594253388, 0.6846949079743022]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.574\n",
      "(*) epoch 2, cost 2.012\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.017\n",
      "(*) epoch 2, cost 3.347\n",
      "(*) epoch 3, cost 2.862\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.1494625598738026, 3.6857605604235824, 4.311985616099209, 5.266846245290118, 3.3318608154675835, 3.0220620063376935, 3.3318608154675835, 1.5056392051562892, 3.4406246349788234, 5.266846245290118, 3.0220620063376935, 1.5056392051562892, 3.6857605604235824, 1.8595389501122879, 1.5056392051562892, 2.7955628149178042, 3.3318608154675835, 3.1494625598738026, 3.6857605604235824, 3.0220620063376935, 1.5056392051562892, 3.3318608154675835, 3.3318608154675835, 5.266846245290118, 3.6857605604235824, 1.5056392051562892, 3.3318608154675835, 6.7832690464715215, 3.6857605604235824, 3.3318608154675835, 1.5056392051562892, 5.266846245290118, 3.4406246349788234, 3.1494625598738026, 3.3318608154675835, 3.3318608154675835, 4.433643209038534, 3.3318608154675835, 3.6857605604235824, 3.3318608154675835, 1.8595389501122879, 1.8595389501122879, 3.2582263793850426, 3.3318608154675835, 2.4857640057879142, 1.5056392051562892, 3.6857605604235824, 3.3318608154675835, 3.1494625598738026, 3.6857605604235824]\n",
      "all_sum after preprocessing is: [-0.09278664  0.39256056  0.95929132  1.82343575  0.07228293 -0.20808355\n",
      "  0.07228293 -1.58043913  0.17071369  1.82343575 -0.20808355 -1.58043913\n",
      "  0.39256056 -1.26016151 -1.58043913 -0.41306426  0.07228293 -0.09278664\n",
      "  0.39256056 -0.20808355 -1.58043913  0.07228293  0.07228293  1.82343575\n",
      "  0.39256056 -1.58043913  0.07228293  3.19579134  0.39256056  0.07228293\n",
      " -1.58043913  1.82343575  0.17071369 -0.09278664  0.07228293  0.07228293\n",
      "  1.06939088  0.07228293  0.39256056  0.07228293 -1.26016151 -1.26016151\n",
      "  0.00564411  0.07228293 -0.69343074 -1.58043913  0.39256056  0.07228293\n",
      " -0.09278664  0.39256056]\n",
      "P is: [0.47681996840568813, 0.5968989493785188, 0.7229798936533358, 0.860977879609705, 0.5180628697591501, 0.4481660073429614, 0.5180628697591501, 0.17073329918929378, 0.5425750739266904, 0.860977879609705, 0.4481660073429614, 0.17073329918929378, 0.5968989493785188, 0.22094609071392696, 0.17073329918929378, 0.39817759660674307, 0.5180628697591501, 0.47681996840568813, 0.5968989493785188, 0.4481660073429614, 0.17073329918929378, 0.5180628697591501, 0.5180628697591501, 0.860977879609705, 0.5968989493785188, 0.17073329918929378, 0.5180628697591501, 0.9606755902523982, 0.5968989493785188, 0.5180628697591501, 0.17073329918929378, 0.860977879609705, 0.5425750739266904, 0.47681996840568813, 0.5180628697591501, 0.5180628697591501, 0.744481060508036, 0.5180628697591501, 0.5968989493785188, 0.5180628697591501, 0.22094609071392696, 0.22094609071392696, 0.5014110243574575, 0.5180628697591501, 0.33327032213060015, 0.17073329918929378, 0.5968989493785188, 0.5180628697591501, 0.47681996840568813, 0.5968989493785188]\n",
      "all_sum before preprocessing is: [2.606307691301161, 2.606307691301161, 2.606307691301161, 2.606307691301161, 1.4838668339942105, 2.606307691301161, 2.606307691301161, 2.606307691301161, 3.293447764087745, 1.4838668339942105, 2.606307691301161, 1.4838668339942105, 2.606307691301161, 1.4838668339942105, 2.606307691301161, 1.4838668339942105, 2.606307691301161, 3.293447764087745, 2.606307691301161, 1.5377677682783992, 1.4838668339942105, 1.4838668339942105, 2.606307691301161, 1.4838668339942105, 2.6602086255853497, 2.606307691301161, 1.3857655920566327, 2.606307691301161, 2.606307691301161, 3.293447764087745, 2.606307691301161, 2.606307691301161, 2.1710069067807947, 2.606307691301161, 1.4838668339942105, 1.4838668339942105, 1.8210663765769992, 1.5377677682783992, 0.6986255192700486, 2.606307691301161, 1.4838668339942105, 2.6602086255853497, 2.6602086255853497, 2.1710069067807947, 1.4838668339942105, 2.1710069067807947, 3.293447764087745, 2.606307691301161, 2.606307691301161, 1.4838668339942105]\n",
      "all_sum after preprocessing is: [ 0.60776471  0.60776471  0.60776471  0.60776471 -1.18387032  0.60776471\n",
      "  0.60776471  0.60776471  1.70457459 -1.18387032  0.60776471 -1.18387032\n",
      "  0.60776471 -1.18387032  0.60776471 -1.18387032  0.60776471  1.70457459\n",
      "  0.60776471 -1.0978339  -1.18387032 -1.18387032  0.60776471 -1.18387032\n",
      "  0.69380114  0.60776471 -1.34045908  0.60776471  0.60776471  1.70457459\n",
      "  0.60776471  0.60776471 -0.08706044  0.60776471 -1.18387032 -1.18387032\n",
      " -0.64563394 -1.0978339  -2.43726897  0.60776471 -1.18387032  0.69380114\n",
      "  0.69380114 -0.08706044 -1.18387032 -0.08706044  1.70457459  0.60776471\n",
      "  0.60776471 -1.18387032]\n",
      "P is: [0.6474307331016061, 0.6474307331016061, 0.6474307331016061, 0.6474307331016061, 0.23435701527778416, 0.6474307331016061, 0.6474307331016061, 0.6474307331016061, 0.8461312588263047, 0.23435701527778416, 0.6474307331016061, 0.23435701527778416, 0.6474307331016061, 0.23435701527778416, 0.6474307331016061, 0.23435701527778416, 0.6474307331016061, 0.8461312588263047, 0.6474307331016061, 0.2501459769044406, 0.23435701527778416, 0.23435701527778416, 0.6474307331016061, 0.23435701527778416, 0.6668119740903702, 0.6474307331016061, 0.20743457242195845, 0.6474307331016061, 0.6474307331016061, 0.8461312588263047, 0.6474307331016061, 0.6474307331016061, 0.47824862676674557, 0.6474307331016061, 0.23435701527778416, 0.23435701527778416, 0.343974093160802, 0.2501459769044406, 0.0803745437584634, 0.6474307331016061, 0.23435701527778416, 0.6668119740903702, 0.6668119740903702, 0.47824862676674557, 0.23435701527778416, 0.47824862676674557, 0.8461312588263047, 0.6474307331016061, 0.6474307331016061, 0.23435701527778416]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.753\n",
      "(*) epoch 2, cost 3.146\n",
      "(*) epoch 3, cost 2.609\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.497\n",
      "(*) epoch 2, cost 2.927\n",
      "(*) epoch 3, cost 2.483\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.4292179120531587, 2.531238023560574, 3.5935098425886394, 2.531238023560574, 3.957843600300356, 2.3669460930250934, 3.5935098425886394, 5.013445413621083, 2.531238023560574, 3.957843600300356, 3.5935098425886394, 2.531238023560574, 3.5935098425886394, 2.531238023560574, 3.4292179120531587, 2.531238023560574, 3.101813023181284, 2.531238023560574, 3.5935098425886394, 2.3669460930250934, 3.5935098425886394, 3.5935098425886394, 3.101813023181284, 3.5935098425886394, 2.531238023560574, 3.5935098425886394, 3.957843600300356, 2.8955717812722903, 3.5935098425886394, 3.5935098425886394, 3.5935098425886394, 2.0395412041532186, 2.8955717812722903, 3.4292179120531587, 3.101813023181284, 2.531238023560574, 3.434858582972261, 2.3669460930250934, 2.531238023560574, 3.5935098425886394, 2.0395412041532186, 2.9375210926458033, 2.531238023560574, 3.7935516697648755, 3.5935098425886394, 3.5935098425886394, 3.5935098425886394, 2.531238023560574, 5.451616674947748, 3.957843600300356]\n",
      "all_sum after preprocessing is: [ 0.30425663 -0.98897023  0.54086186 -0.98897023  1.06555758 -1.22557546\n",
      "  0.54086186  2.58578386 -0.98897023  1.06555758  0.54086186 -0.98897023\n",
      "  0.54086186 -0.98897023  0.30425663 -0.98897023 -0.16725593 -0.98897023\n",
      "  0.54086186 -1.22557546  0.54086186  0.54086186 -0.16725593  0.54086186\n",
      " -0.98897023  0.54086186  1.06555758 -0.46427451  0.54086186  0.54086186\n",
      "  0.54086186 -1.69708802 -0.46427451  0.30425663 -0.16725593 -0.98897023\n",
      "  0.31238005 -1.22557546 -0.98897023  0.54086186 -1.69708802 -0.40386116\n",
      " -0.98897023  0.82895235  0.54086186  0.54086186  0.54086186 -0.98897023\n",
      "  3.21681675  1.06555758]\n",
      "P is: [0.5754827554092001, 0.2711155250930769, 0.6320128866262771, 0.2711155250930769, 0.7437511732467869, 0.22695676238346868, 0.6320128866262771, 0.9299410298250921, 0.2711155250930769, 0.7437511732467869, 0.6320128866262771, 0.2711155250930769, 0.6320128866262771, 0.2711155250930769, 0.5754827554092001, 0.2711155250930769, 0.4582832238146768, 0.2711155250930769, 0.6320128866262771, 0.22695676238346868, 0.6320128866262771, 0.6320128866262771, 0.4582832238146768, 0.6320128866262771, 0.2711155250930769, 0.6320128866262771, 0.7437511732467869, 0.38597228264761313, 0.6320128866262771, 0.6320128866262771, 0.6320128866262771, 0.15484596950747118, 0.38597228264761313, 0.5754827554092001, 0.4582832238146768, 0.2711155250930769, 0.5774660988128228, 0.22695676238346868, 0.2711155250930769, 0.6320128866262771, 0.15484596950747118, 0.4003850102320838, 0.2711155250930769, 0.6961333647626536, 0.6320128866262771, 0.6320128866262771, 0.6320128866262771, 0.2711155250930769, 0.9614622398376483, 0.7437511732467869]\n",
      "all_sum before preprocessing is: [2.6535058986282967, 2.6535058986282967, 2.6535058986282967, 2.109900911545028, 2.8942241405394964, 2.8942241405394964, 2.6535058986282967, 2.6535058986282967, 2.6535058986282967, 2.8942241405394964, 2.109900911545028, 1.8693330805870674, 2.6535058986282967, 2.8942241405394964, 2.6535058986282967, 2.8942241405394964, 3.7988730157602717, 3.7988730157602717, 2.6535058986282967, 2.8942241405394964, 2.6535058986282967, 2.6535058986282967, 2.6535058986282967, 2.109900911545028, 2.6535058986282967, 2.8942241405394964, 2.109900911545028, 3.5563737072632136, 1.8691826696338283, 3.0145497867658033, 2.533263713896643, 2.8942241405394964, 2.6535058986282967, 2.6535058986282967, 3.7988730157602717, 3.7988730157602717, 3.558154773849072, 3.7988730157602717, 1.8691826696338283, 2.6535058986282967, 2.772050478268745, 2.109900911545028, 2.6535058986282967, 2.8942241405394964, 3.558154773849072, 2.8942241405394964, 2.6535058986282967, 2.8942241405394964, 2.8942241405394964, 2.6535058986282967]\n",
      "all_sum after preprocessing is: [-0.26664899 -0.26664899 -0.26664899 -1.36209219  0.21843332  0.21843332\n",
      " -0.26664899 -0.26664899 -0.26664899  0.21843332 -1.36209219 -1.8468714\n",
      " -0.26664899  0.21843332 -0.26664899  0.21843332  2.04143253  2.04143253\n",
      " -0.26664899  0.21843332 -0.26664899 -0.26664899 -0.26664899 -1.36209219\n",
      " -0.26664899  0.21843332 -1.36209219  1.55276111 -1.8471745   0.46090702\n",
      " -0.5089545   0.21843332 -0.26664899 -0.26664899  2.04143253  2.04143253\n",
      "  1.55635022  2.04143253 -1.8471745  -0.26664899 -0.0277644  -1.36209219\n",
      " -0.26664899  0.21843332  1.55635022  0.21843332 -0.26664899  0.21843332\n",
      "  0.21843332 -0.26664899]\n",
      "P is: [0.4337299476574502, 0.4337299476574502, 0.4337299476574502, 0.20390047679868023, 0.5543922330633091, 0.5543922330633091, 0.4337299476574502, 0.4337299476574502, 0.4337299476574502, 0.5543922330633091, 0.20390047679868023, 0.1362406492066045, 0.4337299476574502, 0.5543922330633091, 0.4337299476574502, 0.5543922330633091, 0.8850790566360541, 0.8850790566360541, 0.4337299476574502, 0.5543922330633091, 0.4337299476574502, 0.4337299476574502, 0.4337299476574502, 0.20390047679868023, 0.4337299476574502, 0.5543922330633091, 0.20390047679868023, 0.8253121643472938, 0.13620498459667116, 0.6132293237127662, 0.3754386472842734, 0.5543922330633091, 0.4337299476574502, 0.4337299476574502, 0.8850790566360541, 0.8850790566360541, 0.8258290092709722, 0.8850790566360541, 0.13620498459667116, 0.4337299476574502, 0.4930593459499228, 0.20390047679868023, 0.4337299476574502, 0.5543922330633091, 0.8258290092709722, 0.5543922330633091, 0.4337299476574502, 0.5543922330633091, 0.5543922330633091, 0.4337299476574502]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.854\n",
      "(*) epoch 2, cost 4.156\n",
      "(*) epoch 3, cost 3.571\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.646\n",
      "(*) epoch 2, cost 3.214\n",
      "(*) epoch 3, cost 2.559\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7551645505256193, 1.7551645505256193, 1.7551645505256193, 1.7551645505256193, 1.7551645505256193, 1.7551645505256193, 1.985065797067894, 1.985065797067894, 1.7551645505256193, 1.985065797067894, 1.7551645505256193, 1.016456116321435, 1.7551645505256193, 1.7551645505256193, 2.0542747426676695, 1.016456116321435, 1.7551645505256193, 1.2463573628637095, 1.7551645505256193, 1.7551645505256193, 1.2463573628637095, 1.985065797067894, 1.7551645505256193, 1.7551645505256193, 1.985065797067894, 1.7551645505256193, 1.985065797067894, 1.7551645505256193, 1.7551645505256193, 1.985065797067894, 1.7551645505256193, 1.7551645505256193, 1.016456116321435, 1.985065797067894, 1.985065797067894, 1.016456116321435, 1.7551645505256193, 1.7551645505256193, 1.985065797067894, 1.985065797067894, 1.016456116321435, 1.016456116321435, 1.7551645505256193, 1.7551645505256193, 2.0542747426676695, 2.0542747426676695, 1.7551645505256193, 1.985065797067894, 1.985065797067894, 1.7551645505256193]\n",
      "all_sum after preprocessing is: [ 0.10202842  0.10202842  0.10202842  0.10202842  0.10202842  0.10202842\n",
      "  0.85200248  0.85200248  0.10202842  0.85200248  0.10202842 -2.30775479\n",
      "  0.10202842  0.10202842  1.07777296 -2.30775479  0.10202842 -1.55778073\n",
      "  0.10202842  0.10202842 -1.55778073  0.85200248  0.10202842  0.10202842\n",
      "  0.85200248  0.10202842  0.85200248  0.10202842  0.10202842  0.85200248\n",
      "  0.10202842  0.10202842 -2.30775479  0.85200248  0.85200248 -2.30775479\n",
      "  0.10202842  0.10202842  0.85200248  0.85200248 -2.30775479 -2.30775479\n",
      "  0.10202842  0.10202842  1.07777296  1.07777296  0.10202842  0.85200248\n",
      "  0.85200248  0.10202842]\n",
      "P is: [0.5254850018443217, 0.5254850018443217, 0.5254850018443217, 0.5254850018443217, 0.5254850018443217, 0.5254850018443217, 0.7009870403898694, 0.7009870403898694, 0.5254850018443217, 0.7009870403898694, 0.5254850018443217, 0.09048274605818096, 0.5254850018443217, 0.5254850018443217, 0.746072305451652, 0.09048274605818096, 0.5254850018443217, 0.17396532896637998, 0.5254850018443217, 0.5254850018443217, 0.17396532896637998, 0.7009870403898694, 0.5254850018443217, 0.5254850018443217, 0.7009870403898694, 0.5254850018443217, 0.7009870403898694, 0.5254850018443217, 0.5254850018443217, 0.7009870403898694, 0.5254850018443217, 0.5254850018443217, 0.09048274605818096, 0.7009870403898694, 0.7009870403898694, 0.09048274605818096, 0.5254850018443217, 0.5254850018443217, 0.7009870403898694, 0.7009870403898694, 0.09048274605818096, 0.09048274605818096, 0.5254850018443217, 0.5254850018443217, 0.746072305451652, 0.746072305451652, 0.5254850018443217, 0.7009870403898694, 0.7009870403898694, 0.5254850018443217]\n",
      "all_sum before preprocessing is: [2.052365533014552, 1.2359198368105462, 1.5305681870668528, 2.4042106034726, 1.1615137356890206, 1.3823379276816024, 2.052365533014552, 1.1615137356890206, 2.1833864114800177, 1.5133588061470682, 1.8315413410219703, 2.4042106034726, 1.8634765925339196, 1.3823379276816024, 0.7867164234701783, 1.8634765925339196, 1.1615137356890206, 1.8634765925339196, 2.754328389859451, 1.1615137356890206, 1.2359198368105462, 1.8315413410219703, 1.7341829981396502, 1.8315413410219703, 3.031767359195973, 1.2359198368105462, 2.2153216629919674, 2.052365533014552, 0.5658922314775965, 2.779007915691442, 1.2359198368105462, 0.5658922314775965, 2.2005957923998025, 1.1615137356890206, 1.8315413410219703, 2.779007915691442, 1.9797716004072206, 1.1615137356890206, 1.3823379276816024, 0.7867164234701783, 2.344616524033393, 1.1615137356890206, 0.5658922314775965, 1.1615137356890206, 1.2359198368105462, 0.7141224908628467, 1.1615137356890206, 1.456744028803128, 2.052365533014552, 2.158706885648027]\n",
      "all_sum after preprocessing is: [ 0.69605768 -0.64066489 -0.15825301  1.27211467 -0.76248599 -0.40094243\n",
      "  0.69605768 -0.76248599  0.91057111 -0.186429    0.33451412  1.27211467\n",
      "  0.38679999 -0.40094243 -1.37612144  0.38679999 -0.76248599  0.38679999\n",
      "  1.84534366 -0.76248599 -0.64066489  0.33451412  0.17511455  0.33451412\n",
      "  2.29957954 -0.64066489  0.96285698  0.69605768 -1.737665    1.88575012\n",
      " -0.64066489 -1.737665    0.9387471  -0.76248599  0.33451412  1.88575012\n",
      "  0.57720355 -0.76248599 -0.40094243 -1.37612144  1.17454449 -0.76248599\n",
      " -1.737665   -0.76248599 -0.64066489 -1.49497558 -0.76248599 -0.27912133\n",
      "  0.69605768  0.87016465]\n",
      "P is: [0.6673131306395812, 0.34509625654713855, 0.46051910964928167, 0.7811045289922955, 0.31810677486288913, 0.4010859317657742, 0.6673131306395812, 0.31810677486288913, 0.7131170152234569, 0.45352727094946843, 0.5828573258940697, 0.7811045289922955, 0.5955121258363101, 0.4010859317657742, 0.20163263562548553, 0.5955121258363101, 0.31810677486288913, 0.5955121258363101, 0.8635794680262904, 0.31810677486288913, 0.34509625654713855, 0.5828573258940697, 0.5436671073355663, 0.5828573258940697, 0.9088422110383643, 0.34509625654713855, 0.7236934547228373, 0.6673131306395812, 0.1496097660498551, 0.8682702021357682, 0.34509625654713855, 0.1496097660498551, 0.7188465084282757, 0.31810677486288913, 0.5828573258940697, 0.8682702021357682, 0.6404236886608434, 0.31810677486288913, 0.4010859317657742, 0.20163263562548553, 0.7639654710157261, 0.31810677486288913, 0.1496097660498551, 0.31810677486288913, 0.34509625654713855, 0.1831760945882128, 0.31810677486288913, 0.43066920711615625, 0.6673131306395812, 0.7047799573149556]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.585\n",
      "(*) epoch 2, cost 1.246\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.935\n",
      "(*) epoch 2, cost 3.650\n",
      "(*) epoch 3, cost 2.968\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.8659684052839074, 3.6413549412337587, 3.786491951336862, 0.8659684052839074, 1.1492363255729725, 2.251757412729799, 2.6839708641800355, 3.6413549412337587, 2.1066204026266955, 2.4007029438909706, 3.5303351564244156, 4.069759871625927, 1.1492363255729725, 4.743876028390585, 5.02714394867965, 2.669716774582011, 3.492409410072587, 2.669716774582011, 4.069759871625927, 2.1066204026266955, 3.209141489783522, 2.5350253330188637, 4.9161241638703075, 2.6839708641800355, 1.9956006178173529, 3.786491951336862, 2.5350253330188637, 3.6413549412337587, 4.9161241638703075, 3.786491951336862, 2.952984694871076, 2.5350253330188637, 2.6839708641800355, 2.6839708641800355, 3.492409410072587, 2.6839708641800355, 3.6413549412337587, 2.5350253330188637, 4.338773702316967, 0.8659684052839074, 3.786491951336862, 4.069759871625927, 5.02714394867965, 5.02714394867965, 2.6839708641800355, 2.1066204026266955, 4.069759871625927, 4.2044513131890735, 5.87350824092403, 3.5303351564244156]\n",
      "all_sum after preprocessing is: [-1.98742034  0.38149616  0.50537709 -1.98742034 -1.74563851 -0.80458746\n",
      " -0.43567395  0.38149616 -0.92846839 -0.67745579  0.28673581  0.74715893\n",
      " -1.74563851  1.32254721  1.56432905 -0.44784046  0.25436449 -0.44784046\n",
      "  0.74715893 -0.92846839  0.01258266 -0.56280562  1.4695687  -0.43567395\n",
      " -1.02322874  0.50537709 -0.56280562  0.38149616  1.4695687   0.50537709\n",
      " -0.20605862 -0.56280562 -0.43567395 -0.43567395  0.25436449 -0.43567395\n",
      "  0.38149616 -0.56280562  0.97677426 -1.98742034  0.50537709  0.74715893\n",
      "  1.56432905  1.56432905 -0.43567395 -0.92846839  0.74715893  0.8621241\n",
      "  2.28673881  0.28673581]\n",
      "P is: [0.12053004523711311, 0.5942339089716074, 0.6237221333716558, 0.12053004523711311, 0.1485981547622604, 0.30904507286656663, 0.39277226097265333, 0.5942339089716074, 0.28323554870067547, 0.3368293804206011, 0.571196819123195, 0.6785593290711206, 0.1485981547622604, 0.7896051838590037, 0.8269736656655979, 0.3898743394722625, 0.5632504584964169, 0.3898743394722625, 0.6785593290711206, 0.28323554870067547, 0.5031456230288508, 0.36289854130367694, 0.8129918211493757, 0.39277226097265333, 0.2643989587817693, 0.6237221333716558, 0.36289854130367694, 0.5942339089716074, 0.8129918211493757, 0.6237221333716558, 0.4486668510203539, 0.36289854130367694, 0.39277226097265333, 0.39277226097265333, 0.5632504584964169, 0.39277226097265333, 0.5942339089716074, 0.36289854130367694, 0.7264676906864946, 0.12053004523711311, 0.6237221333716558, 0.6785593290711206, 0.8269736656655979, 0.8269736656655979, 0.39277226097265333, 0.28323554870067547, 0.6785593290711206, 0.7031042478792823, 0.9077727820315656, 0.571196819123195]\n",
      "all_sum before preprocessing is: [4.834136566462903, 2.4973335812526654, 4.834136566462903, 4.031790479569919, 4.834136566462903, 2.4973335812526654, 2.6581142443779506, 3.8872592930114176, 4.834136566462903, 1.6949874943596812, 4.834136566462903, 4.031790479569919, 1.6949874943596812, 4.031790479569919, 4.834136566462903, 1.4755699432802545, 2.4973335812526654, 2.4973335812526654, 4.94378281952415, 4.834136566462903, 4.031790479569919, 4.834136566462903, 1.6949874943596812, 2.4973335812526654, 2.4973335812526654, 4.031790479569919, 4.031790479569919, 4.031790479569919, 2.4973335812526654, 4.834136566462903, 4.834136566462903, 4.834136566462903, 4.141436732631167, 1.6949874943596812, 4.834136566462903, 4.834136566462903, 2.4973335812526654, 4.031790479569919, 4.834136566462903, 4.031790479569919, 1.6949874943596812, 6.333708531282903, 4.031790479569919, 4.834136566462903, 4.834136566462903, 4.031790479569919, 4.031790479569919, 4.031790479569919, 4.834136566462903, 4.834136566462903]\n",
      "all_sum after preprocessing is: [ 0.85043815 -1.1216588   0.85043815  0.17331462  0.85043815 -1.1216588\n",
      " -0.98597126  0.05134049  0.85043815 -1.79878232  0.85043815  0.17331462\n",
      " -1.79878232  0.17331462  0.85043815 -1.98395527 -1.1216588  -1.1216588\n",
      "  0.94297185  0.85043815  0.17331462  0.85043815 -1.79878232 -1.1216588\n",
      " -1.1216588   0.17331462  0.17331462  0.17331462 -1.1216588   0.85043815\n",
      "  0.85043815  0.85043815  0.26584833 -1.79878232  0.85043815  0.85043815\n",
      " -1.1216588   0.17331462  0.85043815  0.17331462 -1.79878232  2.11597115\n",
      "  0.17331462  0.85043815  0.85043815  0.17331462  0.17331462  0.17331462\n",
      "  0.85043815  0.85043815]\n",
      "P is: [0.7006590455662122, 0.24570372251335262, 0.7006590455662122, 0.543220521987346, 0.7006590455662122, 0.24570372251335262, 0.27170856347024513, 0.5128323047585435, 0.7006590455662122, 0.14199935639851288, 0.7006590455662122, 0.543220521987346, 0.14199935639851288, 0.543220521987346, 0.7006590455662122, 0.12089783536538674, 0.24570372251335262, 0.24570372251335262, 0.7196995667081326, 0.7006590455662122, 0.543220521987346, 0.7006590455662122, 0.14199935639851288, 0.24570372251335262, 0.24570372251335262, 0.543220521987346, 0.543220521987346, 0.543220521987346, 0.24570372251335262, 0.7006590455662122, 0.7006590455662122, 0.7006590455662122, 0.5660733934654911, 0.14199935639851288, 0.7006590455662122, 0.7006590455662122, 0.24570372251335262, 0.543220521987346, 0.7006590455662122, 0.543220521987346, 0.14199935639851288, 0.892445825959903, 0.543220521987346, 0.7006590455662122, 0.7006590455662122, 0.543220521987346, 0.543220521987346, 0.543220521987346, 0.7006590455662122, 0.7006590455662122]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.561\n",
      "(*) epoch 2, cost 3.771\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.411\n",
      "(*) epoch 2, cost 3.431\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.3214925401529868, 1.806977197080887, 1.547213200455725, 1.806977197080887, 0.5812565367781487, 0.3214925401529868, 0.3214925401529868, 1.806977197080887, 0.5812565367781487, 1.547213200455725, 1.547213200455725, 1.806977197080887, 0.3214925401529868, 1.547213200455725, 0.3214925401529868, 0.3214925401529868, 1.806977197080887, 0.3214925401529868, 1.806977197080887, 1.547213200455725, 1.547213200455725, 0.3214925401529868, 0.5812565367781487, 0.3214925401529868, 0.3214925401529868, 1.547213200455725, 1.806977197080887, 1.806977197080887, 0.3214925401529868, 1.806977197080887, 1.547213200455725, 1.806977197080887, 1.806977197080887, 1.547213200455725, 1.547213200455725, 0.3214925401529868, 0.3214925401529868, 1.547213200455725, 1.547213200455725, 1.547213200455725, 1.806977197080887, 1.806977197080887, 0.3214925401529868, 0.3214925401529868, 1.806977197080887, 1.547213200455725, 0.5812565367781487, 1.547213200455725, 1.547213200455725, 1.806977197080887]\n",
      "all_sum after preprocessing is: [-1.33957551  0.97790233  0.5726492   0.97790233 -0.93432238 -1.33957551\n",
      " -1.33957551  0.97790233 -0.93432238  0.5726492   0.5726492   0.97790233\n",
      " -1.33957551  0.5726492  -1.33957551 -1.33957551  0.97790233 -1.33957551\n",
      "  0.97790233  0.5726492   0.5726492  -1.33957551 -0.93432238 -1.33957551\n",
      " -1.33957551  0.5726492   0.97790233  0.97790233 -1.33957551  0.97790233\n",
      "  0.5726492   0.97790233  0.97790233  0.5726492   0.5726492  -1.33957551\n",
      " -1.33957551  0.5726492   0.5726492   0.5726492   0.97790233  0.97790233\n",
      " -1.33957551 -1.33957551  0.97790233  0.5726492  -0.93432238  0.5726492\n",
      "  0.5726492   0.97790233]\n",
      "P is: [0.20757987375679393, 0.7266917952282161, 0.6393742398798644, 0.7266917952282161, 0.28204861998378605, 0.20757987375679393, 0.20757987375679393, 0.7266917952282161, 0.28204861998378605, 0.6393742398798644, 0.6393742398798644, 0.7266917952282161, 0.20757987375679393, 0.6393742398798644, 0.20757987375679393, 0.20757987375679393, 0.7266917952282161, 0.20757987375679393, 0.7266917952282161, 0.6393742398798644, 0.6393742398798644, 0.20757987375679393, 0.28204861998378605, 0.20757987375679393, 0.20757987375679393, 0.6393742398798644, 0.7266917952282161, 0.7266917952282161, 0.20757987375679393, 0.7266917952282161, 0.6393742398798644, 0.7266917952282161, 0.7266917952282161, 0.6393742398798644, 0.6393742398798644, 0.20757987375679393, 0.20757987375679393, 0.6393742398798644, 0.6393742398798644, 0.6393742398798644, 0.7266917952282161, 0.7266917952282161, 0.20757987375679393, 0.20757987375679393, 0.7266917952282161, 0.6393742398798644, 0.28204861998378605, 0.6393742398798644, 0.6393742398798644, 0.7266917952282161]\n",
      "all_sum before preprocessing is: [3.8217720498407153, 4.871756181313912, 5.732767931296241, 4.553366273807338, 4.871756181313912, 4.675760114664956, 5.725744246138152, 3.814748364682627, 4.871756181313912, 5.732767931296241, 4.553366273807338, 4.871756181313912, 2.635346707193725, 5.732767931296241, 4.54634258864925, 5.407354338631579, 3.8217720498407153, 3.814748364682627, 4.08043983796441, 3.814748364682627, 3.496358457176054, 4.276435904613366, 5.732767931296241, 4.871756181313912, 5.725744246138152, 5.732767931296241, 5.732767931296241, 4.553366273807338, 3.496358457176054, 5.725744246138152, 3.8217720498407153, 5.732767931296241, 2.960760299858386, 5.732767931296241, 5.725744246138152, 3.496358457176054, 5.732767931296241, 4.675760114664956, 2.960760299858386, 5.725744246138152, 4.675760114664956, 3.814748364682627, 5.725744246138152, 4.871756181313912, 5.463407252798906, 2.642370392351813, 4.54634258864925, 3.8217720498407153, 5.725744246138152, 1.781358642369484]\n",
      "all_sum after preprocessing is: [-0.77983037  0.24777884  1.09044262 -0.06382625  0.24777884  0.0559594\n",
      "  1.08356861 -0.78670438  0.24777884  1.09044262 -0.06382625  0.24777884\n",
      " -1.94097325  1.09044262 -0.07070026  0.77196352 -0.77983037 -0.78670438\n",
      " -0.52667473 -0.78670438 -1.09830947 -0.3348553   1.09044262  0.24777884\n",
      "  1.08356861  1.09044262  1.09044262 -0.06382625 -1.09830947  1.08356861\n",
      " -0.77983037  1.09044262 -1.62249415  1.09044262  1.08356861 -1.09830947\n",
      "  1.09044262  0.0559594  -1.62249415  1.08356861  0.0559594  -0.78670438\n",
      "  1.08356861  0.24777884  0.82682196 -1.93409924 -0.07070026 -0.77983037\n",
      "  1.08356861 -2.77676302]\n",
      "P is: [0.31435644714330824, 0.5616297215844376, 0.7484650602152438, 0.4840488515867836, 0.5616297215844376, 0.5139862010730333, 0.74716871457434, 0.31287674095912416, 0.5616297215844376, 0.7484650602152438, 0.4840488515867836, 0.5616297215844376, 0.12554097390885724, 0.7484650602152438, 0.4823322925845277, 0.6839454885894691, 0.31435644714330824, 0.31287674095912416, 0.37129278751841605, 0.31287674095912416, 0.2500567832296892, 0.4170597256285593, 0.7484650602152438, 0.5616297215844376, 0.74716871457434, 0.7484650602152438, 0.7484650602152438, 0.4840488515867836, 0.2500567832296892, 0.74716871457434, 0.31435644714330824, 0.7484650602152438, 0.16486118396001356, 0.7484650602152438, 0.74716871457434, 0.2500567832296892, 0.7484650602152438, 0.5139862010730333, 0.16486118396001356, 0.74716871457434, 0.5139862010730333, 0.31287674095912416, 0.74716871457434, 0.5616297215844376, 0.6956825299453875, 0.12629755043016577, 0.4823322925845277, 0.31435644714330824, 0.74716871457434, 0.05859285170551586]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.430\n",
      "(*) epoch 2, cost 2.035\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.776\n",
      "(*) epoch 2, cost 4.348\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.8139724207017776, 2.639817952197862, 3.0531498254569134, 2.8139724207017776, 2.639817952197862, 2.639817952197862, 3.0531498254569134, 3.0531498254569134, 2.860016689213142, 2.8139724207017776, 2.8139724207017776, 2.8139724207017776, 2.8139724207017776, 2.639817952197862, 2.8139724207017776, 2.639817952197862, 3.0531498254569134, 1.7231723917093755, 2.8139724207017776, 2.8139724207017776, 2.8139724207017776, 2.8139724207017776, 1.7231723917093755, 3.0531498254569134, 2.8139724207017776, 2.620839284458006, 2.860016689213142, 2.8139724207017776, 3.0531498254569134, 2.8139724207017776, 2.620839284458006, 2.8139724207017776, 2.8139724207017776, 2.639817952197862, 3.0531498254569134, 2.8139724207017776, 3.0531498254569134, 2.878995356952998, 3.0531498254569134, 2.8139724207017776, 3.0531498254569134, 3.0531498254569134, 2.8139724207017776, 3.0531498254569134, 2.639817952197862, 2.8139724207017776, 3.0531498254569134, 2.639817952197862, 3.0531498254569134, 2.860016689213142]\n",
      "all_sum after preprocessing is: [ 0.03093018 -0.62683793  0.93428496  0.03093018 -0.62683793 -0.62683793\n",
      "  0.93428496  0.93428496  0.20483587  0.03093018  0.03093018  0.03093018\n",
      "  0.03093018 -0.62683793  0.03093018 -0.62683793  0.93428496 -4.08893816\n",
      "  0.03093018  0.03093018  0.03093018  0.03093018 -4.08893816  0.93428496\n",
      "  0.03093018 -0.69851891  0.20483587  0.03093018  0.93428496  0.03093018\n",
      " -0.69851891  0.03093018  0.03093018 -0.62683793  0.93428496  0.03093018\n",
      "  0.93428496  0.27651684  0.93428496  0.03093018  0.93428496  0.93428496\n",
      "  0.03093018  0.93428496 -0.62683793  0.03093018  0.93428496 -0.62683793\n",
      "  0.93428496  0.20483587]\n",
      "P is: [0.5077319296537163, 0.3482278721202801, 0.7179438022986996, 0.5077319296537163, 0.3482278721202801, 0.3482278721202801, 0.7179438022986996, 0.7179438022986996, 0.5510306639178727, 0.5077319296537163, 0.5077319296537163, 0.5077319296537163, 0.5077319296537163, 0.3482278721202801, 0.5077319296537163, 0.3482278721202801, 0.7179438022986996, 0.016480847550028013, 0.5077319296537163, 0.5077319296537163, 0.5077319296537163, 0.5077319296537163, 0.016480847550028013, 0.7179438022986996, 0.5077319296537163, 0.33214068611664155, 0.5510306639178727, 0.5077319296537163, 0.7179438022986996, 0.5077319296537163, 0.33214068611664155, 0.5077319296537163, 0.5077319296537163, 0.3482278721202801, 0.7179438022986996, 0.5077319296537163, 0.7179438022986996, 0.5686920760334487, 0.7179438022986996, 0.5077319296537163, 0.7179438022986996, 0.7179438022986996, 0.5077319296537163, 0.7179438022986996, 0.3482278721202801, 0.5077319296537163, 0.7179438022986996, 0.3482278721202801, 0.7179438022986996, 0.5510306639178727]\n",
      "all_sum before preprocessing is: [4.737544435144828, 4.166148106246227, 3.126911761948066, 4.885395797172135, 2.555515433049465, 4.313999468273534, 2.555515433049465, 4.885395797172135, 3.126911761948066, 2.555515433049465, 4.737544435144828, 2.555515433049465, 2.555515433049465, 3.331361807137264, 2.555515433049465, 2.555515433049465, 2.407664071022158, 2.979060399920759, 2.555515433049465, 2.555515433049465, 3.126911761948066, 2.407664071022158, 2.555515433049465, 2.7599654782386627, 2.7599654782386627, 2.407664071022158, 2.555515433049465, 2.555515433049465, 4.313999468273534, 2.979060399920759, 2.555515433049465, 2.979060399920759, 2.979060399920759, 2.555515433049465, 4.737544435144828, 4.166148106246227, 3.126911761948066, 2.555515433049465, 2.555515433049465, 2.555515433049465, 4.518449513462731, 2.7599654782386627, 4.885395797172135, 4.737544435144828, 4.737544435144828, 3.126911761948066, 2.979060399920759, 2.555515433049465, 4.737544435144828, 2.407664071022158]\n",
      "all_sum after preprocessing is: [ 1.67654503  1.03400749 -0.13461807  1.8428045  -0.77715561  1.20026696\n",
      " -0.77715561  1.8428045  -0.13461807 -0.77715561  1.67654503 -0.77715561\n",
      " -0.77715561  0.09528685 -0.77715561 -0.77715561 -0.94341507 -0.30087754\n",
      " -0.77715561 -0.77715561 -0.13461807 -0.94341507 -0.77715561 -0.54725068\n",
      " -0.54725068 -0.94341507 -0.77715561 -0.77715561  1.20026696 -0.30087754\n",
      " -0.77715561 -0.30087754 -0.30087754 -0.77715561  1.67654503  1.03400749\n",
      " -0.13461807 -0.77715561 -0.77715561 -0.77715561  1.43017188 -0.54725068\n",
      "  1.8428045   1.67654503  1.67654503 -0.13461807 -0.30087754 -0.77715561\n",
      "  1.67654503 -0.94341507]\n",
      "P is: [0.8424464938345522, 0.737692094273766, 0.46639621417830546, 0.8632800528576416, 0.31493324161445824, 0.768572271259704, 0.31493324161445824, 0.8632800528576416, 0.46639621417830546, 0.31493324161445824, 0.8424464938345522, 0.31493324161445824, 0.31493324161445824, 0.5238037044877101, 0.31493324161445824, 0.31493324161445824, 0.2802110299980647, 0.4253429753917849, 0.31493324161445824, 0.31493324161445824, 0.46639621417830546, 0.2802110299980647, 0.31493324161445824, 0.3665025060345383, 0.3665025060345383, 0.2802110299980647, 0.31493324161445824, 0.31493324161445824, 0.768572271259704, 0.4253429753917849, 0.31493324161445824, 0.4253429753917849, 0.4253429753917849, 0.31493324161445824, 0.8424464938345522, 0.737692094273766, 0.46639621417830546, 0.31493324161445824, 0.31493324161445824, 0.31493324161445824, 0.8069280958404728, 0.3665025060345383, 0.8632800528576416, 0.8424464938345522, 0.8424464938345522, 0.46639621417830546, 0.4253429753917849, 0.31493324161445824, 0.8424464938345522, 0.2802110299980647]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.306\n",
      "(*) epoch 2, cost 2.537\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.557\n",
      "(*) epoch 2, cost 3.441\n",
      "(*) epoch 3, cost 2.745\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.914467072993667, 2.0010006303667183, 2.0010006303667183, 0.914467072993667, 0.9225044528962998, 0.914467072993667, 0.914467072993667, 0.914467072993667, 2.489950402689206, 0.914467072993667, 1.4034168453161548, 0.914467072993667, 2.009038010269351, 0.914467072993667, 1.4034168453161548, 1.4034168453161548, 1.4034168453161548, 2.0010006303667183, 0.914467072993667, 0.3514387048149303, 2.489950402689206, 1.4034168453161548, 1.4114542252187876, 2.0010006303667183, 0.914467072993667, 1.4379722621879814, 0.914467072993667, 2.489950402689206, 0.914467072993667, 1.4034168453161548, 2.0010006303667183, 2.0010006303667183, 2.0010006303667183, 0.914467072993667, 0.914467072993667, 0.914467072993667, 2.489950402689206, 2.0010006303667183, 0.914467072993667, 1.4034168453161548, 0.914467072993667, 0.3514387048149303, 0.914467072993667, 1.4034168453161548, 0.914467072993667, 0.914467072993667, 2.5169736409642396, 0.914467072993667, 0.914467072993667, 1.4034168453161548]\n",
      "all_sum after preprocessing is: [-0.75953293  1.11653952  1.11653952 -0.75953293 -0.74565511 -0.75953293\n",
      " -0.75953293 -0.75953293  1.96078882 -0.75953293  0.08471637 -0.75953293\n",
      "  1.13041733 -0.75953293  0.08471637  0.08471637  0.08471637  1.11653952\n",
      " -0.75953293 -1.73169066  1.96078882  0.08471637  0.09859418  1.11653952\n",
      " -0.75953293  0.14438178 -0.75953293  1.96078882 -0.75953293  0.08471637\n",
      "  1.11653952  1.11653952  1.11653952 -0.75953293 -0.75953293 -0.75953293\n",
      "  1.96078882  1.11653952 -0.75953293  0.08471637 -0.75953293 -1.73169066\n",
      " -0.75953293  0.08471637 -0.75953293 -0.75953293  2.00744872 -0.75953293\n",
      " -0.75953293  0.08471637]\n",
      "P is: [0.31874768178961677, 0.7533462686379168, 0.7533462686379168, 0.31874768178961677, 0.321768765725664, 0.31874768178961677, 0.31874768178961677, 0.31874768178961677, 0.8766182952308458, 0.31874768178961677, 0.5211664359188268, 0.31874768178961677, 0.7559159074805801, 0.31874768178961677, 0.5211664359188268, 0.5211664359188268, 0.5211664359188268, 0.7533462686379168, 0.31874768178961677, 0.1503714529784105, 0.8766182952308458, 0.5211664359188268, 0.5246285985133529, 0.7533462686379168, 0.31874768178961677, 0.536032871191156, 0.31874768178961677, 0.8766182952308458, 0.31874768178961677, 0.5211664359188268, 0.7533462686379168, 0.7533462686379168, 0.7533462686379168, 0.31874768178961677, 0.31874768178961677, 0.31874768178961677, 0.8766182952308458, 0.7533462686379168, 0.31874768178961677, 0.5211664359188268, 0.31874768178961677, 0.1503714529784105, 0.31874768178961677, 0.5211664359188268, 0.31874768178961677, 0.31874768178961677, 0.8815769304528404, 0.31874768178961677, 0.31874768178961677, 0.5211664359188268]\n",
      "all_sum before preprocessing is: [0.800517922864384, 0.9426170599592947, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.4072250545737363, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.800517922864384, 1.832363743084773, 0.800517922864384, 0.800517922864384, 1.6902646059898623, 0.800517922864384, 0.800517922864384, 1.832363743084773, 0.800517922864384, 1.2969717376992147, 1.5371110039088869, 0.800517922864384, 0.9426170599592947, 1.6902646059898623, 0.800517922864384, 1.6902646059898623, 0.800517922864384, 0.800517922864384, 1.2235249417024145, 0.800517922864384, 0.800517922864384, 1.2969717376992147, 0.4072250545737363, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.800517922864384, 0.800517922864384, 1.2969717376992147, 0.800517922864384, 0.5493241916686471, 0.800517922864384, 0.800517922864384, 1.2969717376992147, 0.4072250545737363, 0.4072250545737363, 1.6902646059898623]\n",
      "all_sum after preprocessing is: [-0.39547327 -0.00672825 -0.39547327 -0.39547327 -0.39547327 -0.39547327\n",
      " -1.47141675 -0.39547327 -0.39547327 -0.39547327 -0.39547327 -0.39547327\n",
      "  2.42737931 -0.39547327 -0.39547327  2.0386343  -0.39547327 -0.39547327\n",
      "  2.42737931 -0.39547327  0.96269082  1.61964725 -0.39547327 -0.00672825\n",
      "  2.0386343  -0.39547327  2.0386343  -0.39547327 -0.39547327  0.76176014\n",
      " -0.39547327 -0.39547327  0.96269082 -1.47141675 -0.39547327 -0.39547327\n",
      " -0.39547327 -0.39547327 -0.39547327 -0.39547327 -0.39547327  0.96269082\n",
      " -0.39547327 -1.08267174 -0.39547327 -0.39547327  0.96269082 -1.47141675\n",
      " -1.47141675  2.0386343 ]\n",
      "P is: [0.4024004206002706, 0.498317942871747, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.18672737023733824, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.9188914274764789, 0.4024004206002706, 0.4024004206002706, 0.8847941308093755, 0.4024004206002706, 0.4024004206002706, 0.9188914274764789, 0.4024004206002706, 0.7236602279702834, 0.8347464752700654, 0.4024004206002706, 0.498317942871747, 0.8847941308093755, 0.4024004206002706, 0.8847941308093755, 0.4024004206002706, 0.4024004206002706, 0.6817357575646986, 0.4024004206002706, 0.4024004206002706, 0.7236602279702834, 0.18672737023733824, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.4024004206002706, 0.7236602279702834, 0.4024004206002706, 0.25300074785673443, 0.4024004206002706, 0.4024004206002706, 0.7236602279702834, 0.18672737023733824, 0.18672737023733824, 0.8847941308093755]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.364\n",
      "(*) epoch 2, cost 1.199\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.686\n",
      "(*) epoch 2, cost 2.988\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.4409790018673645, 2.4409790018673645, 3.809239114742235, 0.9121085221963865, 2.2090539057563356, 2.4409790018673645, 2.2090539057563356, 2.2090539057563356, 2.4409790018673645, 2.2090539057563356, 0.6801834260853576, 0.6801834260853576, 2.4409790018673645, 2.2090539057563356, 2.2090539057563356, 2.4409790018673645, 0.9121085221963865, 2.2090539057563356, 2.2090539057563356, 0.9121085221963865, 2.2090539057563356, 2.2090539057563356, 2.4409790018673645, 2.4409790018673645, 2.2090539057563356, 2.5090259410045426, 2.4409790018673645, 2.4409790018673645, 0.6801834260853576, 2.2090539057563356, 0.9121085221963865, 2.2090539057563356, 2.4409790018673645, 2.2090539057563356, 2.4409790018673645, 0.6801834260853576, 3.877286053879413, 2.2090539057563356, 2.4409790018673645, 2.2090539057563356, 0.9121085221963865, 2.4409790018673645, 0.6801834260853576, 2.2090539057563356, 0.6801834260853576, 2.2090539057563356, 2.2090539057563356, 2.2090539057563356, 2.5344411629928745, 2.2090539057563356]\n",
      "all_sum after preprocessing is: [ 0.5446364   0.5446364   2.39713627 -1.52531532  0.23063089  0.5446364\n",
      "  0.23063089  0.23063089  0.5446364   0.23063089 -1.83932083 -1.83932083\n",
      "  0.5446364   0.23063089  0.23063089  0.5446364  -1.52531532  0.23063089\n",
      "  0.23063089 -1.52531532  0.23063089  0.23063089  0.5446364   0.5446364\n",
      "  0.23063089  0.63676577  0.5446364   0.5446364  -1.83932083  0.23063089\n",
      " -1.52531532  0.23063089  0.5446364   0.23063089  0.5446364  -1.83932083\n",
      "  2.48926564  0.23063089  0.5446364   0.23063089 -1.52531532  0.5446364\n",
      " -1.83932083  0.23063089 -1.83932083  0.23063089  0.23063089  0.23063089\n",
      "  0.67117567  0.23063089]\n",
      "P is: [0.6328903011151668, 0.6328903011151668, 0.9166086690155226, 0.17868014446209451, 0.557403503610643, 0.6328903011151668, 0.557403503610643, 0.557403503610643, 0.6328903011151668, 0.557403503610643, 0.13713163674713316, 0.13713163674713316, 0.6328903011151668, 0.557403503610643, 0.557403503610643, 0.6328903011151668, 0.17868014446209451, 0.557403503610643, 0.557403503610643, 0.17868014446209451, 0.557403503610643, 0.557403503610643, 0.6328903011151668, 0.6328903011151668, 0.557403503610643, 0.6540219929450155, 0.6328903011151668, 0.6328903011151668, 0.13713163674713316, 0.557403503610643, 0.17868014446209451, 0.557403503610643, 0.6328903011151668, 0.557403503610643, 0.6328903011151668, 0.13713163674713316, 0.9233858672048199, 0.557403503610643, 0.6328903011151668, 0.557403503610643, 0.17868014446209451, 0.6328903011151668, 0.13713163674713316, 0.557403503610643, 0.13713163674713316, 0.557403503610643, 0.557403503610643, 0.557403503610643, 0.6617663616042874, 0.557403503610643]\n",
      "all_sum before preprocessing is: [1.8973681219597767, 0.2099947979742111, 1.043146094171377, 1.6165481548053509, 1.8973681219597767, 2.168879483848091, 0.9801424328678023, 0.2099947979742111, 1.6165481548053509, 1.260962400022228, 1.260962400022228, 0.7623261270169512, 1.8973681219597767, 1.6165481548053509, 1.260962400022228, 1.6165481548053509, 0.2099947979742111, 0.2099947979742111, 1.6165481548053509, 0.2099947979742111, 1.1690090695720834, 2.2947424592487975, 1.7991337680304047, 1.6165481548053509, 0.2099947979742111, 0.7623261270169512, 1.6165481548053509, 1.6165481548053509, 0.392580411199265, 0.9801424328678023, 2.0799537351848305, 0.2099947979742111, 0.2099947979742111, 1.6165481548053509, 0.49081476512863687, 0.2099947979742111, 1.8973681219597767, 2.667515756853368, 1.1690090695720834, 0.49081476512863687, 0.49081476512863687, 0.2099947979742111, 2.168879483848091, 1.043146094171377, 1.6165481548053509, 0.2099947979742111, 1.260962400022228, 2.667515756853368, 0.2099947979742111, 0.2099947979742111]\n",
      "all_sum after preprocessing is: [ 1.01752735 -1.25845907 -0.13467632  0.63874785  1.01752735  1.38375109\n",
      " -0.2196578  -1.25845907  0.63874785  0.15912171  0.15912171 -0.51345582\n",
      "  1.01752735  0.63874785  0.15912171  0.63874785 -1.25845907 -1.25845907\n",
      "  0.63874785 -1.25845907  0.03509193  1.55351935  0.88502552  0.63874785\n",
      " -1.25845907 -0.51345582  0.63874785  0.63874785 -1.0121814  -0.2196578\n",
      "  1.26380502 -1.25845907 -1.25845907  0.63874785 -0.87967957 -1.25845907\n",
      "  1.01752735  2.05632862  0.03509193 -0.87967957 -0.87967957 -1.25845907\n",
      "  1.38375109 -0.13467632  0.63874785 -1.25845907  0.15912171  2.05632862\n",
      " -1.25845907 -1.25845907]\n",
      "P is: [0.7344906774464546, 0.2212392688419306, 0.46638171813955565, 0.6544703545209947, 0.7344906774464546, 0.7995927663894509, 0.44530529059555524, 0.2212392688419306, 0.6544703545209947, 0.5396967033341789, 0.5396967033341789, 0.37438374991621737, 0.7344906774464546, 0.6544703545209947, 0.5396967033341789, 0.6544703545209947, 0.2212392688419306, 0.2212392688419306, 0.6544703545209947, 0.2212392688419306, 0.5087720835474661, 0.8254214535568295, 0.7078625485270257, 0.6544703545209947, 0.2212392688419306, 0.37438374991621737, 0.6544703545209947, 0.6544703545209947, 0.2665531650217139, 0.44530529059555524, 0.779680425842021, 0.2212392688419306, 0.2212392688419306, 0.6544703545209947, 0.2932441852765137, 0.2212392688419306, 0.7344906774464546, 0.88658553067439, 0.5087720835474661, 0.2932441852765137, 0.2932441852765137, 0.2212392688419306, 0.7995927663894509, 0.46638171813955565, 0.6544703545209947, 0.2212392688419306, 0.5396967033341789, 0.88658553067439, 0.2212392688419306, 0.2212392688419306]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.025\n",
      "(*) epoch 2, cost 2.672\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.810\n",
      "(*) epoch 2, cost 1.505\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.0427455866818716, 2.384075731248773, 2.384075731248773, 1.3357805722407605, 1.3357805722407605, 1.3357805722407605, 0.7527935523635318, 1.458102313981212, 0.6304718106230803, 1.3357805722407605, 0.7527935523635318, 1.458102313981212, 1.3357805722407605, 1.458102313981212, 1.3357805722407605, 1.3357805722407605, 0.6304718106230803, 1.3357805722407605, 1.458102313981212, 2.261753989508321, 2.261753989508321, 1.3357805722407605, 1.458102313981212, 1.458102313981212, 2.384075731248773, 1.3357805722407605, 1.3357805722407605, 2.384075731248773, 2.384075731248773, 1.458102313981212, 2.384075731248773, 1.458102313981212, 1.458102313981212, 2.384075731248773, 1.3357805722407605, 2.261753989508321, 1.458102313981212, 1.458102313981212, 1.3357805722407605, 1.3357805722407605, 1.3357805722407605, 1.3357805722407605, 1.3357805722407605, 1.458102313981212, 1.3357805722407605, 2.261753989508321, 1.458102313981212, 1.458102313981212, 1.458102313981212, 1.458102313981212]\n",
      "all_sum after preprocessing is: [ 1.02994602  1.75572943  1.75572943 -0.47330087 -0.47330087 -0.47330087\n",
      " -1.71292858 -0.21320345 -1.973026   -0.47330087 -1.71292858 -0.21320345\n",
      " -0.47330087 -0.21320345 -0.47330087 -0.47330087 -1.973026   -0.47330087\n",
      " -0.21320345  1.495632    1.495632   -0.47330087 -0.21320345 -0.21320345\n",
      "  1.75572943 -0.47330087 -0.47330087  1.75572943  1.75572943 -0.21320345\n",
      "  1.75572943 -0.21320345 -0.21320345  1.75572943 -0.47330087  1.495632\n",
      " -0.21320345 -0.21320345 -0.47330087 -0.47330087 -0.47330087 -0.47330087\n",
      " -0.47330087 -0.21320345 -0.47330087  1.495632   -0.21320345 -0.21320345\n",
      " -0.21320345 -0.21320345]\n",
      "P is: [0.7369054301415411, 0.8526739938021148, 0.8526739938021148, 0.3838352700086641, 0.3838352700086641, 0.3838352700086641, 0.15278425084523986, 0.44690012669814116, 0.12206423533763486, 0.3838352700086641, 0.15278425084523986, 0.44690012669814116, 0.3838352700086641, 0.44690012669814116, 0.3838352700086641, 0.3838352700086641, 0.12206423533763486, 0.3838352700086641, 0.44690012669814116, 0.8169221012083457, 0.8169221012083457, 0.3838352700086641, 0.44690012669814116, 0.44690012669814116, 0.8526739938021148, 0.3838352700086641, 0.3838352700086641, 0.8526739938021148, 0.8526739938021148, 0.44690012669814116, 0.8526739938021148, 0.44690012669814116, 0.44690012669814116, 0.8526739938021148, 0.3838352700086641, 0.8169221012083457, 0.44690012669814116, 0.44690012669814116, 0.3838352700086641, 0.3838352700086641, 0.3838352700086641, 0.3838352700086641, 0.3838352700086641, 0.44690012669814116, 0.3838352700086641, 0.8169221012083457, 0.44690012669814116, 0.44690012669814116, 0.44690012669814116, 0.44690012669814116]\n",
      "all_sum before preprocessing is: [1.8907677744678466, 0.8053765941096338, 0.8053765941096338, 0.43247872706780993, 0.8760942744227398, 3.827323647114718, 3.4544257800728944, 2.8126501470696113, 3.3837080997597884, 2.2983169194015756, 2.7419324667565053, 0.36176104675470394, 3.827323647114718, 3.3837080997597884, 0.8053765941096338, 3.827323647114718, 2.7419324667565053, 1.447152227112917, 2.7419324667565053, 0.8760942744227398, 0.8760942744227398, 0.36176104675470394, 2.7419324667565053, 0.8053765941096338, 4.987553462773074, 1.8907677744678466, 2.7419324667565053, 3.827323647114718, 1.8907677744678466, 0.8760942744227398, 0.8760942744227398, 2.7419324667565053, 3.827323647114718, 2.9802799098130968, 2.7419324667565053, 2.3690345997146816, 2.7419324667565053, 0.8053765941096338, 3.827323647114718, 1.447152227112917, 1.9614854547809526, 1.447152227112917, 0.8053765941096338, 2.8126501470696113, 0.8053765941096338, 0.8053765941096338, 0.8053765941096338, 2.7419324667565053, 0.8053765941096338, 3.827323647114718]\n",
      "all_sum after preprocessing is: [-0.17991724 -1.06932863 -1.06932863 -1.37489552 -1.01137983  1.40697132\n",
      "  1.10140443  0.57550873  1.04345563  0.15404425  0.51755993 -1.43284431\n",
      "  1.40697132  1.04345563 -1.06932863  1.40697132  0.51755993 -0.54343292\n",
      "  0.51755993 -1.01137983 -1.01137983 -1.43284431  0.51755993 -1.06932863\n",
      "  2.35770837 -0.17991724  0.51755993  1.40697132 -0.17991724 -1.01137983\n",
      " -1.01137983  0.51755993  1.40697132  0.71287102  0.51755993  0.21199304\n",
      "  0.51755993 -1.06932863  1.40697132 -0.54343292 -0.12196844 -0.54343292\n",
      " -1.06932863  0.57550873 -1.06932863 -1.06932863 -1.06932863  0.51755993\n",
      " -1.06932863  1.40697132]\n",
      "P is: [0.4551416315536292, 0.2555307820399108, 0.2555307820399108, 0.20183005338249957, 0.2667099024360107, 0.8032878018705222, 0.7505231607769935, 0.6400333111415575, 0.73951622259002, 0.538435087649452, 0.6265770202982618, 0.19265589441101472, 0.8032878018705222, 0.73951622259002, 0.2555307820399108, 0.8032878018705222, 0.6265770202982618, 0.36738935867566863, 0.6265770202982618, 0.2667099024360107, 0.2667099024360107, 0.19265589441101472, 0.6265770202982618, 0.2555307820399108, 0.9135449829004165, 0.4551416315536292, 0.6265770202982618, 0.8032878018705222, 0.4551416315536292, 0.2667099024360107, 0.2667099024360107, 0.6265770202982618, 0.8032878018705222, 0.6710352394320952, 0.6265770202982618, 0.5528006652102664, 0.6265770202982618, 0.2555307820399108, 0.8032878018705222, 0.36738935867566863, 0.46954563377016895, 0.36738935867566863, 0.2555307820399108, 0.6400333111415575, 0.2555307820399108, 0.2555307820399108, 0.2555307820399108, 0.6265770202982618, 0.2555307820399108, 0.8032878018705222]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.731\n",
      "(*) epoch 2, cost 2.227\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.757\n",
      "(*) epoch 2, cost 2.970\n",
      "(*) epoch 3, cost 2.416\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.570636160998229, 2.5583696070934203, 2.5583696070934203, 1.5950825353210867, 1.6073490892258955, 2.570636160998229, 2.570636160998229, 1.6073490892258955, 1.6073490892258955, 2.570636160998229, 1.5387546102906744, 2.570636160998229, 2.5583696070934203, 2.5583696070934203, 2.501426850250988, 1.6073490892258955, 2.570636160998229, 2.570636160998229, 1.6073490892258955, 1.6073490892258955, 2.570636160998229, 2.5583696070934203, 2.5583696070934203, 3.475119922068143, 2.5583696070934203, 1.6073490892258955, 1.5510211641954832, 2.5583696070934203, 2.570636160998229, 1.6073490892258955, 2.570636160998229, 1.5387546102906744, 2.570636160998229, 2.570636160998229, 2.5583696070934203, 1.0796367802465807, 3.4647139220233223, 1.5950825353210867, 1.6073490892258955, 1.6073490892258955, 2.5583696070934203, 2.5583696070934203, 2.570636160998229, 2.570636160998229, 2.570636160998229, 2.570636160998229, 0.5877340924231491, 1.6073490892258955, 2.570636160998229, 3.4524473681185137]\n",
      "all_sum after preprocessing is: [ 0.54962212  0.52934956  0.52934956 -1.06264558 -1.04237303  0.54962212\n",
      "  0.54962212 -1.04237303 -1.04237303  0.54962212 -1.15573703  0.54962212\n",
      "  0.52934956  0.52934956  0.435242   -1.04237303  0.54962212  0.54962212\n",
      " -1.04237303 -1.04237303  0.54962212  0.52934956  0.52934956  2.04443482\n",
      "  0.52934956 -1.04237303 -1.13546447  0.52934956  0.54962212 -1.04237303\n",
      "  0.54962212 -1.15573703  0.54962212  0.54962212  0.52934956 -1.91450705\n",
      "  2.02723714 -1.06264558 -1.04237303 -1.04237303  0.52934956  0.52934956\n",
      "  0.54962212  0.54962212  0.54962212  0.54962212 -2.72745961 -1.04237303\n",
      "  0.54962212  2.00696458]\n",
      "P is: [0.6340479145336839, 0.6293313935800751, 0.6293313935800751, 0.2568042046963864, 0.2606923766188232, 0.6340479145336839, 0.6340479145336839, 0.2606923766188232, 0.2606923766188232, 0.6340479145336839, 0.2394427522666133, 0.6340479145336839, 0.6293313935800751, 0.6293313935800751, 0.6071247125281621, 0.2606923766188232, 0.6340479145336839, 0.6340479145336839, 0.2606923766188232, 0.2606923766188232, 0.6340479145336839, 0.6293313935800751, 0.6293313935800751, 0.8853840793277825, 0.6293313935800751, 0.2606923766188232, 0.24315406306074708, 0.6293313935800751, 0.6340479145336839, 0.2606923766188232, 0.6340479145336839, 0.2394427522666133, 0.6340479145336839, 0.6340479145336839, 0.6293313935800751, 0.12847535454436895, 0.8836272738792326, 0.2568042046963864, 0.2606923766188232, 0.2606923766188232, 0.6293313935800751, 0.6293313935800751, 0.6340479145336839, 0.6340479145336839, 0.6340479145336839, 0.6340479145336839, 0.061372341034377526, 0.2606923766188232, 0.6340479145336839, 0.8815263773424195]\n",
      "all_sum before preprocessing is: [2.1765041320931364, 2.3635393412790107, 3.4008318742395973, 3.548631022295753, 2.5394330887666956, 3.735666231481628, 1.5157690859768518, 2.3635393412790107, 3.4008318742395973, 1.691662833464537, 3.735666231481628, 3.548631022295753, 0.3195359432619201, 3.735666231481628, 0.3195359432619201, 3.024274387395295, 4.7729587644422145, 1.1673061985640787, 1.5157690859768518, 2.3635393412790107, 1.5157690859768518, 3.735666231481628, 2.5530616189374387, 3.925188509140056, 2.3635393412790107, 3.925188509140056, 2.8878959761794687, 2.1765041320931364, 2.8878959761794687, 2.5394330887666956, 1.356828476222507, 2.3635393412790107, 2.8878959761794687, 3.735666231481628, 2.8878959761794687, 2.8878959761794687, 4.7729587644422145, 2.8878959761794687, 3.4008318742395973, 2.3635393412790107, 2.5530616189374387, 1.691662833464537, 3.735666231481628, 1.691662833464537, 4.7729587644422145, 3.4008318742395973, 2.728955366425124, 2.3635393412790107, 1.5157690859768518, 1.5157690859768518]\n",
      "all_sum after preprocessing is: [-0.51342944 -0.33182425  0.67535351  0.81886174 -0.16103707  1.00046693\n",
      " -1.15498196 -0.33182425  0.67535351 -0.98419478  1.00046693  0.81886174\n",
      " -2.31648596  1.00046693 -2.31648596  0.30972828  2.00764469 -1.49332825\n",
      " -1.15498196 -0.33182425 -1.15498196  1.00046693 -0.1478042   1.18448698\n",
      " -0.33182425  1.18448698  0.17730922 -0.51342944  0.17730922 -0.16103707\n",
      " -1.3093082  -0.33182425  0.17730922  1.00046693  0.17730922  0.17730922\n",
      "  2.00764469  0.17730922  0.67535351 -0.33182425 -0.1478042  -0.98419478\n",
      "  1.00046693 -0.98419478  2.00764469  0.67535351  0.02298298 -0.33182425\n",
      " -1.15498196 -1.15498196]\n",
      "P is: [0.37438993007710347, 0.41779682107717, 0.6627008618388658, 0.6939946662623891, 0.4598275117409249, 0.7311503725370364, 0.2395802836679794, 0.41779682107717, 0.6627008618388658, 0.2720602409607282, 0.7311503725370364, 0.6939946662623891, 0.08976677332409551, 0.7311503725370364, 0.08976677332409551, 0.5768189350717037, 0.8815973880167423, 0.18342270124306165, 0.2395802836679794, 0.41779682107717, 0.2395802836679794, 0.7311503725370364, 0.4631160727303303, 0.7657536152172494, 0.41779682107717, 0.7657536152172494, 0.5442115355507845, 0.37438993007710347, 0.5442115355507845, 0.4598275117409249, 0.21260263087942027, 0.41779682107717, 0.5442115355507845, 0.7311503725370364, 0.5442115355507845, 0.5442115355507845, 0.8815973880167423, 0.5442115355507845, 0.6627008618388658, 0.41779682107717, 0.4631160727303303, 0.2720602409607282, 0.7311503725370364, 0.2720602409607282, 0.8815973880167423, 0.6627008618388658, 0.5057454929570628, 0.41779682107717, 0.2395802836679794, 0.2395802836679794]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.072\n",
      "(*) epoch 2, cost 3.225\n",
      "(*) epoch 3, cost 2.524\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.484\n",
      "(*) epoch 2, cost 2.760\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.9462220925771694, 2.392161169055967, 3.0060673908340436, 3.0060673908340436, 3.363942658427741, 2.392161169055967, 2.560128314355246, 3.5710445777262376, 2.560128314355246, 2.560128314355246, 2.1850592497574706, 2.560128314355246, 3.739011723025517, 3.12510550124744, 2.560128314355246, 2.560128314355246, 2.392161169055967, 3.739011723025517, 3.363942658427741, 3.0060673908340436, 3.739011723025517, 1.9462220925771694, 3.0060673908340436, 1.9462220925771694, 2.392161169055967, 2.0170921044581913, 2.392161169055967, 3.12510550124744, 3.0060673908340436, 2.392161169055967, 3.5720625893794633, 2.392161169055967, 2.630998326236268, 2.560128314355246, 2.1850592497574706, 1.5711530279793937, 3.12510550124744, 2.560128314355246, 2.560128314355246, 2.1850592497574706, 1.9462220925771694, 3.5710445777262376, 1.5711530279793937, 3.0060673908340436, 2.392161169055967, 2.1850592497574706, 3.0060673908340436, 2.392161169055967, 2.1850592497574706, 2.560128314355246]\n",
      "all_sum after preprocessing is: [-1.28577173 -0.4758518   0.63913208  0.63913208  1.28910946 -0.4758518\n",
      " -0.17078785  1.66525046 -0.17078785 -0.17078785 -0.8519928  -0.17078785\n",
      "  1.97031441  0.85533053 -0.17078785 -0.17078785 -0.4758518   1.97031441\n",
      "  1.28910946  0.63913208  1.97031441 -1.28577173  0.63913208 -1.28577173\n",
      " -0.4758518  -1.15705676 -0.4758518   0.85533053  0.63913208 -0.4758518\n",
      "  1.66709938 -0.4758518  -0.04207288 -0.17078785 -0.8519928  -1.96697668\n",
      "  0.85533053 -0.17078785 -0.17078785 -0.8519928  -1.28577173  1.66525046\n",
      " -1.96697668  0.63913208 -0.4758518  -0.8519928   0.63913208 -0.4758518\n",
      " -0.8519928  -0.17078785]\n",
      "P is: [0.2165693495818564, 0.38323213931844785, 0.6545572398266761, 0.6545572398266761, 0.7839964171895697, 0.38323213931844785, 0.4574065203375275, 0.84094155617869, 0.4574065203375275, 0.4574065203375275, 0.29901498866597576, 0.4574065203375275, 0.8776448801888945, 0.7016841462460457, 0.4574065203375275, 0.4574065203375275, 0.38323213931844785, 0.8776448801888945, 0.7839964171895697, 0.6545572398266761, 0.8776448801888945, 0.2165693495818564, 0.6545572398266761, 0.2165693495818564, 0.38323213931844785, 0.2392024988859791, 0.38323213931844785, 0.7016841462460457, 0.6545572398266761, 0.38323213931844785, 0.841188710404856, 0.38323213931844785, 0.4894833321174821, 0.4574065203375275, 0.29901498866597576, 0.12271399156167273, 0.7016841462460457, 0.4574065203375275, 0.4574065203375275, 0.29901498866597576, 0.2165693495818564, 0.84094155617869, 0.12271399156167273, 0.6545572398266761, 0.38323213931844785, 0.29901498866597576, 0.6545572398266761, 0.38323213931844785, 0.29901498866597576, 0.4574065203375275]\n",
      "all_sum before preprocessing is: [1.554585849858733, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 2.913821650013801, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 2.913821650013801, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 2.0912257157931453, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 2.913821650013801, 1.554585849858733, 1.3887686783235007, 0.566172744102845, 1.3887686783235007, 1.3887686783235007, 2.0912257157931453, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007, 1.3887686783235007]\n",
      "all_sum after preprocessing is: [ 0.13927756 -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903\n",
      "  3.51772374 -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903\n",
      " -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903\n",
      "  3.51772374 -0.27286903 -0.27286903 -0.27286903  1.47312184 -0.27286903\n",
      " -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903\n",
      " -0.27286903  3.51772374  0.13927756 -0.27286903 -2.31747092 -0.27286903\n",
      " -0.27286903  1.47312184 -0.27286903 -0.27286903 -0.27286903 -0.27286903\n",
      " -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903 -0.27286903\n",
      " -0.27286903 -0.27286903]\n",
      "P is: [0.5347632118926677, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.9711878780274801, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.9711878780274801, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.8135314271318366, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.9711878780274801, 0.5347632118926677, 0.43220288936313256, 0.08968632596376959, 0.43220288936313256, 0.43220288936313256, 0.8135314271318366, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256, 0.43220288936313256]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.926\n",
      "(*) epoch 2, cost 2.705\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.231\n",
      "(*) epoch 2, cost 2.318\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.225373318654621, 3.225373318654621, 4.951710442864593, 3.260762643979761, 3.7079311500799914, 3.225373318654621, 2.499541182620529, 4.6339124037088375, 2.9075752794988654, 4.951710442864593, 3.7079311500799914, 3.7079311500799914, 4.277185137963804, 2.9075752794988654, 3.225373318654621, 1.8250158777197394, 3.7079311500799914, 4.469152611439223, 3.3901331109242356, 3.7079311500799914, 3.3901331109242356, 5.489248928470252, 3.7079311500799914, 3.9593870988080484, 4.130958312236283, 2.9075752794988654, 2.9075752794988654, 4.6339124037088375, 2.942964604824005, 3.7079311500799914, 3.5159636766045725, 3.7079311500799914, 2.9075752794988654, 3.3901331109242356, 3.3901331109242356, 4.951710442864593, 3.0334058451792023, 2.9075752794988654, 4.469152611439223, 3.225373318654621, 4.151354572283467, 3.3901331109242356, 3.225373318654621, 3.5159636766045725, 3.7079311500799914, 3.225373318654621, 1.6991853120394032, 2.9075752794988654, 4.951710442864593, 3.7079311500799914]\n",
      "all_sum after preprocessing is: [-0.47106097 -0.47106097  1.78712063 -0.42476901  0.16016175 -0.47106097\n",
      " -1.42050517  1.37141638 -0.88676522  1.78712063  0.16016175  0.16016175\n",
      "  0.90478971 -0.88676522 -0.47106097 -2.30283609  0.16016175  1.15589791\n",
      " -0.2555425   0.16016175 -0.2555425   2.49026227  0.16016175  0.48908546\n",
      "  0.71351378 -0.88676522 -0.88676522  1.37141638 -0.84047326  0.16016175\n",
      " -0.09094645  0.16016175 -0.88676522 -0.2555425  -0.2555425   1.78712063\n",
      " -0.72216917 -0.88676522  1.15589791 -0.47106097  0.74019366 -0.2555425\n",
      " -0.47106097 -0.09094645  0.16016175 -0.47106097 -2.46743214 -0.88676522\n",
      "  1.78712063  0.16016175]\n",
      "P is: [0.384365157883417, 0.384365157883417, 0.8565738948115743, 0.3953761330840287, 0.5399550650855506, 0.384365157883417, 0.1945824013031438, 0.7976088947418203, 0.29177782344722875, 0.8565738948115743, 0.5399550650855506, 0.5399550650855506, 0.7119327937221764, 0.29177782344722875, 0.384365157883417, 0.09088834917305537, 0.5399550650855506, 0.7605865453937692, 0.43645977468981695, 0.5399550650855506, 0.43645977468981695, 0.9234563434378203, 0.5399550650855506, 0.619890965314342, 0.6711771124134709, 0.29177782344722875, 0.29177782344722875, 0.7976088947418203, 0.30143511881064117, 0.5399550650855506, 0.4772790460177718, 0.5399550650855506, 0.29177782344722875, 0.43645977468981695, 0.43645977468981695, 0.8565738948115743, 0.32691549561936656, 0.29177782344722875, 0.7605865453937692, 0.384365157883417, 0.6770382029240355, 0.43645977468981695, 0.384365157883417, 0.4772790460177718, 0.5399550650855506, 0.384365157883417, 0.07817307993589222, 0.29177782344722875, 0.8565738948115743, 0.5399550650855506]\n",
      "all_sum before preprocessing is: [4.238339859845177, 1.8835287497132405, 0.4459427936356819, 1.8835287497132405, 1.8835287497132405, 1.7214568878110814, 2.3452090511466337, 1.8835287497132405, 1.8835287497132405, 1.8835287497132405, 0.4459427936356819, 1.8835287497132405, 1.8835287497132405, 1.7214568878110814, 1.8835287497132405, 3.6392466128306817, 1.8835287497132405, 1.8835287497132405, 3.9202079528052938, 1.8835287497132405, 0.28387093173352274, 1.8835287497132405, 1.7214568878110814, 3.9202079528052938, 3.4771747509285227, 0.4459427936356819, 1.8835287497132405, 1.8835287497132405, 1.7214568878110814, 1.8835287497132405, 3.6392466128306817, 5.513853954020576, 2.18914900600891, 1.8835287497132405, 1.8835287497132405, 3.6392466128306817, 3.4771747509285227, 1.7214568878110814, 1.8835287497132405, 3.9202079528052938, 3.758136090903135, 1.8835287497132405, 1.8835287497132405, 1.8835287497132405, 1.7214568878110814, 0.4459427936356819, 1.8835287497132405, 1.8835287497132405, 1.8835287497132405, 0.4459427936356819]\n",
      "all_sum after preprocessing is: [ 1.9244359  -0.24780283 -1.57393039 -0.24780283 -0.24780283 -0.397309\n",
      "  0.17808263 -0.24780283 -0.24780283 -0.24780283 -1.57393039 -0.24780283\n",
      " -0.24780283 -0.397309   -0.24780283  1.37179134 -0.24780283 -0.24780283\n",
      "  1.63096928 -0.24780283 -1.72343655 -0.24780283 -0.397309    1.63096928\n",
      "  1.22228517 -1.57393039 -0.24780283 -0.24780283 -0.397309   -0.24780283\n",
      "  1.37179134  3.10105729  0.03412218 -0.24780283 -0.24780283  1.37179134\n",
      "  1.22228517 -0.397309   -0.24780283  1.63096928  1.48146312 -0.24780283\n",
      " -0.24780283 -0.24780283 -0.397309   -1.57393039 -0.24780283 -0.24780283\n",
      " -0.24780283 -1.57393039]\n",
      "P is: [0.8726322778693497, 0.43836437028467523, 0.17165680575613762, 0.43836437028467523, 0.43836437028467523, 0.40195905347975014, 0.5444033720336663, 0.43836437028467523, 0.43836437028467523, 0.43836437028467523, 0.17165680575613762, 0.43836437028467523, 0.43836437028467523, 0.40195905347975014, 0.43836437028467523, 0.7976694166286872, 0.43836437028467523, 0.43836437028467523, 0.8363023772740077, 0.43836437028467523, 0.15142904368605234, 0.43836437028467523, 0.40195905347975014, 0.8363023772740077, 0.7724654471789522, 0.17165680575613762, 0.43836437028467523, 0.43836437028467523, 0.40195905347975014, 0.43836437028467523, 0.7976694166286872, 0.9569363360258314, 0.5085297177528166, 0.43836437028467523, 0.43836437028467523, 0.7976694166286872, 0.7724654471789522, 0.40195905347975014, 0.43836437028467523, 0.8363023772740077, 0.8147934741750079, 0.43836437028467523, 0.43836437028467523, 0.43836437028467523, 0.40195905347975014, 0.17165680575613762, 0.43836437028467523, 0.43836437028467523, 0.43836437028467523, 0.17165680575613762]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.733\n",
      "(*) epoch 2, cost 4.655\n",
      "(*) epoch 3, cost 4.315\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.092\n",
      "(*) epoch 2, cost 2.509\n",
      "(*) epoch 3, cost 1.841\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [5.3908759696512405, 5.445352141233309, 4.832767999828466, 5.3908759696512405, 4.840996038619031, 2.7117451741916634, 4.9635317021862075, 5.445352141233309, 4.832767999828466, 4.832767999828466, 4.832767999828466, 4.832767999828466, 4.832767999828466, 5.445352141233309, 5.445352141233309, 4.832767999828466, 4.832767999828466, 6.003460111056084, 5.445352141233309, 4.832767999828466, 4.832767999828466, 4.832767999828466, 5.3908759696512405, 5.445352141233309, 4.840996038619031, 5.3908759696512405, 4.832767999828466, 4.9635317021862075, 5.3908759696512405, 4.832767999828466, 5.3908759696512405, 4.832767999828466, 4.832767999828466, 4.832767999828466, 5.445352141233309, 4.832767999828466, 4.832767999828466, 6.003460111056084, 5.3908759696512405, 6.003460111056084, 5.445352141233309, 4.832767999828466, 4.832767999828466, 4.832767999828466, 4.832767999828466, 4.9635317021862075, 4.832767999828466, 4.832767999828466, 4.832767999828466, 6.003460111056084]\n",
      "all_sum after preprocessing is: [ 0.64664438  0.75585771 -0.47224541  0.64664438 -0.45574991 -4.72445269\n",
      " -0.21009153  0.75585771 -0.47224541 -0.47224541 -0.47224541 -0.47224541\n",
      " -0.47224541  0.75585771  0.75585771 -0.47224541 -0.47224541  1.87474749\n",
      "  0.75585771 -0.47224541 -0.47224541 -0.47224541  0.64664438  0.75585771\n",
      " -0.45574991  0.64664438 -0.47224541 -0.21009153  0.64664438 -0.47224541\n",
      "  0.64664438 -0.47224541 -0.47224541 -0.47224541  0.75585771 -0.47224541\n",
      " -0.47224541  1.87474749  0.64664438  1.87474749  0.75585771 -0.47224541\n",
      " -0.47224541 -0.47224541 -0.47224541 -0.21009153 -0.47224541 -0.47224541\n",
      " -0.47224541  1.87474749]\n",
      "P is: [0.656253882663469, 0.6804537229829494, 0.3840849234861007, 0.656253882663469, 0.38799454614434287, 0.008797487562614057, 0.4476694593721235, 0.6804537229829494, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.6804537229829494, 0.6804537229829494, 0.3840849234861007, 0.3840849234861007, 0.867006647085916, 0.6804537229829494, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.656253882663469, 0.6804537229829494, 0.38799454614434287, 0.656253882663469, 0.3840849234861007, 0.4476694593721235, 0.656253882663469, 0.3840849234861007, 0.656253882663469, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.6804537229829494, 0.3840849234861007, 0.3840849234861007, 0.867006647085916, 0.656253882663469, 0.867006647085916, 0.6804537229829494, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.4476694593721235, 0.3840849234861007, 0.3840849234861007, 0.3840849234861007, 0.867006647085916]\n",
      "all_sum before preprocessing is: [0.9284246337879533, 0.9284246337879533, 2.894615393903291, 1.877076843194026, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 1.689421589807734, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 2.894615393903291, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 2.894615393903291, 2.4001907787244066, 1.689421589807734, 0.9284246337879533, 0.9284246337879533, 1.129514955015097, 0.9284246337879533, 0.9284246337879533, 1.877076843194026, 0.9284246337879533, 0.9284246337879533, 1.129514955015097, 3.655612349923072, 0.9284246337879533, 0.9284246337879533, 2.894615393903291, 0.9284246337879533, 0.9284246337879533, 1.129514955015097, 0.9284246337879533, 1.689421589807734, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533, 2.894615393903291, 0.9284246337879533, 2.894615393903291, 0.9284246337879533, 0.9284246337879533, 0.9284246337879533]\n",
      "all_sum after preprocessing is: [-0.55713623 -0.55713623  2.07870058  0.71460834 -0.55713623 -0.55713623\n",
      " -0.55713623 -0.55713623 -0.55713623 -0.55713623  0.46304138 -0.55713623\n",
      " -0.55713623 -0.55713623  2.07870058 -0.55713623 -0.55713623 -0.55713623\n",
      " -0.55713623 -0.55713623  2.07870058  1.41588463  0.46304138 -0.55713623\n",
      " -0.55713623 -0.28755848 -0.55713623 -0.55713623  0.71460834 -0.55713623\n",
      " -0.55713623 -0.28755848  3.09887819 -0.55713623 -0.55713623  2.07870058\n",
      " -0.55713623 -0.55713623 -0.28755848 -0.55713623  0.46304138 -0.55713623\n",
      " -0.55713623 -0.55713623  2.07870058 -0.55713623  2.07870058 -0.55713623\n",
      " -0.55713623 -0.55713623]\n",
      "P is: [0.3642103403964201, 0.3642103403964201, 0.8888156864318707, 0.6714186331739924, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.6137354280162758, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.8888156864318707, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.8888156864318707, 0.8046924453177774, 0.6137354280162758, 0.3642103403964201, 0.3642103403964201, 0.42860169602570153, 0.3642103403964201, 0.3642103403964201, 0.6714186331739924, 0.3642103403964201, 0.3642103403964201, 0.42860169602570153, 0.9568464476923747, 0.3642103403964201, 0.3642103403964201, 0.8888156864318707, 0.3642103403964201, 0.3642103403964201, 0.42860169602570153, 0.3642103403964201, 0.6137354280162758, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201, 0.8888156864318707, 0.3642103403964201, 0.8888156864318707, 0.3642103403964201, 0.3642103403964201, 0.3642103403964201]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.568\n",
      "(*) epoch 2, cost 2.806\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.171\n",
      "(*) epoch 2, cost 1.287\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.7621636018821345, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 4.70616435014648, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 4.5635632013196705, 4.70616435014648, 3.9200110626522657, 3.9200110626522657, 4.70616435014648, 3.9200110626522657, 3.9200110626522657, 4.5635632013196705, 4.5635632013196705, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 3.9200110626522657, 6.461957394103337]\n",
      "all_sum after preprocessing is: [ 1.61522125 -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891\n",
      " -0.35992891 -0.35992891 -0.35992891 -0.35992891  1.4838829  -0.35992891\n",
      " -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891\n",
      " -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891\n",
      " -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891\n",
      " -0.35992891 -0.35992891 -0.35992891 -0.35992891 -0.35992891  1.14943199\n",
      "  1.4838829  -0.35992891 -0.35992891  1.4838829  -0.35992891 -0.35992891\n",
      "  1.14943199  1.14943199 -0.35992891 -0.35992891 -0.35992891 -0.35992891\n",
      " -0.35992891  5.60184817]\n",
      "P is: [0.8341350274285257, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.8151583530242792, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.7594071518906673, 0.8151583530242792, 0.41097677576559904, 0.41097677576559904, 0.8151583530242792, 0.41097677576559904, 0.41097677576559904, 0.7594071518906673, 0.7594071518906673, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.41097677576559904, 0.9963225378976363]\n",
      "all_sum before preprocessing is: [1.6424675709901644, 1.2308572483963058, 1.2308572483963058, 1.2308572483963058, 1.2308572483963058, 3.0037402208488597, 2.592129898255001, 1.2308572483963058, 2.592129898255001, 2.592129898255001, 1.6424675709901644, 2.592129898255001, 2.592129898255001, 1.2308572483963058, 1.2308572483963058, 1.2308572483963058, 2.592129898255001, 2.592129898255001, 1.2308572483963058, 2.592129898255001, 2.592129898255001, 1.6424675709901644, 2.592129898255001, 1.6424675709901644, 1.2308572483963058, 2.592129898255001, 1.2308572483963058, 2.592129898255001, 1.2308572483963058, 1.2308572483963058, 1.2308572483963058, 2.592129898255001, 1.6399078002148815, 2.592129898255001, 1.2308572483963058, 1.2308572483963058, 1.6424675709901644, 1.2308572483963058, 1.2308572483963058, 1.2308572483963058, 1.6424675709901644, 1.2308572483963058, 1.2308572483963058, 1.2308572483963058, 1.2308572483963058, 3.0037402208488597, 1.2308572483963058, 1.6424675709901644, 1.2308572483963058, 2.592129898255001]\n",
      "all_sum after preprocessing is: [-0.20808307 -0.84968213 -0.84968213 -0.84968213 -0.84968213  1.91380551\n",
      "  1.27220646 -0.84968213  1.27220646  1.27220646 -0.20808307  1.27220646\n",
      "  1.27220646 -0.84968213 -0.84968213 -0.84968213  1.27220646  1.27220646\n",
      " -0.84968213  1.27220646  1.27220646 -0.20808307  1.27220646 -0.20808307\n",
      " -0.84968213  1.27220646 -0.84968213  1.27220646 -0.84968213 -0.84968213\n",
      " -0.84968213  1.27220646 -0.21207313  1.27220646 -0.84968213 -0.84968213\n",
      " -0.20808307 -0.84968213 -0.84968213 -0.84968213 -0.20808307 -0.84968213\n",
      " -0.84968213 -0.84968213 -0.84968213  1.91380551 -0.84968213 -0.20808307\n",
      " -0.84968213  1.27220646]\n",
      "P is: [0.44816612432276587, 0.29949954260544065, 0.29949954260544065, 0.29949954260544065, 0.29949954260544065, 0.8714460737644133, 0.7811202227601831, 0.29949954260544065, 0.7811202227601831, 0.7811202227601831, 0.44816612432276587, 0.7811202227601831, 0.7811202227601831, 0.29949954260544065, 0.29949954260544065, 0.29949954260544065, 0.7811202227601831, 0.7811202227601831, 0.29949954260544065, 0.7811202227601831, 0.7811202227601831, 0.44816612432276587, 0.7811202227601831, 0.44816612432276587, 0.29949954260544065, 0.7811202227601831, 0.29949954260544065, 0.7811202227601831, 0.29949954260544065, 0.29949954260544065, 0.29949954260544065, 0.7811202227601831, 0.447179537002041, 0.7811202227601831, 0.29949954260544065, 0.29949954260544065, 0.44816612432276587, 0.29949954260544065, 0.29949954260544065, 0.29949954260544065, 0.44816612432276587, 0.29949954260544065, 0.29949954260544065, 0.29949954260544065, 0.29949954260544065, 0.8714460737644133, 0.29949954260544065, 0.44816612432276587, 0.29949954260544065, 0.7811202227601831]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.613\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.872\n",
      "(*) epoch 2, cost 1.836\n",
      "(*) epoch 3, cost 1.184\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.4952126733120863, 1.4952126733120863, 1.4952126733120863, 1.387508350462152, 1.387508350462152, 1.4952126733120863, 1.387508350462152, 1.387508350462152, 1.387508350462152, 1.387508350462152, 1.4952126733120863, 1.4952126733120863, 1.387508350462152, 1.4952126733120863, 1.387508350462152, 1.5195330831131186, 1.4952126733120863, 1.387508350462152, 1.387508350462152, 1.4952126733120863, 1.4952126733120863, 1.387508350462152, 1.387508350462152, 1.387508350462152, 0.7826661373514378, 1.387508350462152, 1.4952126733120863, 1.4952126733120863, 1.387508350462152, 1.387508350462152, 1.5195330831131186, 1.387508350462152, 1.627237405963053, 1.387508350462152, 1.387508350462152, 1.387508350462152, 1.4952126733120863, 1.5195330831131186, 1.4952126733120863, 1.387508350462152, 1.4952126733120863, 1.4952126733120863, 1.387508350462152, 0.8903704602013721, 1.387508350462152, 1.387508350462152, 1.387508350462152, 1.5195330831131186, 1.387508350462152, 1.387508350462152]\n",
      "all_sum after preprocessing is: [ 0.59999089  0.59999089  0.59999089 -0.20856779 -0.20856779  0.59999089\n",
      " -0.20856779 -0.20856779 -0.20856779 -0.20856779  0.59999089  0.59999089\n",
      " -0.20856779  0.59999089 -0.20856779  0.78256925  0.59999089 -0.20856779\n",
      " -0.20856779  0.59999089  0.59999089 -0.20856779 -0.20856779 -0.20856779\n",
      " -4.7492437  -0.20856779  0.59999089  0.59999089 -0.20856779 -0.20856779\n",
      "  0.78256925 -0.20856779  1.59112793 -0.20856779 -0.20856779 -0.20856779\n",
      "  0.59999089  0.78256925  0.59999089 -0.20856779  0.59999089  0.59999089\n",
      " -0.20856779 -3.94068502 -0.20856779 -0.20856779 -0.20856779  0.78256925\n",
      " -0.20856779 -0.20856779]\n",
      "P is: [0.6456542219195164, 0.6456542219195164, 0.6456542219195164, 0.4480462496523483, 0.4480462496523483, 0.6456542219195164, 0.4480462496523483, 0.4480462496523483, 0.4480462496523483, 0.4480462496523483, 0.6456542219195164, 0.6456542219195164, 0.4480462496523483, 0.6456542219195164, 0.4480462496523483, 0.6862335815411776, 0.6456542219195164, 0.4480462496523483, 0.4480462496523483, 0.6456542219195164, 0.6456542219195164, 0.4480462496523483, 0.4480462496523483, 0.4480462496523483, 0.008583919306242766, 0.4480462496523483, 0.6456542219195164, 0.6456542219195164, 0.4480462496523483, 0.4480462496523483, 0.6862335815411776, 0.4480462496523483, 0.8307747361222593, 0.4480462496523483, 0.4480462496523483, 0.4480462496523483, 0.6456542219195164, 0.6862335815411776, 0.6456542219195164, 0.4480462496523483, 0.6456542219195164, 0.6456542219195164, 0.4480462496523483, 0.01906438263877743, 0.4480462496523483, 0.4480462496523483, 0.4480462496523483, 0.6862335815411776, 0.4480462496523483, 0.4480462496523483]\n",
      "all_sum before preprocessing is: [2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.9682743585020686, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.9682743585020686, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.9682743585020686, 2.4014670552904187, 2.9682743585020686, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.9682743585020686, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.9682743585020686, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187, 2.4014670552904187]\n",
      "all_sum after preprocessing is: [-0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447  2.7080128  -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447  2.7080128  -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447  2.7080128  -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447]\n",
      "P is: [0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.9374978085838571, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.9374978085838571, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.9374978085838571, 0.40871634611018587, 0.9374978085838571, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.9374978085838571, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.9374978085838571, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587, 0.40871634611018587]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.082\n",
      "(*) epoch 2, cost 1.609\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.053\n",
      "(*) epoch 2, cost 0.748\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.8913310288727843, 0.7722563450881686, 0.5844374922866442, 0.5844374922866442, 1.8913310288727843, 1.8913310288727843, 0.5844374922866442, 0.7722563450881686, 1.8913310288727843, 0.7722563450881686, 1.70351217607126, 1.70351217607126, 0.7722563450881686, 0.7722563450881686, 0.7722563450881686, 1.8913310288727843, 1.8913310288727843, 0.5844374922866442, 1.70351217607126, 1.70351217607126, 0.7722563450881686, 1.8913310288727843, 1.8913310288727843, 1.8913310288727843, 0.7722563450881686, 1.8913310288727843, 1.8913310288727843, 1.8913310288727843, 1.8913310288727843, 1.70351217607126, 0.5844374922866442, 0.7722563450881686, 0.7722563450881686, 1.70351217607126, 0.5844374922866442, 0.5844374922866442, 1.8913310288727843, 1.70351217607126, 0.7722563450881686, 1.8913310288727843, 1.8913310288727843, 0.7722563450881686, 0.7722563450881686, 1.70351217607126, 1.8913310288727843, 1.70351217607126, 0.7722563450881686, 1.8913310288727843, 0.7557691173280815, 1.70351217607126]\n",
      "all_sum after preprocessing is: [ 0.99511622 -1.00568751 -1.34149053 -1.34149053  0.99511622  0.99511622\n",
      " -1.34149053 -1.00568751  0.99511622 -1.00568751  0.6593132   0.6593132\n",
      " -1.00568751 -1.00568751 -1.00568751  0.99511622  0.99511622 -1.34149053\n",
      "  0.6593132   0.6593132  -1.00568751  0.99511622  0.99511622  0.99511622\n",
      " -1.00568751  0.99511622  0.99511622  0.99511622  0.99511622  0.6593132\n",
      " -1.34149053 -1.00568751 -1.00568751  0.6593132  -1.34149053 -1.34149053\n",
      "  0.99511622  0.6593132  -1.00568751  0.99511622  0.99511622 -1.00568751\n",
      " -1.00568751  0.6593132   0.99511622  0.6593132  -1.00568751  0.99511622\n",
      " -1.03516517  0.6593132 ]\n",
      "P is: [0.7300972863918979, 0.2678246604339209, 0.20726504866952825, 0.20726504866952825, 0.7300972863918979, 0.7300972863918979, 0.20726504866952825, 0.2678246604339209, 0.7300972863918979, 0.2678246604339209, 0.6591060911095639, 0.6591060911095639, 0.2678246604339209, 0.2678246604339209, 0.2678246604339209, 0.7300972863918979, 0.7300972863918979, 0.20726504866952825, 0.6591060911095639, 0.6591060911095639, 0.2678246604339209, 0.7300972863918979, 0.7300972863918979, 0.7300972863918979, 0.2678246604339209, 0.7300972863918979, 0.7300972863918979, 0.7300972863918979, 0.7300972863918979, 0.6591060911095639, 0.20726504866952825, 0.2678246604339209, 0.2678246604339209, 0.6591060911095639, 0.20726504866952825, 0.20726504866952825, 0.7300972863918979, 0.6591060911095639, 0.2678246604339209, 0.7300972863918979, 0.7300972863918979, 0.2678246604339209, 0.2678246604339209, 0.6591060911095639, 0.7300972863918979, 0.6591060911095639, 0.2678246604339209, 0.7300972863918979, 0.26208395449385424, 0.6591060911095639]\n",
      "all_sum before preprocessing is: [1.0782012848237212, 1.5038256299773063, 1.0782012848237212, 1.8755393806911997, 3.088061317848208, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 1.8755393806911997, 1.0782012848237212, 1.0782012848237212, 1.8755393806911997, 1.8755393806911997, 1.0782012848237212, 1.0782012848237212, 1.8755393806911997, 1.8755393806911997, 1.0782012848237212, 1.0782012848237212, 1.8755393806911997, 1.8755393806911997, 1.8755393806911997, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 2.894222049735503, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 1.8755393806911997, 2.894222049735503, 1.0782012848237212, 1.8755393806911997, 1.8755393806911997, 1.8755393806911997, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 1.0782012848237212, 1.8755393806911997, 1.0782012848237212, 1.0782012848237212, 2.0968839538680246, 1.0782012848237212, 2.894222049735503, 1.0782012848237212, 1.8755393806911997]\n",
      "all_sum after preprocessing is: [-0.73796947  0.01481848 -0.73796947  0.67225651  2.81680465 -0.73796947\n",
      " -0.73796947 -0.73796947  0.67225651 -0.73796947 -0.73796947  0.67225651\n",
      "  0.67225651 -0.73796947 -0.73796947  0.67225651  0.67225651 -0.73796947\n",
      " -0.73796947  0.67225651  0.67225651  0.67225651 -0.73796947 -0.73796947\n",
      " -0.73796947 -0.73796947  2.47396744 -0.73796947 -0.73796947 -0.73796947\n",
      "  0.67225651  2.47396744 -0.73796947  0.67225651  0.67225651  0.67225651\n",
      " -0.73796947 -0.73796947 -0.73796947 -0.73796947 -0.73796947 -0.73796947\n",
      "  0.67225651 -0.73796947 -0.73796947  1.06374146 -0.73796947  2.47396744\n",
      " -0.73796947  0.67225651]\n",
      "P is: [0.3234483247200918, 0.5037045520103358, 0.3234483247200918, 0.6620082452314635, 0.9435771894827129, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.6620082452314635, 0.3234483247200918, 0.3234483247200918, 0.6620082452314635, 0.6620082452314635, 0.3234483247200918, 0.3234483247200918, 0.6620082452314635, 0.6620082452314635, 0.3234483247200918, 0.3234483247200918, 0.6620082452314635, 0.6620082452314635, 0.6620082452314635, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.9222965707208985, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.6620082452314635, 0.9222965707208985, 0.3234483247200918, 0.6620082452314635, 0.6620082452314635, 0.6620082452314635, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.3234483247200918, 0.6620082452314635, 0.3234483247200918, 0.3234483247200918, 0.7434048942787354, 0.3234483247200918, 0.9222965707208985, 0.3234483247200918, 0.6620082452314635]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.560\n",
      "(*) epoch 2, cost 2.819\n",
      "(*) epoch 3, cost 1.811\n",
      "(*) epoch 4, cost 1.488\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.913\n",
      "(*) epoch 2, cost 1.393\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.140379417254782, 3.872149132948765, 3.09393264050877, 3.140379417254782, 3.2690914485815297, 2.763770430757866, 3.140379417254782, 3.872149132948765, 3.140379417254782, 5.166631693377814, 3.872149132948765, 4.324083207313214, 3.140379417254782, 3.140379417254782, 5.898401409071797, 3.872149132948765, 3.140379417254782, 3.140379417254782, 3.140379417254782, 3.6747333485420413, 3.140379417254782, 3.872149132948765, 2.5373217328875466, 3.872149132948765, 3.6969903248760057, 3.6747333485420413, 5.898401409071797, 3.872149132948765, 3.7897292760259536, 4.521498991719937, 3.140379417254782, 3.872149132948765, 4.181520986258617, 3.872149132948765, 3.2690914485815297, 3.2690914485815297, 3.2690914485815297, 3.140379417254782, 2.763770430757866, 4.969215908971091, 3.140379417254782, 3.140379417254782, 6.207773262381648, 5.898401409071797, 2.5373217328875466, 3.872149132948765, 5.898401409071797, 4.181520986258617, 3.872149132948765, 3.6969903248760057]\n",
      "all_sum after preprocessing is: [-0.70764791  0.10168496 -0.75901776 -0.70764791 -0.56529318 -1.12417516\n",
      " -0.70764791  0.10168496 -0.70764791  1.53337481  0.10168496  0.6015213\n",
      " -0.70764791 -0.70764791  2.34270767  0.10168496 -0.70764791 -0.70764791\n",
      " -0.70764791 -0.1166557  -0.70764791  0.10168496 -1.37462604  0.10168496\n",
      " -0.09203962 -0.1166557   2.34270767  0.10168496  0.01052909  0.81986196\n",
      " -0.70764791  0.10168496  0.44384835  0.10168496 -0.56529318 -0.56529318\n",
      " -0.56529318 -0.70764791 -1.12417516  1.31503415 -0.70764791 -0.70764791\n",
      "  2.68487106  2.34270767 -1.37462604  0.10168496  2.34270767  0.44384835\n",
      "  0.10168496 -0.09203962]\n",
      "P is: [0.3301187748341504, 0.5253993572028695, 0.3188595590270509, 0.3301187748341504, 0.3623236063111132, 0.2452376557703261, 0.3301187748341504, 0.5253993572028695, 0.3301187748341504, 0.8224995524303775, 0.5253993572028695, 0.6460042780209518, 0.3301187748341504, 0.3301187748341504, 0.9123528463045202, 0.5253993572028695, 0.3301187748341504, 0.3301187748341504, 0.3301187748341504, 0.47086910239679464, 0.3301187748341504, 0.5253993572028695, 0.20187346739902362, 0.5253993572028695, 0.47700632416809413, 0.47086910239679464, 0.9123528463045202, 0.5253993572028695, 0.5026322491940638, 0.6942070365849564, 0.3301187748341504, 0.5253993572028695, 0.6091756317688501, 0.5253993572028695, 0.3623236063111132, 0.3623236063111132, 0.3623236063111132, 0.3301187748341504, 0.2452376557703261, 0.7883543318968391, 0.3301187748341504, 0.3301187748341504, 0.9361279954384097, 0.9123528463045202, 0.20187346739902362, 0.5253993572028695, 0.9123528463045202, 0.6091756317688501, 0.5253993572028695, 0.47700632416809413]\n",
      "all_sum before preprocessing is: [1.2661354045320965, 1.722871425345555, 1.722871425345555, 2.090930806412648, 2.090930806412648, 1.146384244505318, 2.8261168705812953, 2.667417987252885, 2.706365710554517, 1.146384244505318, 1.146384244505318, 1.146384244505318, 2.667417987252885, 2.706365710554517, 2.2106819664394264, 2.090930806412648, 1.8426225853723335, 1.722871425345555, 2.090930806412648, 2.3383063294874242, 2.667417987252885, 3.282852891394754, 1.8426225853723335, 2.090930806412648, 2.667417987252885, 1.2661354045320965, 1.146384244505318, 1.146384244505318, 2.090930806412648, 2.667417987252885, 1.5016119686345857, 1.761819148647187, 1.722871425345555, 1.146384244505318, 2.090930806412648, 2.3383063294874242, 2.090930806412648, 3.282852891394754, 1.722871425345555, 2.3383063294874242, 2.667417987252885, 1.146384244505318, 1.722871425345555, 1.146384244505318, 2.090930806412648, 1.722871425345555, 2.667417987252885, 1.146384244505318, 1.761819148647187, 2.090930806412648]\n",
      "all_sum after preprocessing is: [-1.17491921 -0.40986701 -0.40986701  0.20664806  0.20664806 -1.37550748\n",
      "  1.43811589  1.17228853  1.23752762 -1.37550748 -1.37550748 -1.37550748\n",
      "  1.17228853  1.23752762  0.40723633  0.20664806 -0.20927874 -0.40986701\n",
      "  0.20664806  0.62101255  1.17228853  2.2031681  -0.20927874  0.20664806\n",
      "  1.17228853 -1.17491921 -1.37550748 -1.37550748  0.20664806  1.17228853\n",
      " -0.78048598 -0.34462792 -0.40986701 -1.37550748  0.20664806  0.62101255\n",
      "  0.20664806  2.2031681  -0.40986701  0.62101255  1.17228853 -1.37550748\n",
      " -0.40986701 -1.37550748  0.20664806 -0.40986701  1.17228853 -1.37550748\n",
      " -0.34462792  0.20664806]\n",
      "P is: [0.23596696455422256, 0.39894400989275525, 0.39894400989275525, 0.5514789513668662, 0.5514789513668662, 0.20173148659294982, 0.80816271721017, 0.7635584299327565, 0.7751333680065803, 0.20173148659294982, 0.20173148659294982, 0.20173148659294982, 0.7635584299327565, 0.7751333680065803, 0.600425018197923, 0.5514789513668662, 0.44787043878038685, 0.39894400989275525, 0.5514789513668662, 0.6504488025583466, 0.7635584299327565, 0.9005336464765117, 0.44787043878038685, 0.5514789513668662, 0.7635584299327565, 0.23596696455422256, 0.20173148659294982, 0.20173148659294982, 0.5514789513668662, 0.7635584299327565, 0.31421515495793073, 0.41468573915891527, 0.39894400989275525, 0.20173148659294982, 0.5514789513668662, 0.6504488025583466, 0.5514789513668662, 0.9005336464765117, 0.39894400989275525, 0.6504488025583466, 0.7635584299327565, 0.20173148659294982, 0.39894400989275525, 0.20173148659294982, 0.5514789513668662, 0.39894400989275525, 0.7635584299327565, 0.20173148659294982, 0.41468573915891527, 0.5514789513668662]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.842\n",
      "(*) epoch 2, cost 4.064\n",
      "(*) epoch 3, cost 3.586\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.385\n",
      "(*) epoch 2, cost 3.476\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8431344616733771, 2.548393029736, 3.24694415735686, 1.794251429780727, 1.794251429780727, 1.8431344616733771, 1.794251429780727, 2.9961099590656493, 4.7020767438763915, 3.8990521120284685, 4.346769041358117, 4.7020767438763915, 2.548393029736, 1.794251429780727, 4.653193711983741, 5.0313252418263374, 4.346769041358117, 3.8990521120284685, 1.8431344616733771, 1.8431344616733771, 1.794251429780727, 1.794251429780727, 2.9961099590656493, 5.658169510230225, 4.297886009465467, 1.794251429780727, 4.653193711983741, 1.794251429780727, 3.8990521120284685, 4.297886009465467, 4.653193711983741, 2.548393029736, 3.8990521120284685, 1.8431344616733771, 4.653193711983741, 3.8990521120284685, 1.794251429780727, 1.8431344616733771, 3.9479351439211188, 5.05202760942074, 2.548393029736, 3.8990521120284685, 2.59727606162865, 5.05202760942074, 1.8431344616733771, 4.653193711983741, 3.680666159533869, 4.653193711983741, 1.8431344616733771, 2.548393029736]\n",
      "all_sum after preprocessing is: [-1.12245509 -0.55493687  0.0071839  -1.16179103 -1.16179103 -1.12245509\n",
      " -1.16179103 -0.19466118  1.17812218  0.53193208  0.89220776  1.17812218\n",
      " -0.55493687 -1.16179103  1.13878624  1.44306688  0.89220776  0.53193208\n",
      " -1.12245509 -1.12245509 -1.16179103 -1.16179103 -0.19466118  1.94748549\n",
      "  0.85287182 -1.16179103  1.13878624 -1.16179103  0.53193208  0.85287182\n",
      "  1.13878624 -0.55493687  0.53193208 -1.12245509  1.13878624  0.53193208\n",
      " -1.16179103 -1.12245509  0.57126802  1.45972598 -0.55493687  0.53193208\n",
      " -0.51560093  1.45972598 -1.12245509  1.13878624  0.35619794  1.13878624\n",
      " -1.12245509 -0.55493687]\n",
      "P is: [0.24555617418357628, 0.3647197780554348, 0.5017959683149861, 0.23834199796878863, 0.23834199796878863, 0.24555617418357628, 0.23834199796878863, 0.4514877968557027, 0.7646099990218774, 0.6299336252509944, 0.709345566878888, 0.7646099990218774, 0.3647197780554348, 0.23834199796878863, 0.7574567211420258, 0.8089291266277074, 0.709345566878888, 0.6299336252509944, 0.24555617418357628, 0.24555617418357628, 0.23834199796878863, 0.23834199796878863, 0.4514877968557027, 0.8751722008208423, 0.7011692246829248, 0.23834199796878863, 0.7574567211420258, 0.23834199796878863, 0.6299336252509944, 0.7011692246829248, 0.7574567211420258, 0.3647197780554348, 0.6299336252509944, 0.24555617418357628, 0.7574567211420258, 0.6299336252509944, 0.23834199796878863, 0.24555617418357628, 0.6390557125852487, 0.8114907605486418, 0.3647197780554348, 0.6299336252509944, 0.37388145854244903, 0.8114907605486418, 0.24555617418357628, 0.7574567211420258, 0.588119751527477, 0.7574567211420258, 0.24555617418357628, 0.3647197780554348]\n",
      "all_sum before preprocessing is: [4.215700139021825, 5.187863972059261, 4.942836222087716, 4.215700139021825, 4.215700139021825, 4.215700139021825, 4.207867657750864, 3.2357038247134278, 5.187863972059261, 4.546702844482679, 1.7264788919965048, 4.5545353257536405, 2.706475206304902, 4.215700139021825, 3.574539011445243, 3.2357038247134278, 3.2357038247134278, 4.017474226074153, 4.207867657750864, 2.6986427250339413, 5.187863972059261, 1.7264788919965048, 1.7264788919965048, 4.215700139021825, 4.207867657750864, 3.2357038247134278, 4.215700139021825, 5.048941784717133, 2.06531407872832, 2.06531407872832, 2.2208853509599975, 3.6786390393423383, 4.207867657750864, 3.2357038247134278, 4.207867657750864, 3.2357038247134278, 3.2357038247134278, 4.215700139021825, 4.207867657750864, 3.2357038247134278, 4.215700139021825, 2.06531407872832, 1.7264788919965048, 5.187863972059261, 3.2357038247134278, 4.215700139021825, 4.546702844482679, 5.187863972059261, 4.546702844482679, 4.215700139021825]\n",
      "all_sum after preprocessing is: [ 0.47115342  1.42861097  1.18728984  0.47115342  0.47115342  0.47115342\n",
      "  0.46343942 -0.49401814  1.42861097  0.79714892 -1.98041247  0.80486292\n",
      " -1.01524092  0.47115342 -0.16030863 -0.49401814 -0.49401814  0.27592614\n",
      "  0.46343942 -1.02295492  1.42861097 -1.98041247 -1.98041247  0.47115342\n",
      "  0.46343942 -0.49401814  0.47115342  1.29179031 -1.64670297 -1.64670297\n",
      " -1.49348508 -0.05778336  0.46343942 -0.49401814  0.46343942 -0.49401814\n",
      " -0.49401814  0.47115342  0.46343942 -0.49401814  0.47115342 -1.64670297\n",
      " -1.98041247  1.42861097 -0.49401814  0.47115342  0.79714892  1.42861097\n",
      "  0.79714892  0.47115342]\n",
      "P is: [0.6156567180401914, 0.8066847966154687, 0.7662560048028525, 0.6156567180401914, 0.6156567180401914, 0.6156567180401914, 0.6138297841307706, 0.37894745543265224, 0.8066847966154687, 0.6893642778026264, 0.12127487517044352, 0.6910137443855999, 0.2659554478393295, 0.6156567180401914, 0.4600084498784365, 0.37894745543265224, 0.37894745543265224, 0.5685471808750466, 0.6138297841307706, 0.26445221858250256, 0.8066847966154687, 0.12127487517044352, 0.12127487517044352, 0.6156567180401914, 0.6138297841307706, 0.37894745543265224, 0.6156567180401914, 0.7844500635511845, 0.16155505095935546, 0.16155505095935546, 0.18339921225449382, 0.4855581770571662, 0.6138297841307706, 0.37894745543265224, 0.6138297841307706, 0.37894745543265224, 0.37894745543265224, 0.6156567180401914, 0.6138297841307706, 0.37894745543265224, 0.6156567180401914, 0.16155505095935546, 0.12127487517044352, 0.8066847966154687, 0.37894745543265224, 0.6156567180401914, 0.6893642778026264, 0.8066847966154687, 0.6893642778026264, 0.6156567180401914]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.451\n",
      "(*) epoch 2, cost 3.474\n",
      "(*) epoch 3, cost 2.480\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.925\n",
      "(*) epoch 2, cost 2.871\n",
      "(*) epoch 3, cost 2.348\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.751028560441896, 0.340185264390314, 0.340185264390314, 1.01747282512108, 0.340185264390314, 2.117001752357001, 1.01747282512108, 0.46165347394485823, 1.1389410346756244, 0.340185264390314, 0.340185264390314, 1.01747282512108, 0.340185264390314, 1.01747282512108, 0.340185264390314, 0.46165347394485823, 0.340185264390314, 0.46165347394485823, 0.340185264390314, 1.01747282512108, 0.751028560441896, 0.46165347394485823, 0.340185264390314, 0.340185264390314, 0.46165347394485823, 1.01747282512108, 0.340185264390314, 0.46165347394485823, 0.340185264390314, 0.46165347394485823, 0.340185264390314, 1.01747282512108, 0.340185264390314, 0.340185264390314, 0.340185264390314, 1.1389410346756244, 0.340185264390314, 0.340185264390314, 0.340185264390314, 0.340185264390314, 1.01747282512108, 0.340185264390314, 0.46165347394485823, 1.01747282512108, 0.340185264390314, 0.340185264390314, 0.46165347394485823, 0.340185264390314, 1.9955335428024568, 0.46165347394485823]\n",
      "all_sum after preprocessing is: [ 0.36181033 -0.64521296 -0.64521296  1.0148953  -0.64521296  3.70996481\n",
      "  1.0148953  -0.34748067  1.31262759 -0.64521296 -0.64521296  1.0148953\n",
      " -0.64521296  1.0148953  -0.64521296 -0.34748067 -0.64521296 -0.34748067\n",
      " -0.64521296  1.0148953   0.36181033 -0.34748067 -0.64521296 -0.64521296\n",
      " -0.34748067  1.0148953  -0.64521296 -0.34748067 -0.64521296 -0.34748067\n",
      " -0.64521296  1.0148953  -0.64521296 -0.64521296 -0.64521296  1.31262759\n",
      " -0.64521296 -0.64521296 -0.64521296 -0.64521296  1.0148953  -0.64521296\n",
      " -0.34748067  1.0148953  -0.64521296 -0.64521296 -0.34748067 -0.64521296\n",
      "  3.41223252 -0.34748067]\n",
      "P is: [0.5894785928376638, 0.34406909420491066, 0.34406909420491066, 0.7339770732016134, 0.34406909420491066, 0.9761064898363431, 0.7339770732016134, 0.4139934846035423, 0.7879525144521232, 0.34406909420491066, 0.34406909420491066, 0.7339770732016134, 0.34406909420491066, 0.7339770732016134, 0.34406909420491066, 0.4139934846035423, 0.34406909420491066, 0.4139934846035423, 0.34406909420491066, 0.7339770732016134, 0.5894785928376638, 0.4139934846035423, 0.34406909420491066, 0.34406909420491066, 0.4139934846035423, 0.7339770732016134, 0.34406909420491066, 0.4139934846035423, 0.34406909420491066, 0.4139934846035423, 0.34406909420491066, 0.7339770732016134, 0.34406909420491066, 0.34406909420491066, 0.34406909420491066, 0.7879525144521232, 0.34406909420491066, 0.34406909420491066, 0.34406909420491066, 0.34406909420491066, 0.7339770732016134, 0.34406909420491066, 0.4139934846035423, 0.7339770732016134, 0.34406909420491066, 0.34406909420491066, 0.4139934846035423, 0.34406909420491066, 0.9680846521343714, 0.4139934846035423]\n",
      "all_sum before preprocessing is: [3.7632175309318305, 2.203370982339334, 2.1432942078728634, 2.9452619996493916, 1.2968881423290117, 1.2968881423290117, 3.9073817979880436, 1.2968881423290117, 2.1432942078728634, 2.0387791596390694, 2.203370982339334, 4.813864637998366, 2.0387791596390694, 2.0387791596390694, 1.2968881423290117, 3.0497770478831856, 2.9452619996493916, 2.885185225182921, 2.9452619996493916, 1.2968881423290117, 2.1432942078728634, 1.2968881423290117, 1.2968881423290117, 2.9452619996493916, 2.203370982339334, 3.9073817979880436, 1.2968881423290117, 1.2968881423290117, 2.1432942078728634, 2.0387791596390694, 2.9452619996493916, 1.2968881423290117, 3.0497770478831856, 3.9073817979880436, 2.203370982339334, 2.9452619996493916, 2.203370982339334, 2.0387791596390694, 2.203370982339334, 1.2968881423290117, 2.203370982339334, 1.2968881423290117, 2.0387791596390694, 2.203370982339334, 2.1432942078728634, 1.2968881423290117, 1.2968881423290117, 2.203370982339334, 1.2968881423290117, 2.9452619996493916]\n",
      "all_sum after preprocessing is: [ 1.78854827 -0.04622818 -0.11689376  0.82642443 -1.11248266 -1.11248266\n",
      "  1.95812213 -1.11248266 -0.11689376 -0.23983005 -0.04622818  3.02437661\n",
      " -0.23983005 -0.23983005 -1.11248266  0.94936072  0.82642443  0.75575886\n",
      "  0.82642443 -1.11248266 -0.11689376 -1.11248266 -1.11248266  0.82642443\n",
      " -0.04622818  1.95812213 -1.11248266 -1.11248266 -0.11689376 -0.23983005\n",
      "  0.82642443 -1.11248266  0.94936072  1.95812213 -0.04622818  0.82642443\n",
      " -0.04622818 -0.23983005 -0.04622818 -1.11248266 -0.04622818 -1.11248266\n",
      " -0.23983005 -0.04622818 -0.11689376 -1.11248266 -1.11248266 -0.04622818\n",
      " -1.11248266  0.82642443]\n",
      "P is: [0.8567491979953351, 0.4884450122455637, 0.47080979183371274, 0.6955983645237739, 0.24740833356411415, 0.24740833356411415, 0.876329580290734, 0.24740833356411415, 0.47080979183371274, 0.44032823348817457, 0.4884450122455637, 0.9536633106322441, 0.44032823348817457, 0.44032823348817457, 0.24740833356411415, 0.7209865962183202, 0.6955983645237739, 0.6804322287661531, 0.6955983645237739, 0.24740833356411415, 0.47080979183371274, 0.24740833356411415, 0.24740833356411415, 0.6955983645237739, 0.4884450122455637, 0.876329580290734, 0.24740833356411415, 0.24740833356411415, 0.47080979183371274, 0.44032823348817457, 0.6955983645237739, 0.24740833356411415, 0.7209865962183202, 0.876329580290734, 0.4884450122455637, 0.6955983645237739, 0.4884450122455637, 0.44032823348817457, 0.4884450122455637, 0.24740833356411415, 0.4884450122455637, 0.24740833356411415, 0.44032823348817457, 0.4884450122455637, 0.47080979183371274, 0.24740833356411415, 0.24740833356411415, 0.4884450122455637, 0.24740833356411415, 0.6955983645237739]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.323\n",
      "(*) epoch 2, cost 1.244\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.770\n",
      "(*) epoch 2, cost 1.557\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "    female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "    trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s = \\\n",
    "    run_proc_multi(simulate_wrapper, custom_train_reps, svm.SVC , n_times = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = \"../outputs/sim1_svm_scores.csv\"\n",
    "save_scores(male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "        female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "        trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans female to female accuracy increment is 2.7%\n",
      "median trans female to female accuracy increment is 0.0%\n",
      "average trans female to female accuracy f1 is 6.4%\n",
      "median trans female to female accuracy f1 is 0.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Larger is better (>0)\n",
    "\"\"\"\n",
    "hist_plot(score_path, filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans female to female accuracy increment is 10.1%\n",
      "median trans female to female accuracy increment is 2.0%\n",
      "average trans female to female accuracy f1 is 14.9%\n",
      "median trans female to female accuracy f1 is 4.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "female accuracy > 0.7 filtered out \n",
    "\"\"\"\n",
    "\n",
    "hist_plot(score_path, filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
