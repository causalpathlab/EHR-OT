{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation goals\n",
    "\n",
    "* Categorical response variable\n",
    "\n",
    "* Different feature distribution for different domains\n",
    "\n",
    "Simulation\n",
    "\n",
    "* $D$: total number of features\n",
    "\n",
    "* $d_{1}$: number of features with higher frequency in a domain 1\n",
    "\n",
    "* $d_{2}$: number of features with higher frequency in a domain 2\n",
    "\n",
    "\n",
    "* $d_{1} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$\n",
    "\n",
    "* $d_{2} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$ ($d_{1} + d_{2} \\le D$)\n",
    "\n",
    "* $k \\in [D]$ for indexing feature\n",
    "\n",
    "* Let $\\Delta_{r} = \\{j \\in [D]: \\textrm{feature } j \\textrm{ is more frequent in a domain } r \\}$\n",
    "\n",
    "* Sample $\\Delta_{1} \\subseteq [D]$ such that $|\\Delta_{1}| = d_{1}$ \n",
    "\n",
    "* Sample $\\Delta_{2} \\subseteq [D]\\backslash \\Delta_{1}$ such that $|\\Delta_{2}| = d_{2}$\n",
    "\n",
    "* Let $\\alpha_{1} \\overset{\\Delta}{=} \\left( \\alpha_{11}, \\ldots, \\alpha_{1D} \\right)$ be a feature frequency vector for a domain 1\n",
    "\n",
    "* Let $\\alpha_{2} \\overset{\\Delta}{=} \\left( \\alpha_{21}, \\ldots, \\alpha_{2D} \\right)$ be a feature frequency vector for a domain 2\n",
    "\n",
    "\n",
    "* For each $k \\in [D]$: \n",
    "\n",
    "    * If $k \\in \\Delta_{1}$, $\\alpha_{1k} > \\alpha_{2k}$\n",
    "\n",
    "    * If $k \\in \\Delta_{2}$, $\\alpha_{2k} > \\alpha_{1k}$\n",
    "\n",
    "    * Otherwise $\\alpha_{1k} = \\alpha_{2k}$\n",
    "\n",
    "\n",
    "* Sample $\\rho_{1} \\sim \\operatorname{Dir}(\\alpha_{1})$\n",
    "\n",
    "* Sample $\\rho_{2} \\sim \\operatorname{Dir}(\\alpha_{2})$\n",
    "\n",
    "* Sample a code-specific contribution to mortality: $W_{i} \\sim   \\mathcal{N}\\!\\left(0,1\\right)$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "    * $\\tilde{X}_{i} \\sim \\operatorname{Multi}(n_{i}; \\rho_{r})$ where $\\tilde{X}_{i}$ is a vector of counts for each diagnosis code/feature, $n_i = 3k$.\n",
    "\n",
    "\t* We set $X_{ik} = \\min \\left\\{ \\tilde{X}_{ik}, 1 \\right\\}$ where $\\tilde{X}_{ik}$ is a count for a diagnosis code/feature $k$, $k \\in [D]$\n",
    "\n",
    "* For all patient $i$ in a domain $r$\n",
    "\n",
    "    * $b = -\\operatorname{Mean}(\\sum_{k} W_{k} X_{ik})$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "\t* pathogenic score $\\bar{p}_{i} = \\operatorname{sigmoid}(\\sum_{k} W_{k} X_{ik} + b)$ (aka a liability model)\n",
    "\n",
    "    <!-- * If $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; else $Y_{i} = 0$. -->\n",
    "\n",
    "\t* Sample $Y_{i} \\sim \\operatorname{Bern}(\\bar{p}_{i})$\n",
    "\n",
    "    * Alternatively, if $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; otherwise, $Y_{i} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/deep_patient/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from deep_patient.sda import SDA\n",
    "from math import floor, exp, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "base_dir = \"/home/wanxinli/deep_patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    unit_1 = 1/(2*d_1-2*d_2+3*D)\n",
    "    alpha_1 = [5*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([3*unit_1]*(D-d_1-d_2))\n",
    "  \n",
    "    unit_2 = 1/(-2*d_1+2*d_2+3*D)\n",
    "    alpha_2 = [unit_2]*d_1\n",
    "    alpha_2.extend([5*unit_2]*d_2)\n",
    "    alpha_2.extend([3*unit_2]*(D-d_1-d_2))  \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [abs(W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            cur_sum = np.sum(np.multiply(W, X_i))\n",
    "            all_sum.append(cur_sum)\n",
    "        \n",
    "        print(\"all_sum before preprocessing is:\", all_sum)\n",
    "        # standardize\n",
    "        all_sum = preprocessing.scale(all_sum)\n",
    "        print(\"all_sum after preprocessing is:\", all_sum)\n",
    "\n",
    "        all_sum = np.array(all_sum)\n",
    "        \n",
    "        P = []\n",
    "        for cur_sum in all_sum:\n",
    "            p_i = sigmoid(cur_sum)\n",
    "            P.append(p_i)\n",
    "            Y_i = 0\n",
    "            if p_i >= 0.5: # TODO: mimic exact logistic regression, change to np.random.binomial later\n",
    "                Y_i = 1\n",
    "            # Y_i = np.random.binomial(1, p_i) # too much noise, domain 1 data cannot learn well\n",
    "            Y.append(int(Y_i))\n",
    "        print(\"P is:\", P)\n",
    "\n",
    "            \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), label_1, np.array(feature_2), label_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Wrapper function with different set ups for simulate()\n",
    "\"\"\"\n",
    "def simulate_wrapper(num_patient):\n",
    "    D = 20\n",
    "    d_1 = 5\n",
    "    d_2 = 5\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train deep patient model and generate representations for males and females\n",
    "\"\"\"\n",
    "\n",
    "def custom_train_reps(male_seqs, female_seqs):\n",
    "    \"\"\" \n",
    "    Customized training algorithm for generating male representations and female representations\n",
    "    \n",
    "    :returns: male representations, female representations\n",
    "    \"\"\"\n",
    "\n",
    "    # customized parameters\n",
    "    nhidden = 3\n",
    "    nlayer = 1\n",
    "\n",
    "    # for males\n",
    "    # initiate the model\n",
    "    male_sda = SDA(male_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    male_sda.train(male_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    male_reps = male_sda.apply(male_seqs)\n",
    "\n",
    "    # for females\n",
    "    # initiate the model\n",
    "    female_sda = SDA(female_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    female_sda.train(female_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    female_reps = female_sda.apply(female_seqs)\n",
    "    return male_reps, female_reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(male_reps, male_labels, female_reps, female_labels, trans_female_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=130)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\", s=130)\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=100)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\", s=100)\n",
    "\n",
    "    ax.scatter(trans_female_reps[female_0,0], trans_female_reps[female_0,1], trans_female_reps[female_0,2], color='green', label=\"trans female 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_female_reps[female_1,0], trans_female_reps[female_1,1], trans_female_reps[female_1,2], color='green', label=\"trans female 1\",  alpha=0.5, marker=\"x\", s=70)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_opp(male_reps, male_labels, female_reps, female_labels, trans_male_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(trans_male_reps[male_0,0], trans_male_reps[male_0,1], trans_male_reps[male_0,2], color='green', label=\"trans male 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_male_reps[male_1,0], trans_male_reps[male_1,1], trans_male_reps[male_1,2], color='green', label=\"trans male 1\",  alpha=0.5, marker=\"x\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_sum before preprocessing is: [2.39364595660408, 5.834220276130744, 4.320846141569943, 4.320846141569943, 4.320846141569943, 4.320846141569943, 4.320846141569943, 4.320846141569943, 3.8971076775369253, 2.8173844206370973]\n",
      "all_sum after preprocessing is: [-1.90532827  1.96652392  0.26344752  0.26344752  0.26344752  0.26344752\n",
      "  0.26344752  0.26344752 -0.2134068  -1.42847395]\n",
      "P is: [0.12950660752702184, 0.8772372580525896, 0.5654835777710778, 0.5654835777710778, 0.5654835777710778, 0.5654835777710778, 0.5654835777710778, 0.5654835777710778, 0.44684986355399686, 0.19333657131441243]\n",
      "all_sum before preprocessing is: [2.343288509126112, 0.33159901219477417, 0.33159901219477417, 3.181500666249768, 0.33159901219477417, 0.35138459733345945, 0.33159901219477417, 0.3624639725302785, 0.9837458067753039, 3.181500666249768]\n",
      "all_sum after preprocessing is: [ 1.00211367 -0.72052977 -0.72052977  1.71988879 -0.72052977 -0.70358704\n",
      " -0.72052977 -0.69409959 -0.16208554  1.71988879]\n",
      "P is: [0.731473948195714, 0.3272763344804001, 0.3272763344804001, 0.8481145113617575, 0.3272763344804001, 0.33101741469978635, 0.3272763344804001, 0.3331217208961875, 0.4595670969236509, 0.8481145113617575]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[10, -1, -1, -1],\n",
       "        [ 3,  4, 10, 17],\n",
       "        [ 3,  4, 10, -1],\n",
       "        [ 3,  4, 10, -1],\n",
       "        [ 3,  4, 10, -1],\n",
       "        [ 3,  4, 10, -1],\n",
       "        [ 3,  4, 10, -1],\n",
       "        [ 3,  4, 10, -1],\n",
       "        [ 4, 10, -1, -1],\n",
       "        [ 3, 10, -1, -1]]),\n",
       " [0, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       " array([[ 2,  7,  9, 18],\n",
       "        [ 2,  7, -1, -1],\n",
       "        [ 2,  7, -1, -1],\n",
       "        [ 2,  7, 13, -1],\n",
       "        [ 2,  7, -1, -1],\n",
       "        [ 0,  2,  7, -1],\n",
       "        [ 2,  7, -1, -1],\n",
       "        [ 2,  7, 14, -1],\n",
       "        [ 2,  7,  8, -1],\n",
       "        [ 2,  7, 13, -1]]),\n",
       " [1, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_wrapper(num_patient=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_sum before preprocessing is: [1.1738067755977315, 0.5113642941027458, 0.5113642941027458, 0.5264006009314561, 2.085745002012118, 0.49018088292456985, 0.49018088292456985, 0.5113642941027458, 0.4751445760958595, 0.4751445760958595, 0.5113642941027458, 0.4751445760958595, 0.5113642941027458, 0.4751445760958595, 2.1007813088408285, 0.5264006009314561, 1.3761372880306881, 0.4751445760958595, 2.085745002012118, 2.085745002012118, 0.5113642941027458, 0.5113642941027458, 0.4751445760958595, 0.5113642941027458, 0.5113642941027458, 2.049525284005232, 0.5113642941027458, 0.5113642941027458, 0.4751445760958595, 1.4976160246148797, 2.049525284005232, 2.085745002012118, 0.5264006009314561, 2.064561590833942, 2.049525284005232, 2.1007813088408285, 0.4751445760958595, 0.5264006009314561, 0.5264006009314561, 0.5113642941027458, 2.085745002012118, 2.085745002012118, 0.5113642941027458, 2.049525284005232, 0.49018088292456985, 2.085745002012118, 0.4751445760958595, 0.7616497219487927, 0.4751445760958595, 0.4751445760958595]\n",
      "all_sum after preprocessing is: [ 0.25141087 -0.69060662 -0.69060662 -0.66922444  1.54822046 -0.72073021\n",
      " -0.72073021 -0.69060662 -0.74211239 -0.74211239 -0.69060662 -0.74211239\n",
      " -0.69060662 -0.74211239  1.56960264 -0.66922444  0.53913228 -0.74211239\n",
      "  1.54822046  1.54822046 -0.69060662 -0.69060662 -0.74211239 -0.69060662\n",
      " -0.69060662  1.4967147  -0.69060662 -0.69060662 -0.74211239  0.7118795\n",
      "  1.4967147   1.54822046 -0.66922444  1.51809688  1.4967147   1.56960264\n",
      " -0.74211239 -0.66922444 -0.66922444 -0.69060662  1.54822046  1.54822046\n",
      " -0.69060662  1.4967147  -0.72073021  1.54822046 -0.74211239 -0.33469157\n",
      " -0.74211239 -0.74211239]\n",
      "P is: [0.5625237339215391, 0.333898140341538, 0.333898140341538, 0.33867052244455426, 0.8246565628005549, 0.3272322057244157, 0.3272322057244157, 0.333898140341538, 0.3225423948773547, 0.3225423948773547, 0.333898140341538, 0.3225423948773547, 0.333898140341538, 0.3225423948773547, 0.827726954463415, 0.33867052244455426, 0.6316105404142831, 0.3225423948773547, 0.8246565628005549, 0.8246565628005549, 0.333898140341538, 0.333898140341538, 0.3225423948773547, 0.333898140341538, 0.333898140341538, 0.817083973477211, 0.333898140341538, 0.333898140341538, 0.3225423948773547, 0.670816326442491, 0.817083973477211, 0.8246565628005549, 0.33867052244455426, 0.8202580649058142, 0.817083973477211, 0.827726954463415, 0.3225423948773547, 0.33867052244455426, 0.33867052244455426, 0.333898140341538, 0.8246565628005549, 0.8246565628005549, 0.333898140341538, 0.817083973477211, 0.3272322057244157, 0.8246565628005549, 0.3225423948773547, 0.4170995318388829, 0.3225423948773547, 0.3225423948773547]\n",
      "all_sum before preprocessing is: [3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 2.5570762933019204, 3.8257230178073183, 2.5570762933019204, 3.8257230178073183, 3.8257230178073183, 4.336895736400504, 3.8257230178073183, 2.5570762933019204, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.858504537214989, 3.8257230178073183, 2.5570762933019204, 3.8257230178073183, 2.5570762933019204, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 4.336895736400504, 3.8257230178073183, 2.5570762933019204, 3.8257230178073183, 3.8257230178073183, 4.336895736400504, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 2.4977446319812318, 4.336895736400504, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.8257230178073183, 3.9700350207772206, 3.8257230178073183, 3.8257230178073183]\n",
      "all_sum after preprocessing is: [ 0.27913635  0.27913635  0.27913635  0.27913635  0.27913635 -2.35648063\n",
      "  0.27913635 -2.35648063  0.27913635  0.27913635  1.34109905  0.27913635\n",
      " -2.35648063  0.27913635  0.27913635  0.27913635  0.34724004  0.27913635\n",
      " -2.35648063  0.27913635 -2.35648063  0.27913635  0.27913635  0.27913635\n",
      "  0.27913635  0.27913635  0.27913635  0.27913635  1.34109905  0.27913635\n",
      " -2.35648063  0.27913635  0.27913635  1.34109905  0.27913635  0.27913635\n",
      "  0.27913635  0.27913635  0.27913635 -2.47974232  1.34109905  0.27913635\n",
      "  0.27913635  0.27913635  0.27913635  0.27913635  0.27913635  0.57894492\n",
      "  0.27913635  0.27913635]\n",
      "P is: [0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.08655203399021671, 0.5693344759033843, 0.08655203399021671, 0.5693344759033843, 0.5693344759033843, 0.7926706212230935, 0.5693344759033843, 0.08655203399021671, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5859481373080699, 0.5693344759033843, 0.08655203399021671, 0.5693344759033843, 0.08655203399021671, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.7926706212230935, 0.5693344759033843, 0.08655203399021671, 0.5693344759033843, 0.5693344759033843, 0.7926706212230935, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.07729057725666244, 0.7926706212230935, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.5693344759033843, 0.6408245972529724, 0.5693344759033843, 0.5693344759033843]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.974\n",
      "(*) epoch 2, cost 1.794\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.904\n",
      "(*) epoch 2, cost 2.674\n",
      "(*) epoch 3, cost 2.430\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.216999074320006, 5.893859114947103, 6.216999074320006, 6.216999074320006, 6.216999074320006, 5.893859114947103, 5.893859114947103, 6.216999074320006, 6.216999074320006, 6.216999074320006, 6.216999074320006, 5.893859114947103, 6.216999074320006, 6.216999074320006, 5.893859114947103, 6.216999074320006, 5.893859114947103, 6.216999074320006, 6.370180946089504, 5.893859114947103, 6.216999074320006, 6.216999074320006, 6.216999074320006, 5.893859114947103, 6.216999074320006, 5.893859114947103, 6.216999074320006, 5.893859114947103, 6.216999074320006, 5.893859114947103, 6.216999074320006, 6.216999074320006, 6.216999074320006, 5.893859114947103, 5.893859114947103, 6.216999074320006, 6.216999074320006, 6.216999074320006, 6.216999074320006, 5.893859114947103, 6.370180946089504, 6.216999074320006, 6.216999074320006, 5.893859114947103, 5.893859114947103, 6.216999074320006, 5.893859114947103, 5.893859114947103, 6.216999074320006, 5.893859114947103]\n",
      "all_sum after preprocessing is: [ 0.7099136  -1.25639732  0.7099136   0.7099136   0.7099136  -1.25639732\n",
      " -1.25639732  0.7099136   0.7099136   0.7099136   0.7099136  -1.25639732\n",
      "  0.7099136   0.7099136  -1.25639732  0.7099136  -1.25639732  0.7099136\n",
      "  1.64202731 -1.25639732  0.7099136   0.7099136   0.7099136  -1.25639732\n",
      "  0.7099136  -1.25639732  0.7099136  -1.25639732  0.7099136  -1.25639732\n",
      "  0.7099136   0.7099136   0.7099136  -1.25639732 -1.25639732  0.7099136\n",
      "  0.7099136   0.7099136   0.7099136  -1.25639732  1.64202731  0.7099136\n",
      "  0.7099136  -1.25639732 -1.25639732  0.7099136  -1.25639732 -1.25639732\n",
      "  0.7099136  -1.25639732]\n",
      "P is: [0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.6703820686178368, 0.6703820686178368, 0.22159469697311077, 0.22159469697311077, 0.6703820686178368, 0.6703820686178368, 0.6703820686178368, 0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.8378106057203549, 0.22159469697311077, 0.6703820686178368, 0.6703820686178368, 0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.22159469697311077, 0.6703820686178368, 0.6703820686178368, 0.6703820686178368, 0.22159469697311077, 0.22159469697311077, 0.6703820686178368, 0.6703820686178368, 0.6703820686178368, 0.6703820686178368, 0.22159469697311077, 0.8378106057203549, 0.6703820686178368, 0.6703820686178368, 0.22159469697311077, 0.22159469697311077, 0.6703820686178368, 0.22159469697311077, 0.22159469697311077, 0.6703820686178368, 0.22159469697311077]\n",
      "all_sum before preprocessing is: [3.2767845784584826, 3.2767845784584826, 1.3427849829368752, 1.9667299521416115, 3.2767845784584826, 3.2767845784584826, 3.2767845784584826, 3.2767845784584826, 4.440654139083506, 3.8167091698787696, 2.6035897028324424, 4.440654139083506, 2.6035897028324424, 3.2767845784584826, 2.0159798585629156, 3.2767845784584826, 3.2767845784584826, 2.6035897028324424, 3.7674592634574657, 2.6528396092537463, 3.2767845784584826, 3.2767845784584826, 3.2767845784584826, 2.6528396092537463, 2.6399248277676515, 2.6528396092537463, 3.8167091698787696, 1.9796447336277063, 1.9796447336277063, 4.440654139083506, 2.6528396092537463, 3.7674592634574657, 2.6035897028324424, 4.440654139083506, 2.6528396092537463, 4.440654139083506, 3.2767845784584826, 1.9796447336277063, 2.6528396092537463, 2.6528396092537463, 3.2767845784584826, 2.6035897028324424, 2.6528396092537463, 2.0159798585629156, 3.2767845784584826, 2.6528396092537463, 4.440654139083506, 2.6035897028324424, 2.6035897028324424, 2.6035897028324424]\n",
      "all_sum after preprocessing is: [ 0.33092165  0.33092165 -2.28120682 -1.4384846   0.33092165  0.33092165\n",
      "  0.33092165  0.33092165  1.90288517  1.06016296 -0.57831923  1.90288517\n",
      " -0.57831923  0.33092165 -1.37196593  0.33092165  0.33092165 -0.57831923\n",
      "  0.99364429 -0.51180056  0.33092165  0.33092165  0.33092165 -0.51180056\n",
      " -0.52924372 -0.51180056  1.06016296 -1.42104144 -1.42104144  1.90288517\n",
      " -0.51180056  0.99364429 -0.57831923  1.90288517 -0.51180056  1.90288517\n",
      "  0.33092165 -1.42104144 -0.51180056 -0.51180056  0.33092165 -0.57831923\n",
      " -0.51180056 -1.37196593  0.33092165 -0.51180056  1.90288517 -0.57831923\n",
      " -0.57831923 -0.57831923]\n",
      "P is: [0.5819836115093052, 0.5819836115093052, 0.09269141036215216, 0.1917801258778876, 0.5819836115093052, 0.5819836115093052, 0.5819836115093052, 0.5819836115093052, 0.8702177214097353, 0.7427216854817325, 0.3593194300010739, 0.8702177214097353, 0.3593194300010739, 0.5819836115093052, 0.20230240590198872, 0.5819836115093052, 0.5819836115093052, 0.3593194300010739, 0.7298071359824454, 0.3747715269208425, 0.5819836115093052, 0.5819836115093052, 0.5819836115093052, 0.3747715269208425, 0.37069329486482827, 0.3747715269208425, 0.7427216854817325, 0.1944983701316411, 0.1944983701316411, 0.8702177214097353, 0.3747715269208425, 0.7298071359824454, 0.3593194300010739, 0.8702177214097353, 0.3747715269208425, 0.8702177214097353, 0.5819836115093052, 0.1944983701316411, 0.3747715269208425, 0.3747715269208425, 0.5819836115093052, 0.3593194300010739, 0.3747715269208425, 0.20230240590198872, 0.5819836115093052, 0.3747715269208425, 0.8702177214097353, 0.3593194300010739, 0.3593194300010739, 0.3593194300010739]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.274\n",
      "(*) epoch 2, cost 1.897\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.30 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.285\n",
      "(*) epoch 2, cost 2.912\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.390262898803478, 4.4481082693523675, 6.664908747488029, 5.563032817145085, 3.866712883032409, 4.390262898803478, 4.09752726907019, 2.9941152903786104, 5.210915768514273, 4.390262898803478, 5.073663231422878, 5.503651398247561, 4.449644317701002, 5.199403199413135, 5.199403199413135, 4.170961081866834, 5.855768446878372, 5.292965048359521, 3.2883869684605322, 5.000229418626233, 3.4096896310535643, 5.199403199413135, 4.390262898803478, 5.210915768514273, 3.866712883032409, 6.370637069406107, 5.551520248043947, 4.390262898803478, 4.09752726907019, 4.74237994743429, 5.199403199413135, 4.74237994743429, 5.199403199413135, 4.390262898803478, 4.74237994743429, 4.09752726907019, 5.199403199413135, 6.312791698857218, 6.102105348969179, 4.191089118016576, 4.09752726907019, 4.191089118016576, 6.664908747488029, 2.764836952689464, 5.199403199413135, 6.102105348969179, 5.503651398247561, 4.09752726907019, 4.09752726907019, 3.866712883032409]\n",
      "all_sum after preprocessing is: [-0.43807179 -0.37319079  2.11323496  0.87733993 -1.02530021 -0.43807179\n",
      " -0.7664123  -2.0040302   0.48239555 -0.43807179  0.32844924  0.81073606\n",
      " -0.37146792  0.46948273  0.46948273 -0.68404687  1.20568045  0.57442433\n",
      " -1.67396682  0.24608381 -1.53791034  0.46948273 -0.43807179  0.48239555\n",
      " -1.02530021  1.78317157  0.86442711 -0.43807179 -0.7664123  -0.0431274\n",
      "  0.46948273 -0.0431274   0.46948273 -0.43807179 -0.0431274  -0.7664123\n",
      "  0.46948273  1.71829058  1.48197884 -0.6614707  -0.7664123  -0.6614707\n",
      "  2.11323496 -2.26119523  0.46948273  1.48197884  0.81073606 -0.7664123\n",
      " -0.7664123  -1.02530021]\n",
      "P is: [0.3922005196056792, 0.40777023913191457, 0.8921829073332417, 0.7062706864532644, 0.26399627108184, 0.3922005196056792, 0.3172557081051265, 0.11878042541931598, 0.6183133888413801, 0.3922005196056792, 0.581382006057906, 0.6922663325417231, 0.40818636856602736, 0.615261317530051, 0.615261317530051, 0.3353586821209898, 0.7695337614387566, 0.6397834376690764, 0.15789601576218276, 0.5612123604658054, 0.176839255544775, 0.615261317530051, 0.3922005196056792, 0.6183133888413801, 0.26399627108184, 0.8560880489975242, 0.7035847739414884, 0.3922005196056792, 0.3172557081051265, 0.4892198199153406, 0.615261317530051, 0.4892198199153406, 0.615261317530051, 0.3922005196056792, 0.4892198199153406, 0.3172557081051265, 0.615261317530051, 0.8479085207388891, 0.8148712870478434, 0.34040931656109247, 0.3172557081051265, 0.34040931656109247, 0.8921829073332417, 0.09438815188850302, 0.615261317530051, 0.8148712870478434, 0.6922663325417231, 0.3172557081051265, 0.3172557081051265, 0.26399627108184]\n",
      "all_sum before preprocessing is: [4.218021543107973, 3.881519163364023, 2.6966127787569834, 4.218021543107973, 2.6966127787569834, 4.218021543107973, 4.218021543107973, 2.6966127787569834, 4.218021543107973, 4.218021543107973, 4.218021543107973, 2.6966127787569834, 4.218021543107973, 3.5962381476497898, 2.6966127787569834, 2.6966127787569834, 2.6966127787569834, 4.218021543107973, 4.218021543107973, 4.503302558822206, 2.6966127787569834, 4.218021543107973, 4.218021543107973, 4.218021543107973, 4.218021543107973, 4.218021543107973, 4.218021543107973, 4.218021543107973, 2.9818937944712167, 4.218021543107973, 2.6966127787569834, 2.6966127787569834, 3.881519163364023, 2.6966127787569834, 2.6966127787569834, 4.218021543107973, 4.218021543107973, 4.218021543107973, 2.6966127787569834, 4.218021543107973, 4.218021543107973, 2.6966127787569834, 2.6966127787569834, 2.6966127787569834, 4.218021543107973, 2.6966127787569834, 2.6966127787569834, 4.218021543107973, 4.218021543107973, 2.6966127787569834]\n",
      "all_sum after preprocessing is: [ 0.85114509  0.39144963 -1.22724941  0.85114509 -1.22724941  0.85114509\n",
      "  0.85114509 -1.22724941  0.85114509  0.85114509  0.85114509 -1.22724941\n",
      "  0.85114509  0.00172761 -1.22724941 -1.22724941 -1.22724941  0.85114509\n",
      "  0.85114509  1.2408671  -1.22724941  0.85114509  0.85114509  0.85114509\n",
      "  0.85114509  0.85114509  0.85114509  0.85114509 -0.83752739  0.85114509\n",
      " -1.22724941 -1.22724941  0.39144963 -1.22724941 -1.22724941  0.85114509\n",
      "  0.85114509  0.85114509 -1.22724941  0.85114509  0.85114509 -1.22724941\n",
      " -1.22724941 -1.22724941  0.85114509 -1.22724941 -1.22724941  0.85114509\n",
      "  0.85114509 -1.22724941]\n",
      "P is: [0.7008072951130968, 0.5966316195830194, 0.2266632057078519, 0.7008072951130968, 0.2266632057078519, 0.7008072951130968, 0.7008072951130968, 0.2266632057078519, 0.7008072951130968, 0.7008072951130968, 0.7008072951130968, 0.2266632057078519, 0.7008072951130968, 0.5004319031743453, 0.2266632057078519, 0.2266632057078519, 0.2266632057078519, 0.7008072951130968, 0.7008072951130968, 0.7757149100253771, 0.2266632057078519, 0.7008072951130968, 0.7008072951130968, 0.7008072951130968, 0.7008072951130968, 0.7008072951130968, 0.7008072951130968, 0.7008072951130968, 0.30205579892179707, 0.7008072951130968, 0.2266632057078519, 0.2266632057078519, 0.5966316195830194, 0.2266632057078519, 0.2266632057078519, 0.7008072951130968, 0.7008072951130968, 0.7008072951130968, 0.2266632057078519, 0.7008072951130968, 0.7008072951130968, 0.2266632057078519, 0.2266632057078519, 0.2266632057078519, 0.7008072951130968, 0.2266632057078519, 0.2266632057078519, 0.7008072951130968, 0.7008072951130968, 0.2266632057078519]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 7.721\n",
      "(*) epoch 2, cost 4.876\n",
      "(*) epoch 3, cost 3.735\n",
      "(*) epoch 4, cost 3.330\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.829\n",
      "(*) epoch 2, cost 1.835\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [0.21263241794902776, 2.7044200773753633, 0.22683721722435446, 0.42676063955197036, 2.71862487665069, 0.21263241794902776, 0.22683721722435446, 0.21263241794902776, 0.21263241794902776, 0.41255584027664366, 0.21263241794902776, 0.5130006639192364, 0.22683721722435446, 0.21263241794902776, 0.5130006639192364, 0.21263241794902776, 0.527205463194563, 0.527205463194563, 0.42676063955197036, 0.527205463194563, 0.41255584027664366, 0.21263241794902776, 0.42676063955197036, 0.21263241794902776, 0.5130006639192364, 0.21263241794902776, 0.41255584027664366, 0.527205463194563, 0.5130006639192364, 0.22683721722435446, 0.21263241794902776, 0.22683721722435446, 0.22683721722435446, 0.7129240862468522, 0.21263241794902776, 0.41255584027664366, 0.42676063955197036, 0.21263241794902776, 0.21263241794902776, 0.22683721722435446, 0.5130006639192364, 0.42676063955197036, 0.22683721722435446, 0.22683721722435446, 0.22683721722435446, 2.418256630680481, 0.41255584027664366, 0.42676063955197036, 0.22683721722435446, 0.22683721722435446]\n",
      "all_sum after preprocessing is: [-0.4627031   3.99966633 -0.43726471 -0.07923574  4.02510471 -0.4627031\n",
      " -0.43726471 -0.4627031  -0.4627031  -0.10467413 -0.4627031   0.07520553\n",
      " -0.43726471 -0.4627031   0.07520553 -0.4627031   0.10064392  0.10064392\n",
      " -0.07923574  0.10064392 -0.10467413 -0.4627031  -0.07923574 -0.4627031\n",
      "  0.07520553 -0.4627031  -0.10467413  0.10064392  0.07520553 -0.43726471\n",
      " -0.4627031  -0.43726471 -0.43726471  0.4332345  -0.4627031  -0.10467413\n",
      " -0.07923574 -0.4627031  -0.4627031  -0.43726471  0.07520553 -0.07923574\n",
      " -0.43726471 -0.43726471 -0.43726471  3.48719609 -0.10467413 -0.07923574\n",
      " -0.43726471 -0.43726471]\n",
      "P is: [0.3863447703253119, 0.9820078955124181, 0.39239292704231926, 0.4802014224374012, 0.9824518829473577, 0.3863447703253119, 0.39239292704231926, 0.3863447703253119, 0.3863447703253119, 0.4738553351874478, 0.3863447703253119, 0.5187925257703997, 0.39239292704231926, 0.3863447703253119, 0.5187925257703997, 0.3863447703253119, 0.5251397624565646, 0.5251397624565646, 0.4802014224374012, 0.5251397624565646, 0.4738553351874478, 0.3863447703253119, 0.4802014224374012, 0.3863447703253119, 0.5187925257703997, 0.3863447703253119, 0.4738553351874478, 0.5251397624565646, 0.5187925257703997, 0.39239292704231926, 0.3863447703253119, 0.39239292704231926, 0.39239292704231926, 0.6066457716530324, 0.3863447703253119, 0.4738553351874478, 0.4802014224374012, 0.3863447703253119, 0.3863447703253119, 0.39239292704231926, 0.5187925257703997, 0.4802014224374012, 0.39239292704231926, 0.39239292704231926, 0.39239292704231926, 0.9703212554090854, 0.4738553351874478, 0.4802014224374012, 0.39239292704231926, 0.39239292704231926]\n",
      "all_sum before preprocessing is: [4.97804220099705, 5.239589327185754, 4.724755908421538, 2.4910995763574655, 3.610538780424809, 6.524988227749877, 5.6504711067546785, 5.288657615206893, 4.756342344981578, 2.0538534362991148, 4.669015748902845, 2.090652049684481, 5.961086520964522, 5.721386513962991, 4.724755908421538, 3.921154194634652, 3.610538780424809, 4.97804220099705, 4.97804220099705, 2.0538534362991148, 2.3071397288746267, 2.4910995763574655, 3.921154194634652, 2.546839735876158, 5.6504711067546785, 6.303288371734404, 4.414140494211695, 5.288657615206893, 2.546839735876158, 5.9053463614458295, 4.414140494211695, 4.724755908421538, 2.546839735876158, 4.414140494211695, 3.610538780424809, 3.610538780424809, 5.559944058768464, 4.724755908421538, 4.358400334693003, 2.979568634632255, 4.756342344981578, 3.610538780424809, 3.421356856871356, 2.0538534362991148, 5.288657615206893, 4.724755908421538, 4.414140494211695, 5.6504711067546785, 4.922302041478358, 2.546839735876158]\n",
      "all_sum after preprocessing is: [ 0.59414976  0.80320154  0.39170077 -1.39363649 -0.49888088  1.83060693\n",
      "  1.13161488  0.84242129  0.41694747 -1.74312258  0.34714827 -1.71370985\n",
      "  1.37988641  1.1882968   0.39170077 -0.25060935 -0.49888088  0.59414976\n",
      "  0.59414976 -1.74312258 -1.5406736  -1.39363649 -0.25060935 -1.34908398\n",
      "  1.13161488  1.65340464  0.14342924  0.84242129 -1.34908398  1.33533391\n",
      "  0.14342924  0.39170077 -1.34908398  0.14342924 -0.49888088 -0.49888088\n",
      "  1.0592576   0.39170077  0.09887674 -1.00320847  0.41694747 -0.49888088\n",
      " -0.65009194 -1.74312258  0.84242129  0.39170077  0.14342924  1.13161488\n",
      "  0.54959725 -1.34908398]\n",
      "P is: [0.6443167253254913, 0.6906589040406583, 0.5966920587120426, 0.19882784673191534, 0.37780370142510056, 0.8618340131196576, 0.7561367969733305, 0.6989749218135991, 0.6027525758131145, 0.1489167427403113, 0.5859258711439379, 0.15268315009420244, 0.7989727569872962, 0.7664363096500911, 0.5966920587120426, 0.4376735219932488, 0.37780370142510056, 0.6443167253254913, 0.6443167253254913, 0.1489167427403113, 0.1764373748240881, 0.19882784673191534, 0.4376735219932488, 0.20602016957195554, 0.7561367969733305, 0.839350666161879, 0.5357959660184144, 0.6989749218135991, 0.20602016957195554, 0.7917215570422403, 0.5357959660184144, 0.5966920587120426, 0.20602016957195554, 0.5357959660184144, 0.37780370142510056, 0.37780370142510056, 0.7425486454861656, 0.5966920587120426, 0.5246990654469659, 0.26831106533044047, 0.6027525758131145, 0.37780370142510056, 0.3429688188724012, 0.1489167427403113, 0.6989749218135991, 0.5966920587120426, 0.5357959660184144, 0.7561367969733305, 0.6340421456407647, 0.20602016957195554]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.098\n",
      "(*) epoch 2, cost 3.022\n",
      "(*) epoch 3, cost 2.434\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.712\n",
      "(*) epoch 2, cost 5.540\n",
      "(*) epoch 3, cost 4.644\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.5960527857990778, 0.5960527857990778, 0.12610843910768046, 0.12610843910768046, 1.0093633461032394, 0.12610843910768046, 0.44177447376462586, 0.12610843910768046, 0.12610843910768046, 1.0093633461032394, 0.5960527857990778, 0.5960527857990778, 0.12610843910768046, 0.12610843910768046, 0.44177447376462586, 1.3252566908507493, 0.9117188204560233, 0.12610843910768046, 0.12610843910768046, 0.12610843910768046, 0.5960527857990778, 0.44177447376462586, 1.2379817741763195, 0.12610843910768046, 0.44177447376462586, 0.5960527857990778, 0.12610843910768046, 0.12610843910768046, 0.5960527857990778, 0.12610843910768046, 0.12610843910768046, 0.12610843910768046, 0.12610843910768046, 0.12610843910768046, 0.12610843910768046, 0.12610843910768046, 0.5273006186028995, 0.12610843910768046, 0.12610843910768046, 0.12610843910768046, 1.2379817741763195, 0.9117188204560233, 0.12610843910768046, 0.12610843910768046, 0.44177447376462586, 0.5960527857990778, 0.44177447376462586, 0.5960527857990778, 0.12610843910768046, 0.12610843910768046]\n",
      "all_sum after preprocessing is: [ 0.59347515  0.59347515 -0.77208941 -0.77208941  1.79447322 -0.77208941\n",
      "  0.14517314 -0.77208941 -0.77208941  1.79447322  0.59347515  0.59347515\n",
      " -0.77208941 -0.77208941  0.14517314  2.71239629  1.5107377  -0.77208941\n",
      " -0.77208941 -0.77208941  0.59347515  0.14517314  2.45879278 -0.77208941\n",
      "  0.14517314  0.59347515 -0.77208941 -0.77208941  0.59347515 -0.77208941\n",
      " -0.77208941 -0.77208941 -0.77208941 -0.77208941 -0.77208941 -0.77208941\n",
      "  0.39369506 -0.77208941 -0.77208941 -0.77208941  2.45879278  1.5107377\n",
      " -0.77208941 -0.77208941  0.14517314  0.59347515  0.14517314  0.59347515\n",
      " -0.77208941 -0.77208941]\n",
      "P is: [0.6441621089627597, 0.6441621089627597, 0.31602729914377464, 0.31602729914377464, 0.8574748311628598, 0.31602729914377464, 0.536229678759443, 0.31602729914377464, 0.31602729914377464, 0.8574748311628598, 0.6441621089627597, 0.6441621089627597, 0.31602729914377464, 0.31602729914377464, 0.536229678759443, 0.9377541697184513, 0.8191705081970251, 0.31602729914377464, 0.31602729914377464, 0.31602729914377464, 0.6441621089627597, 0.536229678759443, 0.9212020768444101, 0.31602729914377464, 0.536229678759443, 0.6441621089627597, 0.31602729914377464, 0.31602729914377464, 0.6441621089627597, 0.31602729914377464, 0.31602729914377464, 0.31602729914377464, 0.31602729914377464, 0.31602729914377464, 0.31602729914377464, 0.31602729914377464, 0.5971718933298245, 0.31602729914377464, 0.31602729914377464, 0.31602729914377464, 0.9212020768444101, 0.8191705081970251, 0.31602729914377464, 0.31602729914377464, 0.536229678759443, 0.6441621089627597, 0.536229678759443, 0.6441621089627597, 0.31602729914377464, 0.31602729914377464]\n",
      "all_sum before preprocessing is: [1.553065295956735, 1.553065295956735, 1.553065295956735, 2.2605955311341708, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.790292969085908, 1.553065295956735, 1.5940310274909097, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.553065295956735, 2.2605955311341708, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.553065295956735, 0.661875738063824, 1.553065295956735, 2.2605955311341708, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.553065295956735, 2.2605955311341708, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.553065295956735, 2.2605955311341708, 1.553065295956735, 1.553065295956735, 1.553065295956735, 1.553065295956735, 2.2605955311341708, 1.553065295956735, 2.2605955311341708, 2.2382359463133628, 1.0827627339084724, 1.553065295956735, 1.0827627339084724, 2.2605955311341708, 1.0827627339084724, 1.553065295956735, 1.553065295956735, 2.2605955311341708]\n",
      "all_sum after preprocessing is: [-0.29072132 -0.29072132 -0.29072132  1.75434262 -0.29072132 -0.29072132\n",
      " -0.29072132  0.39496777 -0.29072132 -0.17231289 -0.29072132 -0.29072132\n",
      " -0.29072132 -0.29072132  1.75434262 -0.29072132 -0.29072132 -0.29072132\n",
      " -0.29072132 -0.29072132 -2.86663898 -0.29072132  1.75434262 -0.29072132\n",
      " -0.29072132 -0.29072132 -0.29072132  1.75434262 -0.29072132 -0.29072132\n",
      " -0.29072132 -0.29072132 -0.29072132  1.75434262 -0.29072132 -0.29072132\n",
      " -0.29072132 -0.29072132  1.75434262 -0.29072132  1.75434262  1.68971389\n",
      " -1.65009618 -0.29072132 -1.65009618  1.75434262 -1.65009618 -0.29072132\n",
      " -0.29072132  1.75434262]\n",
      "P is: [0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.8524996969130402, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.5974780138370221, 0.4278272853021119, 0.4570280496600148, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.8524996969130402, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.05382757265172427, 0.4278272853021119, 0.8524996969130402, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.8524996969130402, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.8524996969130402, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.4278272853021119, 0.8524996969130402, 0.4278272853021119, 0.8524996969130402, 0.8441865302924519, 0.16109595158680654, 0.4278272853021119, 0.16109595158680654, 0.8524996969130402, 0.16109595158680654, 0.4278272853021119, 0.4278272853021119, 0.8524996969130402]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.378\n",
      "(*) epoch 2, cost 2.520\n",
      "(*) epoch 3, cost 1.676\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.256\n",
      "(*) epoch 2, cost 1.816\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.4276193129842527, 1.661761093379602, 2.2094188515836195, 1.5538806796593196, 1.6936191540219014, 1.756798546946444, 0.879327407246161, 1.6936191540219014, 2.4276193129842527, 2.3044563051504614, 1.661761093379602, 1.661761093379602, 1.661761093379602, 1.661761093379602, 1.4269851654501784, 1.756798546946444, 2.838153817271911, 2.459477373626552, 0.879327407246161, 1.6936191540219014, 1.5220226190170203, 2.3044563051504614, 1.756798546946444, 1.756798546946444, 1.661761093379602, 1.7720811410599533, 1.661761093379602, 2.3044563051504614, 1.0062229214553025, 1.6936191540219014, 0.9111854678884604, 1.661761093379602, 2.2094188515836195, 1.6936191540219014, 1.661761093379602, 1.5220226190170203, 0.974364860813003, 1.661761093379602, 1.661761093379602, 1.661761093379602, 1.661761093379602, 1.6936191540219014, 1.756798546946444, 1.6936191540219014, 2.522656766551095, 1.0062229214553025, 2.3363143657927607, 2.4276193129842527, 1.756798546946444, 3.6292883186060085]\n",
      "all_sum after preprocessing is: [ 1.23329833 -0.26465778  0.80651605 -0.47566306 -0.20234602 -0.07877229\n",
      " -1.79503415 -0.20234602  1.23329833  0.99240155 -0.26465778 -0.26465778\n",
      " -0.26465778 -0.26465778 -0.72386032 -0.07877229  2.03627028  1.29561009\n",
      " -1.79503415 -0.20234602 -0.53797482  0.99240155 -0.07877229 -0.07877229\n",
      " -0.26465778 -0.04888078 -0.26465778  0.99240155 -1.54683689 -0.20234602\n",
      " -1.73272239 -0.26465778  0.80651605 -0.20234602 -0.26465778 -0.53797482\n",
      " -1.60914866 -0.26465778 -0.26465778 -0.26465778 -0.26465778 -0.20234602\n",
      " -0.07877229 -0.20234602  1.41918382 -1.54683689  1.05471331  1.23329833\n",
      " -0.07877229  3.58366473]\n",
      "P is: [0.7743953374349916, 0.4342190687332988, 0.6913665995438882, 0.3832767524237352, 0.44958539233653627, 0.4803171048835332, 0.14245663007124676, 0.44958539233653627, 0.7743953374349916, 0.7295620117370071, 0.4342190687332988, 0.4342190687332988, 0.4342190687332988, 0.4342190687332988, 0.32654348175221604, 0.4803171048835332, 0.88455293848645, 0.7850952417236002, 0.14245663007124676, 0.44958539233653627, 0.3686588157788421, 0.7295620117370071, 0.4803171048835332, 0.4803171048835332, 0.4342190687332988, 0.4877822371059738, 0.4342190687332988, 0.7295620117370071, 0.17554358872921774, 0.44958539233653627, 0.15023968763024634, 0.4342190687332988, 0.6913665995438882, 0.44958539233653627, 0.4342190687332988, 0.3686588157788421, 0.16670684493100674, 0.4342190687332988, 0.4342190687332988, 0.4342190687332988, 0.4342190687332988, 0.44958539233653627, 0.4803171048835332, 0.44958539233653627, 0.8052104337746265, 0.17554358872921774, 0.741678956566083, 0.7743953374349916, 0.4803171048835332, 0.9729768066077822]\n",
      "all_sum before preprocessing is: [1.563636439153696, 1.563636439153696, 2.175956037186764, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.597428298880953, 1.563636439153696, 1.563636439153696, 2.2097478969140214, 1.563636439153696, 2.175956037186764, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.1096079628327273, 1.597428298880953, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 3.726576097340078, 1.563636439153696, 1.563636439153696, 2.175956037186764, 1.563636439153696, 1.563636439153696, 1.563636439153696, 3.726576097340078, 1.563636439153696, 1.563636439153696, 3.114256499307009, 2.175956037186764, 3.114256499307009, 1.597428298880953, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696, 1.563636439153696]\n",
      "all_sum after preprocessing is: [-0.38134967 -0.38134967  0.76668953 -0.38134967 -0.38134967 -0.38134967\n",
      " -0.38134967 -0.38134967 -0.31799324 -0.38134967 -0.38134967  0.83004595\n",
      " -0.38134967  0.76668953 -0.38134967 -0.38134967 -0.38134967 -0.38134967\n",
      " -1.23260853 -0.31799324 -0.38134967 -0.38134967 -0.38134967 -0.38134967\n",
      " -0.38134967  3.67395006 -0.38134967 -0.38134967  0.76668953 -0.38134967\n",
      " -0.38134967 -0.38134967  3.67395006 -0.38134967 -0.38134967  2.52591087\n",
      "  0.76668953  2.52591087 -0.31799324 -0.38134967 -0.38134967 -0.38134967\n",
      " -0.38134967 -0.38134967 -0.38134967 -0.38134967 -0.38134967 -0.38134967\n",
      " -0.38134967 -0.38134967]\n",
      "P is: [0.405801415292876, 0.405801415292876, 0.6828043370558037, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.42116488752873743, 0.405801415292876, 0.405801415292876, 0.6963646453770947, 0.405801415292876, 0.6828043370558037, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.225725198144442, 0.42116488752873743, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.9752519719550751, 0.405801415292876, 0.405801415292876, 0.6828043370558037, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.9752519719550751, 0.405801415292876, 0.405801415292876, 0.9259384231051963, 0.6828043370558037, 0.9259384231051963, 0.42116488752873743, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876, 0.405801415292876]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.284\n",
      "(*) epoch 2, cost 3.314\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.886\n",
      "(*) epoch 2, cost 3.143\n",
      "(*) epoch 3, cost 2.364\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.102938977656242, 2.102938977656242, 2.102938977656242, 2.2463628941734175, 2.102938977656242, 2.349407044514427, 3.712729665519507, 2.349407044514427, 2.2059831279972517, 2.102938977656242, 2.102938977656242, 2.102938977656242, 3.2049972638521615, 2.102938977656242, 2.102938977656242, 4.987619922320513, 2.2463628941734175, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.2463628941734175, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.2463628941734175, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.2463628941734175, 2.102938977656242, 4.132029702982778, 2.102938977656242, 3.8855616361245935, 3.8855616361245935, 2.2463628941734175, 2.102938977656242, 2.2463628941734175, 2.102938977656242, 2.102938977656242, 2.102938977656242, 2.2463628941734175, 2.2463628941734175]\n",
      "all_sum after preprocessing is: [-0.41885495 -0.41885495 -0.41885495 -0.18917391 -0.41885495 -0.02415759\n",
      "  2.15908606 -0.02415759 -0.25383863 -0.41885495 -0.41885495 -0.41885495\n",
      "  1.34599639 -0.41885495 -0.41885495  4.20071291 -0.18917391 -0.41885495\n",
      " -0.41885495 -0.41885495 -0.18917391 -0.41885495 -0.41885495 -0.41885495\n",
      " -0.18917391 -0.41885495 -0.41885495 -0.41885495 -0.41885495 -0.41885495\n",
      " -0.41885495 -0.41885495 -0.41885495 -0.41885495 -0.41885495 -0.41885495\n",
      " -0.18917391 -0.41885495  2.83055893 -0.41885495  2.43586157  2.43586157\n",
      " -0.18917391 -0.41885495 -0.18917391 -0.41885495 -0.41885495 -0.41885495\n",
      " -0.18917391 -0.18917391]\n",
      "P is: [0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.4528470591556399, 0.39679078289423114, 0.4939608966560486, 0.8965147878980113, 0.4939608966560486, 0.43687890889572156, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.7934743164382637, 0.39679078289423114, 0.39679078289423114, 0.9852363416326909, 0.4528470591556399, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.4528470591556399, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.4528470591556399, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.4528470591556399, 0.39679078289423114, 0.9443050051035896, 0.39679078289423114, 0.9195213673636418, 0.9195213673636418, 0.4528470591556399, 0.39679078289423114, 0.4528470591556399, 0.39679078289423114, 0.39679078289423114, 0.39679078289423114, 0.4528470591556399, 0.4528470591556399]\n",
      "all_sum before preprocessing is: [2.814778035490161, 3.1876013537594936, 3.5284461567201015, 2.814778035490161, 2.954177090495028, 2.814778035490161, 2.814778035490161, 3.1876013537594936, 2.814778035490161, 2.581353772225695, 2.954177090495028, 3.1876013537594936, 2.814778035490161, 2.2370447859973646, 2.581353772225695, 2.581353772225695, 3.761870419984567, 3.9012694749894345, 2.581353772225695, 2.581353772225695, 2.954177090495028, 2.814778035490161, 2.581353772225695, 3.1876013537594936, 3.5284461567201015, 3.1876013537594936, 2.814778035490161, 3.1876013537594936, 2.814778035490161, 2.954177090495028, 2.581353772225695, 2.581353772225695, 2.581353772225695, 2.581353772225695, 2.954177090495028, 2.814778035490161, 3.1876013537594936, 2.814778035490161, 2.41383738960843, 2.814778035490161, 2.581353772225695, 3.5284461567201015, 2.581353772225695, 2.814778035490161, 2.814778035490161, 2.814778035490161, 2.786660707877763, 2.954177090495028, 2.814778035490161, 2.814778035490161]\n",
      "all_sum after preprocessing is: [-0.22881638  0.88987151  1.91260517 -0.22881638  0.18946227 -0.22881638\n",
      " -0.22881638  0.88987151 -0.22881638 -0.92922562  0.18946227  0.88987151\n",
      " -0.22881638 -1.96235385 -0.92922562 -0.92922562  2.61301441  3.03129306\n",
      " -0.92922562 -0.92922562  0.18946227 -0.22881638 -0.92922562  0.88987151\n",
      "  1.91260517  0.88987151 -0.22881638  0.88987151 -0.22881638  0.18946227\n",
      " -0.92922562 -0.92922562 -0.92922562 -0.92922562  0.18946227 -0.22881638\n",
      "  0.88987151 -0.22881638 -1.43187269 -0.22881638 -0.92922562  1.91260517\n",
      " -0.92922562 -0.22881638 -0.22881638 -0.22881638 -0.3131848   0.18946227\n",
      " -0.22881638 -0.22881638]\n",
      "P is: [0.4430441913762253, 0.7088636567490545, 0.8713115419495387, 0.4430441913762253, 0.5472243890710563, 0.4430441913762253, 0.4430441913762253, 0.7088636567490545, 0.4430441913762253, 0.283081846056971, 0.5472243890710563, 0.7088636567490545, 0.4430441913762253, 0.12321253306758231, 0.283081846056971, 0.283081846056971, 0.9316944825463253, 0.9539679884738368, 0.283081846056971, 0.283081846056971, 0.5472243890710563, 0.4430441913762253, 0.283081846056971, 0.7088636567490545, 0.8713115419495387, 0.7088636567490545, 0.4430441913762253, 0.7088636567490545, 0.4430441913762253, 0.5472243890710563, 0.283081846056971, 0.283081846056971, 0.283081846056971, 0.283081846056971, 0.5472243890710563, 0.4430441913762253, 0.7088636567490545, 0.4430441913762253, 0.19280706512868037, 0.4430441913762253, 0.283081846056971, 0.8713115419495387, 0.283081846056971, 0.4430441913762253, 0.4430441913762253, 0.4430441913762253, 0.42233755681238155, 0.5472243890710563, 0.4430441913762253, 0.4430441913762253]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.190\n",
      "(*) epoch 2, cost 2.102\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.366\n",
      "(*) epoch 2, cost 2.710\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.9059579935987463, 2.9059579935987463, 2.7109343901190326, 2.1535922574423845, 2.1535922574423845, 2.17850825488157, 1.8142731946024258, 3.9601646171567095, 1.8142731946024258, 2.0342127955213254, 3.620845554316751, 1.9585686539626703, 1.6192495911227116, 1.6192495911227116, 2.9059579935987463, 1.6192495911227116, 1.6192495911227116, 1.8142731946024258, 2.5666389307587876, 1.6192495911227116, 2.9059579935987463, 1.8142731946024258, 2.1535922574423845, 1.8142731946024258, 2.5666389307587876, 1.9585686539626703, 1.9585686539626703, 2.1535922574423845, 2.1535922574423845, 1.6192495911227116, 1.8142731946024258, 1.9585686539626703, 1.8142731946024258, 1.8391891920416115, 1.6192495911227116, 2.371615327279074, 2.1535922574423845, 1.8142731946024258, 1.8142731946024258, 1.8142731946024258, 2.371615327279074, 2.7109343901190326, 1.8142731946024258, 1.6192495911227116, 1.9585686539626703, 1.6192495911227116, 1.6192495911227116, 1.9585686539626703, 2.1535922574423845, 2.371615327279074]\n",
      "all_sum after preprocessing is: [ 1.53424558  1.53424558  1.15448498  0.06919799  0.06919799  0.11771578\n",
      " -0.59154259  3.58705419 -0.59154259 -0.16326421  2.92631361 -0.3105626\n",
      " -0.97130318 -0.97130318  1.53424558 -0.97130318 -0.97130318 -0.59154259\n",
      "  0.87350499 -0.97130318  1.53424558 -0.59154259  0.06919799 -0.59154259\n",
      "  0.87350499 -0.3105626  -0.3105626   0.06919799  0.06919799 -0.97130318\n",
      " -0.59154259 -0.3105626  -0.59154259 -0.5430248  -0.97130318  0.4937444\n",
      "  0.06919799 -0.59154259 -0.59154259 -0.59154259  0.4937444   1.15448498\n",
      " -0.59154259 -0.97130318 -0.3105626  -0.97130318 -0.97130318 -0.3105626\n",
      "  0.06919799  0.4937444 ]\n",
      "P is: [0.8226266435364482, 0.8226266435364482, 0.7603291632561708, 0.5172925979171216, 0.5172925979171216, 0.5293950087664837, 0.3562809908158049, 0.9730657827674963, 0.3562809908158049, 0.4592743705882481, 0.9491319890136494, 0.4229774195746667, 0.2746208260854697, 0.2746208260854697, 0.8226266435364482, 0.2746208260854697, 0.2746208260854697, 0.3562809908158049, 0.7054744906782124, 0.2746208260854697, 0.8226266435364482, 0.3562809908158049, 0.5172925979171216, 0.3562809908158049, 0.7054744906782124, 0.4229774195746667, 0.4229774195746667, 0.5172925979171216, 0.5172925979171216, 0.2746208260854697, 0.3562809908158049, 0.4229774195746667, 0.3562809908158049, 0.3674842173363862, 0.2746208260854697, 0.6209881197351182, 0.5172925979171216, 0.3562809908158049, 0.3562809908158049, 0.3562809908158049, 0.6209881197351182, 0.7603291632561708, 0.3562809908158049, 0.2746208260854697, 0.4229774195746667, 0.2746208260854697, 0.2746208260854697, 0.4229774195746667, 0.5172925979171216, 0.6209881197351182]\n",
      "all_sum before preprocessing is: [2.027363114873083, 3.84762712833181, 2.964567932496981, 1.9685893813451836, 1.5832442940306972, 1.721544529138756, 2.027363114873083, 2.851648577180013, 1.2774257082963703, 1.2774257082963703, 3.601585983756726, 3.9747865749619633, 2.273404259448168, 2.579222845182495, 2.027363114873083, 2.273404259448168, 1.9685893813451836, 1.5832442940306972, 1.5832442940306972, 3.023341666024881, 2.5197640383188125, 1.69030013016194, 1.5832442940306972, 2.964567932496981, 2.7175230802905537, 2.027363114873083, 2.027363114873083, 1.5832442940306972, 2.964567932496981, 1.5832442940306972, 2.851648577180013, 2.579222845182495, 3.84762712833181, 3.023341666024881, 3.84762712833181, 2.4317873523817264, 1.721544529138756, 1.9876685315393408, 4.597564534908523, 2.579222845182495, 2.7175230802905537, 1.2774257082963703, 2.579222845182495, 4.085536722845529, 2.027363114873083, 2.440237536738653, 2.579222845182495, 1.5832442940306972, 2.6587493467626544, 1.996118715896267]\n",
      "all_sum after preprocessing is: [-5.04540022e-01  1.77549985e+00  6.69390975e-01 -5.78159264e-01\n",
      " -1.06083769e+00 -8.87604546e-01 -5.04540022e-01  5.27949608e-01\n",
      " -1.44390221e+00 -1.44390221e+00  1.46731180e+00  1.93477817e+00\n",
      " -1.96351971e-01  1.86712553e-01 -5.04540022e-01 -1.96351971e-01\n",
      " -5.78159264e-01 -1.06083769e+00 -1.06083769e+00  7.43010217e-01\n",
      "  1.12235197e-01 -9.26740889e-01 -1.06083769e+00  6.69390975e-01\n",
      "  3.59945693e-01 -5.04540022e-01 -5.04540022e-01 -1.06083769e+00\n",
      "  6.69390975e-01 -1.06083769e+00  5.27949608e-01  1.86712553e-01\n",
      "  1.77549985e+00  7.43010217e-01  1.77549985e+00  2.03670428e-03\n",
      " -8.87604546e-01 -5.54260959e-01  2.71486203e+00  1.86712553e-01\n",
      "  3.59945693e-01 -1.44390221e+00  1.86712553e-01  2.07350242e+00\n",
      " -5.04540022e-01  1.26212992e-02  1.86712553e-01 -1.06083769e+00\n",
      "  2.86326451e-01 -5.43676365e-01]\n",
      "P is: [0.3764743413733344, 0.8551402981903397, 0.6613667750103331, 0.35935625696556023, 0.2571494043489066, 0.29160441219755007, 0.3764743413733344, 0.6290047636423247, 0.19094179619205226, 0.19094179619205226, 0.8126484482772551, 0.8737773489452614, 0.45106911347943934, 0.5465430032185532, 0.3764743413733344, 0.45106911347943934, 0.35935625696556023, 0.2571494043489066, 0.2571494043489066, 0.6776537567473824, 0.528029382304341, 0.2835863850635874, 0.2571494043489066, 0.6613667750103331, 0.5890272877157373, 0.3764743413733344, 0.3764743413733344, 0.2571494043489066, 0.6613667750103331, 0.2571494043489066, 0.6290047636423247, 0.5465430032185532, 0.8551402981903397, 0.6776537567473824, 0.8551402981903397, 0.5005091758932495, 0.29160441219755007, 0.36487640001412586, 0.9378979433840079, 0.5465430032185532, 0.5890272877157373, 0.19094179619205226, 0.5465430032185532, 0.8883009527927608, 0.3764743413733344, 0.5031552829142723, 0.5465430032185532, 0.2571494043489066, 0.5710965504798324, 0.36733278136516634]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.238\n",
      "(*) epoch 2, cost 2.744\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.682\n",
      "(*) epoch 2, cost 2.286\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.2866079216096393, 2.102910488787401, 1.1831385185842278, 2.1817608690604477, 2.65983601660517, 2.287985571133419, 1.1831385185842278, 1.1831385185842278, 1.1831385185842278, 1.1831385185842278, 2.287985571133419, 1.1831385185842278, 2.287985571133419, 2.1817608690604477, 2.287985571133419, 1.1831385185842278, 3.2866079216096393, 1.1831385185842278, 2.287985571133419, 1.1831385185842278, 2.287985571133419, 3.2077575413365924, 2.287985571133419, 2.287985571133419, 2.287985571133419, 1.1831385185842278, 2.287985571133419, 1.1831385185842278, 2.287985571133419, 2.287985571133419, 1.1831385185842278, 2.287985571133419, 2.287985571133419, 1.1831385185842278, 2.287985571133419, 2.287985571133419, 1.1831385185842278, 1.1831385185842278, 1.1831385185842278, 1.1831385185842278, 2.287985571133419, 2.287985571133419, 2.287985571133419, 2.287985571133419, 2.287985571133419, 2.287985571133419, 1.1831385185842278, 2.287985571133419, 1.1831385185842278, 2.287985571133419]\n",
      "all_sum after preprocessing is: [ 2.16900405  0.28206153 -1.18415509  0.40775762  1.16986143  0.57709135\n",
      " -1.18415509 -1.18415509 -1.18415509 -1.18415509  0.57709135 -1.18415509\n",
      "  0.57709135  0.40775762  0.57709135 -1.18415509  2.16900405 -1.18415509\n",
      "  0.57709135 -1.18415509  0.57709135  2.04330797  0.57709135  0.57709135\n",
      "  0.57709135 -1.18415509  0.57709135 -1.18415509  0.57709135  0.57709135\n",
      " -1.18415509  0.57709135  0.57709135 -1.18415509  0.57709135  0.57709135\n",
      " -1.18415509 -1.18415509 -1.18415509 -1.18415509  0.57709135  0.57709135\n",
      "  0.57709135  0.57709135  0.57709135  0.57709135 -1.18415509  0.57709135\n",
      " -1.18415509  0.57709135]\n",
      "P is: [0.8974313275440269, 0.5700515623619985, 0.23430592308939302, 0.6005500753331908, 0.7631199671292516, 0.6403978517969107, 0.23430592308939302, 0.23430592308939302, 0.23430592308939302, 0.23430592308939302, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107, 0.6005500753331908, 0.6403978517969107, 0.23430592308939302, 0.8974313275440269, 0.23430592308939302, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107, 0.8852696774443729, 0.6403978517969107, 0.6403978517969107, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107, 0.6403978517969107, 0.23430592308939302, 0.23430592308939302, 0.23430592308939302, 0.23430592308939302, 0.6403978517969107, 0.6403978517969107, 0.6403978517969107, 0.6403978517969107, 0.6403978517969107, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107, 0.23430592308939302, 0.6403978517969107]\n",
      "all_sum before preprocessing is: [3.857694842677564, 2.157655869780148, 4.637401472547708, 4.40629238580277, 4.220147373117753, 3.792500583699731, 5.236787935624601, 4.637401472547708, 3.6859551690186914, 3.857694842677564, 3.857694842677564, 5.416496136553836, 3.6859551690186914, 4.572207213569875, 3.857694842677564, 2.092461610802315, 4.048407699458879, 6.564936613833349, 3.857694842677564, 4.637401472547708, 3.6859551690186914, 1.9207219371434423, 3.716457163656421, 4.220147373117753, 3.6859551690186914, 5.613490310304332, 4.572207213569875, 5.065048261965729, 5.065048261965729, 6.106331358700186, 4.113601958436712, 3.6859551690186914, 4.2853416320955855, 4.743946887228748, 2.157655869780148, 6.041137099722353, 6.15512146352687, 3.6859551690186914, 4.2853416320955855, 5.441750636645459, 6.8208437295924975, 4.743946887228748, 4.293310159365947, 4.637401472547708, 4.048407699458879, 4.720956948783968, 4.572207213569875, 4.7583522262548925, 5.013627870752441, 4.743946887228748]\n",
      "all_sum after preprocessing is: [-0.52048447 -2.17156451  0.23676762  0.01231417 -0.1684701  -0.58380122\n",
      "  0.81889252  0.23676762 -0.68727826 -0.52048447 -0.52048447  0.99342536\n",
      " -0.68727826  0.17345087 -0.52048447 -2.23488125 -0.33526389  2.10879223\n",
      " -0.52048447  0.23676762 -0.68727826 -2.40167505 -0.65765468 -0.1684701\n",
      " -0.68727826  1.18474635  0.17345087  0.65209873  0.65209873  1.66339421\n",
      " -0.27194715 -0.68727826 -0.10515335  0.34024466 -2.17156451  1.60007746\n",
      "  1.71077923 -0.68727826 -0.10515335  1.01795256  2.35732955  0.34024466\n",
      " -0.09741431  0.23676762 -0.33526389  0.3179168   0.17345087  0.35423514\n",
      "  0.60215918  0.34024466]\n",
      "P is: [0.3727389560782854, 0.10233322666856487, 0.5589169259166731, 0.5030785044059638, 0.4579818079725315, 0.3580584039002716, 0.6940012023978037, 0.5589169259166731, 0.33463881129411216, 0.3727389560782854, 0.3727389560782854, 0.7297639632686185, 0.33463881129411216, 0.5432543282932082, 0.3727389560782854, 0.09666157906667297, 0.416960390365297, 0.8917548042538108, 0.3727389560782854, 0.5589169259166731, 0.33463881129411216, 0.0830450549501978, 0.34126665115921306, 0.4579818079725315, 0.33463881129411216, 0.7658001370167745, 0.5432543282932082, 0.6574832503420033, 0.6574832503420033, 0.840693109699249, 0.4324291359541125, 0.33463881129411216, 0.47373585763352904, 0.5842499524928698, 0.10233322666856487, 0.832029211565816, 0.8469373260125572, 0.33463881129411216, 0.47373585763352904, 0.7345735910877462, 0.9135150584355294, 0.5842499524928698, 0.47566566280636907, 0.5589169259166731, 0.416960390365297, 0.5788164770941578, 0.5432543282932082, 0.5876442120592009, 0.6461501366679581, 0.5842499524928698]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.738\n",
      "(*) epoch 2, cost 1.764\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.787\n",
      "(*) epoch 2, cost 4.314\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.618284686552003, 2.3666756089290266, 2.9115560580572195, 0.8753196585257683, 2.3666756089290266, 1.7866777155021287, 3.5958120664027615, 0.30593218040541786, 2.6599469804342433, 2.6599469804342433, 2.6599469804342433, 2.3666756089290266, 2.3666756089290266, 2.6599469804342433, 0.5992035519106345, 2.6599469804342433, 0.5992035519106345, 3.5958120664027615, 2.3666756089290266, 2.3666756089290266, 2.3666756089290266, 2.6599469804342433, 3.5958120664027615, 2.6599469804342433, 0.8508126295336105, 2.6599469804342433, 2.6599469804342433, 2.6599469804342433, 2.6599469804342433, 3.5958120664027615, 2.3666756089290266, 2.6599469804342433, 2.6599469804342433, 0.5992035519106345, 2.468291606644997, 2.6599469804342433, 2.6599469804342433, 2.9115560580572195, 0.8508126295336105, 3.0131720557731896, 3.5958120664027615, 2.3666756089290266, 2.6599469804342433, 2.6599469804342433, 1.7866777155021287, 2.6599469804342433, 2.9115560580572195, 2.9115560580572195, 3.5958120664027615, 0.5992035519106345]\n",
      "all_sum after preprocessing is: [ 0.27060422 -0.02385648  0.61382274 -1.76920576 -0.02385648 -0.70263401\n",
      "  1.41461461 -2.43556581  0.31936203  0.31936203  0.31936203 -0.02385648\n",
      " -0.02385648  0.31936203 -2.09234729  0.31936203 -2.09234729  1.41461461\n",
      " -0.02385648 -0.02385648 -0.02385648  0.31936203  1.41461461  0.31936203\n",
      " -1.79788659  0.31936203  0.31936203  0.31936203  0.31936203  1.41461461\n",
      " -0.02385648  0.31936203  0.31936203 -2.09234729  0.09506577  0.31936203\n",
      "  0.31936203  0.61382274 -1.79788659  0.73274499  1.41461461 -0.02385648\n",
      "  0.31936203  0.31936203 -0.70263401  0.31936203  0.61382274  0.61382274\n",
      "  1.41461461 -2.09234729]\n",
      "P is: [0.5672412345662308, 0.494036162560407, 0.6488123263830645, 0.14564112843332855, 0.494036162560407, 0.3312284932172114, 0.8044927693314775, 0.08050052203757638, 0.579168767320083, 0.579168767320083, 0.579168767320083, 0.494036162560407, 0.494036162560407, 0.579168767320083, 0.10984285209065202, 0.579168767320083, 0.10984285209065202, 0.8044927693314775, 0.494036162560407, 0.494036162560407, 0.494036162560407, 0.579168767320083, 0.8044927693314775, 0.579168767320083, 0.14210852396560447, 0.579168767320083, 0.579168767320083, 0.579168767320083, 0.579168767320083, 0.8044927693314775, 0.494036162560407, 0.579168767320083, 0.579168767320083, 0.10984285209065202, 0.5237485597736592, 0.579168767320083, 0.579168767320083, 0.6488123263830645, 0.14210852396560447, 0.6754073524928613, 0.8044927693314775, 0.494036162560407, 0.579168767320083, 0.579168767320083, 0.3312284932172114, 0.579168767320083, 0.6488123263830645, 0.6488123263830645, 0.8044927693314775, 0.10984285209065202]\n",
      "all_sum before preprocessing is: [2.7806495710516517, 2.7806495710516517, 3.5937989804417, 2.7806495710516517, 3.5937989804417, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 3.5937989804417, 0.6786907232573582, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 3.5937989804417, 4.729218682502627, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 3.5937989804417, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 0.6786907232573582, 2.7806495710516517, 2.7806495710516517, 3.5937989804417, 3.5937989804417, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517, 4.729218682502627, 3.5937989804417, 2.7806495710516517, 2.7806495710516517, 0.6786907232573582, 2.7806495710516517, 2.7806495710516517, 2.7806495710516517]\n",
      "all_sum after preprocessing is: [-0.11404902 -0.11404902  1.01789125 -0.11404902  1.01789125 -0.11404902\n",
      " -0.11404902 -0.11404902 -0.11404902 -0.11404902  1.01789125 -3.04006955\n",
      " -0.11404902 -0.11404902 -0.11404902  1.01789125  2.59844616 -0.11404902\n",
      " -0.11404902 -0.11404902 -0.11404902 -0.11404902 -0.11404902 -0.11404902\n",
      " -0.11404902 -0.11404902 -0.11404902  1.01789125 -0.11404902 -0.11404902\n",
      " -0.11404902 -0.11404902 -0.11404902 -0.11404902 -3.04006955 -0.11404902\n",
      " -0.11404902  1.01789125  1.01789125 -0.11404902 -0.11404902 -0.11404902\n",
      "  2.59844616  1.01789125 -0.11404902 -0.11404902 -3.04006955 -0.11404902\n",
      " -0.11404902 -0.11404902]\n",
      "P is: [0.4715186105676269, 0.4715186105676269, 0.7345616377958704, 0.4715186105676269, 0.7345616377958704, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.7345616377958704, 0.04564814060062427, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.7345616377958704, 0.9307615100431134, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.7345616377958704, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.04564814060062427, 0.4715186105676269, 0.4715186105676269, 0.7345616377958704, 0.7345616377958704, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269, 0.9307615100431134, 0.7345616377958704, 0.4715186105676269, 0.4715186105676269, 0.04564814060062427, 0.4715186105676269, 0.4715186105676269, 0.4715186105676269]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.349\n",
      "(*) epoch 2, cost 3.615\n",
      "(*) epoch 3, cost 2.985\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.413\n",
      "(*) epoch 2, cost 1.972\n",
      "(*) epoch 3, cost 1.405\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.5459015503507465, 1.3247481253926416, 1.46789928761069, 1.46789928761069, 1.3247481253926416, 1.3247481253926416, 1.6890527125687949, 2.4315303615650143, 1.7414432974891225, 2.1057478846652757, 1.3247481253926416, 1.8845944597071709, 2.8482255336614952, 1.6890527125687949, 1.6890527125687949, 1.3247481253926416, 2.1057478846652757, 1.8845944597071709, 2.652683786523119, 1.6890527125687949, 1.46789928761069, 1.46789928761069, 1.6890527125687949, 1.46789928761069, 0.9384862974758177, 1.3247481253926416, 1.46789928761069, 1.9625967224472274, 1.5459015503507465, 1.3247481253926416, 1.5459015503507465, 1.9625967224472274, 1.7414432974891225, 1.46789928761069, 1.5876675688054656, 1.46789928761069, 1.9625967224472274, 1.5459015503507465, 1.3247481253926416, 1.3247481253926416, 2.509532624305071, 1.46789928761069, 1.6890527125687949, 2.55129864275979, 1.46789928761069, 1.3247481253926416, 1.8845944597071709, 1.6890527125687949, 1.5459015503507465, 1.46789928761069]\n",
      "all_sum after preprocessing is: [-0.33172255 -0.90418426 -0.53363355 -0.53363355 -0.90418426 -0.90418426\n",
      "  0.03882816  1.96075191  0.17444262  1.11745504 -0.90418426  0.54499333\n",
      "  3.03937879  0.03882816  0.03882816 -0.90418426  1.11745504  0.54499333\n",
      "  2.53321362  0.03882816 -0.53363355 -0.53363355  0.03882816 -0.53363355\n",
      " -1.90403359 -0.90418426 -0.53363355  0.74690433 -0.33172255 -0.90418426\n",
      " -0.33172255  0.74690433  0.17444262 -0.53363355 -0.22361007 -0.53363355\n",
      "  0.74690433 -0.33172255 -0.90418426 -0.90418426  2.16266291 -0.53363355\n",
      "  0.03882816  2.27077539 -0.53363355 -0.90418426  0.54499333  0.03882816\n",
      " -0.33172255 -0.53363355]\n",
      "P is: [0.41782155884029465, 0.28819139079520645, 0.36966982007297844, 0.36966982007297844, 0.28819139079520645, 0.28819139079520645, 0.5097058198864615, 0.8766143035575801, 0.5435004010032352, 0.753516346857084, 0.28819139079520645, 0.632973227536717, 0.9543217573310285, 0.5097058198864615, 0.5097058198864615, 0.28819139079520645, 0.753516346857084, 0.632973227536717, 0.9264376647372263, 0.5097058198864615, 0.36966982007297844, 0.36966982007297844, 0.5097058198864615, 0.36966982007297844, 0.1296526321991474, 0.28819139079520645, 0.36966982007297844, 0.6785037939157477, 0.41782155884029465, 0.28819139079520645, 0.41782155884029465, 0.6785037939157477, 0.5435004010032352, 0.36966982007297844, 0.44432925815115176, 0.36966982007297844, 0.6785037939157477, 0.41782155884029465, 0.28819139079520645, 0.28819139079520645, 0.8968461629882785, 0.36966982007297844, 0.5097058198864615, 0.9064275746745675, 0.36966982007297844, 0.28819139079520645, 0.632973227536717, 0.5097058198864615, 0.41782155884029465, 0.36966982007297844]\n",
      "all_sum before preprocessing is: [0.18208488053721247, 0.5438457752911522, 0.18208488053721247, 0.5715821147169675, 0.18208488053721247, 0.5438457752911522, 1.096492514236607, 1.096492514236607, 0.18208488053721247, 0.5438457752911522, 0.5438457752911522, 0.18208488053721247, 0.18208488053721247, 0.18208488053721247, 0.5438457752911522, 0.18208488053721247, 0.5438457752911522, 1.4582534089905468, 0.18208488053721247, 0.18208488053721247, 0.5438457752911522, 0.18208488053721247, 0.5438457752911522, 0.5438457752911522, 0.20982121996302777, 1.4582534089905468, 0.18208488053721247, 0.18208488053721247, 0.18208488053721247, 0.18208488053721247, 0.5438457752911522, 0.18208488053721247, 0.5438457752911522, 0.5438457752911522, 0.5715821147169675, 0.20982121996302777, 0.18208488053721247, 0.18208488053721247, 1.7795943000026282, 0.5438457752911522, 0.1198908704907105, 0.5438457752911522, 0.18208488053721247, 1.4582534089905468, 0.5438457752911522, 0.5438457752911522, 0.18208488053721247, 0.18208488053721247, 0.5438457752911522, 0.5438457752911522]\n",
      "all_sum after preprocessing is: [-0.74843381  0.18270938 -0.74843381  0.25410047 -0.74843381  0.18270938\n",
      "  1.60517725  1.60517725 -0.74843381  0.18270938  0.18270938 -0.74843381\n",
      " -0.74843381 -0.74843381  0.18270938 -0.74843381  0.18270938  2.53632044\n",
      " -0.74843381 -0.74843381  0.18270938 -0.74843381  0.18270938  0.18270938\n",
      " -0.67704272  2.53632044 -0.74843381 -0.74843381 -0.74843381 -0.74843381\n",
      "  0.18270938 -0.74843381  0.18270938  0.18270938  0.25410047 -0.67704272\n",
      " -0.74843381 -0.74843381  3.36342582  0.18270938 -0.90851614  0.18270938\n",
      " -0.74843381  2.53632044  0.18270938  0.18270938 -0.74843381 -0.74843381\n",
      "  0.18270938  0.18270938]\n",
      "P is: [0.321162662540071, 0.5455506993395962, 0.321162662540071, 0.5631855079999982, 0.321162662540071, 0.5455506993395962, 0.8327407336905961, 0.8327407336905961, 0.321162662540071, 0.5455506993395962, 0.5455506993395962, 0.321162662540071, 0.321162662540071, 0.321162662540071, 0.5455506993395962, 0.321162662540071, 0.5455506993395962, 0.9266491170788032, 0.321162662540071, 0.321162662540071, 0.5455506993395962, 0.321162662540071, 0.5455506993395962, 0.5455506993395962, 0.3369216565426602, 0.9266491170788032, 0.321162662540071, 0.321162662540071, 0.321162662540071, 0.321162662540071, 0.5455506993395962, 0.321162662540071, 0.5455506993395962, 0.5455506993395962, 0.5631855079999982, 0.3369216565426602, 0.321162662540071, 0.321162662540071, 0.9665417408025668, 0.5455506993395962, 0.2873035767073132, 0.5455506993395962, 0.321162662540071, 0.9266491170788032, 0.5455506993395962, 0.5455506993395962, 0.321162662540071, 0.321162662540071, 0.5455506993395962, 0.5455506993395962]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.920\n",
      "(*) epoch 2, cost 3.055\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.332\n",
      "(*) epoch 2, cost 2.321\n",
      "(*) epoch 3, cost 1.570\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.580999883929323, 1.1818582105962154, 3.4905754093684696, 3.4905754093684696, 3.023831328148219, 0.7151141293759652, 3.4905754093684696, 3.023831328148219, 4.2865833887752185, 3.4905754093684696, 0.7151141293759652, 0.7151141293759652, 1.1818582105962154, 4.537304449937404, 3.023831328148219, 3.023831328148219, 3.023831328148219, 3.4905754093684696, 3.023831328148219, 3.4905754093684696, 3.023831328148219, 0.7151141293759652, 3.023831328148219, 3.4905754093684696, 3.023831328148219, 1.1818582105962154, 1.1818582105962154, 0.7151141293759652, 0.7151141293759652, 0.7151141293759652, 0.8878419488220566, 2.0477439651495732, 4.356461163921828, 1.1818582105962154, 0.8878419488220566, 0.7151141293759652, 3.1965591475943107, 4.911246909878218, 3.8897170827015772, 3.023831328148219, 1.1818582105962154, 3.023831328148219, 1.1818582105962154, 3.023831328148219, 1.1818582105962154, 1.580999883929323, 1.1818582105962154, 3.023831328148219, 1.9778661900029642, 4.529188983367919]\n",
      "all_sum after preprocessing is: [-0.62307075 -0.93611459  0.8745951   0.8745951   0.5085312  -1.30217849\n",
      "  0.8745951   0.5085312   1.49889823  0.8745951  -1.30217849 -1.30217849\n",
      " -0.93611459  1.69553689  0.5085312   0.5085312   0.5085312   0.8745951\n",
      "  0.5085312   0.8745951   0.5085312  -1.30217849  0.5085312   0.8745951\n",
      "  0.5085312  -0.93611459 -0.93611459 -1.30217849 -1.30217849 -1.30217849\n",
      " -1.16670935 -0.25700684  1.55370285 -0.93611459 -1.16670935 -1.30217849\n",
      "  0.64400034  1.98881717  1.18763894  0.5085312  -0.93611459  0.5085312\n",
      " -0.93611459  0.5085312  -0.93611459 -0.62307075 -0.93611459  0.5085312\n",
      " -0.31181146  1.68917199]\n",
      "P is: [0.3490833803327939, 0.28168584559983956, 0.7057009429377827, 0.7057009429377827, 0.6244620901857888, 0.2137986088145658, 0.7057009429377827, 0.6244620901857888, 0.8174100932807324, 0.7057009429377827, 0.2137986088145658, 0.2137986088145658, 0.28168584559983956, 0.8449509273829335, 0.6244620901857888, 0.6244620901857888, 0.6244620901857888, 0.7057009429377827, 0.6244620901857888, 0.7057009429377827, 0.6244620901857888, 0.2137986088145658, 0.6244620901857888, 0.7057009429377827, 0.6244620901857888, 0.28168584559983956, 0.28168584559983956, 0.2137986088145658, 0.2137986088145658, 0.2137986088145658, 0.2374502997625179, 0.4360996340681125, 0.8254478945691123, 0.28168584559983956, 0.2374502997625179, 0.2137986088145658, 0.6556571823538274, 0.8796179437655931, 0.7663185249984017, 0.6244620901857888, 0.28168584559983956, 0.6244620901857888, 0.28168584559983956, 0.6244620901857888, 0.28168584559983956, 0.3490833803327939, 0.28168584559983956, 0.6244620901857888, 0.4226726431916541, 0.8441152371106428]\n",
      "all_sum before preprocessing is: [2.4867042242829474, 2.6819017618731773, 2.4867042242829474, 0.26730672116657367, 2.8922576935052713, 0.26730672116657367, 1.141004120380945, 1.141004120380945, 0.07210918357634354, 1.6130068250685756, 1.336201657971175, 1.336201657971175, 0.28246511520843787, 2.6819017618731773, 1.351360052013039, 2.5021688693217907, 2.707252546623579, 2.6819017618731773, 3.347896179515401, 1.336201657971175, 1.336201657971175, 0.26730672116657367, 0.26730672116657367, 0.07210918357634354, 2.5120550090333484, 1.336201657971175, 0.26730672116657367, 0.26730672116657367, 2.052374020373097, 1.336201657971175, 0.26730672116657367, 1.141004120380945, 0.26730672116657367, 0.26730672116657367, 0.26730672116657367, 0.26730672116657367, 1.336201657971175, 2.3069713317315608, 2.6819017618731773, 1.336201657971175, 1.336201657971175, 1.141004120380945, 0.26730672116657367, 1.141004120380945, 1.336201657971175, 3.8478689732237927, 0.26730672116657367, 2.6819017618731773, 1.336201657971175, 1.336201657971175]\n",
      "all_sum after preprocessing is: [ 1.10497344  1.30042109  1.10497344 -1.11726783  1.51104655 -1.11726783\n",
      " -0.24245094 -0.24245094 -1.31271548  0.23015655 -0.04700329 -0.04700329\n",
      " -1.10209001  1.30042109 -0.03182548  1.1204579   1.32580435  1.30042109\n",
      "  1.96726886 -0.04700329 -0.04700329 -1.11726783 -1.11726783 -1.31271548\n",
      "  1.13035671 -0.04700329 -1.11726783 -1.11726783  0.67008672 -0.04700329\n",
      " -1.11726783 -0.24245094 -1.11726783 -1.11726783 -1.11726783 -1.11726783\n",
      " -0.04700329  0.92501025  1.30042109 -0.04700329 -0.04700329 -0.24245094\n",
      " -1.11726783 -0.24245094 -0.04700329  2.46788228 -1.11726783  1.30042109\n",
      " -0.04700329 -0.04700329]\n",
      "P is: [0.7511908178481457, 0.7859058428223109, 0.7511908178481457, 0.24651842453256492, 0.8192162541531451, 0.24651842453256492, 0.43968244318929306, 0.43968244318929306, 0.21203280093232238, 0.5572864787864752, 0.4882513395439507, 0.4882513395439507, 0.2493484936452402, 0.7859058428223109, 0.4920443022897237, 0.7540736420997801, 0.790145778962113, 0.7859058428223109, 0.8773174590995078, 0.4882513395439507, 0.4882513395439507, 0.24651842453256492, 0.24651842453256492, 0.21203280093232238, 0.7559047218925682, 0.4882513395439507, 0.24651842453256492, 0.24651842453256492, 0.661522576360124, 0.4882513395439507, 0.24651842453256492, 0.43968244318929306, 0.24651842453256492, 0.24651842453256492, 0.24651842453256492, 0.24651842453256492, 0.4882513395439507, 0.7160618778322586, 0.7859058428223109, 0.4882513395439507, 0.4882513395439507, 0.43968244318929306, 0.24651842453256492, 0.43968244318929306, 0.4882513395439507, 0.9218593517784698, 0.24651842453256492, 0.7859058428223109, 0.4882513395439507, 0.4882513395439507]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.555\n",
      "(*) epoch 2, cost 3.170\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.318\n",
      "(*) epoch 2, cost 2.782\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.82918687025982, 2.82918687025982, 2.82918687025982, 3.2797156388042974, 2.82918687025982, 3.5150177184099523, 2.82918687025982, 3.8481057019896054, 2.122533730620059, 3.6128036223839506, 2.122533730620059, 2.8930875572019525, 3.6128036223839506, 2.8930875572019525, 3.3436163257464298, 2.808364578770191, 2.82918687025982, 3.3436163257464298, 3.2797156388042974, 2.82918687025982, 3.9655464869544295, 3.3436163257464298, 4.029447173896562, 2.82918687025982, 2.122533730620059, 3.5150177184099523, 3.3436163257464298, 4.029447173896562, 3.5789184053520846, 2.6369631861066685, 3.2797156388042974, 3.2797156388042974, 2.8930875572019525, 4.827238890668402, 3.2797156388042974, 2.82918687025982, 3.3436163257464298, 2.82918687025982, 2.8930875572019525, 2.8930875572019525, 3.2797156388042974, 3.2797156388042974, 3.3436163257464298, 2.82918687025982, 2.8930875572019525, 2.82918687025982, 2.82918687025982, 3.3436163257464298, 3.5789184053520846, 3.2797156388042974]\n",
      "all_sum after preprocessing is: [-0.65644811 -0.65644811 -0.65644811  0.2536688  -0.65644811  0.72900449\n",
      " -0.65644811  1.40187829 -2.08396399  0.9265426  -2.08396399 -0.5273618\n",
      "  0.9265426  -0.5273618   0.38275511 -0.69851139 -0.65644811  0.38275511\n",
      "  0.2536688  -0.65644811  1.6391214   0.38275511  1.7682077  -0.65644811\n",
      " -2.08396399  0.72900449  0.38275511  1.7682077   0.85809079 -1.04476077\n",
      "  0.2536688   0.2536688  -0.5273618   3.37983338  0.2536688  -0.65644811\n",
      "  0.38275511 -0.65644811 -0.5273618  -0.5273618   0.2536688   0.2536688\n",
      "  0.38275511 -0.65644811 -0.5273618  -0.65644811 -0.65644811  0.38275511\n",
      "  0.85809079  0.2536688 ]\n",
      "P is: [0.34153794501608303, 0.34153794501608303, 0.34153794501608303, 0.5630793104173784, 0.34153794501608303, 0.6745867757880992, 0.34153794501608303, 0.8024817755517735, 0.11066523442281377, 0.7163733284365379, 0.11066523442281377, 0.3711324158005909, 0.7163733284365379, 0.3711324158005909, 0.5945374291974261, 0.3321423534090043, 0.34153794501608303, 0.5945374291974261, 0.5630793104173784, 0.34153794501608303, 0.8374153500476794, 0.5945374291974261, 0.8542346399145313, 0.34153794501608303, 0.11066523442281377, 0.6745867757880992, 0.5945374291974261, 0.8542346399145313, 0.7022616122852433, 0.2602324447663711, 0.5630793104173784, 0.5630793104173784, 0.3711324158005909, 0.9670682992681179, 0.5630793104173784, 0.34153794501608303, 0.5945374291974261, 0.34153794501608303, 0.3711324158005909, 0.3711324158005909, 0.5630793104173784, 0.5630793104173784, 0.5945374291974261, 0.34153794501608303, 0.3711324158005909, 0.34153794501608303, 0.34153794501608303, 0.5945374291974261, 0.7022616122852433, 0.5630793104173784]\n",
      "all_sum before preprocessing is: [5.3662014777533695, 4.137260054207106, 5.302706928639902, 2.9568181647394267, 3.8712691984081773, 3.5656597988045657, 4.475995076787105, 2.540004674961208, 6.825841259091465, 3.137127237581457, 5.3662014777533695, 3.7390807635774177, 4.874174367416793, 3.6978482336353253, 5.4761278934127535, 4.677786698622267, 3.7728848060928066, 3.6291543479180337, 5.302706928639902, 4.137260054207106, 5.4761278934127535, 4.1222650391722215, 5.3662014777533695, 3.6291543479180337, 5.3662014777533695, 4.968022187123681, 4.269448489037866, 5.267817085437999, 4.874174367416793, 6.773763202676309, 3.7390807635774177, 4.6938652945747625, 3.6291543479180337, 4.475995076787105, 4.137260054207106, 4.904527638010213, 4.137260054207106, 4.787713114281651, 3.7390807635774177, 6.149547657508973, 4.968022187123681, 4.874174367416793, 4.874174367416793, 5.3662014777533695, 6.414833828457602, 2.400212924371771, 3.64523294387053, 2.400212924371771, 7.8744736097956975, 5.5968998355452015]\n",
      "all_sum after preprocessing is: [ 0.68796112 -0.40899358  0.6312858  -1.46265753 -0.64641736 -0.91920471\n",
      " -0.10663826 -1.83470579  1.99083747 -1.30171342  0.68796112 -0.76440893\n",
      "  0.24877709 -0.80121314  0.78608158  0.0734812  -0.7342354  -0.86252939\n",
      "  0.6312858  -0.40899358  0.78608158 -0.42237815  0.68796112 -0.86252939\n",
      "  0.68796112  0.33254577 -0.29100201  0.60014308  0.24877709  1.94435253\n",
      " -0.76440893  0.08783298 -0.86252939 -0.10663826 -0.40899358  0.27587045\n",
      " -0.40899358  0.17160166 -0.76440893  1.38717693  0.33254577  0.24877709\n",
      "  0.24877709  0.68796112  1.62397171 -1.95948409 -0.84817761 -1.95948409\n",
      "  2.92684806  0.89388277]\n",
      "P is: [0.6655132143787579, 0.3991534662341114, 0.6527809570540605, 0.18806119878279004, 0.3437973302614001, 0.2851199686654691, 0.47336566952899867, 0.13767863309846923, 0.8798317098637488, 0.21387679190511746, 0.6655132143787579, 0.31768980632570704, 0.5618754773349148, 0.3097660766312077, 0.6869893513110106, 0.5183620385864854, 0.3242659876998227, 0.2968111547511318, 0.6527809570540605, 0.3991534662341114, 0.6869893513110106, 0.3959478199770675, 0.6655132143787579, 0.2968111547511318, 0.6655132143787579, 0.582378673012984, 0.42775857544469253, 0.6456890410237204, 0.5618754773349148, 0.8748295360916318, 0.31768980632570704, 0.5219441380837428, 0.2968111547511318, 0.47336566952899867, 0.3991534662341114, 0.5685335215548447, 0.3991534662341114, 0.5427954496642706, 0.31768980632570704, 0.8001411737709049, 0.582378673012984, 0.5618754773349148, 0.5618754773349148, 0.6655132143787579, 0.8353421489730007, 0.12352289172621576, 0.2998152842692025, 0.12352289172621576, 0.9491577862426431, 0.7096907900152983]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.947\n",
      "(*) epoch 2, cost 2.721\n",
      "(*) epoch 3, cost 2.432\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.428\n",
      "(*) epoch 2, cost 5.623\n",
      "(*) epoch 3, cost 5.103\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.6637301238364675, 2.254693932683391, 3.3229954798093044, 2.6637301238364675, 2.6637301238364675, 2.6637301238364675, 2.254693932683391, 2.6637301238364675, 3.1044930137661373, 2.254693932683391, 2.6637301238364675, 2.254693932683391, 2.6637301238364675, 2.254693932683391, 2.6637301238364675, 2.254693932683391, 2.6637301238364675, 2.3306457049487905, 2.6637301238364675, 2.6637301238364675, 2.254693932683391, 2.6637301238364675, 2.6637301238364675, 2.254693932683391, 2.254693932683391, 3.1044930137661373, 2.6637301238364675, 2.695456822613061, 2.254693932683391, 2.254693932683391, 2.6637301238364675, 2.6637301238364675, 2.254693932683391, 2.254693932683391, 2.6637301238364675, 2.254693932683391, 2.254693932683391, 2.254693932683391, 2.254693932683391, 2.6637301238364675, 2.6637301238364675, 2.254693932683391, 2.254693932683391, 2.6637301238364675, 2.6637301238364675, 2.6637301238364675, 2.254693932683391, 2.6637301238364675, 3.1044930137661373, 2.913959288656228]\n",
      "all_sum after preprocessing is: [ 0.45603786 -1.03617882  2.86112273  0.45603786  0.45603786  0.45603786\n",
      " -1.03617882  0.45603786  2.06399761 -1.03617882  0.45603786 -1.03617882\n",
      "  0.45603786 -1.03617882  0.45603786 -1.03617882  0.45603786 -0.75909697\n",
      "  0.45603786  0.45603786 -1.03617882  0.45603786  0.45603786 -1.03617882\n",
      " -1.03617882  2.06399761  0.45603786  0.57178094 -1.03617882 -1.03617882\n",
      "  0.45603786  0.45603786 -1.03617882 -1.03617882  0.45603786 -1.03617882\n",
      " -1.03617882 -1.03617882 -1.03617882  0.45603786  0.45603786 -1.03617882\n",
      " -1.03617882  0.45603786  0.45603786  0.45603786 -1.03617882  0.45603786\n",
      "  2.06399761  1.36890606]\n",
      "P is: [0.6120738259288218, 0.261887966767443, 0.945890791190709, 0.6120738259288218, 0.6120738259288218, 0.6120738259288218, 0.261887966767443, 0.6120738259288218, 0.8873543766055102, 0.261887966767443, 0.6120738259288218, 0.261887966767443, 0.6120738259288218, 0.261887966767443, 0.6120738259288218, 0.261887966767443, 0.6120738259288218, 0.31884235500897723, 0.6120738259288218, 0.6120738259288218, 0.261887966767443, 0.6120738259288218, 0.6120738259288218, 0.261887966767443, 0.261887966767443, 0.8873543766055102, 0.6120738259288218, 0.6391740156626777, 0.261887966767443, 0.261887966767443, 0.6120738259288218, 0.6120738259288218, 0.261887966767443, 0.261887966767443, 0.6120738259288218, 0.261887966767443, 0.261887966767443, 0.261887966767443, 0.261887966767443, 0.6120738259288218, 0.6120738259288218, 0.261887966767443, 0.261887966767443, 0.6120738259288218, 0.6120738259288218, 0.6120738259288218, 0.261887966767443, 0.6120738259288218, 0.8873543766055102, 0.7972033532199396]\n",
      "all_sum before preprocessing is: [0.8658964749669845, 1.5419459697215756, 1.809022863644154, 1.5419459697215756, 1.809022863644154, 1.809022863644154, 1.5419459697215756, 0.8658964749669845, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.809022863644154, 1.5419459697215756, 1.5419459697215756, 1.809022863644154, 1.5419459697215756, 1.5419459697215756, 1.6697962584314836, 1.5419459697215756, 1.5419459697215756, 0.8658964749669845, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.809022863644154, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 0.8658964749669845, 1.5419459697215756, 1.1329733688895631, 1.5419459697215756, 0.8658964749669845, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 1.5419459697215756, 0.8658964749669845, 1.5419459697215756, 1.5419459697215756, 1.809022863644154, 1.5419459697215756, 1.5419459697215756]\n",
      "all_sum after preprocessing is: [-2.43815258  0.19202644  1.23109244  0.19202644  1.23109244  1.23109244\n",
      "  0.19202644 -2.43815258  0.19202644  0.19202644  0.19202644  1.23109244\n",
      "  0.19202644  0.19202644  1.23109244  0.19202644  0.19202644  0.68942959\n",
      "  0.19202644  0.19202644 -2.43815258  0.19202644  0.19202644  0.19202644\n",
      "  0.19202644  1.23109244  0.19202644  0.19202644  0.19202644 -2.43815258\n",
      "  0.19202644 -1.39908658  0.19202644 -2.43815258  0.19202644  0.19202644\n",
      "  0.19202644  0.19202644  0.19202644  0.19202644  0.19202644  0.19202644\n",
      "  0.19202644  0.19202644 -2.43815258  0.19202644  0.19202644  1.23109244\n",
      "  0.19202644  0.19202644]\n",
      "P is: [0.08030925620448613, 0.5478596350565769, 0.7740097194232511, 0.5478596350565769, 0.7740097194232511, 0.7740097194232511, 0.5478596350565769, 0.08030925620448613, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.7740097194232511, 0.5478596350565769, 0.5478596350565769, 0.7740097194232511, 0.5478596350565769, 0.5478596350565769, 0.6658400238971809, 0.5478596350565769, 0.5478596350565769, 0.08030925620448613, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.7740097194232511, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.08030925620448613, 0.5478596350565769, 0.19796109705654855, 0.5478596350565769, 0.08030925620448613, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.5478596350565769, 0.08030925620448613, 0.5478596350565769, 0.5478596350565769, 0.7740097194232511, 0.5478596350565769, 0.5478596350565769]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.131\n",
      "(*) epoch 2, cost 1.911\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.149\n",
      "(*) epoch 2, cost 1.495\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [3.227908539801552, 2.2178288489028573, 2.279001385034663, 3.2890810759333577, 3.6260549998132445, 2.428238531728521, 3.2890810759333577, 3.438318222627216, 3.2890810759333577, 3.6260549998132445, 3.564882463681439, 2.2178288489028573, 2.279001385034663, 2.279001385034663, 3.2890810759333577, 3.2890810759333577, 3.2890810759333577, 2.279001385034663, 2.2178288489028573, 3.2890810759333577, 3.2890810759333577, 3.2890810759333577, 2.279001385034663, 2.279001385034663, 2.279001385034663, 2.279001385034663, 3.255886996587924, 2.279001385034663, 2.428238531728521, 3.438318222627216, 2.279001385034663, 2.279001385034663, 3.2890810759333577, 3.2890810759333577, 2.2178288489028573, 2.428238531728521, 2.279001385034663, 2.279001385034663, 3.2890810759333577, 2.279001385034663, 2.279001385034663, 2.428238531728521, 3.438318222627216, 3.6260549998132445, 3.2890810759333577, 3.227908539801552, 2.279001385034663, 3.7752921465071023, 2.2178288489028573, 2.279001385034663]\n",
      "all_sum after preprocessing is: [ 0.75262203 -1.07065952 -0.96023778  0.86304376  1.47131096 -0.69085177\n",
      "  0.86304376  1.13242977  0.86304376  1.47131096  1.36088922 -1.07065952\n",
      " -0.96023778 -0.96023778  0.86304376  0.86304376  0.86304376 -0.96023778\n",
      " -1.07065952  0.86304376  0.86304376  0.86304376 -0.96023778 -0.96023778\n",
      " -0.96023778 -0.96023778  0.80312557 -0.96023778 -0.69085177  1.13242977\n",
      " -0.96023778 -0.96023778  0.86304376  0.86304376 -1.07065952 -0.69085177\n",
      " -0.96023778 -0.96023778  0.86304376 -0.96023778 -0.96023778 -0.69085177\n",
      "  1.13242977  1.47131096  0.86304376  0.75262203 -0.96023778  1.74069696\n",
      " -1.07065952 -0.96023778]\n",
      "P is: [0.6797497567562965, 0.25527768231717957, 0.2768305901002575, 0.70329619144572, 0.8132565629885266, 0.3338436192402377, 0.70329619144572, 0.7562870261030157, 0.70329619144572, 0.8132565629885266, 0.7959041806209745, 0.25527768231717957, 0.2768305901002575, 0.2768305901002575, 0.70329619144572, 0.70329619144572, 0.70329619144572, 0.2768305901002575, 0.25527768231717957, 0.70329619144572, 0.70329619144572, 0.70329619144572, 0.2768305901002575, 0.2768305901002575, 0.2768305901002575, 0.2768305901002575, 0.690642673365275, 0.2768305901002575, 0.3338436192402377, 0.7562870261030157, 0.2768305901002575, 0.2768305901002575, 0.70329619144572, 0.70329619144572, 0.25527768231717957, 0.3338436192402377, 0.2768305901002575, 0.2768305901002575, 0.70329619144572, 0.2768305901002575, 0.2768305901002575, 0.3338436192402377, 0.7562870261030157, 0.8132565629885266, 0.70329619144572, 0.6797497567562965, 0.2768305901002575, 0.8507755710399673, 0.25527768231717957, 0.2768305901002575]\n",
      "all_sum before preprocessing is: [3.216266156283743, 3.216266156283743, 3.216266156283743, 4.517116682458383, 3.216266156283743, 4.517116682458383, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.097889666253632, 3.216266156283743, 3.216266156283743, 3.216266156283743, 4.517116682458383, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 4.517116682458383, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 4.517116682458383, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743, 3.216266156283743]\n",
      "all_sum after preprocessing is: [-0.32631399 -0.32631399 -0.32631399  2.99731554 -0.32631399  2.99731554\n",
      " -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399\n",
      " -0.32631399 -0.62876196 -0.32631399 -0.32631399 -0.32631399  2.99731554\n",
      " -0.32631399 -0.32631399 -0.32631399 -0.32631399  2.99731554 -0.32631399\n",
      " -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399\n",
      " -0.32631399  2.99731554 -0.32631399 -0.32631399 -0.32631399 -0.32631399\n",
      " -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399\n",
      " -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399 -0.32631399\n",
      " -0.32631399 -0.32631399]\n",
      "P is: [0.419137754565021, 0.419137754565021, 0.419137754565021, 0.9524527043926597, 0.419137754565021, 0.9524527043926597, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.34779131216196196, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.9524527043926597, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.9524527043926597, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.9524527043926597, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021, 0.419137754565021]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.948\n",
      "(*) epoch 2, cost 4.455\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.432\n",
      "(*) epoch 2, cost 1.502\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.116826482459127, 0.44602401603345737, 0.44602401603345737, 1.116826482459127, 1.116826482459127, 0.44602401603345737, 1.116826482459127, 1.116826482459127, 1.116826482459127, 1.116826482459127, 1.116826482459127, 2.151607229252944, 0.44602401603345737, 1.116826482459127, 1.116826482459127, 0.44602401603345737, 1.116826482459127, 0.44602401603345737, 0.44602401603345737, 1.116826482459127, 0.44602401603345737, 0.44602401603345737, 0.44602401603345737, 1.116826482459127, 1.116826482459127, 1.116826482459127, 1.116826482459127, 0.44602401603345737, 1.3362778796419565, 1.116826482459127, 1.116826482459127, 1.116826482459127, 1.116826482459127, 1.116826482459127, 1.116826482459127, 1.116826482459127, 0.44602401603345737, 2.182394243689587, 0.44602401603345737, 1.116826482459127, 0.44602401603345737, 0.44602401603345737, 1.116826482459127, 1.116826482459127, 1.116826482459127, 0.44602401603345737, 0.44602401603345737, 1.116826482459127, 0.44602401603345737, 1.116826482459127]\n",
      "all_sum after preprocessing is: [ 0.47454318 -1.1571141  -1.1571141   0.47454318  0.47454318 -1.1571141\n",
      "  0.47454318  0.47454318  0.47454318  0.47454318  0.47454318  2.99153978\n",
      " -1.1571141   0.47454318  0.47454318 -1.1571141   0.47454318 -1.1571141\n",
      " -1.1571141   0.47454318 -1.1571141  -1.1571141  -1.1571141   0.47454318\n",
      "  0.47454318  0.47454318  0.47454318 -1.1571141   1.00833589  0.47454318\n",
      "  0.47454318  0.47454318  0.47454318  0.47454318  0.47454318  0.47454318\n",
      " -1.1571141   3.06642599 -1.1571141   0.47454318 -1.1571141  -1.1571141\n",
      "  0.47454318  0.47454318  0.47454318 -1.1571141  -1.1571141   0.47454318\n",
      " -1.1571141   0.47454318]\n",
      "P is: [0.6164584997937286, 0.23919206424453165, 0.23919206424453165, 0.6164584997937286, 0.6164584997937286, 0.23919206424453165, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.9521904555898655, 0.23919206424453165, 0.6164584997937286, 0.6164584997937286, 0.23919206424453165, 0.6164584997937286, 0.23919206424453165, 0.23919206424453165, 0.6164584997937286, 0.23919206424453165, 0.23919206424453165, 0.23919206424453165, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.23919206424453165, 0.7326943535049268, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.23919206424453165, 0.9554864094604905, 0.23919206424453165, 0.6164584997937286, 0.23919206424453165, 0.23919206424453165, 0.6164584997937286, 0.6164584997937286, 0.6164584997937286, 0.23919206424453165, 0.23919206424453165, 0.6164584997937286, 0.23919206424453165, 0.6164584997937286]\n",
      "all_sum before preprocessing is: [1.700532932103355, 1.57373193713696, 1.57373193713696, 1.57373193713696, 1.903862160834101, 1.903862160834101, 1.903862160834101, 1.700532932103355, 1.700532932103355, 1.903862160834101, 1.903862160834101, 1.777061165867706, 1.700532932103355, 1.903862160834101, 1.700532932103355, 1.700532932103355, 2.2961910620855295, 1.777061165867706, 2.118290783341048, 1.700532932103355, 1.57373193713696, 2.4229920570519243, 1.700532932103355, 1.57373193713696, 1.700532932103355, 1.700532932103355, 1.700532932103355, 2.118290783341048, 1.57373193713696, 1.700532932103355, 1.57373193713696, 2.4995202908162755, 2.041085538849807, 1.57373193713696, 1.777061165867706, 1.57373193713696, 1.700532932103355, 1.57373193713696, 1.57373193713696, 1.57373193713696, 1.777061165867706, 1.903862160834101, 1.700532932103355, 1.903862160834101, 1.57373193713696, 1.57373193713696, 1.700532932103355, 1.57373193713696, 1.57373193713696, 1.903862160834101]\n",
      "all_sum after preprocessing is: [-0.31030808 -0.88887223 -0.88887223 -0.88887223  0.61743704  0.61743704\n",
      "  0.61743704 -0.31030808 -0.31030808  0.61743704  0.61743704  0.03887288\n",
      " -0.31030808  0.61743704 -0.31030808 -0.31030808  2.40754476  0.03887288\n",
      "  1.59582617 -0.31030808 -0.88887223  2.98610891 -0.31030808 -0.88887223\n",
      " -0.31030808 -0.31030808 -0.31030808  1.59582617 -0.88887223 -0.31030808\n",
      " -0.88887223  3.33528987  1.24355616 -0.88887223  0.03887288 -0.88887223\n",
      " -0.31030808 -0.88887223 -0.88887223 -0.88887223  0.03887288  0.61743704\n",
      " -0.31030808  0.61743704 -0.88887223 -0.88887223 -0.31030808 -0.88887223\n",
      " -0.88887223  0.61743704]\n",
      "P is: [0.423039542391734, 0.29134261347803436, 0.29134261347803436, 0.29134261347803436, 0.6496354187412007, 0.6496354187412007, 0.6496354187412007, 0.423039542391734, 0.423039542391734, 0.6496354187412007, 0.6496354187412007, 0.509716996780084, 0.423039542391734, 0.6496354187412007, 0.423039542391734, 0.423039542391734, 0.9174008226379965, 0.509716996780084, 0.8314342259236374, 0.423039542391734, 0.29134261347803436, 0.9519426139713275, 0.423039542391734, 0.29134261347803436, 0.423039542391734, 0.423039542391734, 0.423039542391734, 0.8314342259236374, 0.29134261347803436, 0.423039542391734, 0.29134261347803436, 0.965619817125669, 0.7761824092624761, 0.29134261347803436, 0.509716996780084, 0.29134261347803436, 0.423039542391734, 0.29134261347803436, 0.29134261347803436, 0.29134261347803436, 0.509716996780084, 0.6496354187412007, 0.423039542391734, 0.6496354187412007, 0.29134261347803436, 0.29134261347803436, 0.423039542391734, 0.29134261347803436, 0.29134261347803436, 0.6496354187412007]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.044\n",
      "(*) epoch 2, cost 1.173\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.900\n",
      "(*) epoch 2, cost 1.415\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.5298685060003705, 2.7493133738058617, 3.132378648350906, 2.124019491180598, 2.5298685060003705, 2.9955286320010126, 2.3930184896504776, 2.1468032314553267, 2.5627165335617192, 2.1468032314553267, 3.271910291229155, 2.124929207381253, 3.132378648350906, 2.124929207381253, 2.5298685060003705, 2.7274393497317875, 2.855996989122763, 2.253486846772228, 2.7493133738058617, 1.8485475481531104, 2.253486846772228, 2.5298685060003705, 2.6694001488786205, 2.451057690503645, 2.1468032314553267, 2.715408229347284, 2.5298685060003705, 2.5298685060003705, 2.205690063979118, 2.1577772349426008, 1.7409542166355543, 2.5298685060003705, 2.3930184896504776, 2.423184890683469, 2.423184890683469, 2.253486846772228, 2.3930184896504776, 2.0652487049002137, 2.5298685060003705, 2.423184890683469, 2.1577772349426008, 2.1468032314553267, 2.253486846772228, 2.45014797430299, 2.2863348743335763, 3.0256950330340047, 2.1468032314553267, 2.253486846772228, 2.5298685060003705, 1.8476378319524558]\n",
      "all_sum after preprocessing is: [ 0.30947473  0.97502163  2.1368073  -0.92141098  0.30947473  1.72175953\n",
      " -0.10557305 -0.85231095  0.4090984  -0.85231095  2.55998809 -0.91865194\n",
      "  2.1368073  -0.91865194  0.30947473  0.90868064  1.29857874 -0.52875383\n",
      "  0.97502163 -1.7568805  -0.52875383  0.30947473  0.73265552  0.07045208\n",
      " -0.85231095  0.87219186  0.30947473  0.30947473 -0.67371507 -0.81902827\n",
      " -2.08319666  0.30947473 -0.10557305 -0.01408239 -0.01408239 -0.52875383\n",
      " -0.10557305 -1.09965491  0.30947473 -0.01408239 -0.81902827 -0.85231095\n",
      " -0.52875383  0.06769303 -0.42913016  1.81325019 -0.85231095 -0.52875383\n",
      "  0.30947473 -1.75963955]\n",
      "P is: [0.57675704300021, 0.7261192818749347, 0.8944295185254829, 0.2846704836353678, 0.57675704300021, 0.848355336305789, 0.4736312255488435, 0.29894830744977663, 0.6008716715967964, 0.29894830744977663, 0.928241664587376, 0.2852326509166221, 0.8944295185254829, 0.2852326509166221, 0.57675704300021, 0.7127301049052573, 0.7855956908009483, 0.37080758356232096, 0.7261192818749347, 0.1471814659648859, 0.37080758356232096, 0.57675704300021, 0.6753877364523527, 0.5176057380413609, 0.29894830744977663, 0.7052015741997495, 0.57675704300021, 0.57675704300021, 0.337665473224625, 0.3059699703761275, 0.1107407760062789, 0.57675704300021, 0.4736312255488435, 0.49647946046518165, 0.49647946046518165, 0.37080758356232096, 0.4736312255488435, 0.2498045595496372, 0.57675704300021, 0.49647946046518165, 0.3059699703761275, 0.29894830744977663, 0.37080758356232096, 0.5169167983598781, 0.394334059428196, 0.8597542300329659, 0.29894830744977663, 0.37080758356232096, 0.57675704300021, 0.1468354898738648]\n",
      "all_sum before preprocessing is: [2.743472983073861, 2.743472983073861, 2.743472983073861, 4.818948157992982, 2.743472983073861, 4.818948157992982, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 2.743472983073861, 1.4869205735656077, 2.743472983073861, 2.743472983073861, 2.743472983073861, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 2.743472983073861, 2.743472983073861, 3.4005674029171806, 3.4005674029171806, 2.743472983073861, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 2.743472983073861, 2.743472983073861, 3.4005674029171806, 3.4005674029171806, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 2.743472983073861, 3.4005674029171806, 2.743472983073861, 2.144014993408927, 2.743472983073861, 1.4869205735656077, 2.144014993408927, 2.743472983073861, 2.743472983073861, 2.743472983073861, 2.743472983073861, 2.743472983073861]\n",
      "all_sum after preprocessing is: [-0.29169358 -0.29169358 -0.29169358  3.34476866 -0.29169358  3.34476866\n",
      " -0.29169358  0.85960858 -0.29169358 -0.29169358 -2.49331249 -0.29169358\n",
      " -0.29169358 -0.29169358 -0.29169358  0.85960858 -0.29169358  0.85960858\n",
      " -0.29169358  0.85960858 -0.29169358  0.85960858 -0.29169358 -0.29169358\n",
      " -0.29169358  0.85960858  0.85960858 -0.29169358 -0.29169358  0.85960858\n",
      " -0.29169358 -0.29169358 -0.29169358  0.85960858  0.85960858 -0.29169358\n",
      "  0.85960858 -0.29169358 -0.29169358  0.85960858 -0.29169358 -1.34201033\n",
      " -0.29169358 -2.49331249 -1.34201033 -0.29169358 -0.29169358 -0.29169358\n",
      " -0.29169358 -0.29169358]\n",
      "P is: [0.42758930112432125, 0.42758930112432125, 0.42758930112432125, 0.9659331104657204, 0.42758930112432125, 0.9659331104657204, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.42758930112432125, 0.07632833128228779, 0.42758930112432125, 0.42758930112432125, 0.42758930112432125, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.42758930112432125, 0.42758930112432125, 0.7025788680858255, 0.7025788680858255, 0.42758930112432125, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.42758930112432125, 0.42758930112432125, 0.7025788680858255, 0.7025788680858255, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.42758930112432125, 0.7025788680858255, 0.42758930112432125, 0.20717965464873458, 0.42758930112432125, 0.07632833128228779, 0.20717965464873458, 0.42758930112432125, 0.42758930112432125, 0.42758930112432125, 0.42758930112432125, 0.42758930112432125]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.402\n",
      "(*) epoch 2, cost 4.388\n",
      "(*) epoch 3, cost 3.578\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.308\n",
      "(*) epoch 2, cost 2.239\n",
      "(*) epoch 3, cost 1.795\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.9065764664914424, 1.5942630826829762, 1.5942630826829762, 1.0009687831172134, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.9065764664914424, 1.9065764664914424, 1.9065764664914424, 1.5942630826829762, 1.5942630826829762, 1.9065764664914424, 1.5942630826829762, 1.9065764664914424, 1.5942630826829762, 1.9065764664914424, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.9065764664914424, 1.5942630826829762, 1.9065764664914424, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 2.0597910453866746, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.5942630826829762, 1.9065764664914424, 1.5942630826829762, 1.5942630826829762]\n",
      "all_sum after preprocessing is: [ 1.52781753 -0.36262009 -0.36262009 -3.95383944 -0.36262009 -0.36262009\n",
      " -0.36262009 -0.36262009  1.52781753  1.52781753  1.52781753 -0.36262009\n",
      " -0.36262009  1.52781753 -0.36262009  1.52781753 -0.36262009  1.52781753\n",
      " -0.36262009 -0.36262009 -0.36262009 -0.36262009 -0.36262009 -0.36262009\n",
      " -0.36262009 -0.36262009  1.52781753 -0.36262009  1.52781753 -0.36262009\n",
      " -0.36262009 -0.36262009 -0.36262009  2.45522769 -0.36262009 -0.36262009\n",
      " -0.36262009 -0.36262009 -0.36262009 -0.36262009 -0.36262009 -0.36262009\n",
      " -0.36262009 -0.36262009 -0.36262009 -0.36262009 -0.36262009  1.52781753\n",
      " -0.36262009 -0.36262009]\n",
      "P is: [0.8216867684309738, 0.41032546348561, 0.41032546348561, 0.018819932697553433, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.8216867684309738, 0.8216867684309738, 0.8216867684309738, 0.41032546348561, 0.41032546348561, 0.8216867684309738, 0.41032546348561, 0.8216867684309738, 0.41032546348561, 0.8216867684309738, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.8216867684309738, 0.41032546348561, 0.8216867684309738, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.9209429020132305, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.41032546348561, 0.8216867684309738, 0.41032546348561, 0.41032546348561]\n",
      "all_sum before preprocessing is: [7.15895148921993, 4.961485345855274, 2.609025986527473, 4.961485345855274, 0.8881608903402826, 2.609025986527473, 2.609025986527473, 0.8881608903402826, 0.8881608903402826, 2.8510253510090706, 0.8881608903402826, 4.806492129892129, 3.6829249510152104, 1.4854588076505553, 5.607167995869963, 3.2063239038377453, 4.961485345855274, 2.609025986527473, 3.085627033704938, 7.15895148921993, 0.8881608903402826, 3.9353236373596765, 2.609025986527473, 4.961485345855274, 0.8881608903402826, 2.609025986527473, 5.451910534568328, 3.576052222417992, 1.7378574939950207, 2.609025986527473, 4.961485345855274, 7.15895148921993, 0.8881608903402826, 3.085627033704938, 3.240620249668084, 2.609025986527473, 2.609025986527473, 3.2063239038377453, 5.558783263165546, 1.3785860790533364, 2.609025986527473, 4.961485345855274, 0.8881608903402826, 6.287782996687478, 4.806492129892129, 2.923835398671997, 3.240620249668084, 5.451910534568328, 3.240620249668084, 3.4597284980879075]\n",
      "all_sum after preprocessing is: [ 2.13237715  0.88746553 -0.44525307  0.88746553 -1.42016    -0.44525307\n",
      " -0.44525307 -1.42016    -1.42016    -0.30815525 -1.42016     0.79965855\n",
      "  0.16313369 -1.08177794  1.25325857 -0.10687101  0.88746553 -0.44525307\n",
      " -0.17524837  2.13237715 -1.42016     0.30612295 -0.44525307  0.88746553\n",
      " -1.42016    -0.44525307  1.1653019   0.102588   -0.93878868 -0.44525307\n",
      "  0.88746553  2.13237715 -1.42016    -0.17524837 -0.0874414  -0.44525307\n",
      " -0.44525307 -0.10687101  1.22584759 -1.14232363 -0.44525307  0.88746553\n",
      " -1.42016     1.63884154  0.79965855 -0.2669068  -0.0874414   1.1653019\n",
      " -0.0874414   0.03668812]\n",
      "P is: [0.8940104679486391, 0.708366869409451, 0.3904899816390923, 0.708366869409451, 0.19463650239821098, 0.3904899816390923, 0.3904899816390923, 0.19463650239821098, 0.19463650239821098, 0.423565085080454, 0.19463650239821098, 0.6899014370911819, 0.540693215451999, 0.25316970607452405, 0.7778634260408694, 0.47330764742263887, 0.708366869409451, 0.3904899816390923, 0.4562996929799265, 0.8940104679486391, 0.19463650239821098, 0.5759386352638085, 0.3904899816390923, 0.708366869409451, 0.19463650239821098, 0.3904899816390923, 0.7622947619118099, 0.5256245297804356, 0.28114508916432235, 0.3904899816390923, 0.708366869409451, 0.8940104679486391, 0.19463650239821098, 0.4562996929799265, 0.47815356850094143, 0.3904899816390923, 0.3904899816390923, 0.47330764742263887, 0.7730909784648274, 0.24189399592615185, 0.3904899816390923, 0.708366869409451, 0.19463650239821098, 0.8373772445499909, 0.6899014370911819, 0.4336666283145437, 0.47815356850094143, 0.7622947619118099, 0.47815356850094143, 0.5091710003698107]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.039\n",
      "(*) epoch 2, cost 1.362\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.955\n",
      "(*) epoch 2, cost 3.221\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.2284125392800357, 1.2829226299931111, 2.9715136321163174, 0.2284125392800357, 1.7579808525131058, 1.4190641264479333, 0.36455403573485795, 1.6218393560582833, 1.6218393560582833, 0.7034707618000303, 0.2284125392800357, 1.4190641264479333, 1.4190641264479333, 0.36455403573485795, 0.6488781794112883, 0.2284125392800357, 1.2829226299931111, 1.4190641264479333, 0.2284125392800357, 0.567329265345208, 0.2284125392800357, 1.2829226299931111, 1.4190641264479333, 1.4190641264479333, 1.2829226299931111, 1.2829226299931111, 1.4190641264479333, 1.7579808525131058, 0.567329265345208, 1.6218393560582833, 1.2829226299931111, 0.2284125392800357, 1.2829226299931111, 1.2829226299931111, 0.2284125392800357, 2.1508106423037874, 1.2829226299931111, 1.4190641264479333, 1.4190641264479333, 2.8353721356614954, 0.567329265345208, 1.917003541403242, 0.36455403573485795, 1.2829226299931111, 0.36455403573485795, 0.36455403573485795, 1.2829226299931111, 1.2829226299931111, 0.2284125392800357, 0.7034707618000303]\n",
      "all_sum after preprocessing is: [-1.28039401  0.30290355  2.83824392 -1.28039401  1.01618124  0.50731363\n",
      " -1.07598393  0.81177115  0.81177115 -0.56711632 -1.28039401  0.50731363\n",
      "  0.50731363 -1.07598393 -0.64908453 -1.28039401  0.30290355  0.50731363\n",
      " -1.28039401 -0.77152641 -1.28039401  0.30290355  0.50731363  0.50731363\n",
      "  0.30290355  0.30290355  0.50731363  1.01618124 -0.77152641  0.81177115\n",
      "  0.30290355 -1.28039401  0.30290355  0.30290355 -1.28039401  1.60599679\n",
      "  0.30290355  0.50731363  0.50731363  2.63383384 -0.77152641  1.25494637\n",
      " -1.07598393  0.30290355 -1.07598393 -1.07598393  0.30290355  0.30290355\n",
      " -1.28039401 -0.56711632]\n",
      "P is: [0.21748316147423477, 0.5751521591265126, 0.9447078052942707, 0.21748316147423477, 0.7342280840468055, 0.6241765166594562, 0.25426677357831906, 0.6924867977451536, 0.6924867977451536, 0.36190248494793087, 0.21748316147423477, 0.6241765166594562, 0.6241765166594562, 0.25426677357831906, 0.3431958665781751, 0.21748316147423477, 0.5751521591265126, 0.6241765166594562, 0.21748316147423477, 0.31614900646436794, 0.21748316147423477, 0.5751521591265126, 0.6241765166594562, 0.6241765166594562, 0.5751521591265126, 0.5751521591265126, 0.6241765166594562, 0.7342280840468055, 0.31614900646436794, 0.6924867977451536, 0.5751521591265126, 0.21748316147423477, 0.5751521591265126, 0.5751521591265126, 0.21748316147423477, 0.8328548509729848, 0.5751521591265126, 0.6241765166594562, 0.6241765166594562, 0.9330075794869059, 0.31614900646436794, 0.7781549262123777, 0.25426677357831906, 0.5751521591265126, 0.25426677357831906, 0.25426677357831906, 0.5751521591265126, 0.5751521591265126, 0.21748316147423477, 0.36190248494793087]\n",
      "all_sum before preprocessing is: [2.8356869351758767, 2.8356869351758767, 1.7597241043610006, 2.8356869351758767, 1.1283491322755672, 2.8356869351758767, 2.8356869351758767, 1.7597241043610006, 1.7597241043610006, 2.8356869351758767, 2.8356869351758767, 2.8356869351758767, 1.7597241043610006, 2.8356869351758767, 1.7597241043610006, 2.8356869351758767, 2.8356869351758767, 0.8868812761348202, 2.8356869351758767, 2.8356869351758767, 3.42172764092011, 1.7597241043610006, 0.8868812761348202, 2.8356869351758767, 1.7597241043610006, 1.7597241043610006, 1.7597241043610006, 2.8356869351758767, 2.8356869351758767, 3.42172764092011, 2.8356869351758767, 2.8356869351758767, 2.345764810105234, 2.8356869351758767, 1.7597241043610006, 2.0011919605017474, 1.7597241043610006, 1.7597241043610006, 1.7597241043610006, 1.7597241043610006, 2.8356869351758767, 2.8356869351758767, 2.8356869351758767, 2.8356869351758767, 2.8356869351758767, 2.8356869351758767, 2.8356869351758767, 2.8356869351758767, 1.9628441069496967, 2.8356869351758767]\n",
      "all_sum after preprocessing is: [ 0.69136797  0.69136797 -1.02316071  0.69136797 -2.02924612  0.69136797\n",
      "  0.69136797 -1.02316071 -1.02316071  0.69136797  0.69136797  0.69136797\n",
      " -1.02316071  0.69136797 -1.02316071  0.69136797  0.69136797 -2.41402108\n",
      "  0.69136797  0.69136797  1.62521398 -1.02316071 -2.41402108  0.69136797\n",
      " -1.02316071 -1.02316071 -1.02316071  0.69136797  0.69136797  1.62521398\n",
      "  0.69136797  0.69136797 -0.0893147   0.69136797 -1.02316071 -0.63838574\n",
      " -1.02316071 -1.02316071 -1.02316071 -1.02316071  0.69136797  0.69136797\n",
      "  0.69136797  0.69136797  0.69136797  0.69136797  0.69136797  0.69136797\n",
      " -0.6994924   0.69136797]\n",
      "P is: [0.6662711692268595, 0.6662711692268595, 0.26441218949800793, 0.6662711692268595, 0.11616630225543625, 0.6662711692268595, 0.6662711692268595, 0.26441218949800793, 0.26441218949800793, 0.6662711692268595, 0.6662711692268595, 0.6662711692268595, 0.26441218949800793, 0.6662711692268595, 0.26441218949800793, 0.6662711692268595, 0.6662711692268595, 0.08210974835960587, 0.6662711692268595, 0.6662711692268595, 0.835512946906939, 0.26441218949800793, 0.08210974835960587, 0.6662711692268595, 0.26441218949800793, 0.26441218949800793, 0.26441218949800793, 0.6662711692268595, 0.6662711692268595, 0.835512946906939, 0.6662711692268595, 0.6662711692268595, 0.47768615628988514, 0.6662711692268595, 0.26441218949800793, 0.34561153545428186, 0.26441218949800793, 0.26441218949800793, 0.26441218949800793, 0.26441218949800793, 0.6662711692268595, 0.6662711692268595, 0.6662711692268595, 0.6662711692268595, 0.6662711692268595, 0.6662711692268595, 0.6662711692268595, 0.6662711692268595, 0.33192477820301064, 0.6662711692268595]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.712\n",
      "(*) epoch 2, cost 2.998\n",
      "(*) epoch 3, cost 1.958\n",
      "(*) epoch 4, cost 1.635\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.603\n",
      "(*) epoch 2, cost 2.177\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 2.9046389659156318, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731, 3.648473951055731]\n",
      "all_sum after preprocessing is: [ 0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714 -7.          0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714  0.14285714\n",
      "  0.14285714  0.14285714]\n",
      "P is: [0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.0009110511944006405, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706, 0.5356536708339706]\n",
      "all_sum before preprocessing is: [0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 2.1550117690391315, 0.28556509449716144, 2.180894620397184, 0.9322220571279549, 0.28556509449716144, 0.9322220571279549, 1.5342376577663908, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.28556509449716144, 0.28556509449716144, 0.9322220571279549, 0.28556509449716144, 0.28556509449716144, 0.9322220571279549, 0.28556509449716144, 0.9322220571279549, 2.1550117690391315, 0.28556509449716144, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.28556509449716144, 0.28556509449716144, 0.9322220571279549, 2.180894620397184, 0.28556509449716144, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.9322220571279549, 0.28556509449716144, 0.28556509449716144, 0.28556509449716144, 2.1550117690391315, 0.28556509449716144, 0.9322220571279549, 0.9322220571279549, 0.28556509449716144, 0.28556509449716144]\n",
      "all_sum after preprocessing is: [ 0.15576149  0.15576149  0.15576149  0.15576149  0.15576149  0.15576149\n",
      "  0.15576149  2.40953404 -1.03611779  2.45723976  0.15576149 -1.03611779\n",
      "  0.15576149  1.26536049  0.15576149  0.15576149  0.15576149 -1.03611779\n",
      " -1.03611779  0.15576149 -1.03611779 -1.03611779  0.15576149 -1.03611779\n",
      "  0.15576149  2.40953404 -1.03611779  0.15576149  0.15576149  0.15576149\n",
      "  0.15576149  0.15576149 -1.03611779 -1.03611779  0.15576149  2.45723976\n",
      " -1.03611779  0.15576149  0.15576149  0.15576149  0.15576149 -1.03611779\n",
      " -1.03611779 -1.03611779  2.40953404 -1.03611779  0.15576149  0.15576149\n",
      " -1.03611779 -1.03611779]\n",
      "P is: [0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.9175514387847566, 0.26189976416115834, 0.9210892711453026, 0.5388618330715476, 0.26189976416115834, 0.5388618330715476, 0.7799475053286842, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.26189976416115834, 0.26189976416115834, 0.5388618330715476, 0.26189976416115834, 0.26189976416115834, 0.5388618330715476, 0.26189976416115834, 0.5388618330715476, 0.9175514387847566, 0.26189976416115834, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.26189976416115834, 0.26189976416115834, 0.5388618330715476, 0.9210892711453026, 0.26189976416115834, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.5388618330715476, 0.26189976416115834, 0.26189976416115834, 0.26189976416115834, 0.9175514387847566, 0.26189976416115834, 0.5388618330715476, 0.5388618330715476, 0.26189976416115834, 0.26189976416115834]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.357\n",
      "(*) epoch 2, cost 1.911\n",
      "(*) epoch 3, cost 1.128\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.649\n",
      "(*) epoch 2, cost 1.894\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.5143429427557296, 0.4005666717918149, 2.735426115613711, 1.5143429427557296, 1.5143429427557296, 2.4652580422347476, 2.6909195294863975, 0.6578057694877242, 1.5143429427557296, 2.4652580422347476, 0.6578057694877242, 1.5143429427557296, 2.735426115613711, 1.5143429427557296, 1.5143429427557296, 1.5143429427557296, 1.5143429427557296, 2.4652580422347476, 0.6578057694877242, 1.5143429427557296, 2.4652580422347476, 2.0700729176321513, 2.735426115613711, 1.5143429427557296, 1.5143429427557296, 2.4652580422347476, 1.5143429427557296, 2.6909195294863975, 1.8788889423457054, 1.5143429427557296, 2.4652580422347476, 1.5143429427557296, 0.6578057694877242, 1.5143429427557296, 2.4652580422347476, 2.735426115613711, 1.5143429427557296, 1.5143429427557296, 2.4652580422347476, 0.6578057694877242, 2.6909195294863975, 0.6578057694877242, 2.735426115613711, 1.5143429427557296, 1.5143429427557296, 2.735426115613711, 1.5143429427557296, 1.5143429427557296, 1.5143429427557296, 1.5143429427557296]\n",
      "all_sum after preprocessing is: [-0.38746841 -2.03075084  1.41413625 -0.38746841 -0.38746841  1.01552617\n",
      "  1.34847056 -1.65121637 -0.38746841  1.01552617 -1.65121637 -0.38746841\n",
      "  1.41413625 -0.38746841 -0.38746841 -0.38746841 -0.38746841  1.01552617\n",
      " -1.65121637 -0.38746841  1.01552617  0.43246404  1.41413625 -0.38746841\n",
      " -0.38746841  1.01552617 -0.38746841  1.34847056  0.15038829 -0.38746841\n",
      "  1.01552617 -0.38746841 -1.65121637 -0.38746841  1.01552617  1.41413625\n",
      " -0.38746841 -0.38746841  1.01552617 -1.65121637  1.34847056 -1.65121637\n",
      "  1.41413625 -0.38746841 -0.38746841  1.41413625 -0.38746841 -0.38746841\n",
      " -0.38746841 -0.38746841]\n",
      "P is: [0.40432687758286917, 0.11601189887979212, 0.8044175195409352, 0.40432687758286917, 0.40432687758286917, 0.7341002364843386, 0.7938794707707755, 0.1609446217976615, 0.40432687758286917, 0.7341002364843386, 0.1609446217976615, 0.40432687758286917, 0.8044175195409352, 0.40432687758286917, 0.40432687758286917, 0.40432687758286917, 0.40432687758286917, 0.7341002364843386, 0.1609446217976615, 0.40432687758286917, 0.7341002364843386, 0.6064619038095833, 0.8044175195409352, 0.40432687758286917, 0.40432687758286917, 0.7341002364843386, 0.40432687758286917, 0.7938794707707755, 0.5375263736888455, 0.40432687758286917, 0.7341002364843386, 0.40432687758286917, 0.1609446217976615, 0.40432687758286917, 0.7341002364843386, 0.8044175195409352, 0.40432687758286917, 0.40432687758286917, 0.7341002364843386, 0.1609446217976615, 0.7938794707707755, 0.1609446217976615, 0.8044175195409352, 0.40432687758286917, 0.40432687758286917, 0.8044175195409352, 0.40432687758286917, 0.40432687758286917, 0.40432687758286917, 0.40432687758286917]\n",
      "all_sum before preprocessing is: [1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 1.7986569193246478, 1.7986569193246478, 1.7986569193246478, 1.9327555411996111, 1.9327555411996111, 1.7986569193246478, 2.020002697919499, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 2.3432485617585965, 1.7986569193246478, 2.020002697919499, 1.9327555411996111, 2.4029346594842993, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 1.7986569193246478, 1.9327555411996111, 1.8859040760445351, 1.9327555411996111, 1.9327555411996111, 2.020002697919499, 1.9327555411996111, 1.9327555411996111, 1.7986569193246478, 1.9327555411996111, 1.9327555411996111, 2.3432485617585965, 1.9327555411996111, 1.7986569193246478, 1.7986569193246478, 1.7986569193246478, 1.7986569193246478, 1.7986569193246478, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 2.020002697919499, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111, 1.9327555411996111]\n",
      "all_sum after preprocessing is: [ 2.50088185e-03  2.50088185e-03  2.50088185e-03 -1.05335777e+00\n",
      " -1.05335777e+00 -1.05335777e+00  2.50088185e-03  2.50088185e-03\n",
      " -1.05335777e+00  6.89462939e-01  2.50088185e-03  2.50088185e-03\n",
      "  2.50088185e-03  3.23461916e+00 -1.05335777e+00  6.89462939e-01\n",
      "  2.50088185e-03  3.70457240e+00  2.50088185e-03  2.50088185e-03\n",
      "  2.50088185e-03  2.50088185e-03  2.50088185e-03 -1.05335777e+00\n",
      "  2.50088185e-03 -3.66395711e-01  2.50088185e-03  2.50088185e-03\n",
      "  6.89462939e-01  2.50088185e-03  2.50088185e-03 -1.05335777e+00\n",
      "  2.50088185e-03  2.50088185e-03  3.23461916e+00  2.50088185e-03\n",
      " -1.05335777e+00 -1.05335777e+00 -1.05335777e+00 -1.05335777e+00\n",
      " -1.05335777e+00  2.50088185e-03  2.50088185e-03  2.50088185e-03\n",
      "  6.89462939e-01  2.50088185e-03  2.50088185e-03  2.50088185e-03\n",
      "  2.50088185e-03  2.50088185e-03]\n",
      "P is: [0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.2585808385547197, 0.2585808385547197, 0.2585808385547197, 0.5006252201373466, 0.5006252201373466, 0.2585808385547197, 0.6658474442199067, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.9621164735710955, 0.2585808385547197, 0.6658474442199067, 0.5006252201373466, 0.9759804015048164, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.2585808385547197, 0.5006252201373466, 0.4094122310089231, 0.5006252201373466, 0.5006252201373466, 0.6658474442199067, 0.5006252201373466, 0.5006252201373466, 0.2585808385547197, 0.5006252201373466, 0.5006252201373466, 0.9621164735710955, 0.5006252201373466, 0.2585808385547197, 0.2585808385547197, 0.2585808385547197, 0.2585808385547197, 0.2585808385547197, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.6658474442199067, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466, 0.5006252201373466]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.659\n",
      "(*) epoch 2, cost 2.423\n",
      "(*) epoch 3, cost 1.984\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.746\n",
      "(*) epoch 2, cost 2.714\n",
      "(*) epoch 3, cost 2.129\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 3.549933291928692, 2.631586748515092, 3.549933291928692, 2.631586748515092, 2.631586748515092, 3.549933291928692, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 2.631586748515092, 3.549933291928692]\n",
      "all_sum after preprocessing is: [-0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391\n",
      " -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391\n",
      " -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391\n",
      " -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391  3.39116499\n",
      " -0.29488391  3.39116499 -0.29488391 -0.29488391  3.39116499 -0.29488391\n",
      " -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391\n",
      " -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391\n",
      " -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391 -0.29488391\n",
      " -0.29488391  3.39116499]\n",
      "P is: [0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.9674272756044334, 0.426808627122289, 0.9674272756044334, 0.426808627122289, 0.426808627122289, 0.9674272756044334, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.426808627122289, 0.9674272756044334]\n",
      "all_sum before preprocessing is: [1.8705046916843318, 3.435945167426071, 3.4479969196190936, 3.435945167426071, 3.4479969196190936, 1.8705046916843318, 4.517444027196174, 3.4479969196190936, 3.435945167426071, 3.7671289865958957, 1.8705046916843318, 1.8705046916843318, 1.8705046916843318, 3.435945167426071, 2.9520035514544354, 1.882556443877354, 3.435945167426071, 3.435945167426071, 3.4479969196190936, 1.8705046916843318, 3.435945167426071, 1.8705046916843318, 1.8705046916843318, 3.8232609161541102, 3.435945167426071, 1.882556443877354, 1.8705046916843318, 1.8705046916843318, 2.9520035514544354, 3.435945167426071, 3.4479969196190936, 3.435945167426071, 1.8705046916843318, 3.435945167426071, 3.4479969196190936, 1.8705046916843318, 1.882556443877354, 3.435945167426071, 1.882556443877354, 3.4479969196190936, 1.882556443877354, 1.882556443877354, 1.8705046916843318, 1.8705046916843318, 3.435945167426071, 1.882556443877354, 3.435945167426071, 1.8705046916843318, 1.882556443877354, 1.8705046916843318]\n",
      "all_sum after preprocessing is: [-1.01646707  0.89081295  0.9054964   0.89081295  0.9054964  -1.01646707\n",
      "  2.20847478  0.9054964   0.89081295  1.29431617 -1.01646707 -1.01646707\n",
      " -1.01646707  0.89081295  0.30119476 -1.00178362  0.89081295  0.89081295\n",
      "  0.9054964  -1.01646707  0.89081295 -1.01646707 -1.01646707  1.36270543\n",
      "  0.89081295 -1.00178362 -1.01646707 -1.01646707  0.30119476  0.89081295\n",
      "  0.9054964   0.89081295 -1.01646707  0.89081295  0.9054964  -1.01646707\n",
      " -1.00178362  0.89081295 -1.00178362  0.9054964  -1.00178362 -1.00178362\n",
      " -1.01646707 -1.01646707  0.89081295 -1.00178362  0.89081295 -1.01646707\n",
      " -1.00178362 -1.01646707]\n",
      "P is: [0.26571614421051665, 0.7090579083233793, 0.712077703366557, 0.7090579083233793, 0.712077703366557, 0.26571614421051665, 0.9010079716431235, 0.712077703366557, 0.7090579083233793, 0.7848768504264356, 0.26571614421051665, 0.26571614421051665, 0.26571614421051665, 0.7090579083233793, 0.5747345607729331, 0.268590885552536, 0.7090579083233793, 0.7090579083233793, 0.712077703366557, 0.26571614421051665, 0.7090579083233793, 0.26571614421051665, 0.26571614421051665, 0.7961990489853741, 0.7090579083233793, 0.268590885552536, 0.26571614421051665, 0.26571614421051665, 0.5747345607729331, 0.7090579083233793, 0.712077703366557, 0.7090579083233793, 0.26571614421051665, 0.7090579083233793, 0.712077703366557, 0.26571614421051665, 0.268590885552536, 0.7090579083233793, 0.268590885552536, 0.712077703366557, 0.268590885552536, 0.268590885552536, 0.26571614421051665, 0.26571614421051665, 0.7090579083233793, 0.268590885552536, 0.7090579083233793, 0.26571614421051665, 0.268590885552536, 0.26571614421051665]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.825\n",
      "(*) epoch 2, cost 2.182\n",
      "(*) epoch 3, cost 1.268\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.305\n",
      "(*) epoch 2, cost 1.919\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 2.435011871306932, 2.435011871306932, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 2.383627663148111, 2.435011871306932, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 2.435011871306932, 2.435011871306932, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 2.435011871306932, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384, 1.5766666155981384]\n",
      "all_sum after preprocessing is: [-0.40336861 -0.40336861 -0.40336861 -0.40336861  2.50268847  2.50268847\n",
      " -0.40336861 -0.40336861 -0.40336861  2.32871949  2.50268847 -0.40336861\n",
      " -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861\n",
      " -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861\n",
      " -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861\n",
      " -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861\n",
      "  2.50268847  2.50268847 -0.40336861 -0.40336861 -0.40336861 -0.40336861\n",
      "  2.50268847 -0.40336861 -0.40336861 -0.40336861 -0.40336861 -0.40336861\n",
      " -0.40336861 -0.40336861]\n",
      "P is: [0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.9243300766476809, 0.9243300766476809, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.9112278089695942, 0.9243300766476809, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.9243300766476809, 0.9243300766476809, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.9243300766476809, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377, 0.40050326454100377]\n",
      "all_sum before preprocessing is: [2.534017655579033, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 1.290656095099032, 1.1473100062952972, 1.290656095099032, 1.1473100062952972, 1.1473100062952972, 1.3686181452691937, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 1.6395902080239346, 1.1473100062952972, 1.1473100062952972, 1.290656095099032, 1.1473100062952972, 1.290656095099032, 1.290656095099032, 1.290656095099032, 1.4985976164389734, 1.1473100062952972, 1.1473100062952972, 1.290656095099032, 0.5081827049874362, 1.1473100062952972, 0.36483661618370145, 1.1473100062952972, 0.36483661618370145, 0.5081827049874362, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972, 0.36483661618370145, 1.1473100062952972, 1.1473100062952972, 1.290656095099032, 2.7553257945529293, 1.1473100062952972, 1.1473100062952972, 0.5081827049874362, 1.1473100062952972, 1.1473100062952972, 1.1473100062952972]\n",
      "all_sum after preprocessing is: [ 3.39176192 -0.04669381 -0.04669381 -0.04669381 -0.04669381  0.30874461\n",
      " -0.04669381  0.30874461 -0.04669381 -0.04669381  0.50205793 -0.04669381\n",
      " -0.04669381 -0.04669381  1.17395546 -0.04669381 -0.04669381  0.30874461\n",
      " -0.04669381  0.30874461  0.30874461  0.30874461  0.82435273 -0.04669381\n",
      " -0.04669381  0.30874461 -1.63146255 -0.04669381 -1.98690097 -0.04669381\n",
      " -1.98690097 -1.63146255 -0.04669381 -0.04669381 -0.04669381 -0.04669381\n",
      " -0.04669381 -0.04669381 -0.04669381 -1.98690097 -0.04669381 -0.04669381\n",
      "  0.30874461  3.94051367 -0.04669381 -0.04669381 -1.63146255 -0.04669381\n",
      " -0.04669381 -0.04669381]\n",
      "P is: [0.9674460806935768, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.5765788062590111, 0.48832866831162136, 0.5765788062590111, 0.48832866831162136, 0.48832866831162136, 0.6229428312327555, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.7638592397581314, 0.48832866831162136, 0.48832866831162136, 0.5765788062590111, 0.48832866831162136, 0.5765788062590111, 0.5765788062590111, 0.5765788062590111, 0.6951595216296671, 0.48832866831162136, 0.48832866831162136, 0.5765788062590111, 0.16363010537121253, 0.48832866831162136, 0.12058511074059118, 0.48832866831162136, 0.12058511074059118, 0.16363010537121253, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136, 0.12058511074059118, 0.48832866831162136, 0.48832866831162136, 0.5765788062590111, 0.9809324126577103, 0.48832866831162136, 0.48832866831162136, 0.16363010537121253, 0.48832866831162136, 0.48832866831162136, 0.48832866831162136]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.054\n",
      "(*) epoch 2, cost 0.638\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.145\n",
      "(*) epoch 2, cost 3.276\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7759710406373521, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521, 1.8201202014259237, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.8201202014259237, 1.7759710406373521, 1.8201202014259237, 1.8201202014259237, 1.7759710406373521, 1.7759710406373521, 1.7759710406373521]\n",
      "all_sum after preprocessing is: [-1.08347268  0.92295821  0.92295821  0.92295821 -1.08347268  0.92295821\n",
      " -1.08347268 -1.08347268 -1.08347268 -1.08347268  0.92295821  0.92295821\n",
      " -1.08347268  0.92295821  0.92295821 -1.08347268  0.92295821  0.92295821\n",
      " -1.08347268  0.92295821 -1.08347268  0.92295821 -1.08347268  0.92295821\n",
      "  0.92295821 -1.08347268  0.92295821 -1.08347268 -1.08347268 -1.08347268\n",
      " -1.08347268 -1.08347268 -1.08347268 -1.08347268  0.92295821  0.92295821\n",
      "  0.92295821  0.92295821  0.92295821  0.92295821  0.92295821  0.92295821\n",
      "  0.92295821  0.92295821 -1.08347268  0.92295821  0.92295821 -1.08347268\n",
      " -1.08347268 -1.08347268]\n",
      "P is: [0.2528494073473347, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347, 0.7156444771343634, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.7156444771343634, 0.2528494073473347, 0.7156444771343634, 0.7156444771343634, 0.2528494073473347, 0.2528494073473347, 0.2528494073473347]\n",
      "all_sum before preprocessing is: [0.8152241067317192, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 0.8152241067317192, 1.3134415437799445, 0.8152241067317192, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.8259582062654114, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445, 1.8259582062654114, 1.8259582062654114, 1.3134415437799445, 1.8259582062654114, 1.3134415437799445, 1.3134415437799445, 1.3134415437799445]\n",
      "all_sum after preprocessing is: [-2.69248277 -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248\n",
      " -0.05872248 -2.69248277 -0.05872248 -2.69248277 -0.05872248 -0.05872248\n",
      " -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248\n",
      " -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248\n",
      " -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248\n",
      "  2.65062876 -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248\n",
      " -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248 -0.05872248\n",
      " -0.05872248  2.65062876  2.65062876 -0.05872248  2.65062876 -0.05872248\n",
      " -0.05872248 -0.05872248]\n",
      "P is: [0.06341839039337624, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.06341839039337624, 0.48532359661819946, 0.06341839039337624, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.9340497334436432, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946, 0.9340497334436432, 0.9340497334436432, 0.48532359661819946, 0.9340497334436432, 0.48532359661819946, 0.48532359661819946, 0.48532359661819946]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.511\n",
      "(*) epoch 2, cost 1.174\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.389\n",
      "(*) epoch 2, cost 2.025\n",
      "(*) epoch 3, cost 1.449\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.417852680045291, 3.450015703862803, 4.736936735689301, 2.3815523806968057, 2.822804378150355, 3.8591046774988405, 4.209212480383319, 3.450015703862803, 3.8591046774988405, 4.295684738235751, 2.3815523806968057, 2.6632536938912352, 3.5820011546708717, 3.614164178488384, 2.3815523806968057, 3.614164178488384, 3.8912677013163526, 2.822804378150355, 3.417852680045291, 3.1729121810348344, 3.1729121810348344, 2.3815523806968057, 3.614164178488384, 5.014040258517269, 2.6586559035247745, 2.822804378150355, 2.822804378150355, 3.18675646444808, 2.3815523806968057, 3.614164178488384, 2.822804378150355, 3.099907900978324, 2.3815523806968057, 2.822804378150355, 3.450015703862803, 5.528296536027329, 2.3815523806968057, 3.099907900978324, 2.3815523806968057, 2.6586559035247745, 2.3815523806968057, 3.450015703862803, 3.614164178488384, 2.822804378150355, 3.099907900978324, 3.1729121810348344, 5.364148061401749, 2.822804378150355, 3.5820011546708717, 4.736936735689301]\n",
      "all_sum after preprocessing is: [ 0.14107481  0.18213628  1.82510593 -1.18193562 -0.61860374  0.70440668\n",
      "  1.15137777  0.18213628  0.70440668  1.26177405 -1.18193562 -0.82229684\n",
      "  0.35063775  0.39169922 -1.18193562  0.39169922  0.74546815 -0.61860374\n",
      "  0.14107481 -0.17163265 -0.17163265 -1.18193562  0.39169922  2.17887486\n",
      " -0.82816669 -0.61860374 -0.61860374 -0.15395811 -1.18193562  0.39169922\n",
      " -0.61860374 -0.26483481 -1.18193562 -0.61860374  0.18213628  2.83540889\n",
      " -1.18193562 -0.26483481 -1.18193562 -0.82816669 -1.18193562  0.18213628\n",
      "  0.39169922 -0.61860374 -0.26483481 -0.17163265  2.62584594 -0.61860374\n",
      "  0.35063775  1.82510593]\n",
      "P is: [0.53521032405565, 0.5454086079931136, 0.861177670401007, 0.23470434557121633, 0.3500990751917453, 0.6691640649548107, 0.759762482127244, 0.5454086079931136, 0.6691640649548107, 0.7793313493535142, 0.23470434557121633, 0.3052763222908592, 0.586772223181186, 0.596691685488981, 0.23470434557121633, 0.596691685488981, 0.6781904316505092, 0.3500990751917453, 0.53521032405565, 0.4571968588194302, 0.4571968588194302, 0.23470434557121633, 0.596691685488981, 0.8983363608569841, 0.3040328541290466, 0.3500990751917453, 0.3500990751917453, 0.461586318647151, 0.23470434557121633, 0.596691685488981, 0.3500990751917453, 0.4341755782412715, 0.23470434557121633, 0.3500990751917453, 0.5454086079931136, 0.9445595304636847, 0.23470434557121633, 0.4341755782412715, 0.23470434557121633, 0.3040328541290466, 0.23470434557121633, 0.5454086079931136, 0.596691685488981, 0.3500990751917453, 0.4341755782412715, 0.4571968588194302, 0.9325065704387865, 0.3500990751917453, 0.586772223181186, 0.861177670401007]\n",
      "all_sum before preprocessing is: [1.8149050862387441, 1.8149050862387441, 1.9591766097315944, 2.031601751487078, 2.023170079132184, 2.9580739546976305, 2.023170079132184, 1.9591766097315944, 2.659688079726299, 2.9580739546976305, 2.8138024312047802, 2.894080485297041, 1.967608282086489, 2.023170079132184, 2.7498089618041908, 2.894080485297041, 2.894080485297041, 2.9580739546976305, 2.9580739546976305, 1.8788985556393334, 2.023170079132184, 2.9580739546976305, 2.7498089618041908, 2.9580739546976305, 2.8138024312047802, 2.9580739546976305, 2.894080485297041, 2.7498089618041908, 1.9591766097315944, 2.894080485297041, 2.031601751487078, 2.894080485297041, 2.894080485297041, 1.9591766097315944, 2.9580739546976305, 2.8138024312047802, 2.9580739546976305, 2.023170079132184, 2.9580739546976305, 2.9580739546976305, 2.894080485297041, 1.096697875921632, 2.894080485297041, 2.894080485297041, 2.894080485297041, 2.8138024312047802, 2.894080485297041, 2.894080485297041, 2.894080485297041, 2.894080485297041]\n",
      "all_sum after preprocessing is: [-1.59741249 -1.59741249 -1.29383756 -1.14144118 -1.15918303  0.80803387\n",
      " -1.15918303 -1.29383756  0.18017281  0.80803387  0.50445894  0.67337934\n",
      " -1.2760957  -1.15918303  0.36980441  0.67337934  0.67337934  0.80803387\n",
      "  0.80803387 -1.46275797 -1.15918303  0.80803387  0.36980441  0.80803387\n",
      "  0.50445894  0.80803387  0.67337934  0.36980441 -1.29383756  0.67337934\n",
      " -1.14144118  0.67337934  0.67337934 -1.29383756  0.80803387  0.50445894\n",
      "  0.80803387 -1.15918303  0.80803387  0.80803387  0.67337934 -3.10865808\n",
      "  0.67337934  0.67337934  0.67337934  0.50445894  0.67337934  0.67337934\n",
      "  0.67337934  0.67337934]\n",
      "P is: [0.168343566207679, 0.168343566207679, 0.21520397287915222, 0.24205585686245087, 0.23881576374867414, 0.6916903749352117, 0.23881576374867414, 0.21520397287915222, 0.5449217461138178, 0.6916903749352117, 0.6235066239879407, 0.6622594374174413, 0.21821555430217612, 0.23881576374867414, 0.5914117169669353, 0.6622594374174413, 0.6622594374174413, 0.6916903749352117, 0.6916903749352117, 0.18804586401101303, 0.23881576374867414, 0.6916903749352117, 0.5914117169669353, 0.6916903749352117, 0.6235066239879407, 0.6916903749352117, 0.6622594374174413, 0.5914117169669353, 0.21520397287915222, 0.6622594374174413, 0.24205585686245087, 0.6622594374174413, 0.6622594374174413, 0.21520397287915222, 0.6916903749352117, 0.6235066239879407, 0.6916903749352117, 0.23881576374867414, 0.6916903749352117, 0.6916903749352117, 0.6622594374174413, 0.04275152701335478, 0.6622594374174413, 0.6622594374174413, 0.6622594374174413, 0.6235066239879407, 0.6622594374174413, 0.6622594374174413, 0.6622594374174413, 0.6622594374174413]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.645\n",
      "(*) epoch 2, cost 3.157\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.18 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.554\n",
      "(*) epoch 2, cost 3.674\n",
      "(*) epoch 3, cost 2.756\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.864031551802875, 6.013051312434698, 6.864031551802875, 6.013051312434698, 6.07762290608119, 6.07762290608119, 6.07762290608119, 6.864031551802875, 6.864031551802875, 6.013051312434698, 6.07762290608119, 6.07762290608119, 6.864031551802875, 6.07762290608119, 6.07762290608119, 6.864031551802875, 6.799459958156382, 6.864031551802875, 6.07762290608119, 6.07762290608119, 6.013051312434698, 6.864031551802875, 6.864031551802875, 6.013051312434698, 6.07762290608119, 6.07762290608119, 6.864031551802875, 6.07762290608119, 6.07762290608119, 6.864031551802875, 6.07762290608119, 6.07762290608119, 6.113516590412677, 6.07762290608119, 6.799459958156382, 6.864031551802875, 6.864031551802875, 6.864031551802875, 6.07762290608119, 6.07762290608119, 6.864031551802875, 6.07762290608119, 6.864031551802875, 6.07762290608119, 7.2272376798989155, 6.07762290608119, 6.013051312434698, 6.013051312434698, 6.799459958156382, 6.013051312434698]\n",
      "all_sum after preprocessing is: [ 1.1906599  -0.92875837  1.1906599  -0.92875837 -0.76793887 -0.76793887\n",
      " -0.76793887  1.1906599   1.1906599  -0.92875837 -0.76793887 -0.76793887\n",
      "  1.1906599  -0.76793887 -0.76793887  1.1906599   1.02984041  1.1906599\n",
      " -0.76793887 -0.76793887 -0.92875837  1.1906599   1.1906599  -0.92875837\n",
      " -0.76793887 -0.76793887  1.1906599  -0.76793887 -0.76793887  1.1906599\n",
      " -0.76793887 -0.76793887 -0.67854346 -0.76793887  1.02984041  1.1906599\n",
      "  1.1906599   1.1906599  -0.76793887 -0.76793887  1.1906599  -0.76793887\n",
      "  1.1906599  -0.76793887  2.09524695 -0.76793887 -0.92875837 -0.92875837\n",
      "  1.02984041 -0.92875837]\n",
      "P is: [0.7668590668143743, 0.2831766827164305, 0.7668590668143743, 0.2831766827164305, 0.3169251388831689, 0.3169251388831689, 0.3169251388831689, 0.7668590668143743, 0.7668590668143743, 0.2831766827164305, 0.3169251388831689, 0.3169251388831689, 0.7668590668143743, 0.3169251388831689, 0.3169251388831689, 0.7668590668143743, 0.7368849539827643, 0.7668590668143743, 0.3169251388831689, 0.3169251388831689, 0.2831766827164305, 0.7668590668143743, 0.7668590668143743, 0.2831766827164305, 0.3169251388831689, 0.3169251388831689, 0.7668590668143743, 0.3169251388831689, 0.3169251388831689, 0.7668590668143743, 0.3169251388831689, 0.3169251388831689, 0.33658646577307255, 0.3169251388831689, 0.7368849539827643, 0.7668590668143743, 0.7668590668143743, 0.7668590668143743, 0.3169251388831689, 0.3169251388831689, 0.7668590668143743, 0.3169251388831689, 0.7668590668143743, 0.3169251388831689, 0.8904403488693999, 0.3169251388831689, 0.2831766827164305, 0.2831766827164305, 0.7368849539827643, 0.2831766827164305]\n",
      "all_sum before preprocessing is: [1.847670803529276, 3.320527788982883, 3.265207453707666, 2.6340762853240554, 3.320527788982883, 0.7066927641530071, 0.7066927641530071, 3.951658957366493, 1.847670803529276, 1.847670803529276, 1.847670803529276, 0.7066927641530071, 3.320527788982883, 2.5341223071881034, 0.7066927641530071, 2.179549749606614, 2.5341223071881034, 2.6340762853240554, 1.847670803529276, 0.7066927641530071, 3.951658957366493, 1.4930982459477866, 2.6340762853240554, 3.320527788982883, 1.847670803529276, 1.3931442678118344, 1.3931442678118344, 1.4930982459477866, 2.6340762853240554, 2.5341223071881034, 1.4930982459477866, 1.4930982459477866, 1.4930982459477866, 2.6340762853240554, 1.847670803529276, 0.7066927641530071, 2.6340762853240554, 2.4788019719128864, 2.179549749606614, 2.179549749606614, 1.3931442678118344, 1.4930982459477866, 1.847670803529276, 1.4930982459477866, 0.7066927641530071, 0.7066927641530071, 0.7066927641530071, 1.847670803529276, 2.5341223071881034, 2.5341223071881034]\n",
      "all_sum after preprocessing is: [-0.16360326  1.51441824  1.45139195  0.73234612  1.51441824 -1.46351608\n",
      " -1.46351608  2.23346407 -0.16360326 -0.16360326 -0.16360326 -1.46351608\n",
      "  1.51441824  0.61846886 -1.46351608  0.21450542  0.61846886  0.73234612\n",
      " -0.16360326 -1.46351608  2.23346407 -0.5675667   0.73234612  1.51441824\n",
      " -0.16360326 -0.68144397 -0.68144397 -0.5675667   0.73234612  0.61846886\n",
      " -0.5675667  -0.5675667  -0.5675667   0.73234612 -0.16360326 -1.46351608\n",
      "  0.73234612  0.55544257  0.21450542  0.21450542 -0.68144397 -0.5675667\n",
      " -0.16360326 -0.5675667  -1.46351608 -1.46351608 -1.46351608 -0.16360326\n",
      "  0.61846886  0.61846886]\n",
      "P is: [0.4591901707369376, 0.8197150672644241, 0.8102125642454614, 0.6753199018437255, 0.8197150672644241, 0.18793013820077173, 0.18793013820077173, 0.9032146043228506, 0.4591901707369376, 0.4591901707369376, 0.4591901707369376, 0.18793013820077173, 0.8197150672644241, 0.6498702343014228, 0.18793013820077173, 0.5534216722689004, 0.6498702343014228, 0.6753199018437255, 0.4591901707369376, 0.18793013820077173, 0.9032146043228506, 0.3617984852039219, 0.6753199018437255, 0.8197150672644241, 0.4591901707369376, 0.33593910062465415, 0.33593910062465415, 0.3617984852039219, 0.6753199018437255, 0.6498702343014228, 0.3617984852039219, 0.3617984852039219, 0.3617984852039219, 0.6753199018437255, 0.4591901707369376, 0.18793013820077173, 0.6753199018437255, 0.6353973841313371, 0.5534216722689004, 0.5534216722689004, 0.33593910062465415, 0.3617984852039219, 0.4591901707369376, 0.3617984852039219, 0.18793013820077173, 0.18793013820077173, 0.18793013820077173, 0.4591901707369376, 0.6498702343014228, 0.6498702343014228]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.796\n",
      "(*) epoch 2, cost 2.401\n",
      "(*) epoch 3, cost 1.867\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.624\n",
      "(*) epoch 2, cost 2.343\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 1.9428372624039376, 0.22900177554962745, 1.9428372624039376, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 2.138809927363176, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 0.22900177554962745, 2.138809927363176]\n",
      "all_sum after preprocessing is: [-0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629\n",
      " -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629\n",
      " -0.29441629 -0.29441629 -0.29441629  3.18675576 -0.29441629  3.18675576\n",
      " -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629\n",
      " -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629\n",
      " -0.29441629 -0.29441629 -0.29441629 -0.29441629  3.5848188  -0.29441629\n",
      " -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629\n",
      " -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629 -0.29441629\n",
      " -0.29441629  3.5848188 ]\n",
      "P is: [0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.9603328199407685, 0.4269230326398353, 0.9603328199407685, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.9730071339869718, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.4269230326398353, 0.9730071339869718]\n",
      "all_sum before preprocessing is: [1.191252946415228, 2.335493244178111, 1.191252946415228, 3.2759070854734955, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 3.2759070854734955, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 3.2759070854734955, 1.191252946415228, 1.191252946415228, 2.335493244178111, 3.2759070854734955, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 3.2759070854734955, 1.191252946415228, 1.191252946415228, 1.191252946415228, 3.2759070854734955, 1.191252946415228, 3.2759070854734955, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228, 1.191252946415228]\n",
      "all_sum after preprocessing is: [-0.45658142  1.09082993 -0.45658142  2.36259693 -0.45658142 -0.45658142\n",
      " -0.45658142 -0.45658142 -0.45658142 -0.45658142  2.36259693 -0.45658142\n",
      " -0.45658142 -0.45658142 -0.45658142 -0.45658142 -0.45658142 -0.45658142\n",
      " -0.45658142 -0.45658142 -0.45658142 -0.45658142 -0.45658142  2.36259693\n",
      " -0.45658142 -0.45658142  1.09082993  2.36259693 -0.45658142 -0.45658142\n",
      " -0.45658142 -0.45658142 -0.45658142 -0.45658142 -0.45658142 -0.45658142\n",
      " -0.45658142 -0.45658142  2.36259693 -0.45658142 -0.45658142 -0.45658142\n",
      "  2.36259693 -0.45658142  2.36259693 -0.45658142 -0.45658142 -0.45658142\n",
      " -0.45658142 -0.45658142]\n",
      "P is: [0.38779711796303035, 0.7485379700491025, 0.38779711796303035, 0.9139303039867878, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.9139303039867878, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.9139303039867878, 0.38779711796303035, 0.38779711796303035, 0.7485379700491025, 0.9139303039867878, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.9139303039867878, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.9139303039867878, 0.38779711796303035, 0.9139303039867878, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035, 0.38779711796303035]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.199\n",
      "(*) epoch 2, cost 1.874\n",
      "(*) epoch 3, cost 0.984\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.383\n",
      "(*) epoch 2, cost 1.176\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.3109226162209895, 2.3109226162209895, 3.3352618911447323, 3.3352618911447323, 0.6306577132719685, 2.3109226162209895, 2.3109226162209895, 0.6306577132719685, 2.3109226162209895, 2.3109226162209895, 1.6549969881957112, 1.6549969881957112, 0.6306577132719685, 2.3109226162209895, 0.6306577132719685, 0.6306577132719685, 2.3109226162209895, 0.6306577132719685, 3.3352618911447323, 1.6549969881957112, 0.6306577132719685, 2.3109226162209895, 0.6306577132719685, 2.3109226162209895, 2.3109226162209895, 2.3109226162209895, 0.6306577132719685, 2.3109226162209895, 1.6549969881957112, 2.3109226162209895, 3.3352618911447323, 4.238789122786953, 0.6306577132719685, 3.3352618911447323, 2.3109226162209895, 2.3109226162209895, 2.3109226162209895, 2.3109226162209895, 0.6306577132719685, 2.3109226162209895, 1.6549969881957112, 2.3109226162209895, 1.6549969881957112, 0.6306577132719685, 2.3109226162209895, 2.3109226162209895, 1.6549969881957112, 0.6306577132719685, 0.6306577132719685, 2.3109226162209895]\n",
      "all_sum after preprocessing is: [ 0.45630411  0.45630411  1.56571867  1.56571867 -1.3635132   0.45630411\n",
      "  0.45630411 -1.3635132   0.45630411  0.45630411 -0.25409864 -0.25409864\n",
      " -1.3635132   0.45630411 -1.3635132  -1.3635132   0.45630411 -1.3635132\n",
      "  1.56571867 -0.25409864 -1.3635132   0.45630411 -1.3635132   0.45630411\n",
      "  0.45630411  0.45630411 -1.3635132   0.45630411 -0.25409864  0.45630411\n",
      "  1.56571867  2.54428729 -1.3635132   1.56571867  0.45630411  0.45630411\n",
      "  0.45630411  0.45630411 -1.3635132   0.45630411 -0.25409864  0.45630411\n",
      " -0.25409864 -1.3635132   0.45630411  0.45630411 -0.25409864 -1.3635132\n",
      " -1.3635132   0.45630411]\n",
      "P is: [0.6121370437156555, 0.6121370437156555, 0.8271724142718437, 0.8271724142718437, 0.20366990881973046, 0.6121370437156555, 0.6121370437156555, 0.20366990881973046, 0.6121370437156555, 0.6121370437156555, 0.43681494262594617, 0.43681494262594617, 0.20366990881973046, 0.6121370437156555, 0.20366990881973046, 0.20366990881973046, 0.6121370437156555, 0.20366990881973046, 0.8271724142718437, 0.43681494262594617, 0.20366990881973046, 0.6121370437156555, 0.20366990881973046, 0.6121370437156555, 0.6121370437156555, 0.6121370437156555, 0.20366990881973046, 0.6121370437156555, 0.43681494262594617, 0.6121370437156555, 0.8271724142718437, 0.9271887907281766, 0.20366990881973046, 0.8271724142718437, 0.6121370437156555, 0.6121370437156555, 0.6121370437156555, 0.6121370437156555, 0.20366990881973046, 0.6121370437156555, 0.43681494262594617, 0.6121370437156555, 0.43681494262594617, 0.20366990881973046, 0.6121370437156555, 0.6121370437156555, 0.43681494262594617, 0.20366990881973046, 0.20366990881973046, 0.6121370437156555]\n",
      "all_sum before preprocessing is: [5.201309215421875, 2.1600513349263024, 2.532269291308955, 3.7872620826579695, 1.636169740280868, 2.1600513349263024, 1.636169740280868, 3.7933045476061893, 5.201309215421875, 3.4344113072852624, 3.913624527001189, 3.9329917080111345, 3.8066292636679155, 5.187984499360149, 5.560202455742803, 2.1600513349263024, 1.636169740280868, 4.8097240780292765, 2.6586317356521745, 5.0616220550169295, 2.1600513349263024, 3.926949243062915, 3.7933045476061893, 1.636169740280868, 6.0840840503882365, 4.165522503988843, 2.532269291308955, 3.8066292636679155, 2.532269291308955, 2.910529712639828, 3.4344113072852624, 3.926949243062915, 2.532269291308955, 1.636169740280868, 5.0616220550169295, 5.201309215421875, 1.636169740280868, 1.636169740280868, 3.4344113072852624, 3.4344113072852624, 4.305209664393788, 3.4344113072852624, 5.0616220550169295, 4.829091259039222, 1.636169740280868, 3.9329917080111345, 2.891162531629882, 3.7933045476061893, 5.0616220550169295, 2.538311756257175]\n",
      "all_sum after preprocessing is: [ 1.37937842 -1.03628883 -0.74063659  0.25620258 -1.45240732 -1.03628883\n",
      " -1.45240732  0.26100211  1.37937842 -0.02406634  0.35657211  0.37195544\n",
      "  0.27158591  1.36879461  1.66444686 -1.03628883 -1.45240732  1.06834284\n",
      " -0.64026706  1.26842508 -1.03628883  0.36715592  0.26100211 -1.45240732\n",
      "  2.08056534  0.55665435 -0.74063659  0.27158591 -0.74063659 -0.44018482\n",
      " -0.02406634  0.36715592 -0.74063659 -1.45240732  1.26842508  1.37937842\n",
      " -1.45240732 -1.45240732 -0.02406634 -0.02406634  0.66760769 -0.02406634\n",
      "  1.26842508  1.08372617 -1.45240732  0.37195544 -0.45556814  0.26100211\n",
      "  1.26842508 -0.73583706]\n",
      "P is: [0.7988911524679444, 0.2618667002943142, 0.3228649553749389, 0.563702574773904, 0.18963135422289798, 0.2618667002943142, 0.18963135422289798, 0.5648826157205887, 0.7988911524679444, 0.4939837063326984, 0.5882103865288575, 0.5919313968559982, 0.5674822023286782, 0.7971853349244789, 0.8408340380055508, 0.2618667002943142, 0.18963135422289798, 0.7442816422606277, 0.3451861728415663, 0.7804730287579971, 0.2618667002943142, 0.5907715693821277, 0.5648826157205887, 0.18963135422289798, 0.8889998327272345, 0.6356780693905745, 0.3228649553749389, 0.5674822023286782, 0.3228649553749389, 0.39169693179484993, 0.4939837063326984, 0.5907715693821277, 0.3228649553749389, 0.18963135422289798, 0.7804730287579971, 0.7988911524679444, 0.18963135422289798, 0.18963135422289798, 0.4939837063326984, 0.4939837063326984, 0.6609672734061971, 0.4939837063326984, 0.7804730287579971, 0.7471984781586513, 0.18963135422289798, 0.5919313968559982, 0.3880377082390838, 0.5648826157205887, 0.7804730287579971, 0.32391513296602764]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.103\n",
      "(*) epoch 2, cost 2.579\n",
      "(*) epoch 3, cost 1.498\n",
      "(*) epoch 4, cost 1.185\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.255\n",
      "(*) epoch 2, cost 2.754\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.8917299083302916, 2.063362941980246, 2.063362941980246, 2.5402695056160276, 2.063362941980246, 2.063362941980246, 4.881001800306361, 2.5107522041916472, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.5402695056160276, 2.063362941980246, 2.698906691276428, 2.063362941980246, 2.063362941980246, 2.5107522041916472, 2.063362941980246, 2.063362941980246, 2.063362941980246, 0.9221077560981618, 2.063362941980246, 2.698906691276428, 0.9221077560981618, 2.5107522041916472, 1.3694970183095632, 2.063362941980246, 2.5402695056160276, 2.5402695056160276, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.5402695056160276, 0.9221077560981618, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 2.063362941980246, 0.9221077560981618, 2.063362941980246, 2.25618615903411, 1.5576515053943438]\n",
      "all_sum after preprocessing is: [ 1.31657519 -0.10547409 -0.10547409  0.71322664 -0.10547409 -0.10547409\n",
      "  4.73153832  0.66255458 -0.10547409 -0.10547409 -0.10547409 -0.10547409\n",
      "  0.71322664 -0.10547409  0.9855575  -0.10547409 -0.10547409  0.66255458\n",
      " -0.10547409 -0.10547409 -0.10547409 -2.06465543 -0.10547409  0.9855575\n",
      " -2.06465543  0.66255458 -1.29662677 -0.10547409  0.71322664  0.71322664\n",
      " -0.10547409 -0.10547409 -0.10547409 -0.10547409 -0.10547409 -0.10547409\n",
      " -0.10547409 -0.10547409 -0.10547409  0.71322664 -2.06465543 -0.10547409\n",
      " -0.10547409 -0.10547409 -0.10547409 -0.10547409 -2.06465543 -0.10547409\n",
      "  0.2255436  -0.97362384]\n",
      "P is: [0.7886113428390547, 0.4736558965640018, 0.4736558965640018, 0.6711137358233259, 0.4736558965640018, 0.4736558965640018, 0.9912640852613595, 0.6598340056010281, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.6711137358233259, 0.4736558965640018, 0.7282095535322506, 0.4736558965640018, 0.4736558965640018, 0.6598340056010281, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.11257988629900716, 0.4736558965640018, 0.7282095535322506, 0.11257988629900716, 0.6598340056010281, 0.21473327364361164, 0.4736558965640018, 0.6711137358233259, 0.6711137358233259, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.6711137358233259, 0.11257988629900716, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.4736558965640018, 0.11257988629900716, 0.4736558965640018, 0.5561480806735987, 0.27415878260469606]\n",
      "all_sum before preprocessing is: [2.4607517488038804, 2.5153901406452883, 2.4607517488038804, 3.122550513942118, 3.069530391609728, 3.122550513942118, 3.124168783451136, 3.069530391609728, 3.731329156747966, 3.731329156747966, 3.122550513942118, 3.122550513942118, 2.4607517488038804, 3.122550513942118, 3.069530391609728, 3.069530391609728, 2.4607517488038804, 2.4607517488038804, 4.044812313408552, 3.069530391609728, 3.122550513942118, 2.5153901406452883, 2.5153901406452883, 2.4607517488038804, 3.122550513942118, 3.731329156747966, 3.1771889057835265, 2.5153901406452883, 3.069530391609728, 3.122550513942118, 3.122550513942118, 3.991792191076162, 4.7082293480558075, 2.4607517488038804, 3.069530391609728, 3.069530391609728, 2.4607517488038804, 3.122550513942118, 3.383013548270314, 3.069530391609728, 2.4607517488038804, 3.122550513942118, 2.4607517488038804, 3.122550513942118, 2.4607517488038804, 3.7859675485893742, 3.069530391609728, 2.4607517488038804, 3.122550513942118, 3.122550513942118]\n",
      "all_sum after preprocessing is: [-1.15559941 -1.04433214 -1.15559941  0.19210758  0.0841358   0.19210758\n",
      "  0.19540307  0.0841358   1.43184279  1.43184279  0.19210758  0.19210758\n",
      " -1.15559941  0.19210758  0.0841358   0.0841358  -1.15559941 -1.15559941\n",
      "  2.07022935  0.0841358   0.19210758 -1.04433214 -1.04433214 -1.15559941\n",
      "  0.19210758  1.43184279  0.30337485 -1.04433214  0.0841358   0.19210758\n",
      "  0.19210758  1.96225757  3.42123183 -1.15559941  0.0841358   0.0841358\n",
      " -1.15559941  0.19210758  0.72252236  0.0841358  -1.15559941  0.19210758\n",
      " -1.15559941  0.19210758 -1.15559941  1.54311006  0.0841358  -1.15559941\n",
      "  0.19210758  0.19210758]\n",
      "P is: [0.23946781447572738, 0.2603149699118505, 0.23946781447572738, 0.5478797331088887, 0.5210215503312171, 0.5478797331088887, 0.5486959219932893, 0.5210215503312171, 0.8071882806522932, 0.8071882806522932, 0.5478797331088887, 0.5478797331088887, 0.23946781447572738, 0.5478797331088887, 0.5210215503312171, 0.5210215503312171, 0.23946781447572738, 0.23946781447572738, 0.887975778044489, 0.5210215503312171, 0.5478797331088887, 0.2603149699118505, 0.2603149699118505, 0.23946781447572738, 0.5478797331088887, 0.8071882806522932, 0.5752673181963404, 0.2603149699118505, 0.5210215503312171, 0.5478797331088887, 0.5478797331088887, 0.8767770659267401, 0.9683615335649896, 0.23946781447572738, 0.5210215503312171, 0.5210215503312171, 0.23946781447572738, 0.5478797331088887, 0.6731622166546906, 0.5210215503312171, 0.23946781447572738, 0.5478797331088887, 0.23946781447572738, 0.5478797331088887, 0.23946781447572738, 0.8239163811012721, 0.5210215503312171, 0.23946781447572738, 0.5478797331088887, 0.5478797331088887]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.808\n",
      "(*) epoch 2, cost 3.206\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.467\n",
      "(*) epoch 2, cost 2.572\n",
      "(*) epoch 3, cost 1.955\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.6529520743885446, 3.6529520743885446, 4.913484072901665, 4.810371199682805, 3.6529520743885446, 3.6529520743885446, 4.913484072901665, 4.913484072901665, 3.6529520743885446, 4.913484072901665, 4.913484072901665, 4.913484072901665, 3.6529520743885446, 5.2940926952871985, 4.913484072901665, 3.0155617186023154, 3.6529520743885446, 6.526140792928532, 4.913484072901665, 3.6529520743885446, 6.070903198195926, 4.913484072901665, 4.260076591852835, 4.913484072901665, 1.755029720089195, 3.6529520743885446, 4.913484072901665, 4.913484072901665, 4.913484072901665, 4.913484072901665, 3.6529520743885446, 3.9678469892711123, 4.913484072901665, 4.913484072901665, 3.0155617186023154, 4.913484072901665, 4.913484072901665, 6.070903198195926, 5.520608590365955, 6.070903198195926, 4.913484072901665, 2.1356383424747287, 3.6529520743885446, 4.913484072901665, 4.913484072901665, 4.810371199682805, 3.6529520743885446, 6.459851174084546, 4.913484072901665, 4.913484072901665]\n",
      "all_sum after preprocessing is: [-0.90176325 -0.90176325  0.39047699  0.28477035 -0.90176325 -0.90176325\n",
      "  0.39047699  0.39047699 -0.90176325  0.39047699  0.39047699  0.39047699\n",
      " -0.90176325  0.78065969  0.39047699 -1.55518693 -0.90176325  2.04369953\n",
      "  0.39047699 -0.90176325  1.57701059  0.39047699 -0.27936672  0.39047699\n",
      " -2.84742717 -0.90176325  0.39047699  0.39047699  0.39047699  0.39047699\n",
      " -0.90176325 -0.57894726  0.39047699  0.39047699 -1.55518693  0.39047699\n",
      "  0.39047699  1.57701059  1.01287351  1.57701059  0.39047699 -2.45724447\n",
      " -0.90176325  0.39047699  0.39047699  0.28477035 -0.90176325  1.97574242\n",
      "  0.39047699  0.39047699]\n",
      "P is: [0.28868828448092526, 0.28868828448092526, 0.5963975203088023, 0.5707153490297098, 0.28868828448092526, 0.28868828448092526, 0.5963975203088023, 0.5963975203088023, 0.28868828448092526, 0.5963975203088023, 0.5963975203088023, 0.5963975203088023, 0.28868828448092526, 0.685822275175886, 0.5963975203088023, 0.17433837593440268, 0.28868828448092526, 0.8853094413228629, 0.5963975203088023, 0.28868828448092526, 0.8287807279630354, 0.5963975203088023, 0.4306090387973798, 0.5963975203088023, 0.054814462399621726, 0.28868828448092526, 0.5963975203088023, 0.5963975203088023, 0.5963975203088023, 0.5963975203088023, 0.28868828448092526, 0.35917486498030854, 0.5963975203088023, 0.5963975203088023, 0.17433837593440268, 0.5963975203088023, 0.5963975203088023, 0.8287807279630354, 0.7335821240182053, 0.8287807279630354, 0.5963975203088023, 0.07891038631089939, 0.28868828448092526, 0.5963975203088023, 0.5963975203088023, 0.5707153490297098, 0.28868828448092526, 0.8782265690171634, 0.5963975203088023, 0.5963975203088023]\n",
      "all_sum before preprocessing is: [0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.889536832832452, 0.889536832832452, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.889536832832452, 0.889536832832452, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.889536832832452, 1.0293110823803786, 0.43180071831103467, 0.889536832832452, 0.43180071831103467, 0.43180071831103467, 0.889536832832452, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.889536832832452, 0.889536832832452, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.889536832832452, 0.889536832832452, 0.43180071831103467, 0.889536832832452, 0.43180071831103467, 0.889536832832452, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.889536832832452, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.43180071831103467, 0.889536832832452]\n",
      "all_sum after preprocessing is: [-0.68335604 -0.68335604 -0.68335604  1.41213907  1.41213907 -0.68335604\n",
      " -0.68335604 -0.68335604 -0.68335604  1.41213907  1.41213907 -0.68335604\n",
      " -0.68335604 -0.68335604  1.41213907  2.05201922 -0.68335604  1.41213907\n",
      " -0.68335604 -0.68335604  1.41213907 -0.68335604 -0.68335604 -0.68335604\n",
      "  1.41213907  1.41213907 -0.68335604 -0.68335604 -0.68335604 -0.68335604\n",
      "  1.41213907  1.41213907 -0.68335604  1.41213907 -0.68335604  1.41213907\n",
      " -0.68335604 -0.68335604 -0.68335604 -0.68335604 -0.68335604 -0.68335604\n",
      " -0.68335604  1.41213907 -0.68335604 -0.68335604 -0.68335604 -0.68335604\n",
      " -0.68335604  1.41213907]\n",
      "P is: [0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855, 0.8041031112186855, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855, 0.8041031112186855, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855, 0.8861514906115526, 0.3355126823512265, 0.8041031112186855, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855, 0.8041031112186855, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855, 0.8041031112186855, 0.3355126823512265, 0.8041031112186855, 0.3355126823512265, 0.8041031112186855, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.3355126823512265, 0.8041031112186855]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.828\n",
      "(*) epoch 2, cost 2.380\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.580\n",
      "(*) epoch 2, cost 0.935\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [3.551222055201153, 2.8153787872680307, 3.551222055201153, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 3.551222055201153, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 3.551222055201153, 2.8153787872680307, 2.7591302971235434, 3.551222055201153, 3.551222055201153, 2.8153787872680307, 3.551222055201153, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 3.581921026474936, 2.8153787872680307, 2.023287029190421, 2.8153787872680307, 2.8153787872680307, 3.551222055201153, 2.8153787872680307, 3.551222055201153, 3.551222055201153, 4.317764294408058, 2.8153787872680307, 3.551222055201153, 3.581921026474936, 2.8153787872680307, 2.8153787872680307, 3.551222055201153, 3.551222055201153, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307, 2.8153787872680307]\n",
      "all_sum after preprocessing is: [ 1.22622336 -0.57557711  1.22622336 -0.57557711 -0.57557711 -0.57557711\n",
      " -0.57557711 -0.57557711 -0.57557711 -0.57557711 -0.57557711  1.22622336\n",
      " -0.57557711 -0.57557711 -0.57557711 -0.57557711 -0.57557711  1.22622336\n",
      " -0.57557711 -0.71330828  1.22622336  1.22622336 -0.57557711  1.22622336\n",
      " -0.57557711 -0.57557711 -0.57557711 -0.57557711 -0.57557711  1.30139347\n",
      " -0.57557711 -2.51510875 -0.57557711 -0.57557711  1.22622336 -0.57557711\n",
      "  1.22622336  1.22622336  3.10319394 -0.57557711  1.22622336  1.30139347\n",
      " -0.57557711 -0.57557711  1.22622336  1.22622336 -0.57557711 -0.57557711\n",
      " -0.57557711 -0.57557711]\n",
      "P is: [0.7731568902165729, 0.35995093438475717, 0.7731568902165729, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.7731568902165729, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.7731568902165729, 0.35995093438475717, 0.3288682433569348, 0.7731568902165729, 0.7731568902165729, 0.35995093438475717, 0.7731568902165729, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.7860694084336102, 0.35995093438475717, 0.07480576465018943, 0.35995093438475717, 0.35995093438475717, 0.7731568902165729, 0.35995093438475717, 0.7731568902165729, 0.7731568902165729, 0.9570242998105211, 0.35995093438475717, 0.7731568902165729, 0.7860694084336102, 0.35995093438475717, 0.35995093438475717, 0.7731568902165729, 0.7731568902165729, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717, 0.35995093438475717]\n",
      "all_sum before preprocessing is: [4.229688029380542, 2.4506861187906743, 3.617235433811036, 3.617235433811036, 3.617235433811036, 2.4506861187906743, 3.8018387435583314, 2.4506861187906743, 3.617235433811036, 3.617235433811036, 3.8018387435583314, 2.4506861187906743, 3.617235433811036, 2.4506861187906743, 3.617235433811036, 2.4506861187906743, 3.617235433811036, 3.617235433811036, 3.0631387143601807, 2.4506861187906743, 2.4506861187906743, 2.4506861187906743, 4.229688029380542, 4.229688029380542, 2.4506861187906743, 3.617235433811036, 3.0631387143601807, 2.4506861187906743, 4.20988609624732, 3.617235433811036, 2.4506861187906743, 4.277048187892784, 3.617235433811036, 4.9485861254454715, 3.617235433811036, 2.4506861187906743, 3.617235433811036, 4.229688029380542, 3.617235433811036, 3.617235433811036, 2.4506861187906743, 3.617235433811036, 3.617235433811036, 3.617235433811036, 3.617235433811036, 2.4506861187906743, 3.617235433811036, 3.617235433811036, 3.617235433811036, 3.617235433811036]\n",
      "all_sum after preprocessing is: [ 1.33150981 -1.3709339   0.40114618  0.40114618  0.40114618 -1.3709339\n",
      "  0.68157312 -1.3709339   0.40114618  0.40114618  0.68157312 -1.3709339\n",
      "  0.40114618 -1.3709339   0.40114618 -1.3709339   0.40114618  0.40114618\n",
      " -0.44057028 -1.3709339  -1.3709339  -1.3709339   1.33150981  1.33150981\n",
      " -1.3709339   0.40114618 -0.44057028 -1.3709339   1.30142912  0.40114618\n",
      " -1.3709339   1.40345361  0.40114618  2.42357251  0.40114618 -1.3709339\n",
      "  0.40114618  1.33150981  0.40114618  0.40114618 -1.3709339   0.40114618\n",
      "  0.40114618  0.40114618  0.40114618 -1.3709339   0.40114618  0.40114618\n",
      "  0.40114618  0.40114618]\n",
      "P is: [0.7910902652249778, 0.2024690020004316, 0.5989630119029191, 0.5989630119029191, 0.5989630119029191, 0.2024690020004316, 0.6640897108249599, 0.2024690020004316, 0.5989630119029191, 0.5989630119029191, 0.6640897108249599, 0.2024690020004316, 0.5989630119029191, 0.2024690020004316, 0.5989630119029191, 0.2024690020004316, 0.5989630119029191, 0.5989630119029191, 0.3916050914789822, 0.2024690020004316, 0.2024690020004316, 0.2024690020004316, 0.7910902652249778, 0.7910902652249778, 0.2024690020004316, 0.5989630119029191, 0.3916050914789822, 0.2024690020004316, 0.7860754027224149, 0.5989630119029191, 0.2024690020004316, 0.8027313526924486, 0.5989630119029191, 0.9186072539844561, 0.5989630119029191, 0.2024690020004316, 0.5989630119029191, 0.7910902652249778, 0.5989630119029191, 0.5989630119029191, 0.2024690020004316, 0.5989630119029191, 0.5989630119029191, 0.5989630119029191, 0.5989630119029191, 0.2024690020004316, 0.5989630119029191, 0.5989630119029191, 0.5989630119029191, 0.5989630119029191]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.365\n",
      "(*) epoch 2, cost 2.525\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.739\n",
      "(*) epoch 2, cost 1.641\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8829670197618973, 1.5687776164254432, 1.5687776164254432, 1.5687776164254432, 2.122198993032886, 1.5687776164254432, 1.8829670197618973, 1.5687776164254432, 1.5687776164254432, 1.5687776164254432, 3.130904183688098, 2.2544780066644905, 1.5687776164254432, 1.5687776164254432, 1.6906317396121042, 1.5687776164254432, 1.5687776164254432, 2.4735291779860837, 1.4364986027938391, 1.5687776164254432, 1.5687776164254432, 1.8829670197618973, 1.5687776164254432, 1.5687776164254432, 1.4364986027938391, 2.4735291779860837, 1.5687776164254432, 1.5687776164254432, 1.8829670197618973, 1.5687776164254432, 2.4735291779860837, 2.2544780066644905, 2.4735291779860837, 1.6906317396121042, 1.5687776164254432, 2.8919129457862933, 1.5687776164254432, 2.8378373074734595, 1.4364986027938391, 3.130904183688098, 1.6906317396121042, 2.8919129457862933, 4.013656862548455, 2.8919129457862933, 1.5687776164254432, 1.4364986027938391, 1.5687776164254432, 1.5687776164254432, 2.004821142948558, 1.5687776164254432]\n",
      "all_sum after preprocessing is: [-0.07548511 -0.62164805 -0.62164805 -0.62164805  0.34037754 -0.62164805\n",
      " -0.07548511 -0.62164805 -0.62164805 -0.62164805  2.09383386  0.57032131\n",
      " -0.62164805 -0.62164805 -0.40982612 -0.62164805 -0.62164805  0.95110319\n",
      " -0.85159182 -0.62164805 -0.62164805 -0.07548511 -0.62164805 -0.62164805\n",
      " -0.85159182  0.95110319 -0.62164805 -0.62164805 -0.07548511 -0.62164805\n",
      "  0.95110319  0.57032131  0.95110319 -0.40982612 -0.62164805  1.67838969\n",
      " -0.62164805  1.58438871 -0.85159182  2.09383386 -0.40982612  1.67838969\n",
      "  3.62834392  1.67838969 -0.62164805 -0.85159182 -0.62164805 -0.62164805\n",
      "  0.13633683 -0.62164805]\n",
      "P is: [0.4811376789974952, 0.3494067214535485, 0.3494067214535485, 0.3494067214535485, 0.5842822301731103, 0.3494067214535485, 0.4811376789974952, 0.3494067214535485, 0.3494067214535485, 0.3494067214535485, 0.8903024167515646, 0.6388373130615718, 0.3494067214535485, 0.3494067214535485, 0.39895381592663737, 0.3494067214535485, 0.3494067214535485, 0.7213369851305935, 0.29909904443752583, 0.3494067214535485, 0.3494067214535485, 0.4811376789974952, 0.3494067214535485, 0.3494067214535485, 0.29909904443752583, 0.7213369851305935, 0.3494067214535485, 0.3494067214535485, 0.4811376789974952, 0.3494067214535485, 0.7213369851305935, 0.6388373130615718, 0.7213369851305935, 0.39895381592663737, 0.3494067214535485, 0.8426911814197707, 0.3494067214535485, 0.8298251692162772, 0.29909904443752583, 0.8903024167515646, 0.39895381592663737, 0.8426911814197707, 0.9741270552063981, 0.8426911814197707, 0.3494067214535485, 0.29909904443752583, 0.3494067214535485, 0.3494067214535485, 0.5340315086317182, 0.3494067214535485]\n",
      "all_sum before preprocessing is: [2.8519402617492284, 2.8519402617492284, 4.076355076060595, 3.885312250847698, 2.8519402617492284, 4.076355076060595, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 3.885312250847698, 2.8519402617492284, 2.8519402617492284, 4.076355076060595, 2.8519402617492284, 4.076355076060595, 3.885312250847698, 2.8519402617492284, 4.076355076060595, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 4.076355076060595, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 4.076355076060595, 4.076355076060595, 2.8519402617492284, 4.233819940358224, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 2.8519402617492284, 4.076355076060595]\n",
      "all_sum after preprocessing is: [-0.59014465 -0.59014465  1.74050456  1.37685835 -0.59014465  1.74050456\n",
      " -0.59014465 -0.59014465 -0.59014465 -0.59014465  1.37685835 -0.59014465\n",
      " -0.59014465  1.74050456 -0.59014465  1.74050456  1.37685835 -0.59014465\n",
      "  1.74050456 -0.59014465 -0.59014465 -0.59014465 -0.59014465 -0.59014465\n",
      " -0.59014465 -0.59014465 -0.59014465 -0.59014465 -0.59014465 -0.59014465\n",
      "  1.74050456 -0.59014465 -0.59014465 -0.59014465 -0.59014465 -0.59014465\n",
      " -0.59014465 -0.59014465  1.74050456  1.74050456 -0.59014465  2.04023579\n",
      " -0.59014465 -0.59014465 -0.59014465 -0.59014465 -0.59014465 -0.59014465\n",
      " -0.59014465  1.74050456]\n",
      "P is: [0.3566016665323368, 0.3566016665323368, 0.8507511428013438, 0.7984859634189503, 0.3566016665323368, 0.8507511428013438, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.7984859634189503, 0.3566016665323368, 0.3566016665323368, 0.8507511428013438, 0.3566016665323368, 0.8507511428013438, 0.7984859634189503, 0.3566016665323368, 0.8507511428013438, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.8507511428013438, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.8507511428013438, 0.8507511428013438, 0.3566016665323368, 0.8849572757918297, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.3566016665323368, 0.8507511428013438]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.178\n",
      "(*) epoch 2, cost 3.566\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.292\n",
      "(*) epoch 2, cost 1.015\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.261569920867074, 3.2159360610303387, 3.261569920867074, 3.261569920867074, 3.2159360610303387, 3.2159360610303387, 2.4440812737136177, 3.2159360610303387, 3.2159360610303387, 3.2159360610303387, 3.5022958758527705, 3.2159360610303387, 3.2159360610303387, 3.2159360610303387, 3.2159360610303387, 3.5479297356895056, 3.2159360610303387, 3.261569920867074, 3.2159360610303387, 3.487532489027143, 3.2409010837761056, 3.2159360610303387, 3.2159360610303387, 3.261569920867074, 2.4440812737136177, 3.2159360610303387, 3.2159360610303387, 3.261569920867074, 3.2159360610303387, 3.2159360610303387, 2.4440812737136177, 3.803385398529538, 2.4440812737136177, 3.2159360610303387, 3.261569920867074, 3.2159360610303387, 2.4897151335503525, 4.259387276343864, 3.2159360610303387, 3.2159360610303387, 2.4440812737136177, 3.2159360610303387, 3.261569920867074, 3.2159360610303387, 3.261569920867074, 3.261569920867074, 2.4440812737136177, 3.261569920867074, 3.2159360610303387, 3.2159360610303387]\n",
      "all_sum after preprocessing is: [ 0.27151796  0.13658303  0.27151796  0.27151796  0.13658303  0.13658303\n",
      " -2.14571726  0.13658303  0.13658303  0.13658303  0.98332143  0.13658303\n",
      "  0.13658303  0.13658303  0.13658303  1.11825636  0.13658303  0.27151796\n",
      "  0.13658303  0.93966752  0.2104022   0.13658303  0.13658303  0.27151796\n",
      " -2.14571726  0.13658303  0.13658303  0.27151796  0.13658303  0.13658303\n",
      " -2.14571726  1.87361416 -2.14571726  0.13658303  0.27151796  0.13658303\n",
      " -2.01078233  3.22196781  0.13658303  0.13658303 -2.14571726  0.13658303\n",
      "  0.27151796  0.13658303  0.27151796  0.27151796 -2.14571726  0.27151796\n",
      "  0.13658303  0.13658303]\n",
      "P is: [0.5674655242264595, 0.53409277450482, 0.5674655242264595, 0.5674655242264595, 0.53409277450482, 0.53409277450482, 0.10473210786753384, 0.53409277450482, 0.53409277450482, 0.53409277450482, 0.7277667637541101, 0.53409277450482, 0.53409277450482, 0.53409277450482, 0.53409277450482, 0.7536651463088728, 0.53409277450482, 0.5674655242264595, 0.53409277450482, 0.7190324929042405, 0.5524073570299798, 0.53409277450482, 0.53409277450482, 0.5674655242264595, 0.10473210786753384, 0.53409277450482, 0.53409277450482, 0.5674655242264595, 0.53409277450482, 0.53409277450482, 0.10473210786753384, 0.8668759124257441, 0.10473210786753384, 0.53409277450482, 0.5674655242264595, 0.53409277450482, 0.118075486753717, 0.9616526470045998, 0.53409277450482, 0.53409277450482, 0.10473210786753384, 0.53409277450482, 0.5674655242264595, 0.53409277450482, 0.5674655242264595, 0.5674655242264595, 0.10473210786753384, 0.5674655242264595, 0.53409277450482, 0.53409277450482]\n",
      "all_sum before preprocessing is: [2.303339359646085, 2.303339359646085, 2.303339359646085, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 2.303339359646085, 1.6042922006931575, 1.6042922006931575, 2.303339359646085, 1.6042922006931575, 1.6042922006931575, 2.303339359646085, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 2.303339359646085, 1.6042922006931575, 1.6042922006931575, 1.7653453006538604, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 2.303339359646085, 1.6042922006931575, 1.6042922006931575, 2.303339359646085, 2.303339359646085, 2.303339359646085, 2.303339359646085, 2.303339359646085, 2.6153348479301726, 2.303339359646085, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 1.6042922006931575, 2.303339359646085, 2.303339359646085, 1.6042922006931575, 1.6042922006931575]\n",
      "all_sum after preprocessing is: [ 1.32537154  1.32537154  1.32537154 -0.72480857 -0.72480857 -0.72480857\n",
      " -0.72480857 -0.72480857  1.32537154 -0.72480857 -0.72480857  1.32537154\n",
      " -0.72480857 -0.72480857  1.32537154 -0.72480857 -0.72480857 -0.72480857\n",
      " -0.72480857 -0.72480857 -0.72480857 -0.72480857  1.32537154 -0.72480857\n",
      " -0.72480857 -0.25246868 -0.72480857 -0.72480857 -0.72480857 -0.72480857\n",
      "  1.32537154 -0.72480857 -0.72480857  1.32537154  1.32537154  1.32537154\n",
      "  1.32537154  1.32537154  2.24039843  1.32537154 -0.72480857 -0.72480857\n",
      " -0.72480857 -0.72480857 -0.72480857 -0.72480857  1.32537154  1.32537154\n",
      " -0.72480857 -0.72480857]\n",
      "P is: [0.7900740024101791, 0.7900740024101791, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237, 0.437215966976284, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237, 0.7900740024101791, 0.7900740024101791, 0.7900740024101791, 0.7900740024101791, 0.7900740024101791, 0.9038190990308866, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.32633498231991237, 0.7900740024101791, 0.7900740024101791, 0.32633498231991237, 0.32633498231991237]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.979\n",
      "(*) epoch 2, cost 2.785\n",
      "(*) epoch 3, cost 2.197\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.653\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1864020469109335, 0.48804963846879434, 0.5660395918338905, 0.5660395918338905, 0.5660395918338905, 1.1864020469109335, 0.5660395918338905, 0.5660395918338905, 3.4824463103274956, 1.1864020469109335, 0.5660395918338905, 0.5660395918338905, 1.1864020469109335, 0.5660395918338905, 2.862083855250453, 1.1864020469109335, 1.1084120935458373, 0.5660395918338905, 2.784093901885357, 1.1084120935458373, 1.1084120935458373, 1.1084120935458373, 0.5660395918338905, 0.5660395918338905, 3.4044563569624, 0.5660395918338905, 3.4824463103274956, 0.5660395918338905, 0.5660395918338905, 1.6227575574260606, 1.1864020469109335, 3.4824463103274956, 0.5660395918338905, 2.862083855250453, 3.4824463103274956, 2.862083855250453, 3.4824463103274956, 0.5660395918338905, 1.1864020469109335, 1.1864020469109335, 1.1864020469109335, 0.5660395918338905, 3.4824463103274956, 2.862083855250453, 0.5660395918338905, 1.1864020469109335, 0.5660395918338905, 0.5660395918338905, 2.225496047419127, 2.862083855250453]\n",
      "all_sum after preprocessing is: [-0.25897189 -0.90357433 -0.83158702 -0.83158702 -0.83158702 -0.25897189\n",
      " -0.83158702 -0.83158702  1.86035314 -0.25897189 -0.83158702 -0.83158702\n",
      " -0.25897189 -0.83158702  1.28773801 -0.25897189 -0.33095921 -0.83158702\n",
      "  1.21575069 -0.33095921 -0.33095921 -0.33095921 -0.83158702 -0.83158702\n",
      "  1.78836582 -0.83158702  1.86035314 -0.83158702 -0.83158702  0.14379872\n",
      " -0.25897189  1.86035314 -0.83158702  1.28773801  1.86035314  1.28773801\n",
      "  1.86035314 -0.83158702 -0.25897189 -0.25897189 -0.25897189 -0.83158702\n",
      "  1.86035314  1.28773801 -0.83158702 -0.25897189 -0.83158702 -0.83158702\n",
      "  0.70014634  1.28773801]\n",
      "P is: [0.43561645680841493, 0.2883165251481991, 0.30330960812875957, 0.30330960812875957, 0.30330960812875957, 0.43561645680841493, 0.30330960812875957, 0.30330960812875957, 0.8653381035392594, 0.43561645680841493, 0.30330960812875957, 0.30330960812875957, 0.43561645680841493, 0.30330960812875957, 0.7837640776001326, 0.43561645680841493, 0.4180072519298012, 0.30330960812875957, 0.7713148861798139, 0.4180072519298012, 0.4180072519298012, 0.4180072519298012, 0.30330960812875957, 0.30330960812875957, 0.8567268045254364, 0.30330960812875957, 0.8653381035392594, 0.30330960812875957, 0.30330960812875957, 0.5358878605397988, 0.43561645680841493, 0.8653381035392594, 0.30330960812875957, 0.7837640776001326, 0.8653381035392594, 0.7837640776001326, 0.8653381035392594, 0.30330960812875957, 0.43561645680841493, 0.43561645680841493, 0.43561645680841493, 0.30330960812875957, 0.8653381035392594, 0.7837640776001326, 0.30330960812875957, 0.43561645680841493, 0.30330960812875957, 0.30330960812875957, 0.6682202175212724, 0.7837640776001326]\n",
      "all_sum before preprocessing is: [5.790773261415964, 4.903434250055238, 5.790773261415964, 4.903434250055238, 5.790773261415964, 6.065738418175242, 5.178399406814515, 5.790773261415964, 5.790773261415964, 5.790773261415964, 6.713261463571801, 5.790773261415964, 5.790773261415964, 5.790773261415964, 5.178399406814515, 5.790773261415964, 5.790773261415964, 4.903434250055238, 5.790773261415964, 6.375867502246187, 5.790773261415964, 5.790773261415964, 5.790773261415964, 5.790773261415964, 4.903434250055238, 5.790773261415964, 5.790773261415964, 9.238653536660939, 5.790773261415964, 4.903434250055238, 5.790773261415964, 4.903434250055238, 5.790773261415964, 5.790773261415964, 5.790773261415964, 4.903434250055238, 5.790773261415964, 5.790773261415964, 6.065738418175242, 5.790773261415964, 5.790773261415964, 5.790773261415964, 6.375867502246187, 5.790773261415964, 5.790773261415964, 5.790773261415964, 5.790773261415964, 5.790773261415964, 4.903434250055238, 5.790773261415964]\n",
      "all_sum after preprocessing is: [ 0.06970557 -1.31527502  0.06970557 -1.31527502  0.06970557  0.49887796\n",
      " -0.88610263  0.06970557  0.06970557  0.06970557  1.50954788  0.06970557\n",
      "  0.06970557  0.06970557 -0.88610263  0.06970557  0.06970557 -1.31527502\n",
      "  0.06970557  0.98293508  0.06970557  0.06970557  0.06970557  0.06970557\n",
      " -1.31527502  0.06970557  0.06970557  5.45124204  0.06970557 -1.31527502\n",
      "  0.06970557 -1.31527502  0.06970557  0.06970557  0.06970557 -1.31527502\n",
      "  0.06970557  0.06970557  0.49887796  0.06970557  0.06970557  0.06970557\n",
      "  0.98293508  0.06970557  0.06970557  0.06970557  0.06970557  0.06970557\n",
      " -1.31527502  0.06970557]\n",
      "P is: [0.5174193400416384, 0.21160548141049992, 0.5174193400416384, 0.21160548141049992, 0.5174193400416384, 0.6221956117190597, 0.2919147625311543, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.8189941934110383, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.2919147625311543, 0.5174193400416384, 0.5174193400416384, 0.21160548141049992, 0.5174193400416384, 0.7276902111864032, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.21160548141049992, 0.5174193400416384, 0.5174193400416384, 0.9957273619693111, 0.5174193400416384, 0.21160548141049992, 0.5174193400416384, 0.21160548141049992, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.21160548141049992, 0.5174193400416384, 0.5174193400416384, 0.6221956117190597, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.7276902111864032, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.5174193400416384, 0.21160548141049992, 0.5174193400416384]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.134\n",
      "(*) epoch 2, cost 1.989\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.691\n",
      "(*) epoch 2, cost 2.380\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.6610633712474142, 0.8922675333607396, 1.8204812050861048, 1.6550765823598437, 0.8922675333607396, 1.5254576590301216, 1.1872910794167228, 1.5254576590301216, 2.22171804079586, 0.8922675333607396, 0.6610633712474142, 0.6610633712474142, 1.8835514611824613, 1.9866522625396477, 1.5885279151264782, 0.32289679163401536, 2.351336964125582, 1.9501001284158268, 2.22171804079586, 1.5885279151264782, 1.5254576590301216, 1.5254576590301216, 0.8922675333607396, 0.8922675333607396, 1.5885279151264782, 1.5254576590301216, 1.1872910794167228, 1.9866522625396477, 2.22171804079586, 1.5254576590301216, 2.22171804079586, 1.6550765823598437, 1.1872910794167228, 0.8922675333607396, 1.8835514611824613, 0.8922675333607396, 1.6550765823598437, 1.1872910794167228, 1.8204812050861048, 1.5885279151264782, 1.8204812050861048, 1.5254576590301216, 2.22171804079586, 1.5254576590301216, 1.1872910794167228, 1.6550765823598437, 1.1872910794167228, 1.5254576590301216, 0.8922675333607396, 0.8922675333607396]\n",
      "all_sum after preprocessing is: [-1.61829807 -1.14733405  0.74344177  0.40651174 -1.14733405  0.14247735\n",
      " -0.54636964  0.14247735  1.56076317 -1.14733405 -1.61829807 -1.61829807\n",
      "  0.87191619  1.08193303  0.27095177 -2.30714505  1.82479756  1.00747615\n",
      "  1.56076317  0.27095177  0.14247735  0.14247735 -1.14733405 -1.14733405\n",
      "  0.27095177  0.14247735 -0.54636964  1.08193303  1.56076317  0.14247735\n",
      "  1.56076317  0.40651174 -0.54636964 -1.14733405  0.87191619 -1.14733405\n",
      "  0.40651174 -0.54636964  0.74344177  0.27095177  0.74344177  0.14247735\n",
      "  1.56076317  0.14247735 -0.54636964  0.40651174 -0.54636964  0.14247735\n",
      " -1.14733405 -1.14733405]\n",
      "P is: [0.1654397214878124, 0.24097636654434726, 0.6777480167816154, 0.6002511643425801, 0.24097636654434726, 0.5355592044479283, 0.3667070908078864, 0.5355592044479283, 0.8264628362825601, 0.24097636654434726, 0.1654397214878124, 0.1654397214878124, 0.7051442603890695, 0.7468596165532284, 0.5673265489750031, 0.0905329371221705, 0.8611408008780939, 0.7325259374708092, 0.8264628362825601, 0.5673265489750031, 0.5355592044479283, 0.5355592044479283, 0.24097636654434726, 0.24097636654434726, 0.5673265489750031, 0.5355592044479283, 0.3667070908078864, 0.7468596165532284, 0.8264628362825601, 0.5355592044479283, 0.8264628362825601, 0.6002511643425801, 0.3667070908078864, 0.24097636654434726, 0.7051442603890695, 0.24097636654434726, 0.6002511643425801, 0.3667070908078864, 0.6777480167816154, 0.5673265489750031, 0.6777480167816154, 0.5355592044479283, 0.8264628362825601, 0.5355592044479283, 0.3667070908078864, 0.6002511643425801, 0.3667070908078864, 0.5355592044479283, 0.24097636654434726, 0.24097636654434726]\n",
      "all_sum before preprocessing is: [3.152247041657815, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 3.152247041657815, 2.2133717163301685, 2.2133717163301685, 3.152247041657815, 3.281447970294346, 3.152247041657815, 2.2133717163301685, 3.281447970294346, 4.220323295621993, 3.152247041657815, 0.9100555286054759, 3.152247041657815, 2.2133717163301685, 3.152247041657815, 3.152247041657815, 2.2133717163301685, 3.152247041657815, 2.2133717163301685, 3.152247041657815, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 3.281447970294346, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 3.152247041657815, 3.152247041657815, 3.152247041657815, 2.575936414322607, 3.152247041657815, 3.281447970294346, 3.281447970294346, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685, 2.2133717163301685]\n",
      "all_sum after preprocessing is: [ 0.96077146 -0.68572018 -0.68572018 -0.68572018 -0.68572018  0.96077146\n",
      " -0.68572018 -0.68572018  0.96077146  1.1873492   0.96077146 -0.68572018\n",
      "  1.1873492   2.83384084  0.96077146 -2.97132632  0.96077146 -0.68572018\n",
      "  0.96077146  0.96077146 -0.68572018  0.96077146 -0.68572018  0.96077146\n",
      " -0.68572018 -0.68572018 -0.68572018 -0.68572018 -0.68572018 -0.68572018\n",
      "  1.1873492  -0.68572018 -0.68572018 -0.68572018 -0.68572018 -0.68572018\n",
      " -0.68572018 -0.68572018 -0.68572018  0.96077146  0.96077146  0.96077146\n",
      " -0.04989588  0.96077146  1.1873492   1.1873492  -0.68572018 -0.68572018\n",
      " -0.68572018 -0.68572018]\n",
      "P is: [0.7232762375200421, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.7232762375200421, 0.33498581565971136, 0.33498581565971136, 0.7232762375200421, 0.7662666353407729, 0.7232762375200421, 0.33498581565971136, 0.7662666353407729, 0.9444773593569455, 0.7232762375200421, 0.04873819431940855, 0.7232762375200421, 0.33498581565971136, 0.7232762375200421, 0.7232762375200421, 0.33498581565971136, 0.7232762375200421, 0.33498581565971136, 0.7232762375200421, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.7662666353407729, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.7232762375200421, 0.7232762375200421, 0.7232762375200421, 0.48752861649679313, 0.7232762375200421, 0.7662666353407729, 0.7662666353407729, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136, 0.33498581565971136]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.671\n",
      "(*) epoch 2, cost 3.368\n",
      "(*) epoch 3, cost 2.761\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.878\n",
      "(*) epoch 2, cost 2.617\n",
      "(*) epoch 3, cost 2.135\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.63968197890187, 3.63968197890187, 4.79368025483122, 4.79368025483122, 3.63968197890187, 3.63968197890187, 4.479821823971, 3.0339954899438086, 3.799814631464363, 2.645816355535012, 5.495717820100237, 1.7537555201334625, 3.63968197890187, 2.74762114350032, 3.63968197890187, 1.7537555201334625, 3.63968197890187, 2.74762114350032, 2.645816355535012, 4.3417195441708865, 3.63968197890187, 4.79368025483122, 3.63968197890187, 3.32582354804165, 2.74762114350032, 4.501852196733379, 3.63968197890187, 2.645816355535012, 3.63968197890187, 2.645816355535012, 2.645816355535012, 4.3417195441708865, 3.63968197890187, 2.645816355535012, 3.63968197890187, 3.63968197890187, 2.645816355535012, 3.63968197890187, 2.645816355535012, 2.74762114350032, 4.832590881425225, 2.645816355535012, 3.63968197890187, 2.645816355535012, 2.645816355535012, 3.799814631464363, 2.74762114350032, 3.63968197890187, 4.79368025483122, 2.645816355535012]\n",
      "all_sum after preprocessing is: [ 0.24186274  0.24186274  1.63929502  1.63929502  0.24186274  0.24186274\n",
      "  1.25922867 -0.4915923   0.4357751  -0.96165717  2.48942623 -2.04189675\n",
      "  0.24186274 -0.83837684  0.24186274 -2.04189675  0.24186274 -0.83837684\n",
      " -0.96165717  1.09199395  0.24186274  1.63929502  0.24186274 -0.1382036\n",
      " -0.83837684  1.28590632  0.24186274 -0.96165717  0.24186274 -0.96165717\n",
      " -0.96165717  1.09199395  0.24186274 -0.96165717  0.24186274  0.24186274\n",
      " -0.96165717  0.24186274 -0.96165717 -0.83837684  1.68641377 -0.96165717\n",
      "  0.24186274 -0.96165717 -0.96165717  0.4357751  -0.83837684  0.24186274\n",
      "  1.63929502 -0.96165717]\n",
      "P is: [0.5601726402523854, 0.5601726402523854, 0.8374389872198964, 0.8374389872198964, 0.5601726402523854, 0.5601726402523854, 0.778893299799843, 0.3795185337278732, 0.6072518634385109, 0.2765465235982363, 0.9233972269227035, 0.1148737339610559, 0.5601726402523854, 0.30187675090611893, 0.5601726402523854, 0.1148737339610559, 0.5601726402523854, 0.30187675090611893, 0.2765465235982363, 0.7487570094192456, 0.5601726402523854, 0.8374389872198964, 0.5601726402523854, 0.46550398828330847, 0.30187675090611893, 0.7834534849726131, 0.5601726402523854, 0.2765465235982363, 0.5601726402523854, 0.2765465235982363, 0.2765465235982363, 0.7487570094192456, 0.5601726402523854, 0.2765465235982363, 0.5601726402523854, 0.5601726402523854, 0.2765465235982363, 0.5601726402523854, 0.2765465235982363, 0.30187675090611893, 0.8437519537868944, 0.2765465235982363, 0.5601726402523854, 0.2765465235982363, 0.2765465235982363, 0.6072518634385109, 0.30187675090611893, 0.5601726402523854, 0.8374389872198964, 0.2765465235982363]\n",
      "all_sum before preprocessing is: [2.7670596420040767, 3.6214694585696705, 3.395974934381765, 3.395974934381765, 3.395974934381765, 2.7670596420040767, 4.4158401791891935, 3.395974934381765, 5.044755471566882, 3.395974934381765, 3.395974934381765, 2.7670596420040767, 3.395974934381765, 3.395974934381765, 3.395974934381765, 3.395974934381765, 3.395974934381765, 3.395974934381765, 3.395974934381765, 2.7670596420040767, 3.395974934381765, 3.395974934381765, 3.395974934381765, 4.250384750947359, 3.395974934381765, 5.044755471566882, 5.044755471566882, 5.044755471566882, 4.0914979137898815, 3.395974934381765, 5.044755471566882, 5.044755471566882, 3.395974934381765, 5.044755471566882, 5.044755471566882, 4.4158401791891935, 5.899165288132475, 2.7670596420040767, 2.7670596420040767, 3.395974934381765, 4.4158401791891935, 4.4158401791891935, 3.395974934381765, 5.044755471566882, 3.395974934381765, 3.395974934381765, 5.044755471566882, 4.4158401791891935, 3.395974934381765, 2.7670596420040767]\n",
      "all_sum after preprocessing is: [-1.29333098 -0.24905453 -0.52465837 -0.52465837 -0.52465837 -1.29333098\n",
      "  0.72184096 -0.52465837  1.49051358 -0.52465837 -0.52465837 -1.29333098\n",
      " -0.52465837 -0.52465837 -0.52465837 -0.52465837 -0.52465837 -0.52465837\n",
      " -0.52465837 -1.29333098 -0.52465837 -0.52465837 -0.52465837  0.51961809\n",
      " -0.52465837  1.49051358  1.49051358  1.49051358  0.32542348 -0.52465837\n",
      "  1.49051358  1.49051358 -0.52465837  1.49051358  1.49051358  0.72184096\n",
      "  2.53479003 -1.29333098 -1.29333098 -0.52465837  0.72184096  0.72184096\n",
      " -0.52465837  1.49051358 -0.52465837 -0.52465837  1.49051358  0.72184096\n",
      " -0.52465837 -1.29333098]\n",
      "P is: [0.21528954103704345, 0.43805622504136055, 0.37176359888489885, 0.37176359888489885, 0.37176359888489885, 0.21528954103704345, 0.6730122801557156, 0.37176359888489885, 0.8161553453222706, 0.37176359888489885, 0.37176359888489885, 0.21528954103704345, 0.37176359888489885, 0.37176359888489885, 0.37176359888489885, 0.37176359888489885, 0.37176359888489885, 0.37176359888489885, 0.37176359888489885, 0.21528954103704345, 0.37176359888489885, 0.37176359888489885, 0.37176359888489885, 0.6270584580314259, 0.37176359888489885, 0.8161553453222706, 0.8161553453222706, 0.8161553453222706, 0.5806454230789623, 0.37176359888489885, 0.8161553453222706, 0.8161553453222706, 0.37176359888489885, 0.8161553453222706, 0.8161553453222706, 0.6730122801557156, 0.9265450265397672, 0.21528954103704345, 0.21528954103704345, 0.37176359888489885, 0.6730122801557156, 0.6730122801557156, 0.37176359888489885, 0.8161553453222706, 0.37176359888489885, 0.37176359888489885, 0.8161553453222706, 0.6730122801557156, 0.37176359888489885, 0.21528954103704345]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.524\n",
      "(*) epoch 2, cost 4.279\n",
      "(*) epoch 3, cost 3.791\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.088\n",
      "(*) epoch 2, cost 3.817\n",
      "(*) epoch 3, cost 3.325\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.9452957017149641, 1.8724135851617754, 1.8724135851617754, 1.9452957017149641, 1.716987771142953, 3.4370614747260904, 0.1523398815786382, 1.8724135851617754, 1.8724135851617754, 1.716987771142953, 1.8724135851617754, 3.4370614747260904, 0.2252219981318267, 1.8724135851617754, 0.1523398815786382, 1.9452957017149641, 0.1523398815786382, 1.8724135851617754, 1.8724135851617754, 1.9452957017149641, 1.8724135851617754, 0.2252219981318267, 1.8724135851617754, 1.716987771142953, 1.716987771142953, 1.9452957017149641, 3.364179358172902, 1.9452957017149641, 1.9452957017149641, 1.9452957017149641, 1.8724135851617754, 2.4850033234759854, 0.2252219981318267, 3.4370614747260904, 1.8724135851617754, 1.9452957017149641, 0.1523398815786382, 1.9452957017149641, 1.9452957017149641, 1.9452957017149641, 3.4370614747260904, 1.8724135851617754, 1.716987771142953, 1.8724135851617754, 1.9452957017149641, 3.364179358172902, 1.8724135851617754, 1.9452957017149641, 1.8724135851617754, 0.1523398815786382]\n",
      "all_sum after preprocessing is: [ 0.1636725   0.07952603  0.07952603  0.1636725  -0.09992174  1.88599931\n",
      " -1.90639502  0.07952603  0.07952603 -0.09992174  0.07952603  1.88599931\n",
      " -1.82224855  0.07952603 -1.90639502  0.1636725  -1.90639502  0.07952603\n",
      "  0.07952603  0.1636725   0.07952603 -1.82224855  0.07952603 -0.09992174\n",
      " -0.09992174  0.1636725   1.80185284  0.1636725   0.1636725   0.1636725\n",
      "  0.07952603  0.78679506 -1.82224855  1.88599931  0.07952603  0.1636725\n",
      " -1.90639502  0.1636725   0.1636725   0.1636725   1.88599931  0.07952603\n",
      " -0.09992174  0.07952603  0.1636725   1.80185284  0.07952603  0.1636725\n",
      "  0.07952603 -1.90639502]\n",
      "P is: [0.5408270237974069, 0.5198710360694344, 0.5198710360694344, 0.5408270237974069, 0.47504032814316494, 0.8682987005612222, 0.12938639520051104, 0.5198710360694344, 0.5198710360694344, 0.47504032814316494, 0.5198710360694344, 0.8682987005612222, 0.139164283775076, 0.5198710360694344, 0.12938639520051104, 0.5408270237974069, 0.12938639520051104, 0.5198710360694344, 0.5198710360694344, 0.5408270237974069, 0.5198710360694344, 0.139164283775076, 0.5198710360694344, 0.47504032814316494, 0.47504032814316494, 0.5408270237974069, 0.8583743299425658, 0.5408270237974069, 0.5408270237974069, 0.5408270237974069, 0.5198710360694344, 0.6871427533867248, 0.139164283775076, 0.8682987005612222, 0.5198710360694344, 0.5408270237974069, 0.12938639520051104, 0.5408270237974069, 0.5408270237974069, 0.5408270237974069, 0.8682987005612222, 0.5198710360694344, 0.47504032814316494, 0.5198710360694344, 0.5408270237974069, 0.8583743299425658, 0.5198710360694344, 0.5408270237974069, 0.5198710360694344, 0.12938639520051104]\n",
      "all_sum before preprocessing is: [1.3358587322774538, 0.46812377761665647, 2.4187493285982766, 0.46812377761665647, 1.1260195579040349, 1.1260195579040349, 1.1260195579040349, 0.46812377761665647, 0.46812377761665647, 0.46812377761665647, 0.46812377761665647, 0.46812377761665647, 1.1509608658175452, 1.1260195579040349, 1.1260195579040349, 0.46812377761665647, 0.46812377761665647, 1.1260195579040349, 0.46812377761665647, 1.7608535483108985, 3.295142166884374, 2.6372463865969955, 2.6372463865969955, 1.1260195579040349, 3.295142166884374, 1.1260195579040349, 2.6372463865969955, 2.6372463865969955, 0.46812377761665647, 0.46812377761665647, 3.295142166884374, 0.46812377761665647, 1.1260195579040349, 2.6372463865969955, 0.46812377761665647, 1.1260195579040349, 1.1260195579040349, 1.1260195579040349, 3.0327479463000575, 1.1260195579040349, 3.295142166884374, 1.1260195579040349, 0.46812377761665647, 2.6372463865969955, 1.1260195579040349, 1.1260195579040349, 0.46812377761665647, 1.1260195579040349, 1.1260195579040349, 1.1260195579040349]\n",
      "all_sum after preprocessing is: [-0.01720663 -0.9566843   1.15521535 -0.9566843  -0.24439492 -0.24439492\n",
      " -0.24439492 -0.9566843  -0.9566843  -0.9566843  -0.9566843  -0.9566843\n",
      " -0.21739151 -0.24439492 -0.24439492 -0.9566843  -0.9566843  -0.24439492\n",
      " -0.9566843   0.44292597  2.10406672  1.39177734  1.39177734 -0.24439492\n",
      "  2.10406672 -0.24439492  1.39177734  1.39177734 -0.9566843  -0.9566843\n",
      "  2.10406672 -0.9566843  -0.24439492  1.39177734 -0.9566843  -0.24439492\n",
      " -0.24439492 -0.24439492  1.81997823 -0.24439492  2.10406672 -0.24439492\n",
      " -0.9566843   1.39177734 -0.24439492 -0.24439492 -0.9566843  -0.24439492\n",
      " -0.24439492 -0.24439492]\n",
      "P is: [0.49569844811222136, 0.277542543978982, 0.760462231686615, 0.277542543978982, 0.4392035777977805, 0.4392035777977805, 0.4392035777977805, 0.277542543978982, 0.277542543978982, 0.277542543978982, 0.277542543978982, 0.277542543978982, 0.44586515148212175, 0.4392035777977805, 0.4392035777977805, 0.277542543978982, 0.277542543978982, 0.4392035777977805, 0.277542543978982, 0.6089560085616316, 0.8912978142832256, 0.8008758331217803, 0.8008758331217803, 0.4392035777977805, 0.8912978142832256, 0.4392035777977805, 0.8008758331217803, 0.8008758331217803, 0.277542543978982, 0.277542543978982, 0.8912978142832256, 0.277542543978982, 0.4392035777977805, 0.8008758331217803, 0.277542543978982, 0.4392035777977805, 0.4392035777977805, 0.4392035777977805, 0.8605635147723376, 0.4392035777977805, 0.8912978142832256, 0.4392035777977805, 0.277542543978982, 0.8008758331217803, 0.4392035777977805, 0.4392035777977805, 0.277542543978982, 0.4392035777977805, 0.4392035777977805, 0.4392035777977805]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.253\n",
      "(*) epoch 2, cost 1.922\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.362\n",
      "(*) epoch 2, cost 1.714\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.9279797992028646, 0.9279797992028646, 0.48069119556948303, 1.1398530051024227, 1.1398530051024227, 1.1806985988107432, 0.9279797992028646, 0.48069119556948303, 1.1398530051024227, 0.9279797992028646, 0.48069119556948303, 0.48069119556948303, 0.9279797992028646, 0.48069119556948303, 0.6925644014690413, 0.9279797992028646, 0.48069119556948303, 1.7695709189902966, 0.48069119556948303, 0.48069119556948303, 0.9279797992028646, 0.9279797992028646, 0.9279797992028646, 0.48069119556948303, 0.48069119556948303, 0.6925644014690413, 0.9279797992028646, 0.6925644014690413, 1.5576977130907383, 0.9279797992028646, 0.9725481404259729, 0.48069119556948303, 0.9725481404259729, 1.1398530051024227, 0.9279797992028646, 1.318559567842127, 0.48069119556948303, 0.9279797992028646, 0.6925644014690413, 0.48069119556948303, 0.6925644014690413, 1.1398530051024227, 0.48069119556948303, 0.6888416539542531, 0.9279797992028646, 0.48069119556948303, 0.2415530503208716, 0.9279797992028646, 0.6925644014690413, 0.6888416539542531]\n",
      "all_sum after preprocessing is: [ 0.39113418  0.39113418 -1.06111412  1.07904015  1.07904015  1.21165686\n",
      "  0.39113418 -1.06111412  1.07904015  0.39113418 -1.06111412 -1.06111412\n",
      "  0.39113418 -1.06111412 -0.37320815  0.39113418 -1.06111412  3.12359654\n",
      " -1.06111412 -1.06111412  0.39113418  0.39113418  0.39113418 -1.06111412\n",
      " -1.06111412 -0.37320815  0.39113418 -0.37320815  2.43569056  0.39113418\n",
      "  0.53583784 -1.06111412  0.53583784  1.07904015  0.39113418  1.65926129\n",
      " -1.06111412  0.39113418 -0.37320815 -1.06111412 -0.37320815  1.07904015\n",
      " -1.06111412 -0.3852951   0.39113418 -1.06111412 -1.8375434   0.39113418\n",
      " -0.37320815 -0.3852951 ]\n",
      "P is: [0.5965556993656081, 0.5965556993656081, 0.2570966018511087, 0.7463122979836427, 0.7463122979836427, 0.7705919807217271, 0.5965556993656081, 0.2570966018511087, 0.7463122979836427, 0.5965556993656081, 0.2570966018511087, 0.2570966018511087, 0.5965556993656081, 0.2570966018511087, 0.4077660479110831, 0.5965556993656081, 0.2570966018511087, 0.957855653129125, 0.2570966018511087, 0.2570966018511087, 0.5965556993656081, 0.5965556993656081, 0.5965556993656081, 0.2570966018511087, 0.2570966018511087, 0.4077660479110831, 0.5965556993656081, 0.4077660479110831, 0.9195087117293489, 0.5965556993656081, 0.630843662218246, 0.2570966018511087, 0.630843662218246, 0.7463122979836427, 0.5965556993656081, 0.8401388148523496, 0.2570966018511087, 0.5965556993656081, 0.4077660479110831, 0.2570966018511087, 0.4077660479110831, 0.7463122979836427, 0.2570966018511087, 0.40485042190984494, 0.5965556993656081, 0.2570966018511087, 0.13734209001225242, 0.5965556993656081, 0.4077660479110831, 0.40485042190984494]\n",
      "all_sum before preprocessing is: [2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 3.4210749330352654, 2.152518266916289, 3.4210749330352654, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 2.152518266916289, 3.4210749330352654, 2.152518266916289, 2.152518266916289, 2.152518266916289, 3.4210749330352654, 2.152518266916289, 2.152518266916289, 2.152518266916289, 3.4210749330352654, 2.152518266916289, 3.4210749330352654]\n",
      "all_sum after preprocessing is: [-0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447 -0.36927447  2.7080128  -0.36927447\n",
      "  2.7080128  -0.36927447 -0.36927447 -0.36927447 -0.36927447 -0.36927447\n",
      " -0.36927447 -0.36927447 -0.36927447  2.7080128  -0.36927447 -0.36927447\n",
      " -0.36927447  2.7080128  -0.36927447 -0.36927447 -0.36927447  2.7080128\n",
      " -0.36927447  2.7080128 ]\n",
      "P is: [0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.9374978085838571, 0.40871634611018604, 0.9374978085838571, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.9374978085838571, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.9374978085838571, 0.40871634611018604, 0.40871634611018604, 0.40871634611018604, 0.9374978085838571, 0.40871634611018604, 0.9374978085838571]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.032\n",
      "(*) epoch 2, cost 2.940\n",
      "(*) epoch 3, cost 2.468\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.501\n",
      "(*) epoch 2, cost 1.467\n",
      "(*) epoch 3, cost 0.994\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.629234389426291, 1.629234389426291, 1.629234389426291, 2.8291695686422735, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 2.55646525996144, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 2.7561708955957105, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 2.8291695686422735, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291, 1.629234389426291]\n",
      "all_sum after preprocessing is: [-0.29328715 -0.29328715 -0.29328715  3.6573481  -0.29328715 -0.29328715\n",
      " -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715  2.75950355\n",
      " -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715\n",
      " -0.29328715  3.41700917 -0.29328715 -0.29328715 -0.29328715 -0.29328715\n",
      " -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715\n",
      " -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715\n",
      " -0.29328715 -0.29328715 -0.29328715  3.6573481  -0.29328715 -0.29328715\n",
      " -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715 -0.29328715\n",
      " -0.29328715 -0.29328715]\n",
      "P is: [0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.9748480969267806, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.9404478362825326, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.9682319058547463, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.9748480969267806, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648, 0.4271993093305648]\n",
      "all_sum before preprocessing is: [1.0734028491867644, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 1.0734028491867644, 0.2477664588004622, 1.0734028491867644, 0.2477664588004622, 1.0734028491867644, 0.2477664588004622, 2.3856485581114706, 0.2477664588004622, 1.0734028491867644, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 1.0734028491867644, 2.3856485581114706, 2.999214748245849, 0.2477664588004622, 0.2477664588004622, 1.0734028491867644, 1.0734028491867644, 0.2477664588004622, 1.0734028491867644, 1.0734028491867644, 0.2477664588004622, 1.0734028491867644, 0.2477664588004622, 1.0734028491867644, 0.2477664588004622, 0.2477664588004622, 1.0734028491867644, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 0.2477664588004622, 0.5030944776696008, 1.0734028491867644, 0.2477664588004622, 1.0734028491867644, 1.0734028491867644, 0.2477664588004622, 2.173578357859547, 1.0734028491867644, 1.7189793845870769]\n",
      "all_sum after preprocessing is: [ 0.49925364 -0.74483406 -0.74483406 -0.74483406  0.49925364 -0.74483406\n",
      "  0.49925364 -0.74483406  0.49925364 -0.74483406  2.47657534 -0.74483406\n",
      "  0.49925364 -0.74483406 -0.74483406 -0.74483406 -0.74483406  0.49925364\n",
      "  2.47657534  3.40111084 -0.74483406 -0.74483406  0.49925364  0.49925364\n",
      " -0.74483406  0.49925364  0.49925364 -0.74483406  0.49925364 -0.74483406\n",
      "  0.49925364 -0.74483406 -0.74483406  0.49925364 -0.74483406 -0.74483406\n",
      " -0.74483406 -0.74483406 -0.74483406 -0.74483406 -0.74483406 -0.36009999\n",
      "  0.49925364 -0.74483406  0.49925364  0.49925364 -0.74483406  2.15702314\n",
      "  0.49925364  1.47202306]\n",
      "P is: [0.6222839184694592, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.6222839184694592, 0.3219479732827239, 0.6222839184694592, 0.3219479732827239, 0.6222839184694592, 0.3219479732827239, 0.9224832619607903, 0.3219479732827239, 0.6222839184694592, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.6222839184694592, 0.9224832619607903, 0.9677392338829205, 0.3219479732827239, 0.3219479732827239, 0.6222839184694592, 0.6222839184694592, 0.3219479732827239, 0.6222839184694592, 0.6222839184694592, 0.3219479732827239, 0.6222839184694592, 0.3219479732827239, 0.6222839184694592, 0.3219479732827239, 0.3219479732827239, 0.6222839184694592, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.3219479732827239, 0.4109353610040332, 0.6222839184694592, 0.3219479732827239, 0.6222839184694592, 0.6222839184694592, 0.3219479732827239, 0.8963232413565876, 0.6222839184694592, 0.8133646864117728]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.319\n",
      "(*) epoch 2, cost 1.748\n",
      "(*) epoch 3, cost 1.136\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.553\n",
      "(*) epoch 2, cost 1.234\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7006426416370182, 1.5845541973043311, 3.8921504016305932, 1.5845541973043311, 1.7006426416370182, 3.096964734735602, 1.5845541973043311, 1.5845541973043311, 1.5845541973043311, 1.5845541973043311, 3.213053179068289, 1.435998030986638, 3.096964734735602, 3.096964734735602, 1.5845541973043311, 0.905456974742027, 1.5845541973043311, 1.5845541973043311, 3.8921504016305932, 3.8921504016305932, 1.7006426416370182, 2.0231591688491095, 1.5845541973043311, 1.5845541973043311, 3.8921504016305932, 1.5845541973043311, 1.5845541973043311, 1.1118850576214312, 1.7006426416370182, 3.8921504016305932, 1.435998030986638, 1.7006426416370182, 3.8921504016305932, 0.7893685304093399, 2.231183697881629, 3.8921504016305932, 1.5845541973043311, 1.7006426416370182, 0.905456974742027, 1.5845541973043311, 3.096964734735602, 0.905456974742027, 3.213053179068289, 1.5845541973043311, 0.905456974742027, 3.213053179068289, 4.00823884596328, 1.5845541973043311, 0.7893685304093399, 1.7006426416370182]\n",
      "all_sum after preprocessing is: [-0.40867091 -0.52422021  1.77265892 -0.52422021 -0.40867091  0.98116631\n",
      " -0.52422021 -0.52422021 -0.52422021 -0.52422021  1.0967156  -0.67208644\n",
      "  0.98116631  0.98116631 -0.52422021 -1.20016353 -0.52422021 -0.52422021\n",
      "  1.77265892  1.77265892 -0.40867091 -0.08765223 -0.52422021 -0.52422021\n",
      "  1.77265892 -0.52422021 -0.52422021 -0.99469415 -0.40867091  1.77265892\n",
      " -0.67208644 -0.40867091  1.77265892 -1.31571283  0.11940618  1.77265892\n",
      " -0.52422021 -0.40867091 -1.20016353 -0.52422021  0.98116631 -1.20016353\n",
      "  1.0967156  -0.52422021 -1.20016353  1.0967156   1.88820822 -0.52422021\n",
      " -1.31571283 -0.40867091]\n",
      "P is: [0.3992308552843821, 0.371865938721303, 0.8547880227224036, 0.371865938721303, 0.3992308552843821, 0.7273395754411247, 0.371865938721303, 0.371865938721303, 0.371865938721303, 0.371865938721303, 0.7496442031444484, 0.33802980937181615, 0.7273395754411247, 0.7273395754411247, 0.371865938721303, 0.23144612718033222, 0.371865938721303, 0.371865938721303, 0.8547880227224036, 0.8547880227224036, 0.3992308552843821, 0.47810096123938245, 0.371865938721303, 0.371865938721303, 0.8547880227224036, 0.371865938721303, 0.371865938721303, 0.2699858928832461, 0.3992308552843821, 0.8547880227224036, 0.33802980937181615, 0.3992308552843821, 0.8547880227224036, 0.21153245165381224, 0.529816126985407, 0.8547880227224036, 0.371865938721303, 0.3992308552843821, 0.23144612718033222, 0.371865938721303, 0.7273395754411247, 0.23144612718033222, 0.7496442031444484, 0.371865938721303, 0.23144612718033222, 0.7496442031444484, 0.8685510983992729, 0.371865938721303, 0.21153245165381224, 0.3992308552843821]\n",
      "all_sum before preprocessing is: [2.919930813262426, 2.919930813262426, 4.6794512122545, 2.919930813262426, 3.58950410584214, 3.9929462065929755, 3.5037363553335057, 2.919930813262426, 3.5037363553335057, 3.58950410584214, 2.919930813262426, 2.919930813262426, 2.919930813262426, 4.499087770934255, 3.5037363553335057, 3.5037363553335057, 3.5037363553335057, 2.919930813262426, 2.919930813262426, 3.426072377603706, 2.919930813262426, 2.919930813262426, 2.919930813262426, 2.919930813262426, 2.919930813262426, 2.919930813262426, 2.919930813262426, 4.6625194991726895, 2.919930813262426, 2.919930813262426, 2.919930813262426, 1.9179747950191945, 2.919930813262426, 3.58950410584214, 3.5037363553335057, 4.576751748664055, 3.426072377603706, 4.009877919674786, 2.919930813262426, 2.919930813262426, 2.919930813262426, 2.919930813262426, 4.726707101849606, 2.919930813262426, 2.919930813262426, 2.919930813262426, 2.919930813262426, 3.5037363553335057, 2.919930813262426, 2.919930813262426]\n",
      "all_sum after preprocessing is: [-0.5841638  -0.5841638   2.47244968 -0.5841638   0.57900927  1.27986308\n",
      "  0.43001477 -0.5841638   0.43001477  0.57900927 -0.5841638  -0.5841638\n",
      " -0.5841638   2.15912491  0.43001477  0.43001477  0.43001477 -0.5841638\n",
      " -0.5841638   0.29509803 -0.5841638  -0.5841638  -0.5841638  -0.5841638\n",
      " -0.5841638  -0.5841638  -0.5841638   2.44303615 -0.5841638  -0.5841638\n",
      " -0.5841638  -2.32474735 -0.5841638   0.57900927  0.43001477  2.29404165\n",
      "  0.29509803  1.3092766  -0.5841638  -0.5841638  -0.5841638  -0.5841638\n",
      "  2.55454193 -0.5841638  -0.5841638  -0.5841638  -0.5841638   0.43001477\n",
      " -0.5841638  -0.5841638 ]\n",
      "P is: [0.3579750676406622, 0.3579750676406622, 0.9221877294114145, 0.3579750676406622, 0.6408394084488386, 0.782426467984395, 0.6058771963616393, 0.3579750676406622, 0.6058771963616393, 0.6408394084488386, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.8965183913945641, 0.6058771963616393, 0.6058771963616393, 0.6058771963616393, 0.3579750676406622, 0.3579750676406622, 0.5732437548459355, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.9200507039843836, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.08909402978903262, 0.3579750676406622, 0.6408394084488386, 0.6058771963616393, 0.9083823671625132, 0.5732437548459355, 0.7873920803132141, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.9278780533085812, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.3579750676406622, 0.6058771963616393, 0.3579750676406622, 0.3579750676406622]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.119\n",
      "(*) epoch 2, cost 2.322\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.988\n",
      "(*) epoch 2, cost 3.158\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.30 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [3.1492576534094887, 1.5008196497118584, 0.10710028118324597, 2.9497948619312835, 1.487476467794205, 1.9683442582767352, 1.487476467794205, 4.310114214857917, 2.6483330292426333, 2.6483330292426333, 3.1292008197251637, 4.310114214857917, 3.1492576534094887, 2.9631380438489368, 0.30656307266145144, 2.6483330292426333, 3.1492576534094887, 3.1492576534094887, 1.2679568426316745, 1.7688814667985298, 2.9631380438489368, 2.448870237764428, 1.487476467794205, 0.10710028118324597, 1.9683442582767352, 4.310114214857917, 2.6483330292426333, 3.1492576534094887, 0.30656307266145144, 1.487476467794205, 0.30656307266145144, 1.3013568582336528, 1.9683442582767352, 1.7688814667985298, 0.30656307266145144, 1.9683442582767352, 1.487476467794205, 0.10710028118324597, 0.30656307266145144, 1.2880136763159995, 1.487476467794205, 4.1106514233797125, 0.30656307266145144, 1.2880136763159995, 3.1292008197251637, 2.9497948619312835, 1.487476467794205, 0.30656307266145144, 0.30656307266145144, 3.1492576534094887]\n",
      "all_sum after preprocessing is: [ 9.70219004e-01 -3.81574738e-01 -1.52448767e+00  8.06650491e-01\n",
      " -3.92516751e-01  1.81659293e-03 -3.92516751e-01  1.92217390e+00\n",
      "  5.59438149e-01  5.59438149e-01  9.53771493e-01  1.92217390e+00\n",
      "  9.70219004e-01  8.17592504e-01 -1.36091916e+00  5.59438149e-01\n",
      "  9.70219004e-01  9.70219004e-01 -5.72532775e-01 -1.61751920e-01\n",
      "  8.17592504e-01  3.95869636e-01 -3.92516751e-01 -1.52448767e+00\n",
      "  1.81659293e-03  1.92217390e+00  5.59438149e-01  9.70219004e-01\n",
      " -1.36091916e+00 -3.92516751e-01 -1.36091916e+00 -5.45143251e-01\n",
      "  1.81659293e-03 -1.61751920e-01 -1.36091916e+00  1.81659293e-03\n",
      " -3.92516751e-01 -1.52448767e+00 -1.36091916e+00 -5.56085264e-01\n",
      " -3.92516751e-01  1.75860539e+00 -1.36091916e+00 -5.56085264e-01\n",
      "  9.53771493e-01  8.06650491e-01 -3.92516751e-01 -1.36091916e+00\n",
      " -1.36091916e+00  9.70219004e-01]\n",
      "P is: [0.7251631477310889, 0.4057471456676602, 0.17880163684677736, 0.6913952852516626, 0.40311159131288543, 0.5004541481069964, 0.40311159131288543, 0.8723806561055308, 0.6363225288682441, 0.6363225288682441, 0.7218730227845153, 0.8723806561055308, 0.7251631477310889, 0.6937250565821413, 0.20409095506998323, 0.6363225288682441, 0.7251631477310889, 0.7251631477310889, 0.3606526059260345, 0.4596499570988579, 0.6937250565821413, 0.597694892529885, 0.40311159131288543, 0.17880163684677736, 0.5004541481069964, 0.8723806561055308, 0.6363225288682441, 0.7251631477310889, 0.20409095506998323, 0.40311159131288543, 0.20409095506998323, 0.3669919442294241, 0.5004541481069964, 0.4596499570988579, 0.20409095506998323, 0.5004541481069964, 0.40311159131288543, 0.17880163684677736, 0.20409095506998323, 0.36445373710105144, 0.40311159131288543, 0.8530349091520224, 0.20409095506998323, 0.36445373710105144, 0.7218730227845153, 0.6913952852516626, 0.40311159131288543, 0.20409095506998323, 0.20409095506998323, 0.7251631477310889]\n",
      "all_sum before preprocessing is: [3.092774290786446, 3.092774290786446, 3.944778966148668, 3.092774290786446, 3.944778966148668, 3.092774290786446, 1.7241832255744283, 2.6625449307352493, 3.092774290786446, 3.092774290786446, 3.4159721570472827, 3.092774290786446, 3.092774290786446, 3.092774290786446, 1.7241832255744283, 3.092774290786446, 3.092774290786446, 3.092774290786446, 1.4816679977854041, 2.9050601585242735, 3.944778966148668, 3.7570648338864956, 3.092774290786446, 2.5639674816850606, 4.9435636907121445, 2.5639674816850606, 2.9050601585242735, 2.850259062997422, 2.5761879009366506, 3.944778966148668, 3.092774290786446, 2.850259062997422, 3.092774290786446, 3.944778966148668, 2.6625449307352493, 1.7241832255744283, 3.092774290786446, 1.7241832255744283, 2.5761879009366506, 2.675537830323088, 2.850259062997422, 2.850259062997422, 2.5639674816850606, 3.092774290786446, 3.092774290786446, 2.9050601585242735, 2.9050601585242735, 3.092774290786446, 3.092774290786446, 3.092774290786446]\n",
      "all_sum after preprocessing is: [ 0.18019495  0.18019495  1.54965674  0.18019495  1.54965674  0.18019495\n",
      " -2.01959716 -0.51133021  0.18019495  0.18019495  0.69968404  0.18019495\n",
      "  0.18019495  0.18019495 -2.01959716  0.18019495  0.18019495  0.18019495\n",
      " -2.40940176 -0.12152561  1.54965674  1.24793618  0.18019495 -0.66977775\n",
      "  3.15504408 -0.66977775 -0.12152561 -0.20960964 -0.65013537  1.54965674\n",
      "  0.18019495 -0.20960964  0.18019495  1.54965674 -0.51133021 -2.01959716\n",
      "  0.18019495 -2.01959716 -0.65013537 -0.49044619 -0.20960964 -0.20960964\n",
      " -0.66977775  0.18019495  0.18019495 -0.12152561 -0.12152561  0.18019495\n",
      "  0.18019495  0.18019495]\n",
      "P is: [0.5449272376534404, 0.5449272376534404, 0.8248641491843693, 0.5449272376534404, 0.8248641491843693, 0.5449272376534404, 0.11716065151834615, 0.3748817460231882, 0.5449272376534404, 0.5449272376534404, 0.6681177153792784, 0.5449272376534404, 0.5449272376534404, 0.5449272376534404, 0.11716065151834615, 0.5449272376534404, 0.5449272376534404, 0.5449272376534404, 0.08245856930006111, 0.46965593276852646, 0.8248641491843693, 0.7769423992313375, 0.5449272376534404, 0.33854660773114975, 0.959107013064614, 0.33854660773114975, 0.46965593276852646, 0.4477886138891969, 0.34295903167522895, 0.8248641491843693, 0.5449272376534404, 0.4477886138891969, 0.5449272376534404, 0.8248641491843693, 0.3748817460231882, 0.11716065151834615, 0.5449272376534404, 0.11716065151834615, 0.34295903167522895, 0.37978846241808223, 0.4477886138891969, 0.4477886138891969, 0.33854660773114975, 0.5449272376534404, 0.5449272376534404, 0.46965593276852646, 0.46965593276852646, 0.5449272376534404, 0.5449272376534404, 0.5449272376534404]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.979\n",
      "(*) epoch 2, cost 2.728\n",
      "(*) epoch 3, cost 2.358\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.063\n",
      "(*) epoch 2, cost 3.306\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.735362059395195, 2.6238936116372424, 2.735362059395195, 2.6238936116372424, 2.6238936116372424, 2.6238936116372424, 2.735362059395195, 2.735362059395195, 2.6238936116372424, 1.5503399204463266, 2.6238936116372424, 2.735362059395195, 2.735362059395195, 2.6238936116372424, 2.735362059395195, 2.735362059395195, 2.735362059395195, 2.6238936116372424, 2.6238936116372424, 1.6618083682042792, 2.6238936116372424, 2.735362059395195, 2.6238936116372424, 2.735362059395195, 2.735362059395195, 2.6238936116372424, 2.6238936116372424, 2.735362059395195, 2.6238936116372424, 2.6238936116372424, 2.6238936116372424, 2.6238936116372424, 2.735362059395195, 2.6238936116372424, 2.6238936116372424, 2.735362059395195, 2.6238936116372424, 2.735362059395195, 2.735362059395195, 2.6238936116372424, 2.6238936116372424, 2.735362059395195, 2.735362059395195, 2.6238936116372424, 2.735362059395195, 2.735362059395195, 2.6238936116372424, 2.6238936116372424, 2.735362059395195, 2.6238936116372424]\n",
      "all_sum after preprocessing is: [ 0.47592854 -0.03845512  0.47592854 -0.03845512 -0.03845512 -0.03845512\n",
      "  0.47592854  0.47592854 -0.03845512 -4.99248911 -0.03845512  0.47592854\n",
      "  0.47592854 -0.03845512  0.47592854  0.47592854  0.47592854 -0.03845512\n",
      " -0.03845512 -4.47810545 -0.03845512  0.47592854 -0.03845512  0.47592854\n",
      "  0.47592854 -0.03845512 -0.03845512  0.47592854 -0.03845512 -0.03845512\n",
      " -0.03845512 -0.03845512  0.47592854 -0.03845512 -0.03845512  0.47592854\n",
      " -0.03845512  0.47592854  0.47592854 -0.03845512 -0.03845512  0.47592854\n",
      "  0.47592854 -0.03845512  0.47592854  0.47592854 -0.03845512 -0.03845512\n",
      "  0.47592854 -0.03845512]\n",
      "P is: [0.6167859981563282, 0.4903874033439687, 0.6167859981563282, 0.4903874033439687, 0.4903874033439687, 0.4903874033439687, 0.6167859981563282, 0.6167859981563282, 0.4903874033439687, 0.006742969213728594, 0.4903874033439687, 0.6167859981563282, 0.6167859981563282, 0.4903874033439687, 0.6167859981563282, 0.6167859981563282, 0.6167859981563282, 0.4903874033439687, 0.4903874033439687, 0.011227418971699953, 0.4903874033439687, 0.6167859981563282, 0.4903874033439687, 0.6167859981563282, 0.6167859981563282, 0.4903874033439687, 0.4903874033439687, 0.6167859981563282, 0.4903874033439687, 0.4903874033439687, 0.4903874033439687, 0.4903874033439687, 0.6167859981563282, 0.4903874033439687, 0.4903874033439687, 0.6167859981563282, 0.4903874033439687, 0.6167859981563282, 0.6167859981563282, 0.4903874033439687, 0.4903874033439687, 0.6167859981563282, 0.6167859981563282, 0.4903874033439687, 0.6167859981563282, 0.6167859981563282, 0.4903874033439687, 0.4903874033439687, 0.6167859981563282, 0.4903874033439687]\n",
      "all_sum before preprocessing is: [1.660245975729151, 2.8024840401382773, 2.4475015389200947, 2.4475015389200947, 2.8024840401382773, 2.4475015389200947, 2.4475015389200947, 2.8024840401382773, 2.4475015389200947, 1.660245975729151, 1.660245975729151, 2.8024840401382773, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.8024840401382773, 2.8024840401382773, 2.4475015389200947, 1.660245975729151, 1.660245975729151, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.8024840401382773, 2.4475015389200947, 2.8024840401382773, 2.8024840401382773, 2.8024840401382773, 2.8024840401382773, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.8024840401382773, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947, 2.8024840401382773, 2.8024840401382773, 2.4475015389200947, 2.4475015389200947, 2.4475015389200947]\n",
      "all_sum after preprocessing is: [-2.59632145  1.07433708 -0.06642296 -0.06642296  1.07433708 -0.06642296\n",
      " -0.06642296  1.07433708 -0.06642296 -2.59632145 -2.59632145  1.07433708\n",
      " -0.06642296 -0.06642296 -0.06642296 -0.06642296 -0.06642296  1.07433708\n",
      "  1.07433708 -0.06642296 -2.59632145 -2.59632145 -0.06642296 -0.06642296\n",
      " -0.06642296 -0.06642296 -0.06642296 -0.06642296  1.07433708 -0.06642296\n",
      "  1.07433708  1.07433708  1.07433708  1.07433708 -0.06642296 -0.06642296\n",
      " -0.06642296 -0.06642296 -0.06642296 -0.06642296  1.07433708 -0.06642296\n",
      " -0.06642296 -0.06642296 -0.06642296  1.07433708  1.07433708 -0.06642296\n",
      " -0.06642296 -0.06642296]\n",
      "P is: [0.06937554108883749, 0.7454208335150985, 0.4834003616355463, 0.4834003616355463, 0.7454208335150985, 0.4834003616355463, 0.4834003616355463, 0.7454208335150985, 0.4834003616355463, 0.06937554108883749, 0.06937554108883749, 0.7454208335150985, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.7454208335150985, 0.7454208335150985, 0.4834003616355463, 0.06937554108883749, 0.06937554108883749, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.7454208335150985, 0.4834003616355463, 0.7454208335150985, 0.7454208335150985, 0.7454208335150985, 0.7454208335150985, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.7454208335150985, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463, 0.7454208335150985, 0.7454208335150985, 0.4834003616355463, 0.4834003616355463, 0.4834003616355463]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.107\n",
      "(*) epoch 2, cost 2.941\n",
      "(*) epoch 3, cost 1.965\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.544\n",
      "(*) epoch 2, cost 1.665\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.8545998490748126, 3.7666961256013436, 4.678797148735715, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.119355173222984, 3.7666961256013436, 3.7666961256013436, 4.678797148735715, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.8545998490748126, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 4.487799326512168, 3.8545998490748126, 4.487799326512168, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 4.575703049985638, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 4.487799326512168, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 4.487799326512168, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436, 3.7666961256013436]\n",
      "all_sum after preprocessing is: [-0.05030792 -0.34959179  2.75581845 -0.34959179 -0.34959179 -0.34959179\n",
      " -0.34959179 -2.55357925 -0.34959179 -0.34959179  2.75581845 -0.34959179\n",
      " -0.34959179 -0.34959179 -0.34959179 -0.34959179 -0.05030792 -0.34959179\n",
      " -0.34959179 -0.34959179 -0.34959179  2.10553238 -0.05030792  2.10553238\n",
      " -0.34959179 -0.34959179 -0.34959179 -0.34959179 -0.34959179  2.40481624\n",
      " -0.34959179 -0.34959179 -0.34959179 -0.34959179  2.10553238 -0.34959179\n",
      " -0.34959179 -0.34959179 -0.34959179  2.10553238 -0.34959179 -0.34959179\n",
      " -0.34959179 -0.34959179 -0.34959179 -0.34959179 -0.34959179 -0.34959179\n",
      " -0.34959179 -0.34959179]\n",
      "P is: [0.4874256725391115, 0.4134814154970163, 0.9402411140032019, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.07218639610707803, 0.4134814154970163, 0.4134814154970163, 0.9402411140032019, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4874256725391115, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.8914397346488773, 0.4874256725391115, 0.8914397346488773, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.9171938296216733, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.8914397346488773, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.8914397346488773, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163, 0.4134814154970163]\n",
      "all_sum before preprocessing is: [3.3942146254373693, 1.9972108013299645, 1.9972108013299645, 1.9972108013299645, 1.9972108013299645, 1.2261663080581904, 1.2261663080581904, 1.2261663080581904, 1.9972108013299645, 1.2261663080581904, 1.2261663080581904, 1.2261663080581904, 1.9972108013299645, 1.2261663080581904, 1.2261663080581904, 1.2261663080581904, 2.195202197670801, 1.2261663080581904, 1.9972108013299645, 1.9972108013299645, 1.2261663080581904, 1.9972108013299645, 2.195202197670801, 1.3504328674884325, 2.1214773607602067, 1.2261663080581904, 3.8714474388892715, 1.2261663080581904, 1.3504328674884325, 1.3504328674884325, 1.9972108013299645, 1.2261663080581904, 1.2261663080581904, 2.539555600010321, 1.9972108013299645, 1.2261663080581904, 1.2261663080581904, 1.3504328674884325, 1.2261663080581904, 1.3504328674884325, 1.2261663080581904, 2.4544427409443976, 1.3504328674884325, 1.2261663080581904, 1.2261663080581904, 1.2261663080581904, 1.2261663080581904, 1.2261663080581904, 1.2261663080581904, 1.6442445473083047]\n",
      "all_sum after preprocessing is: [ 3.07882697  0.65069787  0.65069787  0.65069787  0.65069787 -0.68945277\n",
      " -0.68945277 -0.68945277  0.65069787 -0.68945277 -0.68945277 -0.68945277\n",
      "  0.65069787 -0.68945277 -0.68945277 -0.68945277  0.99482626 -0.68945277\n",
      "  0.65069787  0.65069787 -0.68945277  0.65069787  0.99482626 -0.47346535\n",
      "  0.86668529 -0.68945277  3.90830422 -0.68945277 -0.47346535 -0.47346535\n",
      "  0.65069787 -0.68945277 -0.68945277  1.59334611  0.65069787 -0.68945277\n",
      " -0.68945277 -0.47346535 -0.68945277 -0.47346535 -0.68945277  1.44541164\n",
      " -0.47346535 -0.68945277 -0.68945277 -0.68945277 -0.68945277 -0.68945277\n",
      " -0.68945277  0.03720805]\n",
      "P is: [0.9560108803425602, 0.6571677091699646, 0.6571677091699646, 0.6571677091699646, 0.6571677091699646, 0.3341548182739236, 0.3341548182739236, 0.3341548182739236, 0.6571677091699646, 0.3341548182739236, 0.3341548182739236, 0.3341548182739236, 0.6571677091699646, 0.3341548182739236, 0.3341548182739236, 0.3341548182739236, 0.7300401438629283, 0.3341548182739236, 0.6571677091699646, 0.6571677091699646, 0.3341548182739236, 0.6571677091699646, 0.7300401438629283, 0.38379636986855126, 0.70405550792439, 0.3341548182739236, 0.9803205413037246, 0.3341548182739236, 0.38379636986855126, 0.38379636986855126, 0.6571677091699646, 0.3341548182739236, 0.3341548182739236, 0.831086355997533, 0.6571677091699646, 0.3341548182739236, 0.3341548182739236, 0.38379636986855126, 0.3341548182739236, 0.38379636986855126, 0.3341548182739236, 0.8092912767798749, 0.38379636986855126, 0.3341548182739236, 0.3341548182739236, 0.3341548182739236, 0.3341548182739236, 0.3341548182739236, 0.3341548182739236, 0.5093009383928528]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.665\n",
      "(*) epoch 2, cost 1.934\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.202\n",
      "(*) epoch 2, cost 1.357\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.7237013475558194, 2.7237013475558194, 1.0255451447375252, 1.0255451447375252, 0.3064492061757771, 3.236302278550539, 2.7237013475558194, 0.8190501371704967, 1.5381460757322447, 3.4427972861175675, 1.5381460757322447, 2.7237013475558194, 1.0255451447375252, 0.8190501371704967, 0.3064492061757771, 3.236302278550539, 2.7237013475558194, 1.0255451447375252, 3.236302278550539, 1.0255451447375252, 0.3064492061757771, 1.5381460757322447, 0.3064492061757771, 3.4427972861175675, 2.7237013475558194, 0.8190501371704967, 2.7237013475558194, 2.7237013475558194, 1.0255451447375252, 3.4427972861175675, 2.7237013475558194, 2.7237013475558194, 0.3064492061757771, 0.3064492061757771, 2.7237013475558194, 0.8190501371704967, 3.4427972861175675, 0.3064492061757771, 1.0255451447375252, 2.7237013475558194, 2.7237013475558194, 3.236302278550539, 3.4427972861175675, 0.3064492061757771, 1.5381460757322447, 3.4427972861175675, 2.7237013475558194, 0.8190501371704967, 0.3064492061757771, 3.236302278550539]\n",
      "all_sum after preprocessing is: [ 0.70741034  0.70741034 -0.75650102 -0.75650102 -1.37640437  1.14930275\n",
      "  0.70741034 -0.93451196 -0.31460861  1.32731369 -0.31460861  0.70741034\n",
      " -0.75650102 -0.93451196 -1.37640437  1.14930275  0.70741034 -0.75650102\n",
      "  1.14930275 -0.75650102 -1.37640437 -0.31460861 -1.37640437  1.32731369\n",
      "  0.70741034 -0.93451196  0.70741034  0.70741034 -0.75650102  1.32731369\n",
      "  0.70741034  0.70741034 -1.37640437 -1.37640437  0.70741034 -0.93451196\n",
      "  1.32731369 -1.37640437 -0.75650102  0.70741034  0.70741034  1.14930275\n",
      "  1.32731369 -1.37640437 -0.31460861  1.32731369  0.70741034 -0.93451196\n",
      " -1.37640437  1.14930275]\n",
      "P is: [0.6698286879891424, 0.6698286879891424, 0.31940641462687813, 0.31940641462687813, 0.20158709529767938, 0.7593835377865612, 0.6698286879891424, 0.28201023257154667, 0.42199022885319576, 0.7903959404949158, 0.42199022885319576, 0.6698286879891424, 0.31940641462687813, 0.28201023257154667, 0.20158709529767938, 0.7593835377865612, 0.6698286879891424, 0.31940641462687813, 0.7593835377865612, 0.31940641462687813, 0.20158709529767938, 0.42199022885319576, 0.20158709529767938, 0.7903959404949158, 0.6698286879891424, 0.28201023257154667, 0.6698286879891424, 0.6698286879891424, 0.31940641462687813, 0.7903959404949158, 0.6698286879891424, 0.6698286879891424, 0.20158709529767938, 0.20158709529767938, 0.6698286879891424, 0.28201023257154667, 0.7903959404949158, 0.20158709529767938, 0.31940641462687813, 0.6698286879891424, 0.6698286879891424, 0.7593835377865612, 0.7903959404949158, 0.20158709529767938, 0.42199022885319576, 0.7903959404949158, 0.6698286879891424, 0.28201023257154667, 0.20158709529767938, 0.7593835377865612]\n",
      "all_sum before preprocessing is: [2.0960111263309025, 2.0960111263309025, 2.6646504011689522, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.6646504011689522, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.63916016410543, 2.6646504011689522, 2.0960111263309025, 2.0960111263309025, 3.986250174809137, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.6646504011689522, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.0960111263309025, 2.6646504011689522, 2.0960111263309025, 2.0960111263309025]\n",
      "all_sum after preprocessing is: [-0.33615226 -0.33615226  1.47514611 -0.33615226 -0.33615226 -0.33615226\n",
      " -0.33615226 -0.33615226 -0.33615226 -0.33615226 -0.33615226 -0.33615226\n",
      " -0.33615226 -0.33615226 -0.33615226  1.47514611 -0.33615226 -0.33615226\n",
      " -0.33615226 -0.33615226 -0.33615226 -0.33615226 -0.33615226 -0.33615226\n",
      " -0.33615226 -0.33615226  1.39395153  1.47514611 -0.33615226 -0.33615226\n",
      "  5.68486502 -0.33615226 -0.33615226 -0.33615226 -0.33615226 -0.33615226\n",
      " -0.33615226 -0.33615226 -0.33615226 -0.33615226  1.47514611 -0.33615226\n",
      " -0.33615226 -0.33615226 -0.33615226 -0.33615226 -0.33615226  1.47514611\n",
      " -0.33615226 -0.33615226]\n",
      "P is: [0.4167444413499869, 0.4167444413499869, 0.8138383092018788, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.8138383092018788, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.8012223334256404, 0.8138383092018788, 0.4167444413499869, 0.4167444413499869, 0.996614508740993, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.8138383092018788, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.4167444413499869, 0.8138383092018788, 0.4167444413499869, 0.4167444413499869]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.500\n",
      "(*) epoch 2, cost 2.001\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.513\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [0.9664598381827468, 2.7146655826226644, 3.4914271893294133, 0.9664598381827468, 0.9622081510886594, 4.057508305060296, 6.134324978365789, 2.7146655826226644, 4.390370921019958, 3.0432765114882394, 4.791482255928157, 4.057508305060296, 2.7146655826226644, 1.747473131983583, 2.7146655826226644, 4.7957339430222445, 3.047528198582327, 4.7957339430222445, 5.57674723682308, 4.7957339430222445, 4.7957339430222445, 4.057508305060296, 4.390370921019958, 6.138576665459875, 4.791482255928157, 4.057508305060296, 6.138576665459875, 2.7146655826226644, 3.047528198582327, 4.386119233925871, 4.7957339430222445, 3.3371806549150635, 4.7957339430222445, 2.7146655826226644, 4.057508305060296, 2.7146655826226644, 0.9664598381827468, 2.7146655826226644, 6.138576665459875, 0.9664598381827468, 6.138576665459875, 4.7957339430222445, 2.7146655826226644, 4.390370921019958, 4.791482255928157, 4.7957339430222445, 2.7146655826226644, 3.4914271893294133, 3.4956788764235007, 2.3093025606203783]\n",
      "all_sum after preprocessing is: [-1.91320591 -0.69707454 -0.15672387 -1.91320591 -1.91616357  0.23706788\n",
      "  1.68179594 -0.69707454  0.46862224 -0.46847785  0.74765352  0.23706788\n",
      " -0.69707454 -1.36989757 -0.69707454  0.75061118 -0.46552018  0.75061118\n",
      "  1.29391952  0.75061118  0.75061118  0.23706788  0.46862224  1.68475361\n",
      "  0.74765352  0.23706788  1.68475361 -0.69707454 -0.46552018  0.46566458\n",
      "  0.75061118 -0.26402477  0.75061118 -0.69707454  0.23706788 -0.69707454\n",
      " -1.91320591 -0.69707454  1.68475361 -1.91320591  1.68475361  0.75061118\n",
      " -0.69707454  0.46862224  0.74765352  0.75061118 -0.69707454 -0.15672387\n",
      " -0.1537662  -0.97906348]\n",
      "P is: [0.12862111339128438, 0.33246115804111775, 0.4608990342155331, 0.12862111339128438, 0.12828998879007025, 0.5589909484149054, 0.8431421967065599, 0.33246115804111775, 0.6150576079655663, 0.3849765799111288, 0.6786671972560903, 0.5589909484149054, 0.33246115804111775, 0.20263639661623375, 0.33246115804111775, 0.6793118582713316, 0.3856771033332791, 0.6793118582713316, 0.7848098702869751, 0.6793118582713316, 0.6793118582713316, 0.5589909484149054, 0.6150576079655663, 0.8435329614169398, 0.6786671972560903, 0.5589909484149054, 0.8435329614169398, 0.33246115804111775, 0.3856771033332791, 0.6143571077454134, 0.6793118582713316, 0.4343745895390507, 0.6793118582713316, 0.33246115804111775, 0.5589909484149054, 0.33246115804111775, 0.12862111339128438, 0.33246115804111775, 0.8435329614169398, 0.12862111339128438, 0.8435329614169398, 0.6793118582713316, 0.33246115804111775, 0.6150576079655663, 0.6786671972560903, 0.6793118582713316, 0.33246115804111775, 0.4608990342155331, 0.46163401343491234, 0.2730776485445221]\n",
      "all_sum before preprocessing is: [4.095185556441424, 4.095185556441424, 3.7360990162263383, 4.095185556441424, 3.7360990162263383, 2.48349866568808, 4.095185556441424, 3.7360990162263383, 2.48349866568808, 4.095185556441424, 4.095185556441424, 2.48349866568808, 3.7360990162263383, 4.095185556441424, 4.095185556441424, 4.095185556441424, 2.124412125472994, 4.095185556441424, 3.7360990162263383, 4.095185556441424, 3.7360990162263383, 2.48349866568808, 4.095185556441424, 4.095185556441424, 4.095185556441424, 3.7360990162263383, 3.7360990162263383, 4.095185556441424, 2.48349866568808, 4.095185556441424, 4.095185556441424, 3.7360990162263383, 4.095185556441424, 3.7360990162263383, 4.095185556441424, 4.095185556441424, 4.095185556441424, 4.095185556441424, 4.095185556441424, 4.095185556441424, 3.652665020320113, 4.095185556441424, 4.095185556441424, 4.095185556441424, 4.095185556441424, 2.48349866568808, 2.48349866568808, 2.124412125472994, 4.095185556441424, 3.7360990162263383]\n",
      "all_sum after preprocessing is: [ 0.62234497  0.62234497  0.05271389  0.62234497  0.05271389 -1.93432828\n",
      "  0.62234497  0.05271389 -1.93432828  0.62234497  0.62234497 -1.93432828\n",
      "  0.05271389  0.62234497  0.62234497  0.62234497 -2.50395937  0.62234497\n",
      "  0.05271389  0.62234497  0.05271389 -1.93432828  0.62234497  0.62234497\n",
      "  0.62234497  0.05271389  0.05271389  0.62234497 -1.93432828  0.62234497\n",
      "  0.62234497  0.05271389  0.62234497  0.05271389  0.62234497  0.62234497\n",
      "  0.62234497  0.62234497  0.62234497  0.62234497 -0.07964027  0.62234497\n",
      "  0.62234497  0.62234497  0.62234497 -1.93432828 -1.93432828 -2.50395937\n",
      "  0.62234497  0.05271389]\n",
      "P is: [0.6507516881824472, 0.6507516881824472, 0.5131754210445871, 0.6507516881824472, 0.5131754210445871, 0.1262722780760603, 0.6507516881824472, 0.5131754210445871, 0.1262722780760603, 0.6507516881824472, 0.6507516881824472, 0.1262722780760603, 0.5131754210445871, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.07558107918497628, 0.6507516881824472, 0.5131754210445871, 0.6507516881824472, 0.5131754210445871, 0.1262722780760603, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.5131754210445871, 0.5131754210445871, 0.6507516881824472, 0.1262722780760603, 0.6507516881824472, 0.6507516881824472, 0.5131754210445871, 0.6507516881824472, 0.5131754210445871, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.4801004483650063, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.6507516881824472, 0.1262722780760603, 0.1262722780760603, 0.07558107918497628, 0.6507516881824472, 0.5131754210445871]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.034\n",
      "(*) epoch 2, cost 3.334\n",
      "(*) epoch 3, cost 2.686\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.268\n",
      "(*) epoch 2, cost 2.474\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.340261697808663, 3.340261697808663, 3.025410990314977, 4.633924464359023, 3.025410990314977, 3.340261697808663, 3.340261697808663, 3.340261697808663, 3.2349622995968823, 4.319073756865338, 5.898841261021305, 3.340261697808663, 3.340261697808663, 3.340261697808663, 3.025410990314977, 4.633924464359023, 3.2349622995968823, 3.340261697808663, 3.340261697808663, 4.633924464359023, 3.340261697808663, 3.340261697808663, 3.025410990314977, 3.340261697808663, 4.633924464359023, 3.340261697808663, 5.898841261021305, 3.340261697808663, 3.340261697808663, 3.340261697808663, 4.633924464359023, 4.605178494470945, 5.898841261021305, 3.340261697808663, 3.2349622995968823, 3.340261697808663, 3.340261697808663, 4.633924464359023, 3.340261697808663, 4.633924464359023, 3.340261697808663, 4.319073756865338, 4.319073756865338, 3.340261697808663, 3.025410990314977, 3.340261697808663, 3.025410990314977, 3.340261697808663, 3.340261697808663, 6.593261590038939]\n",
      "all_sum after preprocessing is: [-0.50847015 -0.50847015 -0.87263503  0.98781534 -0.87263503 -0.50847015\n",
      " -0.50847015 -0.50847015 -0.63026229  0.62365046  2.45085246 -0.50847015\n",
      " -0.50847015 -0.50847015 -0.87263503  0.98781534 -0.63026229 -0.50847015\n",
      " -0.50847015  0.98781534 -0.50847015 -0.50847015 -0.87263503 -0.50847015\n",
      "  0.98781534 -0.50847015  2.45085246 -0.50847015 -0.50847015 -0.50847015\n",
      "  0.98781534  0.95456697  2.45085246 -0.50847015 -0.63026229 -0.50847015\n",
      " -0.50847015  0.98781534 -0.50847015  0.98781534 -0.50847015  0.62365046\n",
      "  0.62365046 -0.50847015 -0.87263503 -0.50847015 -0.87263503 -0.50847015\n",
      " -0.50847015  3.25403787]\n",
      "P is: [0.3755522262559524, 0.3755522262559524, 0.2947063029141404, 0.7286561952462619, 0.2947063029141404, 0.3755522262559524, 0.3755522262559524, 0.3755522262559524, 0.347451065607922, 0.6510483329230968, 0.9206237673730786, 0.3755522262559524, 0.3755522262559524, 0.3755522262559524, 0.2947063029141404, 0.7286561952462619, 0.347451065607922, 0.3755522262559524, 0.3755522262559524, 0.7286561952462619, 0.3755522262559524, 0.3755522262559524, 0.2947063029141404, 0.3755522262559524, 0.7286561952462619, 0.3755522262559524, 0.9206237673730786, 0.3755522262559524, 0.3755522262559524, 0.3755522262559524, 0.7286561952462619, 0.7220327045959543, 0.9206237673730786, 0.3755522262559524, 0.347451065607922, 0.3755522262559524, 0.3755522262559524, 0.7286561952462619, 0.3755522262559524, 0.7286561952462619, 0.3755522262559524, 0.6510483329230968, 0.6510483329230968, 0.3755522262559524, 0.2947063029141404, 0.3755522262559524, 0.2947063029141404, 0.3755522262559524, 0.3755522262559524, 0.962817937238748]\n",
      "all_sum before preprocessing is: [3.116222559700871, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 3.213180397869604, 1.7877703556666695, 1.7877703556666695, 3.213180397869604, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 3.116222559700871, 1.7877703556666695, 1.7877703556666695, 1.884728193835402, 1.884728193835402, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 1.7877703556666695, 3.116222559700871, 3.116222559700871]\n",
      "all_sum after preprocessing is: [ 2.6305635  -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969\n",
      " -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969\n",
      " -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969\n",
      " -0.37867969 -0.37867969 -0.37867969 -0.37867969  2.85019482 -0.37867969\n",
      " -0.37867969  2.85019482 -0.37867969 -0.37867969 -0.37867969 -0.37867969\n",
      " -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969\n",
      " -0.37867969  2.6305635  -0.37867969 -0.37867969 -0.15904837 -0.15904837\n",
      " -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969 -0.37867969\n",
      "  2.6305635   2.6305635 ]\n",
      "P is: [0.9328028791583073, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.9453287525279417, 0.40644537959456534, 0.40644537959456534, 0.9453287525279417, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.9328028791583073, 0.40644537959456534, 0.40644537959456534, 0.4603215167200408, 0.4603215167200408, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.40644537959456534, 0.9328028791583073, 0.9328028791583073]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.256\n",
      "(*) epoch 2, cost 3.390\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.326\n",
      "(*) epoch 2, cost 1.931\n",
      "(*) epoch 3, cost 1.477\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.63195030290265, 4.071235997852087, 3.742185827607004, 3.742185827607004, 3.742185827607004, 3.6009022564808335, 5.04018795143027, 2.63195030290265, 3.742185827607004, 5.04018795143027, 5.181471522556441, 2.63195030290265, 2.63195030290265, 3.742185827607004, 2.63195030290265, 2.63195030290265, 3.6009022564808335, 3.742185827607004, 2.63195030290265, 3.742185827607004, 3.742185827607004, 3.742185827607004, 3.742185827607004, 5.04018795143027, 2.63195030290265, 5.181471522556441, 2.63195030290265, 3.742185827607004, 3.6009022564808335, 3.6009022564808335, 3.742185827607004, 4.071235997852087, 3.6009022564808335, 3.6009022564808335, 3.6009022564808335, 2.63195030290265, 2.63195030290265, 5.181471522556441, 3.6009022564808335, 2.63195030290265, 2.4906667317764795, 2.63195030290265, 3.929952426725916, 2.63195030290265, 3.6009022564808335, 2.63195030290265, 3.742185827607004, 3.742185827607004, 5.290393843600225, 3.6009022564808335]\n",
      "all_sum after preprocessing is: [-1.1582004   0.62276908  0.215603    0.215603    0.215603    0.04077897\n",
      "  1.82174844 -1.1582004   0.215603    1.82174844  1.99657247 -1.1582004\n",
      " -1.1582004   0.215603   -1.1582004  -1.1582004   0.04077897  0.215603\n",
      " -1.1582004   0.215603    0.215603    0.215603    0.215603    1.82174844\n",
      " -1.1582004   1.99657247 -1.1582004   0.215603    0.04077897  0.04077897\n",
      "  0.215603    0.62276908  0.04077897  0.04077897  0.04077897 -1.1582004\n",
      " -1.1582004   1.99657247  0.04077897 -1.1582004  -1.33302443 -1.1582004\n",
      "  0.44794504 -1.1582004   0.04077897 -1.1582004   0.215603    0.215603\n",
      "  2.13135275  0.04077897]\n",
      "P is: [0.23899443606638565, 0.6508480694383627, 0.5536929196129994, 0.5536929196129994, 0.5536929196129994, 0.510193329714914, 0.860775794050717, 0.23899443606638565, 0.5536929196129994, 0.860775794050717, 0.880436739762506, 0.23899443606638565, 0.23899443606638565, 0.5536929196129994, 0.23899443606638565, 0.23899443606638565, 0.510193329714914, 0.5536929196129994, 0.23899443606638565, 0.5536929196129994, 0.5536929196129994, 0.5536929196129994, 0.5536929196129994, 0.860775794050717, 0.23899443606638565, 0.880436739762506, 0.23899443606638565, 0.5536929196129994, 0.510193329714914, 0.510193329714914, 0.5536929196129994, 0.6508480694383627, 0.510193329714914, 0.510193329714914, 0.510193329714914, 0.23899443606638565, 0.23899443606638565, 0.880436739762506, 0.510193329714914, 0.23899443606638565, 0.20865952927384657, 0.23899443606638565, 0.6101505390129495, 0.23899443606638565, 0.510193329714914, 0.23899443606638565, 0.5536929196129994, 0.5536929196129994, 0.8939133613998915, 0.510193329714914]\n",
      "all_sum before preprocessing is: [2.8425512734551663, 2.401873864244486, 3.0854498452884878, 1.7178475725008533, 1.4128523487650142, 2.401873864244486, 2.401873864244486, 2.8784642974821644, 2.635565725648843, 2.8425512734551663, 2.8425512734551663, 2.6084091013511785, 2.8425512734551663, 3.526127254499168, 1.7178475725008533, 2.8425512734551663, 2.1948883164381625, 2.8425512734551663, 2.635565725648843, 2.8425512734551663, 2.365510529517857, 1.4128523487650142, 2.635565725648843, 2.842100962755536, 2.365510529517857, 3.0120587141861406, 2.8425512734551663, 2.635565725648843, 1.8898930927023234, 2.6458945491138937, 2.365510529517857, 2.365510529517857, 2.401873864244486, 2.1585249817115337, 3.0854498452884878, 2.8425512734551663, 1.8898930927023234, 2.6084091013511785, 2.8425512734551663, 1.9248331203071767, 2.8425512734551663, 2.57138130497546, 3.3191417066928453, 1.4492156834916428, 2.6458945491138937, 2.401873864244486, 2.365510529517857, 2.401873864244486, 2.8425512734551663, 2.401873864244486]\n",
      "all_sum after preprocessing is: [ 0.70516996 -0.2517814   1.23263543 -1.73717611 -2.39948733 -0.2517814\n",
      " -0.2517814   0.78315675  0.25569127  0.70516996  0.70516996  0.19671941\n",
      "  0.70516996  2.18958679 -1.73717611  0.70516996 -0.70126009  0.70516996\n",
      "  0.25569127  0.70516996 -0.33074607 -2.39948733  0.25569127  0.70419209\n",
      " -0.33074607  1.0732632   0.70516996  0.25569127 -1.36357131  0.27812079\n",
      " -0.33074607 -0.33074607 -0.2517814  -0.78022475  1.23263543  0.70516996\n",
      " -1.36357131  0.19671941  0.70516996 -1.28769743  0.70516996  0.11631184\n",
      "  1.74010811 -2.32052267  0.27812079 -0.2517814  -0.33074607 -0.2517814\n",
      "  0.70516996 -0.2517814 ]\n",
      "P is: [0.669333019592224, 0.43738508358592904, 0.7742795033012978, 0.1496719765623219, 0.08321179835040533, 0.43738508358592904, 0.43738508358592904, 0.6863600661529902, 0.5635768178840787, 0.669333019592224, 0.669333019592224, 0.5490218644963283, 0.669333019592224, 0.8993104959779727, 0.1496719765623219, 0.669333019592224, 0.33153290962873155, 0.669333019592224, 0.5635768178840787, 0.669333019592224, 0.418059104953953, 0.08321179835040533, 0.5635768178840787, 0.6691165552796425, 0.418059104953953, 0.7452169902377825, 0.669333019592224, 0.5635768178840787, 0.20366048384590865, 0.5690854506489855, 0.418059104953953, 0.418059104953953, 0.43738508358592904, 0.31427144962586684, 0.7742795033012978, 0.669333019592224, 0.20366048384590865, 0.5490218644963283, 0.669333019592224, 0.21624280042134308, 0.669333019592224, 0.5290452220130458, 0.8507007965703596, 0.08943748477274699, 0.5690854506489855, 0.43738508358592904, 0.418059104953953, 0.43738508358592904, 0.669333019592224, 0.43738508358592904]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.037\n",
      "(*) epoch 2, cost 2.230\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.941\n",
      "(*) epoch 2, cost 4.147\n",
      "(*) epoch 3, cost 3.524\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.671960497309397, 2.077298197485592, 2.077298197485592, 3.2101075491500124, 2.85697005603426, 2.671960497309397, 2.077298197485592, 3.4516323558580644, 2.077298197485592, 2.671960497309397, 3.395117107874875, 2.671960497309397, 1.4381562996844006, 2.077298197485592, 2.077298197485592, 2.077298197485592, 2.077298197485592, 2.85697005603426, 2.671960497309397, 2.671960497309397, 2.6154452493262075, 2.077298197485592, 3.4516323558580644, 2.671960497309397, 2.671960497309397, 2.077298197485592, 2.671960497309397, 1.4566079734145623, 2.671960497309397, 2.077298197485592, 2.077298197485592, 2.077298197485592, 2.077298197485592, 2.671960497309397, 2.671960497309397, 2.6154452493262075, 3.4516323558580644, 2.077298197485592, 2.0328185995082055, 2.671960497309397, 2.051270273238367, 2.077298197485592, 2.077298197485592, 2.077298197485592, 2.077298197485592, 3.395117107874875, 2.671960497309397, 3.2101075491500124, 2.6154452493262075, 3.5884489760534004]\n",
      "all_sum after preprocessing is: [ 0.35081199 -0.80443747 -0.80443747  1.39626938  0.71022976  0.35081199\n",
      " -0.80443747  1.86547922 -0.80443747  0.35081199  1.75568714  0.35081199\n",
      " -2.04609738 -0.80443747 -0.80443747 -0.80443747 -0.80443747  0.71022976\n",
      "  0.35081199  0.35081199  0.24101991 -0.80443747  1.86547922  0.35081199\n",
      "  0.35081199 -0.80443747  0.35081199 -2.01025134  0.35081199 -0.80443747\n",
      " -0.80443747 -0.80443747 -0.80443747  0.35081199  0.35081199  0.24101991\n",
      "  1.86547922 -0.80443747 -0.89084791  0.35081199 -0.85500188 -0.80443747\n",
      " -0.80443747 -0.80443747 -0.80443747  1.75568714  0.35081199  1.39626938\n",
      "  0.24101991  2.13127264]\n",
      "P is: [0.5868144711824123, 0.30907710137954625, 0.30907710137954625, 0.8015912280741386, 0.6704519255853942, 0.5868144711824123, 0.30907710137954625, 0.8659343187049121, 0.30907710137954625, 0.5868144711824123, 0.8526686821564352, 0.5868144711824123, 0.11444731358419805, 0.30907710137954625, 0.30907710137954625, 0.30907710137954625, 0.30907710137954625, 0.6704519255853942, 0.5868144711824123, 0.5868144711824123, 0.559964975706438, 0.30907710137954625, 0.8659343187049121, 0.5868144711824123, 0.5868144711824123, 0.30907710137954625, 0.5868144711824123, 0.11813079122805126, 0.5868144711824123, 0.30907710137954625, 0.30907710137954625, 0.30907710137954625, 0.30907710137954625, 0.5868144711824123, 0.5868144711824123, 0.559964975706438, 0.8659343187049121, 0.30907710137954625, 0.29093487859765704, 0.5868144711824123, 0.29838465307717776, 0.30907710137954625, 0.30907710137954625, 0.30907710137954625, 0.30907710137954625, 0.8526686821564352, 0.5868144711824123, 0.8015912280741386, 0.559964975706438, 0.8939057641871361]\n",
      "all_sum before preprocessing is: [3.4036592572651436, 2.103862884894295, 2.223721219791527, 3.4036592572651436, 2.103862884894295, 5.1252991206118885, 5.1252991206118885, 1.5441250587243354, 5.1252991206118885, 5.245157455509121, 2.103862884894295, 1.5441250587243354, 1.2857739328379347, 2.2079593002202555, 3.4036592572651436, 1.4242667238271032, 2.5378477551101075, 2.103862884894295, 2.223721219791527, 1.5441250587243354, 2.4663104261066566, 2.223721219791527, 3.0074137961846796, 3.1453081313787425, 1.5441250587243354, 2.8875554612874472, 2.103862884894295, 2.417989420212875, 2.103862884894295, 1.5441250587243354, 2.223721219791527, 1.4242667238271032, 2.223721219791527, 2.223721219791527, 3.2657649220710803, 3.5235175921623756, 4.565561294441929, 2.103862884894295, 3.217443916177299, 4.083255418332335, 3.2657649220710803, 2.103862884894295, 3.9447626273431666, 4.083255418332335, 1.4242667238271032, 5.245157455509121, 2.103862884894295, 2.223721219791527, 1.8455117590078944, 3.1459065871738483]\n",
      "all_sum after preprocessing is: [ 0.5856077  -0.57774148 -0.47046537  0.5856077  -0.57774148  2.12651701\n",
      "  2.12651701 -1.07872037  2.12651701  2.23379312 -0.57774148 -1.07872037\n",
      " -1.30995088 -0.48457267  0.5856077  -1.18599648 -0.18931453 -0.57774148\n",
      " -0.47046537 -1.07872037 -0.25334217 -0.47046537  0.23095843  0.3543772\n",
      " -1.07872037  0.12368232 -0.57774148 -0.29659064 -0.57774148 -1.07872037\n",
      " -0.47046537 -1.18599648 -0.47046537 -0.47046537  0.46218894  0.69288381\n",
      "  1.62553812 -0.57774148  0.41894047  1.1938627   0.46218894 -0.57774148\n",
      "  1.0699083   1.1938627  -1.18599648  2.23379312 -0.57774148 -0.47046537\n",
      " -0.80897199  0.35491283]\n",
      "P is: [0.6423567150535178, 0.35945244401698706, 0.38450610172762295, 0.6423567150535178, 0.35945244401698706, 0.8934539025509851, 0.8934539025509851, 0.25374825086017627, 0.8934539025509851, 0.9032433651705427, 0.35945244401698706, 0.25374825086017627, 0.21249506441715887, 0.3811729379792612, 0.6423567150535178, 0.23397572674332026, 0.4528122177553476, 0.35945244401698706, 0.38450610172762295, 0.25374825086017627, 0.4370010492391306, 0.38450610172762295, 0.5574843085682064, 0.5876786337042519, 0.25374825086017627, 0.5308812244200672, 0.35945244401698706, 0.4263911410624465, 0.35945244401698706, 0.25374825086017627, 0.38450610172762295, 0.23397572674332026, 0.38450610172762295, 0.38450610172762295, 0.6135333242083147, 0.6666081371804666, 0.8355574888424824, 0.35945244401698706, 0.6032296854557089, 0.7674311929120117, 0.6135333242083147, 0.35945244401698706, 0.7445794770108509, 0.7674311929120117, 0.23397572674332026, 0.9032433651705427, 0.35945244401698706, 0.38450610172762295, 0.30810960231247086, 0.587808418010908]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.481\n",
      "(*) epoch 2, cost 3.243\n",
      "(*) epoch 3, cost 2.931\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.325\n",
      "(*) epoch 2, cost 4.246\n",
      "(*) epoch 3, cost 3.288\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.931678934965639, 6.438580734691357, 3.088582451449918, 5.784979037799991, 5.838021363066284, 6.438580734691357, 5.398393914927215, 8.091148105518238, 3.088582451449918, 4.491858481205231, 4.491858481205231, 4.491858481205231, 5.28823844176666, 4.381703008044676, 5.784979037799991, 3.088582451449918, 5.035304704936044, 5.421889827808819, 5.784979037799991, 5.784979037799991, 6.691514471521973, 7.731701291286116, 5.532045300969374, 6.691514471521973, 6.687872075762925, 3.088582451449918, 5.398393914927215, 6.825165857564132, 5.784979037799991, 6.691514471521973, 5.784979037799991, 5.781336642040941, 4.491858481205231, 3.088582451449918, 5.838021363066284, 6.691514471521973, 4.491858481205231, 3.9951178851719016, 5.035304704936044, 4.488216085446183, 3.1416247767162115, 4.491858481205231, 5.784979037799991, 4.544900806471524, 3.9951178851719016, 3.9951178851719016, 5.891492115201496, 5.784979037799991, 4.381703008044676, 5.784979037799991]\n",
      "all_sum after preprocessing is: [ 1.34830585  0.94698484 -1.77949983  0.41503382  0.45820372  0.94698484\n",
      "  0.1004013   2.29197048 -1.77949983 -0.63740653 -0.63740653 -0.63740653\n",
      "  0.01074835 -0.72705948  0.41503382 -1.77949983 -0.19510846  0.11952406\n",
      "  0.41503382  0.41503382  1.15284165  1.99942519  0.20917701  1.15284165\n",
      "  1.14987719 -1.77949983  0.1004013   1.26161736  0.41503382  1.15284165\n",
      "  0.41503382  0.41206936 -0.63740653 -1.77949983  0.45820372  1.15284165\n",
      " -0.63740653 -1.041692   -0.19510846 -0.64037099 -1.73632993 -0.63740653\n",
      "  0.41503382 -0.59423664 -1.041692   -1.041692    0.5017223   0.41503382\n",
      " -0.72705948  0.41503382]\n",
      "P is: [0.7938525166440269, 0.7205084006441984, 0.1443649058027349, 0.6022942774895729, 0.6125879613617552, 0.7205084006441984, 0.5250792598403023, 0.9082098510841775, 0.1443649058027349, 0.34583303084757056, 0.34583303084757056, 0.34583303084757056, 0.5026870618606964, 0.3258403359614798, 0.6022942774895729, 0.1443649058027349, 0.45137703323026196, 0.5298454936199115, 0.6022942774895729, 0.6022942774895729, 0.7600295726307386, 0.8807367135148936, 0.5521044048814108, 0.7600295726307386, 0.7594884840000069, 0.1443649058027349, 0.5250792598403023, 0.7793044018903017, 0.6022942774895729, 0.7600295726307386, 0.6022942774895729, 0.6015839680525986, 0.34583303084757056, 0.1443649058027349, 0.6125879613617552, 0.7600295726307386, 0.34583303084757056, 0.2608236530533006, 0.45137703323026196, 0.34516268035168385, 0.14977970154410647, 0.34583303084757056, 0.6022942774895729, 0.3556633648328321, 0.2608236530533006, 0.2608236530533006, 0.6228639930730879, 0.6022942774895729, 0.3258403359614798, 0.6022942774895729]\n",
      "all_sum before preprocessing is: [1.5617454762085352, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 1.2459779096078105, 0.5851956560854354, 1.1259254945619523, 0.5851956560854354, 0.5851956560854354, 1.5617454762085352, 0.5851956560854354, 0.5851956560854354, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 0.5851956560854354, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 0.5851956560854354, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 0.5851956560854354, 1.5617454762085352, 1.5617454762085352, 1.5617454762085352, 0.5851956560854354]\n",
      "all_sum after preprocessing is: [ 0.89527923  0.89527923 -1.16097757  0.89527923 -1.16097757  0.89527923\n",
      " -1.16097757  0.89527923  0.89527923  0.23038821 -1.16097757 -0.02239828\n",
      " -1.16097757 -1.16097757  0.89527923 -1.16097757 -1.16097757  0.89527923\n",
      " -1.16097757  0.89527923 -1.16097757  0.89527923  0.89527923 -1.16097757\n",
      "  0.89527923  0.89527923  0.89527923 -1.16097757  0.89527923  0.89527923\n",
      " -1.16097757  0.89527923 -1.16097757 -1.16097757  0.89527923  0.89527923\n",
      " -1.16097757 -1.16097757  0.89527923  0.89527923 -1.16097757  0.89527923\n",
      "  0.89527923 -1.16097757  0.89527923 -1.16097757  0.89527923  0.89527923\n",
      "  0.89527923 -1.16097757]\n",
      "P is: [0.7099784170032217, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.5573436318066327, 0.2384897002908547, 0.4944006648650121, 0.2384897002908547, 0.2384897002908547, 0.7099784170032217, 0.2384897002908547, 0.2384897002908547, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.2384897002908547, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.2384897002908547, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.2384897002908547, 0.7099784170032217, 0.7099784170032217, 0.7099784170032217, 0.2384897002908547]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.608\n",
      "(*) epoch 2, cost 3.286\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.953\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 1.5358751756144673, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 1.5358751756144673, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263, 0.8591473577534263]\n",
      "all_sum after preprocessing is: [-0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415  4.89897949 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415  4.89897949 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415]\n",
      "P is: [0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.9926009674715031, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.9926009674715031, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764, 0.44914541959383764]\n",
      "all_sum before preprocessing is: [1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3999167638108754, 1.3957822242442304, 4.007066200944799, 1.557693545999581, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 0.6612557659901723, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 2.3764490421940856, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 4.007066200944799, 0.6612557659901723, 1.3957822242442304, 0.6612557659901723, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.862617713792506, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304, 1.3957822242442304]\n",
      "all_sum after preprocessing is: [-0.16361697 -0.16361697 -0.16361697 -0.16361697 -0.16361697 -0.16361697\n",
      " -0.16361697 -0.15631556 -0.16361697  4.44779127  0.12231103 -0.16361697\n",
      " -0.16361697 -0.16361697 -1.46075714 -0.16361697 -0.16361697 -0.16361697\n",
      "  1.56819584 -0.16361697 -0.16361697 -0.16361697 -0.16361697 -0.16361697\n",
      " -0.16361697 -0.16361697 -0.16361697  4.44779127 -1.46075714 -0.16361697\n",
      " -1.46075714 -0.16361697 -0.16361697 -0.16361697 -0.16361697 -0.16361697\n",
      " -0.16361697 -0.16361697 -0.16361697 -0.16361697  0.66079319 -0.16361697\n",
      " -0.16361697 -0.16361697 -0.16361697 -0.16361697 -0.16361697 -0.16361697\n",
      " -0.16361697 -0.16361697]\n",
      "P is: [0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4610004894389906, 0.4591867671106561, 0.9884310175979096, 0.5305396949243377, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.18835154950271754, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.8275262593724647, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.9884310175979096, 0.18835154950271754, 0.4591867671106561, 0.18835154950271754, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.6594385442083506, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561, 0.4591867671106561]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.011\n",
      "(*) epoch 2, cost 0.488\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.385\n",
      "(*) epoch 2, cost 1.017\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.432039991832656, 4.049550277644185, 4.678032778995087, 5.907383692453074, 3.8403747288595325, 4.678032778995087, 5.488076739886824, 6.432039991832656, 2.8964114769137, 6.432039991832656, 6.432039991832656, 5.488076739886824, 5.095283519997274, 4.334937939156339, 5.278901191102172, 4.049550277644185, 4.049550277644185, 6.432039991832656, 5.278901191102172, 6.432039991832656, 5.488076739886824, 5.278901191102172, 5.488076739886824, 6.432039991832656, 4.049550277644185, 4.9634204405072415, 6.432039991832656, 4.759874669693277, 5.802577826205323, 4.993513529590016, 4.678032778995087, 4.993513529590016, 5.488076739886824, 5.278901191102172, 5.488076739886824, 7.060522493183558, 6.432039991832656, 3.8403747288595325, 4.993513529590016, 6.116559241237726, 4.049550277644185, 5.174095324854421, 6.432039991832656, 4.334937939156339, 6.432039991832656, 5.907383692453074, 4.436707929563597, 4.049550277644185, 6.432039991832656, 4.993513529590016]\n",
      "all_sum after preprocessing is: [ 1.22303748e+00 -1.30649217e+00 -6.39221663e-01  6.66001005e-01\n",
      " -1.52857739e+00 -6.39221663e-01  2.20815718e-01  1.22303748e+00\n",
      " -2.53079915e+00  1.22303748e+00  1.22303748e+00  2.20815718e-01\n",
      " -1.96219490e-01 -1.00349126e+00 -1.26950161e-03 -1.30649217e+00\n",
      " -1.30649217e+00  1.22303748e+00 -1.26950161e-03  1.22303748e+00\n",
      "  2.20815718e-01 -1.26950161e-03  2.20815718e-01  1.22303748e+00\n",
      " -1.30649217e+00 -3.36220753e-01  1.22303748e+00 -5.52328742e-01\n",
      "  5.54726843e-01 -3.04270411e-01 -6.39221663e-01 -3.04270411e-01\n",
      "  2.20815718e-01 -1.26950161e-03  2.20815718e-01  1.89030798e+00\n",
      "  1.22303748e+00 -1.52857739e+00 -3.04270411e-01  8.88086225e-01\n",
      " -1.30649217e+00 -1.12543663e-01  1.22303748e+00 -1.00349126e+00\n",
      "  1.22303748e+00  6.66001005e-01 -8.95440339e-01 -1.30649217e+00\n",
      "  1.22303748e+00 -3.04270411e-01]\n",
      "P is: [0.7725976470758067, 0.21307442311420388, 0.3454225048165905, 0.6606071398643656, 0.17820192608344293, 0.3454225048165905, 0.5549807078608167, 0.7725976470758067, 0.07372705313125888, 0.7725976470758067, 0.7725976470758067, 0.5549807078608167, 0.45110191672998173, 0.2682555519974446, 0.49968262463997837, 0.21307442311420388, 0.21307442311420388, 0.7725976470758067, 0.49968262463997837, 0.7725976470758067, 0.5549807078608167, 0.49968262463997837, 0.5549807078608167, 0.7725976470758067, 0.21307442311420388, 0.4167277924258575, 0.7725976470758067, 0.3653242919336225, 0.6352315579023794, 0.4245138790384865, 0.3454225048165905, 0.4245138790384865, 0.5549807078608167, 0.49968262463997837, 0.5549807078608167, 0.8687906426245184, 0.7725976470758067, 0.17820192608344293, 0.4245138790384865, 0.708495078759647, 0.21307442311420388, 0.47189374424042463, 0.7725976470758067, 0.2682555519974446, 0.7725976470758067, 0.6606071398643656, 0.2899884096460026, 0.21307442311420388, 0.7725976470758067, 0.4245138790384865]\n",
      "all_sum before preprocessing is: [6.690883835292812, 5.860874579954941, 5.575221758667404, 5.575221758667404, 5.860874579954941, 4.834905228065223, 6.690883835292812, 4.549252406777686, 1.7097653355083653, 4.834905228065223, 5.860874579954941, 1.7097653355083653, 4.834905228065223, 6.1107146680945075, 5.860874579954941, 5.575221758667404, 4.834905228065223, 5.860874579954941, 4.834905228065223, 5.860874579954941, 4.549252406777686, 5.860874579954941, 6.690883835292812, 5.860874579954941, 5.575221758667404, 4.549252406777686, 5.860874579954941, 6.690883835292812, 3.02138750868562, 4.834905228065223, 5.860874579954941, 4.834905228065223, 5.860874579954941, 5.575221758667404, 4.834905228065223, 6.940723923432379, 4.549252406777686, 5.575221758667404, 4.549252406777686, 5.860874579954941, 4.3559541607884755, 1.7097653355083653, 4.55828403459569, 4.834905228065223, 4.834905228065223, 5.860874579954941, 4.834905228065223, 5.860874579954941, 4.834905228065223, 3.02138750868562]\n",
      "all_sum after preprocessing is: [ 1.32197926  0.62196899  0.38105613  0.38105613  0.62196899 -0.24330941\n",
      "  1.32197926 -0.48422227 -2.87897883 -0.24330941  0.62196899 -2.87897883\n",
      " -0.24330941  0.83267824  0.62196899  0.38105613 -0.24330941  0.62196899\n",
      " -0.24330941  0.62196899 -0.48422227  0.62196899  1.32197926  0.62196899\n",
      "  0.38105613 -0.48422227  0.62196899  1.32197926 -1.77278756 -0.24330941\n",
      "  0.62196899 -0.24330941  0.62196899  0.38105613 -0.24330941  1.53268851\n",
      " -0.48422227  0.38105613 -0.48422227  0.62196899 -0.64724546 -2.87897883\n",
      " -0.47660521 -0.24330941 -0.24330941  0.62196899 -0.24330941  0.62196899\n",
      " -0.24330941 -1.77278756]\n",
      "P is: [0.7895108155845045, 0.6506662329793058, 0.5941278031124567, 0.5941278031124567, 0.6506662329793058, 0.43947096156238347, 0.7895108155845045, 0.3812555943315678, 0.0532025515987982, 0.43947096156238347, 0.6506662329793058, 0.0532025515987982, 0.43947096156238347, 0.6969209322665963, 0.6506662329793058, 0.5941278031124567, 0.43947096156238347, 0.6506662329793058, 0.43947096156238347, 0.6506662329793058, 0.3812555943315678, 0.6506662329793058, 0.7895108155845045, 0.6506662329793058, 0.5941278031124567, 0.3812555943315678, 0.6506662329793058, 0.7895108155845045, 0.14519601106182997, 0.43947096156238347, 0.6506662329793058, 0.43947096156238347, 0.6506662329793058, 0.5941278031124567, 0.43947096156238347, 0.8223993349172508, 0.3812555943315678, 0.5941278031124567, 0.3812555943315678, 0.6506662329793058, 0.34361053448088985, 0.0532025515987982, 0.38305407554682286, 0.43947096156238347, 0.43947096156238347, 0.6506662329793058, 0.43947096156238347, 0.6506662329793058, 0.43947096156238347, 0.14519601106182997]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.824\n",
      "(*) epoch 2, cost 4.735\n",
      "(*) epoch 3, cost 3.774\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.762\n",
      "(*) epoch 2, cost 3.271\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.8449928147899028, 0.766022894595511, 0.766022894595511, 0.8449928147899028, 1.7207974872374323, 0.8449928147899028, 0.766022894595511, 1.6418275670430404, 0.766022894595511, 0.766022894595511, 0.766022894595511, 1.2413017299131535, 2.117106402360683, 0.8449928147899028, 0.8449928147899028, 0.766022894595511, 0.8449928147899028, 1.6418275670430404, 0.766022894595511, 0.766022894595511, 0.766022894595511, 0.8449928147899028, 0.8449928147899028, 0.766022894595511, 0.766022894595511, 0.8449928147899028, 1.2413017299131535, 1.3202716501075453, 0.766022894595511, 0.8449928147899028, 0.766022894595511, 1.2413017299131535, 1.7207974872374323, 0.8449928147899028, 1.3202716501075453, 1.6418275670430404, 1.6418275670430404, 0.766022894595511, 1.2413017299131535, 0.8449928147899028, 0.8449928147899028, 1.6418275670430404, 1.6418275670430404, 2.117106402360683, 0.766022894595511, 1.7207974872374323, 0.8449928147899028, 0.8449928147899028, 1.3202716501075453, 1.7207974872374323]\n",
      "all_sum after preprocessing is: [-0.61522568 -0.80838842 -0.80838842 -0.61522568  1.52701824 -0.61522568\n",
      " -0.80838842  1.3338555  -0.80838842 -0.80838842 -0.80838842  0.35415755\n",
      "  2.49640147 -0.61522568 -0.61522568 -0.80838842 -0.61522568  1.3338555\n",
      " -0.80838842 -0.80838842 -0.80838842 -0.61522568 -0.61522568 -0.80838842\n",
      " -0.80838842 -0.61522568  0.35415755  0.54732029 -0.80838842 -0.61522568\n",
      " -0.80838842  0.35415755  1.52701824 -0.61522568  0.54732029  1.3338555\n",
      "  1.3338555  -0.80838842  0.35415755 -0.61522568 -0.61522568  1.3338555\n",
      "  1.3338555   2.49640147 -0.80838842  1.52701824 -0.61522568 -0.61522568\n",
      "  0.54732029  1.52701824]\n",
      "P is: [0.3508680732847452, 0.30823401975534587, 0.30823401975534587, 0.3508680732847452, 0.8215696276620318, 0.3508680732847452, 0.30823401975534587, 0.7914776638295518, 0.30823401975534587, 0.30823401975534587, 0.30823401975534587, 0.5876254096718587, 0.9238891640585362, 0.3508680732847452, 0.3508680732847452, 0.30823401975534587, 0.3508680732847452, 0.7914776638295518, 0.30823401975534587, 0.30823401975534587, 0.30823401975534587, 0.3508680732847452, 0.3508680732847452, 0.30823401975534587, 0.30823401975534587, 0.3508680732847452, 0.5876254096718587, 0.6335136549526209, 0.30823401975534587, 0.3508680732847452, 0.30823401975534587, 0.5876254096718587, 0.8215696276620318, 0.3508680732847452, 0.6335136549526209, 0.7914776638295518, 0.7914776638295518, 0.30823401975534587, 0.5876254096718587, 0.3508680732847452, 0.3508680732847452, 0.7914776638295518, 0.7914776638295518, 0.9238891640585362, 0.30823401975534587, 0.8215696276620318, 0.3508680732847452, 0.3508680732847452, 0.6335136549526209, 0.8215696276620318]\n",
      "all_sum before preprocessing is: [1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 2.661216201771826, 2.661216201771826, 1.3412336950081931, 2.661216201771826, 1.3412336950081931, 2.661216201771826, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 2.646483525169815, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 2.661216201771826, 2.661216201771826, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 2.661216201771826, 1.3412336950081931, 1.3412336950081931, 2.661216201771826, 1.3412336950081931, 1.3412336950081931, 2.661216201771826, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931, 1.3412336950081931]\n",
      "all_sum after preprocessing is: [-0.49999649 -0.49999649 -0.49999649 -0.49999649  2.00277937  2.00277937\n",
      " -0.49999649  2.00277937 -0.49999649  2.00277937 -0.49999649 -0.49999649\n",
      " -0.49999649 -0.49999649 -0.49999649 -0.49999649 -0.49999649 -0.49999649\n",
      " -0.49999649  1.97484522 -0.49999649 -0.49999649 -0.49999649 -0.49999649\n",
      " -0.49999649 -0.49999649 -0.49999649  2.00277937  2.00277937 -0.49999649\n",
      " -0.49999649 -0.49999649 -0.49999649 -0.49999649 -0.49999649 -0.49999649\n",
      "  2.00277937 -0.49999649 -0.49999649  2.00277937 -0.49999649 -0.49999649\n",
      "  2.00277937 -0.49999649 -0.49999649 -0.49999649 -0.49999649 -0.49999649\n",
      " -0.49999649 -0.49999649]\n",
      "P is: [0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.8810885851928223, 0.8810885851928223, 0.3775414939992911, 0.8810885851928223, 0.3775414939992911, 0.8810885851928223, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.8781305861357832, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.8810885851928223, 0.8810885851928223, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.8810885851928223, 0.3775414939992911, 0.3775414939992911, 0.8810885851928223, 0.3775414939992911, 0.3775414939992911, 0.8810885851928223, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911, 0.3775414939992911]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.533\n",
      "(*) epoch 2, cost 1.330\n",
      "(*) epoch 3, cost 0.986\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.379\n",
      "(*) epoch 2, cost 2.514\n",
      "(*) epoch 3, cost 1.839\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.18 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.40094921279299456, 1.0066084137992548, 1.0066084137992548, 1.0066084137992548, 1.0066084137992548, 1.0066084137992548, 0.40094921279299456, 1.0066084137992548, 0.40094921279299456, 1.0066084137992548, 0.40094921279299456, 0.40094921279299456, 0.40094921279299456, 0.40094921279299456, 1.0066084137992548, 0.7613314846893857, 1.0066084137992548, 0.40094921279299456, 1.0066084137992548, 1.0066084137992548, 1.0066084137992548, 1.0066084137992548, 0.40094921279299456, 1.0066084137992548, 1.0066084137992548, 0.40094921279299456, 1.0066084137992548, 1.0066084137992548, 0.40094921279299456, 0.40094921279299456, 1.0066084137992548, 0.40094921279299456, 1.0066084137992548, 0.15567228368312538, 0.40094921279299456, 1.374459308462431, 0.15567228368312538, 0.7613314846893857, 1.0066084137992548, 0.40094921279299456, 1.374459308462431, 0.40094921279299456, 0.40094921279299456, 0.40094921279299456, 0.15567228368312538, 0.40094921279299456, 0.40094921279299456, 0.40094921279299456, 0.40094921279299456, 0.40094921279299456]\n",
      "all_sum after preprocessing is: [-0.83001173  0.95959064  0.95959064  0.95959064  0.95959064  0.95959064\n",
      " -0.83001173  0.95959064 -0.83001173  0.95959064 -0.83001173 -0.83001173\n",
      " -0.83001173 -0.83001173  0.95959064  0.23484614  0.95959064 -0.83001173\n",
      "  0.95959064  0.95959064  0.95959064  0.95959064 -0.83001173  0.95959064\n",
      "  0.95959064 -0.83001173  0.95959064  0.95959064 -0.83001173 -0.83001173\n",
      "  0.95959064 -0.83001173  0.95959064 -1.55475623 -0.83001173  2.0465168\n",
      " -1.55475623  0.23484614  0.95959064 -0.83001173  2.0465168  -0.83001173\n",
      " -0.83001173 -0.83001173 -1.55475623 -0.83001173 -0.83001173 -0.83001173\n",
      " -0.83001173 -0.83001173]\n",
      "P is: [0.30364258910605657, 0.7230398359511292, 0.7230398359511292, 0.7230398359511292, 0.7230398359511292, 0.7230398359511292, 0.30364258910605657, 0.7230398359511292, 0.30364258910605657, 0.7230398359511292, 0.30364258910605657, 0.30364258910605657, 0.30364258910605657, 0.30364258910605657, 0.7230398359511292, 0.5584431726564639, 0.7230398359511292, 0.30364258910605657, 0.7230398359511292, 0.7230398359511292, 0.7230398359511292, 0.7230398359511292, 0.30364258910605657, 0.7230398359511292, 0.7230398359511292, 0.30364258910605657, 0.7230398359511292, 0.7230398359511292, 0.30364258910605657, 0.30364258910605657, 0.7230398359511292, 0.30364258910605657, 0.7230398359511292, 0.1744003818010446, 0.30364258910605657, 0.8855951872931505, 0.1744003818010446, 0.5584431726564639, 0.7230398359511292, 0.30364258910605657, 0.8855951872931505, 0.30364258910605657, 0.30364258910605657, 0.30364258910605657, 0.1744003818010446, 0.30364258910605657, 0.30364258910605657, 0.30364258910605657, 0.30364258910605657, 0.30364258910605657]\n",
      "all_sum before preprocessing is: [3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 2.553297812694793, 4.158948492074877, 3.09574776172647, 3.0467496904474647, 3.09574776172647, 2.553297812694793, 2.553297812694793, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.09574776172647, 3.107142473490295, 3.09574776172647, 3.5891996394791414, 2.553297812694793, 3.09574776172647, 3.0936894974466274, 3.09574776172647, 2.6002376196939556, 3.09574776172647, 3.09574776172647, 2.553297812694793, 3.09574776172647, 3.09574776172647, 3.5891996394791414, 2.553297812694793, 3.09574776172647, 3.09574776172647, 2.553297812694793, 3.09574776172647, 2.553297812694793, 3.142687568725633, 2.553297812694793, 3.09574776172647, 3.09574776172647, 3.09574776172647, 2.553297812694793, 3.09574776172647, 3.142687568725633, 3.09574776172647]\n",
      "all_sum after preprocessing is: [ 0.25378241  0.25378241  0.25378241  0.25378241  0.25378241  0.25378241\n",
      "  0.25378241  0.25378241  0.25378241  0.25378241 -1.55014238  3.7894711\n",
      "  0.25378241  0.09083864  0.25378241 -1.55014238 -1.55014238  0.25378241\n",
      "  0.25378241  0.25378241  0.25378241  0.29167568  0.25378241  1.89476343\n",
      " -1.55014238  0.25378241  0.24693762  0.25378241 -1.39404341  0.25378241\n",
      "  0.25378241 -1.55014238  0.25378241  0.25378241  1.89476343 -1.55014238\n",
      "  0.25378241  0.25378241 -1.55014238  0.25378241 -1.55014238  0.40988138\n",
      " -1.55014238  0.25378241  0.25378241  0.25378241 -1.55014238  0.25378241\n",
      "  0.40988138  0.25378241]\n",
      "P is: [0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.17506570476335417, 0.9778922464021075, 0.5631072597419743, 0.5226940577107086, 0.5631072597419743, 0.17506570476335417, 0.17506570476335417, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.5724063166832976, 0.5631072597419743, 0.8692977004883128, 0.17506570476335417, 0.5631072597419743, 0.5614226015997668, 0.5631072597419743, 0.19876303456732508, 0.5631072597419743, 0.5631072597419743, 0.17506570476335417, 0.5631072597419743, 0.5631072597419743, 0.8692977004883128, 0.17506570476335417, 0.5631072597419743, 0.5631072597419743, 0.17506570476335417, 0.5631072597419743, 0.17506570476335417, 0.6010594358667819, 0.17506570476335417, 0.5631072597419743, 0.5631072597419743, 0.5631072597419743, 0.17506570476335417, 0.5631072597419743, 0.6010594358667819, 0.5631072597419743]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.709\n",
      "(*) epoch 2, cost 1.793\n",
      "(*) epoch 3, cost 1.103\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.658\n",
      "(*) epoch 2, cost 2.758\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.567882993216057, 5.123623634665193, 2.4414274153505438, 4.567882993216057, 2.4414274153505438, 4.567882993216057, 2.4414274153505438, 2.4414274153505438, 2.9971680567996795, 2.4414274153505438, 2.9971680567996795, 2.9971680567996795, 2.4414274153505438, 1.0256147569536087, 5.3143918872579095, 2.4414274153505438, 4.567882993216057, 2.4414274153505438, 4.567882993216057, 2.9971680567996795, 2.632195667943261, 4.567882993216057, 4.567882993216057, 3.517042723675541, 2.9613020822264056, 1.3905871458100272, 4.758651245808774, 4.567882993216057, 2.4414274153505438, 5.123623634665193, 4.567882993216057, 2.9613020822264056, 2.4414274153505438, 2.4414274153505438, 2.4414274153505438, 2.9971680567996795, 3.65503141852111, 4.567882993216057, 2.4414274153505438, 4.758651245808774, 4.567882993216057, 2.632195667943261, 4.758651245808774, 2.9971680567996795, 5.123623634665193, 2.4414274153505438, 5.123623634665193, 2.9971680567996795, 1.0256147569536087, 2.9971680567996795]\n",
      "all_sum after preprocessing is: [ 1.00235044  1.48170058 -0.83180871  1.00235044 -0.83180871  1.00235044\n",
      " -0.83180871 -0.83180871 -0.35245857 -0.83180871 -0.35245857 -0.35245857\n",
      " -0.83180871 -2.05300786  1.64624638 -0.83180871  1.00235044 -0.83180871\n",
      "  1.00235044 -0.35245857 -0.66726291  1.00235044  1.00235044  0.09595563\n",
      " -0.38339451 -1.73820352  1.16689624  1.00235044 -0.83180871  1.48170058\n",
      "  1.00235044 -0.38339451 -0.83180871 -0.83180871 -0.83180871 -0.35245857\n",
      "  0.2149768   1.00235044 -0.83180871  1.16689624  1.00235044 -0.66726291\n",
      "  1.16689624 -0.35245857  1.48170058 -0.83180871  1.48170058 -0.35245857\n",
      " -2.05300786 -0.35245857]\n",
      "P is: [0.731520451717741, 0.8148293058611565, 0.3032627631000663, 0.731520451717741, 0.3032627631000663, 0.731520451717741, 0.3032627631000663, 0.3032627631000663, 0.4127863511491701, 0.3032627631000663, 0.4127863511491701, 0.4127863511491701, 0.3032627631000663, 0.11374880606093599, 0.838383092523289, 0.3032627631000663, 0.731520451717741, 0.3032627631000663, 0.731520451717741, 0.4127863511491701, 0.3391099911331274, 0.731520451717741, 0.731520451717741, 0.5239705177395997, 0.4053084433942233, 0.14954126436290063, 0.7625835381818186, 0.731520451717741, 0.3032627631000663, 0.8148293058611565, 0.731520451717741, 0.4053084433942233, 0.3032627631000663, 0.3032627631000663, 0.3032627631000663, 0.4127863511491701, 0.5535381690275762, 0.731520451717741, 0.3032627631000663, 0.7625835381818186, 0.731520451717741, 0.3391099911331274, 0.7625835381818186, 0.4127863511491701, 0.8148293058611565, 0.3032627631000663, 0.8148293058611565, 0.4127863511491701, 0.11374880606093599, 0.4127863511491701]\n",
      "all_sum before preprocessing is: [0.9314218640420994, 2.3901630346531735, 1.4355516748779416, 2.3901630346531735, 4.160913720886939, 2.702172550275865, 0.9314218640420994, 2.8942928454890158, 0.9314218640420994, 2.702172550275865, 3.879120244523839, 0.9314218640420994, 2.423419847633857, 2.273920010565435, 2.8942928454890158, 0.9314218640420994, 0.9314218640420994, 0.9314218640420994, 0.9314218640420994, 1.4355516748779416, 1.4355516748779416, 1.4355516748779416, 4.396834432578078, 0.9314218640420994, 1.4355516748779416, 1.4355516748779416, 1.4355516748779416, 2.3901630346531735, 0.9314218640420994, 0.9314218640420994, 1.4355516748779416, 0.9314218640420994, 1.4355516748779416, 1.4355516748779416, 2.273920010565435, 0.9314218640420994, 0.9314218640420994, 1.4355516748779416, 1.4355516748779416, 0.9314218640420994, 0.9314218640420994, 2.3901630346531735, 2.8942928454890158, 2.3901630346531735, 0.9314218640420994, 0.9314218640420994, 0.9314218640420994, 2.848631613623194, 0.9314218640420994, 1.4355516748779416]\n",
      "all_sum after preprocessing is: [-0.85171823  0.74056458 -0.30143745  0.74056458  2.67342007  1.08113726\n",
      " -0.85171823  1.29084536 -0.85171823  1.08113726  2.36582958 -0.85171823\n",
      "  0.77686591  0.61367999  1.29084536 -0.85171823 -0.85171823 -0.85171823\n",
      " -0.85171823 -0.30143745 -0.30143745 -0.30143745  2.93093833 -0.85171823\n",
      " -0.30143745 -0.30143745 -0.30143745  0.74056458 -0.85171823 -0.85171823\n",
      " -0.30143745 -0.85171823 -0.30143745 -0.30143745  0.61367999 -0.85171823\n",
      " -0.85171823 -0.30143745 -0.30143745 -0.85171823 -0.85171823  0.74056458\n",
      "  1.29084536  0.74056458 -0.85171823 -0.85171823 -0.85171823  1.24100404\n",
      " -0.85171823 -0.30143745]\n",
      "P is: [0.2990725438694029, 0.6771193019808743, 0.42520612470710123, 0.6771193019808743, 0.9354398843852538, 0.7467091386590349, 0.2990725438694029, 0.7842902410300081, 0.2990725438694029, 0.7467091386590349, 0.9141842499319814, 0.2990725438694029, 0.6850042540464877, 0.6487798008052417, 0.7842902410300081, 0.2990725438694029, 0.2990725438694029, 0.2990725438694029, 0.2990725438694029, 0.42520612470710123, 0.42520612470710123, 0.42520612470710123, 0.9493548093541473, 0.2990725438694029, 0.42520612470710123, 0.42520612470710123, 0.42520612470710123, 0.6771193019808743, 0.2990725438694029, 0.2990725438694029, 0.42520612470710123, 0.2990725438694029, 0.42520612470710123, 0.42520612470710123, 0.6487798008052417, 0.2990725438694029, 0.2990725438694029, 0.42520612470710123, 0.42520612470710123, 0.2990725438694029, 0.2990725438694029, 0.6771193019808743, 0.7842902410300081, 0.6771193019808743, 0.2990725438694029, 0.2990725438694029, 0.2990725438694029, 0.7757387328042432, 0.2990725438694029, 0.42520612470710123]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.622\n",
      "(*) epoch 2, cost 2.994\n",
      "(*) epoch 3, cost 2.325\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.517\n",
      "(*) epoch 2, cost 2.013\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.0848654101655675, 3.0848654101655675, 3.0848654101655675, 4.903119464432782, 3.0848654101655675, 1.7726710630348246, 1.7726710630348246, 3.5909251173020396, 3.0848654101655675, 4.903119464432782, 3.0848654101655675, 4.903119464432782, 3.0848654101655675, 4.903119464432782, 1.7726710630348246, 3.0848654101655675, 3.0848654101655675, 4.903119464432782, 4.903119464432782, 1.7726710630348246, 4.903119464432782, 4.903119464432782, 4.903119464432782, 3.0848654101655675, 1.7726710630348246, 4.903119464432782, 4.903119464432782, 4.903119464432782, 3.0848654101655675, 3.0848654101655675, 1.7726710630348246, 3.0848654101655675, 4.903119464432782, 4.903119464432782, 4.903119464432782, 4.903119464432782, 4.903119464432782, 1.7726710630348246, 4.903119464432782, 4.903119464432782, 3.0848654101655675, 3.0848654101655675, 3.987282568380694, 3.0848654101655675, 1.7726710630348246, 1.7726710630348246, 3.5909251173020396, 1.7726710630348246, 4.903119464432782, 3.0848654101655675]\n",
      "all_sum after preprocessing is: [-0.41927164 -0.41927164 -0.41927164  1.09585722 -0.41927164 -1.51270714\n",
      " -1.51270714  0.00242172 -0.41927164  1.09585722 -0.41927164  1.09585722\n",
      " -0.41927164  1.09585722 -1.51270714 -0.41927164 -0.41927164  1.09585722\n",
      "  1.09585722 -1.51270714  1.09585722  1.09585722  1.09585722 -0.41927164\n",
      " -1.51270714  1.09585722  1.09585722  1.09585722 -0.41927164 -0.41927164\n",
      " -1.51270714 -0.41927164  1.09585722  1.09585722  1.09585722  1.09585722\n",
      "  1.09585722 -1.51270714  1.09585722  1.09585722 -0.41927164 -0.41927164\n",
      "  0.33270154 -0.41927164 -1.51270714 -1.51270714  0.00242172 -1.51270714\n",
      "  1.09585722 -0.41927164]\n",
      "P is: [0.3966910525981771, 0.3966910525981771, 0.3966910525981771, 0.7494830687402618, 0.3966910525981771, 0.1805379413140159, 0.1805379413140159, 0.500605429807926, 0.3966910525981771, 0.7494830687402618, 0.3966910525981771, 0.7494830687402618, 0.3966910525981771, 0.7494830687402618, 0.1805379413140159, 0.3966910525981771, 0.3966910525981771, 0.7494830687402618, 0.7494830687402618, 0.1805379413140159, 0.7494830687402618, 0.7494830687402618, 0.7494830687402618, 0.3966910525981771, 0.1805379413140159, 0.7494830687402618, 0.7494830687402618, 0.7494830687402618, 0.3966910525981771, 0.3966910525981771, 0.1805379413140159, 0.3966910525981771, 0.7494830687402618, 0.7494830687402618, 0.7494830687402618, 0.7494830687402618, 0.7494830687402618, 0.1805379413140159, 0.7494830687402618, 0.7494830687402618, 0.3966910525981771, 0.3966910525981771, 0.5824165566484104, 0.3966910525981771, 0.1805379413140159, 0.1805379413140159, 0.500605429807926, 0.1805379413140159, 0.7494830687402618, 0.3966910525981771]\n",
      "all_sum before preprocessing is: [2.0884692877368285, 2.0054837601949864, 2.870985756849265, 2.86346269455304, 2.0884692877368285, 2.0054837601949864, 2.0884692877368285, 2.0884692877368285, 2.0054837601949864, 2.870985756849265, 2.0884692877368285, 2.0884692877368285, 2.0884692877368285, 2.870985756849265, 2.0884692877368285, 2.0884692877368285, 2.0884692877368285, 2.0054837601949864, 2.870985756849265, 2.870985756849265, 2.0054837601949864, 2.0884692877368285, 2.0884692877368285, 2.0054837601949864, 2.0054837601949864, 2.0884692877368285, 2.870985756849265, 2.080946225440604, 3.084613041747834, 2.0884692877368285, 2.0884692877368285, 2.0884692877368285, 2.788000229307423, 2.870985756849265, 0.9784937823383781, 2.0884692877368285, 2.0054837601949864, 2.0884692877368285, 2.0884692877368285, 2.788000229307423, 2.0884692877368285, 2.0884692877368285, 2.0054837601949864, 2.0884692877368285, 2.0884692877368285, 2.0884692877368285, 2.0884692877368285, 2.0884692877368285, 2.0054837601949864, 2.0054837601949864]\n",
      "all_sum after preprocessing is: [-0.34661282 -0.56394532  1.70273562  1.68303332 -0.34661282 -0.56394532\n",
      " -0.34661282 -0.34661282 -0.56394532  1.70273562 -0.34661282 -0.34661282\n",
      " -0.34661282  1.70273562 -0.34661282 -0.34661282 -0.34661282 -0.56394532\n",
      "  1.70273562  1.70273562 -0.56394532 -0.34661282 -0.34661282 -0.56394532\n",
      " -0.56394532 -0.34661282  1.70273562 -0.36631512  2.2622085  -0.34661282\n",
      " -0.34661282 -0.34661282  1.48540312  1.70273562 -3.25355045 -0.34661282\n",
      " -0.56394532 -0.34661282 -0.34661282  1.48540312 -0.34661282 -0.34661282\n",
      " -0.56394532 -0.34661282 -0.34661282 -0.34661282 -0.34661282 -0.34661282\n",
      " -0.56394532 -0.56394532]\n",
      "P is: [0.4142040437708743, 0.36263508095627023, 0.8458916851841993, 0.8433057749322296, 0.4142040437708743, 0.36263508095627023, 0.4142040437708743, 0.4142040437708743, 0.36263508095627023, 0.8458916851841993, 0.4142040437708743, 0.4142040437708743, 0.4142040437708743, 0.8458916851841993, 0.4142040437708743, 0.4142040437708743, 0.4142040437708743, 0.36263508095627023, 0.8458916851841993, 0.8458916851841993, 0.36263508095627023, 0.4142040437708743, 0.4142040437708743, 0.36263508095627023, 0.36263508095627023, 0.4142040437708743, 0.8458916851841993, 0.40943171720475474, 0.9056984256457208, 0.4142040437708743, 0.4142040437708743, 0.4142040437708743, 0.8153873033605958, 0.8458916851841993, 0.03719951623335587, 0.4142040437708743, 0.36263508095627023, 0.4142040437708743, 0.4142040437708743, 0.8153873033605958, 0.4142040437708743, 0.4142040437708743, 0.36263508095627023, 0.4142040437708743, 0.4142040437708743, 0.4142040437708743, 0.4142040437708743, 0.4142040437708743, 0.36263508095627023, 0.36263508095627023]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.887\n",
      "(*) epoch 2, cost 1.580\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.239\n",
      "(*) epoch 2, cost 3.175\n",
      "(*) epoch 3, cost 2.376\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 1.87303754944621, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 2.3948949124007335, 2.3948949124007335, 3.345794549013277, 1.87303754944621, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 3.345794549013277, 4.74532521105675, 3.345794549013277, 3.345794549013277, 3.345794549013277, 1.87303754944621, 3.345794549013277, 2.3948949124007335]\n",
      "all_sum after preprocessing is: [ 0.25638642  0.25638642  0.25638642  0.25638642 -2.95913598  0.25638642\n",
      "  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642\n",
      "  0.25638642  0.25638642  0.25638642  0.25638642 -1.81974636 -1.81974636\n",
      "  0.25638642 -2.95913598  0.25638642  0.25638642  0.25638642  0.25638642\n",
      "  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642\n",
      "  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642\n",
      "  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642  0.25638642\n",
      "  0.25638642  3.31203117  0.25638642  0.25638642  0.25638642 -2.95913598\n",
      "  0.25638642 -1.81974636]\n",
      "P is: [0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.04930649134524905, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.13946431015887473, 0.13946431015887473, 0.5637477861960158, 0.04930649134524905, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.9648392521162226, 0.5637477861960158, 0.5637477861960158, 0.5637477861960158, 0.04930649134524905, 0.5637477861960158, 0.13946431015887473]\n",
      "all_sum before preprocessing is: [4.290613051450545, 4.692505020980874, 1.373442169781125, 2.8175109336418562, 2.8175109336418562, 1.373442169781125, 2.8175109336418562, 1.6735409510752972, 2.8175109336418562, 3.117609714936029, 2.8175109336418562, 4.290613051450545, 3.117609714936029, 2.8175109336418562, 4.290613051450545, 3.8633732597005115, 4.290613051450545, 1.373442169781125, 2.8175109336418562, 2.8175109336418562, 2.8175109336418562, 4.290613051450545, 2.8175109336418562, 4.290613051450545, 2.8175109336418562, 4.290613051450545, 2.8175109336418562, 3.117609714936029, 4.290613051450545, 2.8175109336418562, 2.8175109336418562, 2.8465442875898126, 3.117609714936029, 1.373442169781125, 2.8175109336418562, 4.692505020980874, 2.8175109336418562, 2.945834989898776, 2.8175109336418562, 1.373442169781125, 2.8175109336418562, 2.8175109336418562, 4.943492880299595, 2.8465442875898126, 2.8175109336418562, 2.8175109336418562, 2.8175109336418562, 1.373442169781125, 2.8175109336418562, 2.8175109336418562]\n",
      "all_sum after preprocessing is: [ 1.38139346  1.81943233 -1.79815316 -0.22420219 -0.22420219 -1.79815316\n",
      " -0.22420219 -1.47106294 -0.22420219  0.10288803 -0.22420219  1.38139346\n",
      "  0.10288803 -0.22420219  1.38139346  0.91572693  1.38139346 -1.79815316\n",
      " -0.22420219 -0.22420219 -0.22420219  1.38139346 -0.22420219  1.38139346\n",
      " -0.22420219  1.38139346 -0.22420219  0.10288803  1.38139346 -0.22420219\n",
      " -0.22420219 -0.19255752  0.10288803 -1.79815316 -0.22420219  1.81943233\n",
      " -0.22420219 -0.08433643 -0.22420219 -1.79815316 -0.22420219 -0.22420219\n",
      "  2.0929945  -0.19255752 -0.22420219 -0.22420219 -0.22420219 -1.79815316\n",
      " -0.22420219 -0.22420219]\n",
      "P is: [0.7992147023115836, 0.8604979975401725, 0.142076027778287, 0.44418306827229087, 0.44418306827229087, 0.142076027778287, 0.44418306827229087, 0.18678110552129562, 0.44418306827229087, 0.5256993412629958, 0.44418306827229087, 0.7992147023115836, 0.5256993412629958, 0.44418306827229087, 0.7992147023115836, 0.7141706385661473, 0.7992147023115836, 0.142076027778287, 0.44418306827229087, 0.44418306827229087, 0.44418306827229087, 0.7992147023115836, 0.44418306827229087, 0.7992147023115836, 0.44418306827229087, 0.7992147023115836, 0.44418306827229087, 0.5256993412629958, 0.7992147023115836, 0.44418306827229087, 0.44418306827229087, 0.4520088148704627, 0.5256993412629958, 0.142076027778287, 0.44418306827229087, 0.8604979975401725, 0.44418306827229087, 0.47892838103144525, 0.44418306827229087, 0.142076027778287, 0.44418306827229087, 0.44418306827229087, 0.8902204147509423, 0.4520088148704627, 0.44418306827229087, 0.44418306827229087, 0.44418306827229087, 0.142076027778287, 0.44418306827229087, 0.44418306827229087]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.656\n",
      "(*) epoch 2, cost 2.242\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.567\n",
      "(*) epoch 2, cost 2.864\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1580318578960136, 3.111525844655831, 1.1580318578960136, 3.5760363732245315, 1.5473963522930145, 1.1580318578960136, 1.1580318578960136, 1.5473963522930145, 1.1580318578960136, 0.47310076024998, 1.1580318578960136, 1.5473963522930145, 3.111525844655831, 1.1580318578960136, 1.1580318578960136, 1.5473963522930145, 0.47310076024998, 3.111525844655831, 1.1580318578960136, 1.5473963522930145, 1.5473963522930145, 0.47310076024998, 1.1580318578960136, 1.5473963522930145, 1.1580318578960136, 1.5473963522930145, 1.1580318578960136, 1.5473963522930145, 1.1580318578960136, 3.5760363732245315, 0.47310076024998, 0.47310076024998, 1.1580318578960136, 0.47310076024998, 1.1580318578960136, 1.5473963522930145, 1.5473963522930145, 1.5473963522930145, 1.1580318578960136, 1.5473963522930145, 1.5473963522930145, 1.1580318578960136, 1.1580318578960136, 1.1580318578960136, 1.1580318578960136, 2.112376286784496, 1.5473963522930145, 1.5473963522930145, 1.1580318578960136, 1.5473963522930145]\n",
      "all_sum after preprocessing is: [-0.39708303  2.34188206 -0.39708303  2.99316542  0.14883919 -0.39708303\n",
      " -0.39708303  0.14883919 -0.39708303 -1.35741481 -0.39708303  0.14883919\n",
      "  2.34188206 -0.39708303 -0.39708303  0.14883919 -1.35741481  2.34188206\n",
      " -0.39708303  0.14883919  0.14883919 -1.35741481 -0.39708303  0.14883919\n",
      " -0.39708303  0.14883919 -0.39708303  0.14883919 -0.39708303  2.99316542\n",
      " -1.35741481 -1.35741481 -0.39708303 -1.35741481 -0.39708303  0.14883919\n",
      "  0.14883919  0.14883919 -0.39708303  0.14883919  0.14883919 -0.39708303\n",
      " -0.39708303 -0.39708303 -0.39708303  0.94098921  0.14883919  0.14883919\n",
      " -0.39708303  0.14883919]\n",
      "P is: [0.40201337562066863, 0.9122868039727796, 0.40201337562066863, 0.952264406497783, 0.537141255512853, 0.40201337562066863, 0.40201337562066863, 0.537141255512853, 0.40201337562066863, 0.2046607847814016, 0.40201337562066863, 0.537141255512853, 0.9122868039727796, 0.40201337562066863, 0.40201337562066863, 0.537141255512853, 0.2046607847814016, 0.9122868039727796, 0.40201337562066863, 0.537141255512853, 0.537141255512853, 0.2046607847814016, 0.40201337562066863, 0.537141255512853, 0.40201337562066863, 0.537141255512853, 0.40201337562066863, 0.537141255512853, 0.40201337562066863, 0.952264406497783, 0.2046607847814016, 0.2046607847814016, 0.40201337562066863, 0.2046607847814016, 0.40201337562066863, 0.537141255512853, 0.537141255512853, 0.537141255512853, 0.40201337562066863, 0.537141255512853, 0.537141255512853, 0.40201337562066863, 0.40201337562066863, 0.40201337562066863, 0.40201337562066863, 0.7192994306213112, 0.537141255512853, 0.537141255512853, 0.40201337562066863, 0.537141255512853]\n",
      "all_sum before preprocessing is: [4.175869400409541, 4.175869400409541, 4.175869400409541, 2.4438458820603133, 4.175869400409541, 6.665449405633245, 4.175869400409541, 1.3505881042915515, 4.175869400409541, 4.175869400409541, 0.9858208405388852, 7.5923853370481424, 2.4438458820603133, 4.175869400409541, 0.8324417243786666, 1.3505881042915515, 4.175869400409541, 4.342191246763406, 4.175869400409541, 4.175869400409541, 4.175869400409541, 4.175869400409541, 4.175869400409541, 2.4438458820603133, 4.175869400409541, 4.175869400409541, 4.175869400409541, 6.49912755927938, 7.5923853370481424, 4.175869400409541, 6.49912755927938, 4.175869400409541, 4.175869400409541, 5.269127178178302, 4.175869400409541, 1.3505881042915515, 4.175869400409541, 4.175869400409541, 5.269127178178302, 3.6447802903030087, 7.5923853370481424, 6.49912755927938, 4.175869400409541, 4.175869400409541, 4.175869400409541, 4.175869400409541, 1.3505881042915515, 1.3505881042915515, 4.175869400409541, 4.175869400409541]\n",
      "all_sum after preprocessing is: [ 0.05364877  0.05364877  0.05364877 -1.02050652  0.05364877  1.59762061\n",
      "  0.05364877 -1.69851615  0.05364877  0.05364877 -1.92473518  2.17248182\n",
      " -1.02050652  0.05364877 -2.01985686 -1.69851615  0.05364877  0.15679719\n",
      "  0.05364877  0.05364877  0.05364877  0.05364877  0.05364877 -1.02050652\n",
      "  0.05364877  0.05364877  0.05364877  1.49447219  2.17248182  0.05364877\n",
      "  1.49447219  0.05364877  0.05364877  0.7316584   0.05364877 -1.69851615\n",
      "  0.05364877  0.05364877  0.7316584  -0.27571868  2.17248182  1.49447219\n",
      "  0.05364877  0.05364877  0.05364877  0.05364877 -1.69851615 -1.69851615\n",
      "  0.05364877  0.05364877]\n",
      "P is: [0.5134089770987419, 0.5134089770987419, 0.5134089770987419, 0.2649287485306168, 0.5134089770987419, 0.8316855698794267, 0.5134089770987419, 0.15465916380283964, 0.5134089770987419, 0.5134089770987419, 0.12733446167994492, 0.8977510081169483, 0.2649287485306168, 0.5134089770987419, 0.11713379216202248, 0.15465916380283964, 0.5134089770987419, 0.5391191845830657, 0.5134089770987419, 0.5134089770987419, 0.5134089770987419, 0.5134089770987419, 0.5134089770987419, 0.2649287485306168, 0.5134089770987419, 0.5134089770987419, 0.5134089770987419, 0.8167485751011438, 0.8977510081169483, 0.5134089770987419, 0.8167485751011438, 0.5134089770987419, 0.5134089770987419, 0.6751690922338335, 0.5134089770987419, 0.15465916380283964, 0.5134089770987419, 0.5134089770987419, 0.6751690922338335, 0.4315037091221732, 0.8977510081169483, 0.8167485751011438, 0.5134089770987419, 0.5134089770987419, 0.5134089770987419, 0.5134089770987419, 0.15465916380283964, 0.15465916380283964, 0.5134089770987419, 0.5134089770987419]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.242\n",
      "(*) epoch 2, cost 1.156\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.780\n",
      "(*) epoch 2, cost 3.010\n",
      "(*) epoch 3, cost 2.553\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.5137516532586925, 2.5137516532586925, 1.7800997270874204, 1.5869640027947591, 1.5869640027947591, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.138897969789195, 1.5869640027947591, 3.0656856202531286, 2.5137516532586925, 2.5137516532586925, 3.0656856202531286, 2.5137516532586925, 1.5869640027947591, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 1.5869640027947591, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 3.0656856202531286, 1.5869640027947591, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 2.5137516532586925, 1.5869640027947591, 2.5137516532586925, 2.5137516532586925]\n",
      "all_sum after preprocessing is: [ 0.31982265  0.31982265 -1.65517671 -2.17510029 -2.17510029  0.31982265\n",
      "  0.31982265  0.31982265  0.31982265  0.31982265  0.31982265 -0.68928774\n",
      " -2.17510029  1.8056352   0.31982265  0.31982265  1.8056352   0.31982265\n",
      " -2.17510029  0.31982265  0.31982265  0.31982265 -2.17510029  0.31982265\n",
      "  0.31982265  0.31982265  0.31982265  0.31982265  0.31982265  0.31982265\n",
      "  0.31982265  0.31982265  0.31982265  0.31982265  0.31982265  0.31982265\n",
      "  0.31982265  0.31982265  0.31982265  0.31982265  0.31982265  1.8056352\n",
      " -2.17510029  0.31982265  0.31982265  0.31982265  0.31982265 -2.17510029\n",
      "  0.31982265  0.31982265]\n",
      "P is: [0.5792810311438668, 0.5792810311438668, 0.16041052890619173, 0.10200888203648768, 0.10200888203648768, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.3341915368803982, 0.10200888203648768, 0.8588335207914786, 0.5792810311438668, 0.5792810311438668, 0.8588335207914786, 0.5792810311438668, 0.10200888203648768, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.10200888203648768, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.8588335207914786, 0.10200888203648768, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.5792810311438668, 0.10200888203648768, 0.5792810311438668, 0.5792810311438668]\n",
      "all_sum before preprocessing is: [3.4100215728827052, 4.883124791179208, 2.192642372383995, 4.0192058083066575, 2.192642372383995, 2.192642372383995, 4.0192058083066575, 2.192642372383995, 3.665745590680497, 2.546102590010155, 4.0192058083066575, 2.192642372383995, 3.731912045432047, 3.583670938295168, 3.665745590680497, 3.665745590680497, 3.970331671401897, 3.186297178642675, 3.665745590680497, 3.665745590680497, 2.546102590010155, 4.0192058083066575, 3.665745590680497, 2.192642372383995, 3.970331671401897, 2.546102590010155, 3.665745590680497, 4.309096657298237, 2.192642372383995, 2.192642372383995, 3.665745590680497, 2.192642372383995, 3.937131155921328, 5.236585008805368, 3.665745590680497, 4.0192058083066575, 5.236585008805368, 2.6122690447617045, 4.0192058083066575, 2.192642372383995, 2.192642372383995, 2.192642372383995, 4.0192058083066575, 3.665745590680497, 3.665745590680497, 2.192642372383995, 2.192642372383995, 2.192642372383995, 2.546102590010155, 3.665745590680497]\n",
      "all_sum after preprocessing is: [ 0.16402153  1.83352836 -1.2156665   0.85442613 -1.2156665  -1.2156665\n",
      "  0.85442613 -1.2156665   0.45384032 -0.81508069  0.85442613 -1.2156665\n",
      "  0.52882852  0.36082295  0.45384032  0.45384032  0.79903578 -0.08953124\n",
      "  0.45384032  0.45384032 -0.81508069  0.85442613  0.45384032 -1.2156665\n",
      "  0.79903578 -0.81508069  0.45384032  1.1829671  -1.2156665  -1.2156665\n",
      "  0.45384032 -1.2156665   0.76140876  2.23411416  0.45384032  0.85442613\n",
      "  2.23411416 -0.7400925   0.85442613 -1.2156665  -1.2156665  -1.2156665\n",
      "  0.85442613  0.45384032  0.45384032 -1.2156665  -1.2156665  -1.2156665\n",
      " -0.81508069  0.45384032]\n",
      "P is: [0.5409136994054787, 0.8621815180380742, 0.22869996571142379, 0.7014947998554178, 0.22869996571142379, 0.22869996571142379, 0.7014947998554178, 0.22869996571142379, 0.611551916534964, 0.30680889001188333, 0.7014947998554178, 0.22869996571142379, 0.6292098406429988, 0.5892396326703323, 0.611551916534964, 0.611551916534964, 0.6897681876945181, 0.4776321304691982, 0.611551916534964, 0.611551916534964, 0.30680889001188333, 0.7014947998554178, 0.611551916534964, 0.22869996571142379, 0.6897681876945181, 0.30680889001188333, 0.611551916534964, 0.7654808760309826, 0.22869996571142379, 0.22869996571142379, 0.611551916534964, 0.22869996571142379, 0.6816595126019307, 0.9032714192797705, 0.611551916534964, 0.7014947998554178, 0.9032714192797705, 0.32298391794839065, 0.7014947998554178, 0.22869996571142379, 0.22869996571142379, 0.22869996571142379, 0.7014947998554178, 0.611551916534964, 0.611551916534964, 0.22869996571142379, 0.22869996571142379, 0.22869996571142379, 0.30680889001188333, 0.611551916534964]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.928\n",
      "(*) epoch 2, cost 2.621\n",
      "(*) epoch 3, cost 1.919\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.30 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.488\n",
      "(*) epoch 2, cost 4.086\n",
      "(*) epoch 3, cost 3.631\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 2.918357077548917, 1.0356449566547656, 1.3937185803304284, 1.0356449566547656, 1.0356449566547656, 1.3937185803304284, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.3937185803304284, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.3937185803304284, 1.3937185803304284, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.3937185803304284, 1.3937185803304284, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.0356449566547656, 1.3937185803304284]\n",
      "all_sum after preprocessing is: [-0.33077615 -0.33077615 -0.33077615 -0.33077615 -0.33077615 -0.33077615\n",
      " -0.33077615 -0.33077615  6.22827966 -0.33077615  0.91669279 -0.33077615\n",
      " -0.33077615  0.91669279 -0.33077615 -0.33077615 -0.33077615 -0.33077615\n",
      " -0.33077615 -0.33077615 -0.33077615  0.91669279 -0.33077615 -0.33077615\n",
      " -0.33077615 -0.33077615 -0.33077615 -0.33077615 -0.33077615 -0.33077615\n",
      " -0.33077615 -0.33077615 -0.33077615 -0.33077615 -0.33077615 -0.33077615\n",
      " -0.33077615 -0.33077615  0.91669279  0.91669279 -0.33077615 -0.33077615\n",
      " -0.33077615  0.91669279  0.91669279 -0.33077615 -0.33077615 -0.33077615\n",
      " -0.33077615  0.91669279]\n",
      "P is: [0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.9980310415006319, 0.41805178706944124, 0.7143677592765318, 0.41805178706944124, 0.41805178706944124, 0.7143677592765318, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.7143677592765318, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.7143677592765318, 0.7143677592765318, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.7143677592765318, 0.7143677592765318, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.41805178706944124, 0.7143677592765318]\n",
      "all_sum before preprocessing is: [1.251482991741451, 2.2808182375949224, 1.251482991741451, 3.0061193502252817, 1.2067342220269266, 0.521840123842437, 1.251482991741451, 1.251482991741451, 2.126879304813849, 1.9363770899259403, 1.251482991741451, 0.521840123842437, 1.6504242443726518, 1.251482991741451, 1.9363770899259403, 1.9363770899259403, 1.9363770899259403, 2.2808182375949224, 2.9657123357794117, 1.9363770899259403, 1.251482991741451, 2.8629927347516464, 1.251482991741451, 1.9363770899259403, 1.9363770899259403, 1.251482991741451, 1.9363770899259403, 1.251482991741451, 1.4025347602592606, 1.251482991741451, 2.08742885844375, 1.9363770899259403, 1.251482991741451, 1.251482991741451, 1.251482991741451, 1.251482991741451, 1.251482991741451, 2.6350107205115987, 1.2067342220269266, 2.2808182375949224, 1.251482991741451, 1.251482991741451, 1.251482991741451, 1.9363770899259403, 1.251482991741451, 1.251482991741451, 1.9363770899259403, 1.9363770899259403, 1.251482991741451, 3.0061193502252817]\n",
      "all_sum after preprocessing is: [-0.69539617  1.07306397 -0.69539617  2.3191751  -0.77227726 -1.9489667\n",
      " -0.69539617 -0.69539617  0.80858758  0.48129327 -0.69539617 -1.9489667\n",
      " -0.00999099 -0.69539617  0.48129327  0.48129327  0.48129327  1.07306397\n",
      "  2.24975341  0.48129327 -0.69539617  2.07327493 -0.69539617  0.48129327\n",
      "  0.48129327 -0.69539617  0.48129327 -0.69539617 -0.4358801  -0.69539617\n",
      "  0.74080933  0.48129327 -0.69539617 -0.69539617 -0.69539617 -0.69539617\n",
      " -0.69539617  1.68158806 -0.77227726  1.07306397 -0.69539617 -0.69539617\n",
      " -0.69539617  0.48129327 -0.69539617 -0.69539617  0.48129327  0.48129327\n",
      " -0.69539617  2.3191751 ]\n",
      "P is: [0.3328337459901973, 0.7451791616763471, 0.3328337459901973, 0.9104527106317614, 0.31598669583544514, 0.12466607329543143, 0.3328337459901973, 0.3328337459901973, 0.6918084455718225, 0.618053215278327, 0.3328337459901973, 0.12466607329543143, 0.49750227239595385, 0.3328337459901973, 0.618053215278327, 0.618053215278327, 0.618053215278327, 0.7451791616763471, 0.9046292625865545, 0.618053215278327, 0.3328337459901973, 0.8882783785957126, 0.3328337459901973, 0.618053215278327, 0.618053215278327, 0.3328337459901973, 0.618053215278327, 0.3328337459901973, 0.39272309483171924, 0.3328337459901973, 0.677172810094934, 0.618053215278327, 0.3328337459901973, 0.3328337459901973, 0.3328337459901973, 0.3328337459901973, 0.3328337459901973, 0.8431147013321059, 0.31598669583544514, 0.7451791616763471, 0.3328337459901973, 0.3328337459901973, 0.3328337459901973, 0.618053215278327, 0.3328337459901973, 0.3328337459901973, 0.618053215278327, 0.618053215278327, 0.3328337459901973, 0.9104527106317614]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.445\n",
      "(*) epoch 2, cost 1.762\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.163\n",
      "(*) epoch 2, cost 1.709\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.427571107694484, 2.5681026597766827, 2.427571107694484, 2.427571107694484, 2.5681026597766827, 1.3113151445727245, 3.649482808702164, 2.427571107694484, 1.3113151445727245, 2.5681026597766827, 2.427571107694484, 1.3113151445727245, 2.427571107694484, 1.3113151445727245, 2.427571107694484, 1.3113151445727245, 1.3113151445727245, 2.427571107694484, 2.427571107694484, 2.427571107694484, 3.7900143607843626, 3.649482808702164, 2.427571107694484, 2.427571107694484, 2.427571107694484, 2.427571107694484, 1.3113151445727245, 2.5681026597766827, 2.427571107694484, 2.427571107694484, 2.5681026597766827, 2.5681026597766827, 1.3113151445727245, 1.3113151445727245, 1.4518466966549235, 1.3113151445727245, 2.5681026597766827, 2.427571107694484, 2.427571107694484, 3.7900143607843626, 2.533226845580405, 2.427571107694484, 2.427571107694484, 1.3113151445727245, 2.427571107694484, 1.4518466966549235, 1.3113151445727245, 2.427571107694484, 1.4518466966549235, 2.533226845580405]\n",
      "all_sum after preprocessing is: [ 0.29569715  0.50433685  0.29569715  0.29569715  0.50433685 -1.36154853\n",
      "  2.10980427  0.29569715 -1.36154853  0.50433685  0.29569715 -1.36154853\n",
      "  0.29569715 -1.36154853  0.29569715 -1.36154853 -1.36154853  0.29569715\n",
      "  0.29569715  0.29569715  2.31844397  2.10980427  0.29569715  0.29569715\n",
      "  0.29569715  0.29569715 -1.36154853  0.50433685  0.29569715  0.29569715\n",
      "  0.50433685  0.50433685 -1.36154853 -1.36154853 -1.15290883 -1.36154853\n",
      "  0.50433685  0.29569715  0.29569715  2.31844397  0.45255859  0.29569715\n",
      "  0.29569715 -1.36154853  0.29569715 -1.15290883 -1.36154853  0.29569715\n",
      " -1.15290883  0.45255859]\n",
      "P is: [0.5733903138825548, 0.6234779640967496, 0.5733903138825548, 0.5733903138825548, 0.6234779640967496, 0.20398874055338087, 0.8918524561136516, 0.5733903138825548, 0.20398874055338087, 0.6234779640967496, 0.5733903138825548, 0.20398874055338087, 0.5733903138825548, 0.20398874055338087, 0.5733903138825548, 0.20398874055338087, 0.20398874055338087, 0.5733903138825548, 0.5733903138825548, 0.5733903138825548, 0.910393084454797, 0.8918524561136516, 0.5733903138825548, 0.5733903138825548, 0.5733903138825548, 0.5733903138825548, 0.20398874055338087, 0.6234779640967496, 0.5733903138825548, 0.5733903138825548, 0.6234779640967496, 0.6234779640967496, 0.20398874055338087, 0.20398874055338087, 0.2399581739436251, 0.20398874055338087, 0.6234779640967496, 0.5733903138825548, 0.5733903138825548, 0.910393084454797, 0.6112473885701145, 0.5733903138825548, 0.5733903138825548, 0.20398874055338087, 0.5733903138825548, 0.2399581739436251, 0.20398874055338087, 0.5733903138825548, 0.2399581739436251, 0.6112473885701145]\n",
      "all_sum before preprocessing is: [2.9129801595312164, 1.9986968886649912, 3.0262809033291407, 1.9986968886649912, 3.0262809033291407, 1.9986968886649912, 3.0262809033291407, 3.0262809033291407, 3.0262809033291407, 2.9129801595312164, 3.0262809033291407, 1.9986968886649912, 3.119308701869631, 3.0262809033291407, 2.9129801595312164, 2.9129801595312164, 1.9986968886649912, 3.0262809033291407, 1.9986968886649912, 1.9986968886649912, 2.1119976324629155, 2.1119976324629155, 2.9129801595312164, 3.0262809033291407, 2.9129801595312164, 2.9129801595312164, 3.0262809033291407, 1.9986968886649912, 2.9129801595312164, 2.9129801595312164, 2.9129801595312164, 2.9129801595312164, 2.9129801595312164, 2.9129801595312164, 2.1119976324629155, 1.9986968886649912, 2.9129801595312164, 1.9986968886649912, 3.0262809033291407, 2.1119976324629155, 2.9129801595312164, 3.0262809033291407, 1.9986968886649912, 3.0262809033291407, 3.0262809033291407, 2.1119976324629155, 3.0262809033291407, 3.0262809033291407, 3.0262809033291407, 2.1119976324629155]\n",
      "all_sum after preprocessing is: [ 0.56751682 -1.47037754  0.82005884 -1.47037754  0.82005884 -1.47037754\n",
      "  0.82005884  0.82005884  0.82005884  0.56751682  0.82005884 -1.47037754\n",
      "  1.02741342  0.82005884  0.56751682  0.56751682 -1.47037754  0.82005884\n",
      " -1.47037754 -1.47037754 -1.21783551 -1.21783551  0.56751682  0.82005884\n",
      "  0.56751682  0.56751682  0.82005884 -1.47037754  0.56751682  0.56751682\n",
      "  0.56751682  0.56751682  0.56751682  0.56751682 -1.21783551 -1.47037754\n",
      "  0.56751682 -1.47037754  0.82005884 -1.21783551  0.56751682  0.82005884\n",
      " -1.47037754  0.82005884  0.82005884 -1.21783551  0.82005884  0.82005884\n",
      "  0.82005884 -1.21783551]\n",
      "P is: [0.6381899965916832, 0.18688523727869566, 0.6942488300187561, 0.18688523727869566, 0.6942488300187561, 0.18688523727869566, 0.6942488300187561, 0.6942488300187561, 0.6942488300187561, 0.6381899965916832, 0.6942488300187561, 0.18688523727869566, 0.736414126455783, 0.6942488300187561, 0.6381899965916832, 0.6381899965916832, 0.18688523727869566, 0.6942488300187561, 0.18688523727869566, 0.18688523727869566, 0.22831758436874444, 0.22831758436874444, 0.6381899965916832, 0.6942488300187561, 0.6381899965916832, 0.6381899965916832, 0.6942488300187561, 0.18688523727869566, 0.6381899965916832, 0.6381899965916832, 0.6381899965916832, 0.6381899965916832, 0.6381899965916832, 0.6381899965916832, 0.22831758436874444, 0.18688523727869566, 0.6381899965916832, 0.18688523727869566, 0.6942488300187561, 0.22831758436874444, 0.6381899965916832, 0.6942488300187561, 0.18688523727869566, 0.6942488300187561, 0.6942488300187561, 0.22831758436874444, 0.6942488300187561, 0.6942488300187561, 0.6942488300187561, 0.22831758436874444]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.064\n",
      "(*) epoch 2, cost 2.881\n",
      "(*) epoch 3, cost 2.505\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.132\n",
      "(*) epoch 2, cost 1.835\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 2.600889415409884, 2.600889415409884, 1.358378890292098, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 2.600889415409884, 1.0544344687462741, 1.358378890292098, 1.0544344687462741, 1.35442718643894, 1.0544344687462741, 2.600889415409884, 2.470221836169525, 1.0544344687462741, 2.470221836169525, 2.600889415409884, 1.0544344687462741, 1.0745993202047444, 0.7369895061932555, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 2.3602682405191553, 1.0544344687462741, 2.600889415409884, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 2.3602682405191553, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 1.0544344687462741, 2.4165160414485403, 1.0544344687462741, 1.0544344687462741, 2.600889415409884]\n",
      "all_sum after preprocessing is: [-0.58067367 -0.58067367 -0.58067367  1.88076007  1.88076007 -0.09689685\n",
      " -0.58067367 -0.58067367 -0.58067367 -0.58067367  1.88076007 -0.58067367\n",
      " -0.09689685 -0.58067367 -0.10318663 -0.58067367  1.88076007  1.67278144\n",
      " -0.58067367  1.67278144  1.88076007 -0.58067367 -0.54857804 -1.08593879\n",
      " -0.58067367 -0.58067367 -0.58067367 -0.58067367 -0.58067367 -0.58067367\n",
      "  1.49777247 -0.58067367  1.88076007 -0.58067367 -0.58067367 -0.58067367\n",
      " -0.58067367 -0.58067367 -0.58067367  1.49777247 -0.58067367 -0.58067367\n",
      " -0.58067367 -0.58067367 -0.58067367 -0.58067367  1.58729996 -0.58067367\n",
      " -0.58067367  1.88076007]\n",
      "P is: [0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.8676984056139512, 0.8676984056139512, 0.475794722901469, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.8676984056139512, 0.3587775968796653, 0.475794722901469, 0.3587775968796653, 0.4742262077010555, 0.3587775968796653, 0.8676984056139512, 0.84194630682911, 0.3587775968796653, 0.84194630682911, 0.8676984056139512, 0.3587775968796653, 0.3661943773992192, 0.2523838020328802, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.8172420123598738, 0.3587775968796653, 0.8676984056139512, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.8172420123598738, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.3587775968796653, 0.8302358871187137, 0.3587775968796653, 0.3587775968796653, 0.8676984056139512]\n",
      "all_sum before preprocessing is: [2.9591132647456395, 3.1803231662468243, 4.886036311923578, 1.2372178843126846, 4.244834057878339, 2.7147117417687956, 2.5777193519351362, 4.626227970688841, 3.148734113232731, 3.124431504147601, 2.1679995895563313, 1.2372178843126846, 2.9043325902558874, 5.035947733067647, 5.225708509099923, 3.148734113232731, 2.5777193519351362, 4.244834057878339, 1.4816194072895281, 1.2372178843126846, 2.9043325902558874, 1.7839300365251494, 2.028331559501993, 1.2372178843126846, 4.244834057878339, 1.7839300365251494, 2.9043325902558874, 2.0051399380263346, 4.281867845000684, 2.8591546620343244, 3.148734113232731, 2.9359216432699813, 2.5777193519351362, 2.028331559501993, 2.0051399380263346, 1.4816194072895281, 1.4816194072895281, 2.0051399380263346, 3.451044742468352, 2.8591546620343244, 3.5085010571787825, 2.9043325902558874, 2.7147117417687956, 1.2372178843126846, 1.2372178843126846, 2.1679995895563313, 2.5518520902387993, 4.055213209391247, 1.2372178843126846, 2.0051399380263346]\n",
      "all_sum after preprocessing is: [ 0.22777977  0.43147803  2.00216181 -1.35780521  1.41171905  0.0027258\n",
      " -0.12342186  1.76292068  0.40238966  0.38001092 -0.50070698 -1.35780521\n",
      "  0.1773357   2.1402058   2.31494454  0.40238966 -0.12342186  1.41171905\n",
      " -1.13275125 -1.35780521  0.1773357  -0.85437243 -0.62931847 -1.35780521\n",
      "  1.41171905 -0.85437243  0.1773357  -0.65067417  1.44582113  0.13573419\n",
      "  0.40238966  0.20642406 -0.12342186 -0.62931847 -0.65067417 -1.13275125\n",
      " -1.13275125 -0.65067417  0.68076848  0.13573419  0.73367638  0.1773357\n",
      "  0.0027258  -1.35780521 -1.35780521 -0.50070698 -0.14724139  1.23710916\n",
      " -1.35780521 -0.65067417]\n",
      "P is: [0.5567000036250995, 0.606226553270372, 0.8810238675845701, 0.20459724414810407, 0.8040369413717611, 0.5006814501208622, 0.4691836438729496, 0.853575077217209, 0.5992616664365145, 0.5938757367621421, 0.3773745408277689, 0.20459724414810407, 0.5442181039694285, 0.8947499923405174, 0.9101071995547116, 0.5992616664365145, 0.4691836438729496, 0.8040369413717611, 0.2436537253590368, 0.20459724414810407, 0.5442181039694285, 0.2985164448810265, 0.3476650892172659, 0.20459724414810407, 0.8040369413717611, 0.2985164448810265, 0.5442181039694285, 0.3428376305111907, 0.8093544687927886, 0.5338815441466591, 0.5992616664365145, 0.5514235455030285, 0.4691836438729496, 0.3476650892172659, 0.3428376305111907, 0.2436537253590368, 0.2436537253590368, 0.3428376305111907, 0.6639101916477763, 0.5338815441466591, 0.6756115090458616, 0.5442181039694285, 0.5006814501208622, 0.20459724414810407, 0.20459724414810407, 0.3773745408277689, 0.46325601243165615, 0.7750604202428557, 0.20459724414810407, 0.3428376305111907]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.545\n",
      "(*) epoch 2, cost 0.846\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.539\n",
      "(*) epoch 2, cost 2.963\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.699282474715662, 1.0208943567216067, 1.0208943567216067, 1.699282474715662, 0.6644275062191042, 0.6644275062191042, 1.699282474715662, 0.6644275062191042, 1.0208943567216067, 1.699282474715662, 1.699282474715662, 0.6644275062191042, 0.6644275062191042, 1.0208943567216067, 0.6644275062191042, 0.6644275062191042, 1.0208943567216067, 1.0208943567216067, 0.6644275062191042, 1.0208943567216067, 0.6644275062191042, 0.6644275062191042, 1.699282474715662, 1.0208943567216067, 0.6644275062191042, 1.0208943567216067, 2.0557493252181644, 0.6644275062191042, 1.0208943567216067, 0.6644275062191042, 1.0208943567216067, 2.0557493252181644, 1.0208943567216067, 1.0208943567216067, 2.0557493252181644, 1.0208943567216067, 1.699282474715662, 0.6644275062191042, 1.8872423076447582, 1.0208943567216067, 1.0208943567216067, 0.6644275062191042, 0.6644275062191042, 1.0208943567216067, 1.0208943567216067, 1.0208943567216067, 0.6644275062191042, 1.0208943567216067, 1.0208943567216067, 1.699282474715662]\n",
      "all_sum after preprocessing is: [ 1.39712668 -0.15250231 -0.15250231  1.39712668 -0.96677271 -0.96677271\n",
      "  1.39712668 -0.96677271 -0.15250231  1.39712668  1.39712668 -0.96677271\n",
      " -0.96677271 -0.15250231 -0.96677271 -0.96677271 -0.15250231 -0.15250231\n",
      " -0.96677271 -0.15250231 -0.96677271 -0.96677271  1.39712668 -0.15250231\n",
      " -0.96677271 -0.15250231  2.21139708 -0.96677271 -0.15250231 -0.96677271\n",
      " -0.15250231  2.21139708 -0.15250231 -0.15250231  2.21139708 -0.15250231\n",
      "  1.39712668 -0.96677271  1.82647973 -0.15250231 -0.15250231 -0.96677271\n",
      " -0.96677271 -0.15250231 -0.15250231 -0.15250231 -0.96677271 -0.15250231\n",
      " -0.15250231  1.39712668]\n",
      "P is: [0.8017275403716009, 0.4619481425201935, 0.4619481425201935, 0.8017275403716009, 0.2755242374598766, 0.2755242374598766, 0.8017275403716009, 0.2755242374598766, 0.4619481425201935, 0.8017275403716009, 0.8017275403716009, 0.2755242374598766, 0.2755242374598766, 0.4619481425201935, 0.2755242374598766, 0.2755242374598766, 0.4619481425201935, 0.4619481425201935, 0.2755242374598766, 0.4619481425201935, 0.2755242374598766, 0.2755242374598766, 0.8017275403716009, 0.4619481425201935, 0.2755242374598766, 0.4619481425201935, 0.9012683141008516, 0.2755242374598766, 0.4619481425201935, 0.2755242374598766, 0.4619481425201935, 0.9012683141008516, 0.4619481425201935, 0.4619481425201935, 0.9012683141008516, 0.4619481425201935, 0.8017275403716009, 0.2755242374598766, 0.8613418280129976, 0.4619481425201935, 0.4619481425201935, 0.2755242374598766, 0.2755242374598766, 0.4619481425201935, 0.4619481425201935, 0.4619481425201935, 0.2755242374598766, 0.4619481425201935, 0.4619481425201935, 0.8017275403716009]\n",
      "all_sum before preprocessing is: [2.1219887904559993, 2.3928780769273312, 2.3928780769273312, 2.1219887904559993, 2.1219887904559993, 2.3928780769273312, 2.3928780769273312, 2.3928780769273312, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993, 2.3928780769273312, 2.3928780769273312, 2.3928780769273312, 2.1219887904559993, 5.3756667166315015, 2.3928780769273312, 2.1219887904559993, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993, 2.1219887904559993, 2.3928780769273312, 2.3928780769273312, 2.5772963632559693, 2.3928780769273312, 2.3928780769273312, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993, 2.1219887904559993, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993, 2.3928780769273312, 2.3928780769273312, 2.1219887904559993, 2.1219887904559993, 2.1219887904559993, 2.1219887904559993, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993, 2.1219887904559993, 2.3928780769273312, 2.1219887904559993]\n",
      "all_sum after preprocessing is: [-0.43367625  0.15729397  0.15729397 -0.43367625 -0.43367625  0.15729397\n",
      "  0.15729397  0.15729397 -0.43367625  0.15729397 -0.43367625  0.15729397\n",
      "  0.15729397  0.15729397 -0.43367625  6.66452524  0.15729397 -0.43367625\n",
      " -0.43367625  0.15729397 -0.43367625 -0.43367625  0.15729397  0.15729397\n",
      "  0.55961964  0.15729397  0.15729397 -0.43367625  0.15729397 -0.43367625\n",
      "  0.15729397 -0.43367625 -0.43367625 -0.43367625  0.15729397 -0.43367625\n",
      "  0.15729397  0.15729397 -0.43367625 -0.43367625 -0.43367625 -0.43367625\n",
      " -0.43367625  0.15729397 -0.43367625  0.15729397 -0.43367625 -0.43367625\n",
      "  0.15729397 -0.43367625]\n",
      "P is: [0.3932488206800009, 0.5392426154590741, 0.5392426154590741, 0.3932488206800009, 0.3932488206800009, 0.5392426154590741, 0.5392426154590741, 0.5392426154590741, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009, 0.5392426154590741, 0.5392426154590741, 0.5392426154590741, 0.3932488206800009, 0.9987262625052366, 0.5392426154590741, 0.3932488206800009, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009, 0.3932488206800009, 0.5392426154590741, 0.5392426154590741, 0.63636452734488, 0.5392426154590741, 0.5392426154590741, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009, 0.3932488206800009, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009, 0.5392426154590741, 0.5392426154590741, 0.3932488206800009, 0.3932488206800009, 0.3932488206800009, 0.3932488206800009, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009, 0.3932488206800009, 0.5392426154590741, 0.3932488206800009]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.955\n",
      "(*) epoch 2, cost 2.099\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.873\n",
      "(*) epoch 2, cost 3.110\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.6397809829818172, 1.6107402987788588, 1.5834086059947299, 0.6397809829818172, 1.6107402987788588, 3.0559911162799906, 1.8421085546327505, 1.2632048707210832, 0.6397809829818172, 4.2090327096578255, 1.6881155911771906, 1.6107402987788588, 2.4162464640989176, 0.6397809829818172, 3.1450822342018725, 3.160698101462452, 0.6397809829818172, 1.4903565723928072, 0.5350739977993563, 3.160698101462452, 0.6397809829818172, 4.026950432077032, 0.6397809829818172, 0.6397809829818172, 1.6107402987788588, 1.367911855903544, 1.6107402987788588, 0.6397809829818172, 1.6684800120373562, 0.6397809829818172, 2.659074906974232, 1.6881155911771906, 0.6397809829818172, 1.5834086059947299, 1.2632048707210832, 1.6998314167007407, 4.104325724475364, 2.5386911805881804, 4.131657417259493, 4.739404563795168, 0.5350739977993563, 2.55040700611173, 1.6107402987788588, 1.6881155911771906, 0.6397809829818172, 2.4162464640989176, 3.8614024786251657, 0.6397809829818172, 0.6397809829818172, 1.2150954607154374]\n",
      "all_sum after preprocessing is: [-0.99539142 -0.16106054 -0.18454625 -0.99539142 -0.16106054  1.08082197\n",
      "  0.03775076 -0.45969256 -0.99539142  2.07161345 -0.0945731  -0.16106054\n",
      "  0.53109892 -0.99539142  1.15737665  1.17079513 -0.99539142 -0.26450448\n",
      " -1.08536457  1.17079513 -0.99539142  1.91515286 -0.99539142 -0.99539142\n",
      " -0.16106054 -0.3697194  -0.16106054 -0.99539142 -0.11144566 -0.99539142\n",
      "  0.73975778 -0.0945731  -0.99539142 -0.18454625 -0.45969256 -0.08450587\n",
      "  1.9816403   0.63631384  2.00512601  2.52735409 -1.08536457  0.64638108\n",
      " -0.16106054 -0.0945731  -0.99539142  0.53109892  1.77289997 -0.99539142\n",
      " -0.99539142 -0.50103226]\n",
      "P is: [0.26984848721180366, 0.4598216821169425, 0.45399393289847484, 0.26984848721180366, 0.4598216821169425, 0.7466495028613566, 0.5094365696226454, 0.38705876067152867, 0.26984848721180366, 0.8881133871255532, 0.47637433157097514, 0.4598216821169425, 0.6297393809268965, 0.26984848721180366, 0.7608557109608531, 0.7632887087817399, 0.26984848721180366, 0.43425673130125947, 0.2524921637546748, 0.7632887087817399, 0.26984848721180366, 0.871596938850354, 0.26984848721180366, 0.26984848721180366, 0.4598216821169425, 0.40860882557672584, 0.4598216821169425, 0.26984848721180366, 0.47216738595808383, 0.26984848721180366, 0.6769428882142916, 0.47637433157097514, 0.26984848721180366, 0.45399393289847484, 0.38705876067152867, 0.4788860971307932, 0.878855910034008, 0.6539197247014341, 0.8813342267642343, 0.9260373332418093, 0.2524921637546748, 0.6561944835719516, 0.4598216821169425, 0.47637433157097514, 0.26984848721180366, 0.6297393809268965, 0.8548179397426494, 0.26984848721180366, 0.26984848721180366, 0.37729811555457404]\n",
      "all_sum before preprocessing is: [1.2413720058628985, 1.2413720058628985, 1.2413720058628985, 1.2413720058628985, 1.306326127620904, 0.7980570089807174, 1.7319075713527696, 0.8630111307387229, 1.2413720058628985, 1.306326127620904, 1.7968616931107753, 2.175222568234951, 1.306326127620904, 2.175222568234951, 1.7319075713527696, 1.306326127620904, 1.2413720058628985, 1.7968616931107753, 1.7968616931107753, 1.7968616931107753, 2.8594062880470066, 1.2413720058628985, 0.714124519432961, 1.306326127620904, 1.2413720058628985, 2.240176689992956, 1.7968616931107753, 1.7538555616846656, 1.306326127620904, 1.2413720058628985, 2.175222568234951, 2.175222568234951, 1.7319075713527696, 2.240176689992956, 3.414895975294883, 0.7980570089807174, 1.306326127620904, 2.924360409805012, 0.8630111307387229, 1.2413720058628985, 2.240176689992956, 1.306326127620904, 1.306326127620904, 1.2413720058628985, 2.240176689992956, 2.240176689992956, 1.7968616931107753, 1.6479750818050132, 1.2413720058628985, 1.7538555616846656]\n",
      "all_sum after preprocessing is: [-0.67078188 -0.67078188 -0.67078188 -0.67078188 -0.55523644 -1.45938504\n",
      "  0.2018209  -1.3438396  -0.67078188 -0.55523644  0.31736634  0.99042406\n",
      " -0.55523644  0.99042406  0.2018209  -0.55523644 -0.67078188  0.31736634\n",
      "  0.31736634  0.31736634  2.20750323 -0.67078188 -1.60869068 -0.55523644\n",
      " -0.67078188  1.1059695   0.31736634  0.24086369 -0.55523644 -0.67078188\n",
      "  0.99042406  0.99042406  0.2018209   1.1059695   3.19565145 -1.45938504\n",
      " -0.55523644  2.32304867 -1.3438396  -0.67078188  1.1059695  -0.55523644\n",
      " -0.55523644 -0.67078188  1.1059695   1.1059695   0.31736634  0.05251527\n",
      " -0.67078188  0.24086369]\n",
      "P is: [0.33832178702603033, 0.33832178702603033, 0.33832178702603033, 0.33832178702603033, 0.3646503702643745, 0.18856139937120941, 0.5502846592922491, 0.20687934623321602, 0.33832178702603033, 0.3646503702643745, 0.5786822750755841, 0.7291716746758375, 0.3646503702643745, 0.7291716746758375, 0.5502846592922491, 0.3646503702643745, 0.33832178702603033, 0.5786822750755841, 0.5786822750755841, 0.5786822750755841, 0.9009212825406113, 0.33832178702603033, 0.16677047525575125, 0.3646503702643745, 0.33832178702603033, 0.7513769387353615, 0.5786822750755841, 0.5599264813234067, 0.3646503702643745, 0.33832178702603033, 0.7291716746758375, 0.7291716746758375, 0.5502846592922491, 0.7513769387353615, 0.9606703050722568, 0.18856139937120941, 0.3646503702643745, 0.9107680151065684, 0.20687934623321602, 0.33832178702603033, 0.7513769387353615, 0.3646503702643745, 0.3646503702643745, 0.33832178702603033, 0.7513769387353615, 0.7513769387353615, 0.5786822750755841, 0.5131258000825754, 0.33832178702603033, 0.5599264813234067]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.783\n",
      "(*) epoch 2, cost 3.218\n",
      "(*) epoch 3, cost 2.554\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.019\n",
      "(*) epoch 2, cost 3.438\n",
      "(*) epoch 3, cost 2.610\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7367072132028505, 1.7911054047389212, 2.2893414723629713, 1.7367072132028505, 1.529510700944986, 2.0520963935755776, 2.025199155286182, 1.7911054047389212, 4.423900019867175, 3.928211565525979, 1.5449631235632624, 1.8180026430283172, 1.5449631235632624, 1.5449631235632624, 5.832308050425481, 1.7367072132028505, 2.6923801652849124, 1.7911054047389212, 1.7018595353095445, 2.0520963935755776, 1.7911054047389212, 1.5449631235632624, 2.4810855620025594, 2.00084953027964, 1.7911054047389212, 2.6923801652849124, 4.381550358959503, 2.025199155286182, 2.5354837535386303, 1.7911054047389212, 1.7636044514922464, 2.025199155286182, 2.473135122398649, 4.4507972581565705, 1.7636044514922464, 1.4133675932262133, 1.0223774309326707, 4.93103328987949, 2.0520963935755776, 2.7695775040858908, 1.5449631235632624, 1.7367072132028505, 1.0223774309326707, 1.5449631235632624, 2.025199155286182, 2.025199155286182, 1.7367072132028505, 1.0492746692220667, 4.4507972581565705, 1.310869373016002]\n",
      "all_sum after preprocessing is: [-0.46949233 -0.41815566  0.05203979 -0.46949233 -0.66502787 -0.17185319\n",
      " -0.19723665 -0.41815566  2.06646585  1.59867463 -0.65044511 -0.39277219\n",
      " -0.65044511 -0.65044511  3.39560899 -0.46949233  0.43239556 -0.41815566\n",
      " -0.50237879 -0.17185319 -0.41815566 -0.65044511  0.23299257 -0.22021589\n",
      " -0.41815566  0.43239556  2.02649962 -0.19723665  0.28432924 -0.41815566\n",
      " -0.44410886 -0.19723665  0.22548958  2.09184932 -0.44410886 -0.77463447\n",
      " -1.14361979  2.54505777 -0.17185319  0.50524824 -0.65044511 -0.46949233\n",
      " -1.14361979 -0.65044511 -0.19723665 -0.19723665 -0.46949233 -1.11823632\n",
      "  2.09184932 -0.87136411]\n",
      "P is: [0.3847364088443199, 0.39695816890251956, 0.5130070126853641, 0.3847364088443199, 0.3396110763667439, 0.4571421303054434, 0.45085007053575116, 0.39695816890251956, 0.8876008577109878, 0.8318330654838939, 0.34288924066823795, 0.4030501306059041, 0.34288924066823795, 0.34288924066823795, 0.967567023068455, 0.3847364088443199, 0.6064455595724609, 0.39695816890251956, 0.3769818073257965, 0.4571421303054434, 0.39695816890251956, 0.34288924066823795, 0.5579860614927296, 0.44516744164264455, 0.39695816890251956, 0.6064455595724609, 0.883551412937875, 0.45085007053575116, 0.570607273487875, 0.39695816890251956, 0.3907623457983355, 0.45085007053575116, 0.556134745007813, 0.8901084480016423, 0.3907623457983355, 0.31547743131839157, 0.24165638318907842, 0.9272407888876023, 0.4571421303054434, 0.6236918931827703, 0.34288924066823795, 0.3847364088443199, 0.24165638318907842, 0.34288924066823795, 0.45085007053575116, 0.45085007053575116, 0.3847364088443199, 0.24633857410748847, 0.8901084480016423, 0.29497053803960616]\n",
      "all_sum before preprocessing is: [2.662047106218993, 4.4160698449992335, 4.515430935187815, 2.662047106218993, 4.4160698449992335, 2.662047106218993, 2.662047106218993, 2.761408196407574, 4.4160698449992335, 2.684017304709509, 4.4160698449992335, 3.2804672218903335, 4.4160698449992335, 4.4160698449992335, 4.4160698449992335, 2.662047106218993, 3.2804672218903335, 4.4160698449992335, 4.4160698449992335, 2.662047106218993, 4.438040043489749, 4.4160698449992335, 2.662047106218993, 2.662047106218993, 3.2804672218903335, 5.034489960670574, 3.2804672218903335, 2.662047106218993, 2.662047106218993, 4.515430935187815, 1.983001293229192, 3.2804672218903335, 5.034489960670574, 3.2804672218903335, 5.034489960670574, 4.4160698449992335, 4.4160698449992335, 5.056460159161089, 4.4160698449992335, 4.4160698449992335, 4.4160698449992335, 2.662047106218993, 2.662047106218993, 4.438040043489749, 5.034489960670574, 2.662047106218993, 2.662047106218993, 4.4160698449992335, 2.662047106218993, 3.2804672218903335]\n",
      "all_sum after preprocessing is: [-1.11478876  0.80304303  0.9116835  -1.11478876  0.80304303 -1.11478876\n",
      " -1.11478876 -1.00614829  0.80304303 -1.09076676  0.80304303 -0.43861409\n",
      "  0.80304303  0.80304303  0.80304303 -1.11478876 -0.43861409  0.80304303\n",
      "  0.80304303 -1.11478876  0.82706504  0.80304303 -1.11478876 -1.11478876\n",
      " -0.43861409  1.47921771 -0.43861409 -1.11478876 -1.11478876  0.9116835\n",
      " -1.857251   -0.43861409  1.47921771 -0.43861409  1.47921771  0.80304303\n",
      "  0.80304303  1.50323971  0.80304303  0.80304303  0.80304303 -1.11478876\n",
      " -1.11478876  0.82706504  1.47921771 -1.11478876 -1.11478876  0.80304303\n",
      " -1.11478876 -0.43861409]\n",
      "P is: [0.2469791934620692, 0.690625038116542, 0.7133445356582914, 0.2469791934620692, 0.690625038116542, 0.2469791934620692, 0.2469791934620692, 0.2677343125992044, 0.690625038116542, 0.25147392061972196, 0.690625038116542, 0.3920712543795367, 0.690625038116542, 0.690625038116542, 0.690625038116542, 0.2469791934620692, 0.3920712543795367, 0.690625038116542, 0.690625038116542, 0.2469791934620692, 0.6957339897223865, 0.690625038116542, 0.2469791934620692, 0.2469791934620692, 0.3920712543795367, 0.8144543908760787, 0.3920712543795367, 0.2469791934620692, 0.2469791934620692, 0.7133445356582914, 0.13502379201894865, 0.3920712543795367, 0.8144543908760787, 0.3920712543795367, 0.8144543908760787, 0.690625038116542, 0.690625038116542, 0.818057170868463, 0.690625038116542, 0.690625038116542, 0.690625038116542, 0.2469791934620692, 0.2469791934620692, 0.6957339897223865, 0.8144543908760787, 0.2469791934620692, 0.2469791934620692, 0.690625038116542, 0.2469791934620692, 0.3920712543795367]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.295\n",
      "(*) epoch 2, cost 5.040\n",
      "(*) epoch 3, cost 3.938\n",
      "(*) epoch 4, cost 3.557\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.215\n",
      "(*) epoch 2, cost 2.786\n",
      "(*) epoch 3, cost 2.098\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.4670909833277657, 1.7904305395636222, 2.4670909833277657, 2.9895268219918854, 2.4670909833277657, 2.9895268219918854, 2.9895268219918854, 2.114734200173704, 1.7904305395636222, 3.535871112704133, 2.9895268219918854, 2.9895268219918854, 2.4670909833277657, 2.114734200173704, 1.7904305395636222, 1.7904305395636222, 1.7904305395636222, 2.9895268219918854, 1.9760443039312956, 2.9895268219918854, 2.4670909833277657, 2.4670909833277657, 2.9895268219918854, 1.7904305395636222, 2.336774830275869, 1.7904305395636222, 2.9895268219918854, 2.9895268219918854, 1.7904305395636222, 1.969656381127512, 2.4670909833277657, 2.9895268219918854, 1.7904305395636222, 1.7904305395636222, 2.9895268219918854, 0.9156379177454403, 1.2679947008995023, 1.592298361509584, 1.7904305395636222, 3.5274973695136214, 2.9895268219918854, 1.7904305395636222, 2.4670909833277657, 1.7904305395636222, 2.9895268219918854, 2.114734200173704, 3.4668822794052265, 1.7904305395636222, 1.7904305395636222, 2.9895268219918854]\n",
      "all_sum after preprocessing is: [ 0.16082811 -0.93057514  0.16082811  1.00347848  0.16082811  1.00347848\n",
      "  1.00347848 -0.40749732 -0.93057514  1.88469142  1.00347848  1.00347848\n",
      "  0.16082811 -0.40749732 -0.93057514 -0.93057514 -0.93057514  1.00347848\n",
      " -0.63119386  1.00347848  0.16082811  0.16082811  1.00347848 -0.93057514\n",
      " -0.0493622  -0.93057514  1.00347848  1.00347848 -0.93057514 -0.64149711\n",
      "  0.16082811  1.00347848 -0.93057514 -0.93057514  1.00347848 -2.34155094\n",
      " -1.77322551 -1.25014769 -0.93057514  1.87118519  1.00347848 -0.93057514\n",
      "  0.16082811 -0.93057514  1.00347848 -0.40749732  1.77341753 -0.93057514\n",
      " -0.93057514  1.00347848]\n",
      "P is: [0.5401205869705867, 0.2828080463236211, 0.5401205869705867, 0.7317419400552017, 0.5401205869705867, 0.7317419400552017, 0.7317419400552017, 0.39951236910493687, 0.2828080463236211, 0.8681490636127189, 0.7317419400552017, 0.7317419400552017, 0.5401205869705867, 0.39951236910493687, 0.2828080463236211, 0.2828080463236211, 0.2828080463236211, 0.7317419400552017, 0.3472398824302284, 0.7317419400552017, 0.5401205869705867, 0.5401205869705867, 0.7317419400552017, 0.2828080463236211, 0.48766195452439004, 0.2828080463236211, 0.7317419400552017, 0.7317419400552017, 0.2828080463236211, 0.34490819420309526, 0.5401205869705867, 0.7317419400552017, 0.2828080463236211, 0.2828080463236211, 0.7317419400552017, 0.08773969618225547, 0.1451416642455566, 0.22267457467609794, 0.2828080463236211, 0.8665953541614835, 0.7317419400552017, 0.2828080463236211, 0.5401205869705867, 0.2828080463236211, 0.7317419400552017, 0.39951236910493687, 0.8548821598577874, 0.2828080463236211, 0.2828080463236211, 0.7317419400552017]\n",
      "all_sum before preprocessing is: [1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 2.7349397628855514, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 2.182630502304267, 1.6506869029937221, 1.6506869029937221, 2.182630502304267, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 2.7349397628855514, 1.6506869029937221, 2.182630502304267, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 2.182630502304267, 1.6506869029937221, 1.6506869029937221, 2.8308190491985377, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221, 1.6506869029937221]\n",
      "all_sum after preprocessing is: [-0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688\n",
      " -0.37453688 -0.37453688 -0.37453688  3.33311574 -0.37453688 -0.37453688\n",
      " -0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688\n",
      " -0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688\n",
      "  1.44446877 -0.37453688 -0.37453688  1.44446877 -0.37453688 -0.37453688\n",
      " -0.37453688  3.33311574 -0.37453688  1.44446877 -0.37453688 -0.37453688\n",
      " -0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688 -0.37453688\n",
      "  1.44446877 -0.37453688 -0.37453688  3.66097938 -0.37453688 -0.37453688\n",
      " -0.37453688 -0.37453688]\n",
      "P is: [0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.9655475668691783, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.8091457126780661, 0.40744520731074824, 0.40744520731074824, 0.8091457126780661, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.9655475668691783, 0.40744520731074824, 0.8091457126780661, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.8091457126780661, 0.40744520731074824, 0.40744520731074824, 0.9749369800712944, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824, 0.40744520731074824]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.243\n",
      "(*) epoch 2, cost 3.476\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.537\n",
      "(*) epoch 2, cost 1.147\n",
      "(*) epoch 3, cost 0.693\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.30 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.364882879571909, 3.9617569757713396, 3.5994081472782797, 3.5994081472782797, 3.5994081472782797, 3.2563627804769038, 4.307841820624345, 3.9617569757713396, 2.6429885003646794, 4.707928246373284, 2.9860338671660553, 3.2563627804769038, 3.9617569757713396, 3.2563627804769038, 3.2563627804769038, 4.670190649117405, 3.5994081472782797, 3.2563627804769038, 3.2563627804769038, 3.2563627804769038, 4.364882879571909, 3.5994081472782797, 3.5994081472782797, 3.2563627804769038, 3.2563627804769038, 2.6429885003646794, 4.3048023425727155, 2.6429885003646794, 3.964796453822969, 3.787532936952774, 3.2563627804769038, 4.307841820624345, 3.2563627804769038, 3.5994081472782797, 4.307841820624345, 3.2563627804769038, 3.2563627804769038, 3.2563627804769038, 2.6429885003646794, 3.694467540512121, 4.307841820624345, 3.5994081472782797, 3.2563627804769038, 4.364882879571909, 2.6429885003646794, 3.964796453822969, 1.536035018592943, 3.2563627804769038, 3.5994081472782797, 1.536035018592943]\n",
      "all_sum after preprocessing is: [ 1.29535497  0.69053051  0.14688538  0.14688538  0.14688538 -0.36779806\n",
      "  1.2097742   0.69053051 -1.28806581  1.81003842 -0.77338237 -0.36779806\n",
      "  0.69053051 -0.36779806 -0.36779806  1.75341933  0.14688538 -0.36779806\n",
      " -0.36779806 -0.36779806  1.29535497  0.14688538  0.14688538 -0.36779806\n",
      " -0.36779806 -1.28806581  1.20521396 -1.28806581  0.69509075  0.42913585\n",
      " -0.36779806  1.2097742  -0.36779806  0.14688538  1.2097742  -0.36779806\n",
      " -0.36779806 -0.36779806 -1.28806581  0.28950645  1.2097742   0.14688538\n",
      " -0.36779806  1.29535497 -1.28806581  0.69509075 -2.94886839 -0.36779806\n",
      "  0.14688538 -2.94886839]\n",
      "P is: [0.785052194514317, 0.666084931479661, 0.5366554648572769, 0.5366554648572769, 0.5366554648572769, 0.4090731944531803, 0.7702589931891101, 0.666084931479661, 0.21618037260222672, 0.8593665171264125, 0.3157478873546139, 0.4090731944531803, 0.666084931479661, 0.4090731944531803, 0.4090731944531803, 0.8523835600879822, 0.5366554648572769, 0.4090731944531803, 0.4090731944531803, 0.4090731944531803, 0.785052194514317, 0.5366554648572769, 0.5366554648572769, 0.4090731944531803, 0.4090731944531803, 0.21618037260222672, 0.7694510184731322, 0.21618037260222672, 0.6670984314077147, 0.6056672981689629, 0.4090731944531803, 0.7702589931891101, 0.4090731944531803, 0.5366554648572769, 0.7702589931891101, 0.4090731944531803, 0.4090731944531803, 0.4090731944531803, 0.21618037260222672, 0.5718752990460615, 0.7702589931891101, 0.5366554648572769, 0.4090731944531803, 0.785052194514317, 0.21618037260222672, 0.6670984314077147, 0.04979002187078109, 0.4090731944531803, 0.5366554648572769, 0.04979002187078109]\n",
      "all_sum before preprocessing is: [1.623361330625293, 1.7231255913230785, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 1.623361330625293, 2.6600656176609743, 1.5745091436482048, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 1.623361330625293, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 0.9493527584849416, 1.5745091436482048, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 1.623361330625293, 1.623361330625293, 1.623361330625293, 1.5745091436482048, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 1.623361330625293, 2.7089178046380624, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 1.623361330625293, 1.5745091436482048, 1.5745091436482048, 1.5745091436482048, 2.307640939329432, 1.5745091436482048, 1.5745091436482048, 1.623361330625293]\n",
      "all_sum after preprocessing is: [-0.06406267  0.32775322 -0.06406267 -0.25592559 -0.25592559 -0.25592559\n",
      " -0.25592559 -0.25592559 -0.06406267  4.0075077  -0.25592559 -0.06406267\n",
      " -0.25592559 -0.25592559 -0.25592559 -0.06406267 -0.06406267 -0.25592559\n",
      " -0.25592559 -2.7111756  -0.25592559 -0.06406267 -0.25592559 -0.25592559\n",
      " -0.25592559 -0.06406267 -0.06406267 -0.06406267 -0.25592559 -0.06406267\n",
      " -0.25592559 -0.25592559 -0.25592559 -0.06406267  4.19937062 -0.06406267\n",
      " -0.25592559 -0.25592559 -0.06406267 -0.25592559 -0.25592559 -0.25592559\n",
      " -0.06406267 -0.25592559 -0.25592559 -0.25592559  2.62338891 -0.25592559\n",
      " -0.25592559 -0.06406267]\n",
      "P is: [0.483989808330415, 0.5812125997666701, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.483989808330415, 0.9821459174979087, 0.4363655503695451, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.483989808330415, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.062317121304848594, 0.4363655503695451, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.483989808330415, 0.483989808330415, 0.483989808330415, 0.4363655503695451, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.483989808330415, 0.9852168044131385, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.483989808330415, 0.4363655503695451, 0.4363655503695451, 0.4363655503695451, 0.9323517652362662, 0.4363655503695451, 0.4363655503695451, 0.483989808330415]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.396\n",
      "(*) epoch 2, cost 3.800\n",
      "(*) epoch 3, cost 2.789\n",
      "(*) epoch 4, cost 2.468\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.112\n",
      "(*) epoch 2, cost 2.400\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.82170249770543, 1.4124871135506316, 1.9393286830651795, 1.9393286830651795, 3.2948609281908823, 3.82170249770543, 3.82170249770543, 3.1659770356195667, 1.9393286830651795, 1.9393286830651795, 3.82170249770543, 1.9393286830651795, 1.9393286830651795, 3.82170249770543, 3.82170249770543, 3.2948609281908823, 3.2948609281908823, 3.82170249770543, 1.9393286830651795, 2.639135466105019, 1.9393286830651795, 3.82170249770543, 3.2948609281908823, 3.82170249770543, 3.1659770356195667, 1.4124871135506316, 3.6064495722667798, 3.82170249770543, 3.2948609281908823, 3.2948609281908823, 3.82170249770543, 1.4124871135506316, 3.2948609281908823, 3.82170249770543, 3.82170249770543, 1.2836032209793165, 3.1659770356195667, 3.2948609281908823, 1.2836032209793165, 3.82170249770543, 3.82170249770543, 3.82170249770543, 1.4124871135506316, 3.82170249770543, 3.2948609281908823, 1.9393286830651795, 3.2948609281908823, 3.82170249770543, 3.82170249770543, 3.82170249770543]\n",
      "all_sum after preprocessing is: [ 0.88938327 -1.76987576 -1.18835523 -1.18835523  0.30786274  0.88938327\n",
      "  0.88938327  0.16560246 -1.18835523 -1.18835523  0.88938327 -1.18835523\n",
      " -1.18835523  0.88938327  0.88938327  0.30786274  0.30786274  0.88938327\n",
      " -1.18835523 -0.41591806 -1.18835523  0.88938327  0.30786274  0.88938327\n",
      "  0.16560246 -1.76987576  0.65179003  0.88938327  0.30786274  0.30786274\n",
      "  0.88938327 -1.76987576  0.30786274  0.88938327  0.88938327 -1.91213604\n",
      "  0.16560246  0.30786274 -1.91213604  0.88938327  0.88938327  0.88938327\n",
      " -1.76987576  0.88938327  0.30786274 -1.18835523  0.30786274  0.88938327\n",
      "  0.88938327  0.88938327]\n",
      "P is: [0.7087628848322549, 0.14555778022627505, 0.23355323037044476, 0.23355323037044476, 0.5763634954162912, 0.7087628848322549, 0.7087628848322549, 0.5413062597157325, 0.23355323037044476, 0.23355323037044476, 0.7087628848322549, 0.23355323037044476, 0.23355323037044476, 0.7087628848322549, 0.7087628848322549, 0.5763634954162912, 0.5763634954162912, 0.7087628848322549, 0.23355323037044476, 0.3974939329263885, 0.23355323037044476, 0.7087628848322549, 0.5763634954162912, 0.7087628848322549, 0.5413062597157325, 0.14555778022627505, 0.6574137288088724, 0.7087628848322549, 0.5763634954162912, 0.5763634954162912, 0.7087628848322549, 0.14555778022627505, 0.5763634954162912, 0.7087628848322549, 0.7087628848322549, 0.1287410694406221, 0.5413062597157325, 0.5763634954162912, 0.1287410694406221, 0.7087628848322549, 0.7087628848322549, 0.7087628848322549, 0.14555778022627505, 0.7087628848322549, 0.5763634954162912, 0.23355323037044476, 0.5763634954162912, 0.7087628848322549, 0.7087628848322549, 0.7087628848322549]\n",
      "all_sum before preprocessing is: [3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 1.1228738529410696, 1.6118871005984743, 3.655982343706374, 3.655982343706374, 4.144995591363779, 3.655982343706374, 4.645198482449101, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 1.1228738529410696, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 4.144995591363779, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 1.1228738529410696, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 3.655982343706374, 4.144995591363779, 3.655982343706374]\n",
      "all_sum after preprocessing is: [ 0.20708299  0.20708299  0.20708299  0.20708299  0.20708299  0.20708299\n",
      "  0.20708299 -3.44222581 -2.73773156  0.20708299  0.20708299  0.91157723\n",
      "  0.20708299  1.63219177  0.20708299  0.20708299  0.20708299  0.20708299\n",
      "  0.20708299  0.20708299 -3.44222581  0.20708299  0.20708299  0.20708299\n",
      "  0.20708299  0.20708299  0.20708299  0.20708299  0.20708299  0.20708299\n",
      "  0.20708299  0.20708299  0.20708299  0.91157723  0.20708299  0.20708299\n",
      "  0.20708299  0.20708299  0.20708299  0.20708299 -3.44222581  0.20708299\n",
      "  0.20708299  0.20708299  0.20708299  0.20708299  0.20708299  0.20708299\n",
      "  0.91157723  0.20708299]\n",
      "P is: [0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.03100155011976608, 0.06078327637954079, 0.5515865284375592, 0.5515865284375592, 0.7133228043487936, 0.5515865284375592, 0.8364696680726607, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.03100155011976608, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.7133228043487936, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.03100155011976608, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.5515865284375592, 0.7133228043487936, 0.5515865284375592]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.633\n",
      "(*) epoch 2, cost 2.447\n",
      "(*) epoch 3, cost 2.089\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.784\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.8662097355956335, 3.7405793187072423, 2.6420204839649095, 2.6420204839649095, 0.8662097355956335, 2.6420204839649095, 2.6420204839649095, 0.8662097355956335, 1.9647685703379663, 2.6420204839649095, 0.8662097355956335, 2.6420204839649095, 1.9647685703379663, 2.6420204839649095, 2.6420204839649095, 2.6420204839649095, 0.8662097355956335, 2.6420204839649095, 2.6420204839649095, 0.8662097355956335, 0.8662097355956335, 0.8662097355956335, 2.6420204839649095, 0.8662097355956335, 3.7405793187072423, 2.6420204839649095, 2.6420204839649095, 0.8662097355956335, 0.8662097355956335, 2.6420204839649095, 3.7405793187072423, 2.6420204839649095, 1.9647685703379663, 2.6420204839649095, 2.6420204839649095, 2.6420204839649095, 2.6420204839649095, 0.8662097355956335, 0.8662097355956335, 3.7405793187072423, 2.6420204839649095, 0.8662097355956335, 1.9647685703379663, 1.9647685703379663, 0.8662097355956335, 0.8662097355956335, 2.6420204839649095, 0.8662097355956335, 2.6420204839649095, 0.8662097355956335]\n",
      "all_sum after preprocessing is: [-1.22309125  1.81631564  0.654681    0.654681   -1.22309125  0.654681\n",
      "  0.654681   -1.22309125 -0.0614566   0.654681   -1.22309125  0.654681\n",
      " -0.0614566   0.654681    0.654681    0.654681   -1.22309125  0.654681\n",
      "  0.654681   -1.22309125 -1.22309125 -1.22309125  0.654681   -1.22309125\n",
      "  1.81631564  0.654681    0.654681   -1.22309125 -1.22309125  0.654681\n",
      "  1.81631564  0.654681   -0.0614566   0.654681    0.654681    0.654681\n",
      "  0.654681   -1.22309125 -1.22309125  1.81631564  0.654681   -1.22309125\n",
      " -0.0614566  -0.0614566  -1.22309125 -1.22309125  0.654681   -1.22309125\n",
      "  0.654681   -1.22309125]\n",
      "P is: [0.22739290586346725, 0.860123445687948, 0.658064537868942, 0.658064537868942, 0.22739290586346725, 0.658064537868942, 0.658064537868942, 0.22739290586346725, 0.48464068321203047, 0.658064537868942, 0.22739290586346725, 0.658064537868942, 0.48464068321203047, 0.658064537868942, 0.658064537868942, 0.658064537868942, 0.22739290586346725, 0.658064537868942, 0.658064537868942, 0.22739290586346725, 0.22739290586346725, 0.22739290586346725, 0.658064537868942, 0.22739290586346725, 0.860123445687948, 0.658064537868942, 0.658064537868942, 0.22739290586346725, 0.22739290586346725, 0.658064537868942, 0.860123445687948, 0.658064537868942, 0.48464068321203047, 0.658064537868942, 0.658064537868942, 0.658064537868942, 0.658064537868942, 0.22739290586346725, 0.22739290586346725, 0.860123445687948, 0.658064537868942, 0.22739290586346725, 0.48464068321203047, 0.48464068321203047, 0.22739290586346725, 0.22739290586346725, 0.658064537868942, 0.22739290586346725, 0.658064537868942, 0.22739290586346725]\n",
      "all_sum before preprocessing is: [2.9705064217937056, 3.272186297767225, 3.2698382999901723, 3.2698382999901723, 3.2698382999901723, 1.5349089524247248, 4.52132957228203, 1.7190151495018475, 2.8595830319283175, 2.9705064217937056, 1.7190151495018475, 4.52132957228203, 2.8595830319283175, 2.8595830319283175, 2.9705064217937056, 2.8595830319283175, 2.1292704175637023, 1.794545954490635, 1.794545954490635, 1.8567018451133896, 1.794545954490635, 2.8595830319283175, 2.8595830319283175, 3.2922993144823702, 2.8595830319283175, 1.7190151495018475, 2.8595830319283175, 2.8595830319283175, 4.111074304220176, 1.7190151495018475, 2.8595830319283175, 2.9705064217937056, 1.7190151495018475, 1.5349089524247248, 1.7190151495018475, 1.7190151495018475, 3.3453691049789596, 2.86193102970537, 4.111074304220176, 1.7190151495018475, 2.2048012225524896, 4.111074304220176, 1.7190151495018475, 2.7864002247165827, 2.040808042190512, 2.9705064217937056, 4.111074304220176, 2.1292704175637023, 1.794545954490635, 3.181375924616982]\n",
      "all_sum after preprocessing is: [ 0.36173945  0.72645431  0.72361571  0.72361571  0.72361571 -1.37382125\n",
      "  2.23660184 -1.15124669  0.22763899  0.36173945 -1.15124669  2.23660184\n",
      "  0.22763899  0.22763899  0.36173945  0.22763899 -0.65526997 -1.05993398\n",
      " -1.05993398 -0.98479083 -1.05993398  0.22763899  0.22763899  0.75076987\n",
      "  0.22763899 -1.15124669  0.22763899  0.22763899  1.74062513 -1.15124669\n",
      "  0.22763899  0.36173945 -1.15124669 -1.37382125 -1.15124669 -1.15124669\n",
      "  0.81492842  0.23047759  1.74062513 -1.15124669 -0.56395726  1.74062513\n",
      " -1.15124669  0.13916488 -0.76221626  0.36173945  1.74062513 -0.65526997\n",
      " -1.05993398  0.61666942]\n",
      "P is: [0.5894614396387281, 0.674026713808686, 0.6734027229541022, 0.6734027229541022, 0.6734027229541022, 0.2020031668243172, 0.9034885553333236, 0.24026144358690585, 0.5566652613048071, 0.5894614396387281, 0.24026144358690585, 0.9034885553333236, 0.5566652613048071, 0.5566652613048071, 0.5894614396387281, 0.5566652613048071, 0.34180294549333695, 0.2573220714701326, 0.2573220714701326, 0.2719422140205644, 0.2573220714701326, 0.5566652613048071, 0.5566652613048071, 0.6793464278326102, 0.5566652613048071, 0.24026144358690585, 0.5566652613048071, 0.5566652613048071, 0.85076645075065, 0.24026144358690585, 0.5566652613048071, 0.5894614396387281, 0.24026144358690585, 0.2020031668243172, 0.24026144358690585, 0.24026144358690585, 0.6931587247985594, 0.557365684541593, 0.85076645075065, 0.24026144358690585, 0.36263232095478304, 0.85076645075065, 0.24026144358690585, 0.5347351794371653, 0.3181652851683369, 0.5894614396387281, 0.85076645075065, 0.34180294549333695, 0.2573220714701326, 0.6494606811898302]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.644\n",
      "(*) epoch 2, cost 1.996\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.900\n",
      "(*) epoch 2, cost 2.237\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.013610855787548887, 1.079545599381086, 0.013610855787548887, 1.079545599381086, 1.079545599381086, 1.079545599381086, 0.36782454597587444, 0.192981318640502, 0.36782454597587444, 1.079545599381086, 1.1260663226704526, 0.013610855787548887, 0.013610855787548887, 1.079545599381086, 1.079545599381086, 1.079545599381086, 1.2589160622340392, 1.6131297524223647, 1.4337592895694116, 0.192981318640502, 1.079545599381086, 1.079545599381086, 1.079545599381086, 1.079545599381086, 1.2589160622340392, 1.079545599381086, 0.36782454597587444, 1.4337592895694116, 1.1260663226704526, 1.079545599381086, 0.36782454597587444, 1.079545599381086, 1.079545599381086, 0.013610855787548887, 1.4337592895694116, 1.4337592895694116, 1.4337592895694116, 1.079545599381086, 1.079545599381086, 0.5471950088288274, 0.013610855787548887, 0.013610855787548887, 0.013610855787548887, 0.36782454597587444, 0.36782454597587444, 0.013610855787548887, 1.079545599381086, 1.079545599381086, 0.013610855787548887, 1.079545599381086]\n",
      "all_sum after preprocessing is: [-1.51994549  0.56692388 -1.51994549  0.56692388  0.56692388  0.56692388\n",
      " -0.8264718  -1.16877697 -0.8264718   0.56692388  0.65800138 -1.51994549\n",
      " -1.51994549  0.56692388  0.56692388  0.56692388  0.9180924   1.61156609\n",
      "  1.26039757 -1.16877697  0.56692388  0.56692388  0.56692388  0.56692388\n",
      "  0.9180924   0.56692388 -0.8264718   1.26039757  0.65800138  0.56692388\n",
      " -0.8264718   0.56692388  0.56692388 -1.51994549  1.26039757  1.26039757\n",
      "  1.26039757  0.56692388  0.56692388 -0.47530328 -1.51994549 -1.51994549\n",
      " -1.51994549 -0.8264718  -0.8264718  -1.51994549  0.56692388  0.56692388\n",
      " -1.51994549  0.56692388]\n",
      "P is: [0.1794695461155889, 0.6380530737638387, 0.1794695461155889, 0.6380530737638387, 0.6380530737638387, 0.6380530737638387, 0.30439160567733886, 0.23707612324105967, 0.30439160567733886, 0.6380530737638387, 0.6588112833961192, 0.1794695461155889, 0.1794695461155889, 0.6380530737638387, 0.6380530737638387, 0.6380530737638387, 0.7146532592352363, 0.8336287037442354, 0.7790945396580296, 0.23707612324105967, 0.6380530737638387, 0.6380530737638387, 0.6380530737638387, 0.6380530737638387, 0.7146532592352363, 0.6380530737638387, 0.30439160567733886, 0.7790945396580296, 0.6588112833961192, 0.6380530737638387, 0.30439160567733886, 0.6380530737638387, 0.6380530737638387, 0.1794695461155889, 0.7790945396580296, 0.7790945396580296, 0.7790945396580296, 0.6380530737638387, 0.6380530737638387, 0.383361798344485, 0.1794695461155889, 0.1794695461155889, 0.1794695461155889, 0.30439160567733886, 0.30439160567733886, 0.1794695461155889, 0.6380530737638387, 0.6380530737638387, 0.1794695461155889, 0.6380530737638387]\n",
      "all_sum before preprocessing is: [4.738727414340005, 4.20433440797917, 2.8828895529636704, 4.20433440797917, 4.20433440797917, 2.8828895529636704, 2.8828895529636704, 4.20433440797917, 4.20433440797917, 4.20433440797917, 4.20433440797917, 3.5030043160543367, 2.8828895529636704, 2.8828895529636704, 2.8828895529636704, 4.20433440797917, 4.20433440797917, 4.5308171775467905, 2.8828895529636704, 3.1919628825138244, 2.8828895529636704, 4.20433440797917, 4.20433440797917, 2.8828895529636704, 4.20433440797917, 2.8828895529636704, 3.1919628825138244, 3.4172825593245064, 2.490632790588992, 3.7263558888746604, 2.8828895529636704, 4.20433440797917, 4.20433440797917, 4.20433440797917, 2.8828895529636704, 4.20433440797917, 2.181559461038838, 4.20433440797917, 4.20433440797917, 4.738727414340005, 4.513407737529324, 4.037397322415172, 4.20433440797917, 4.513407737529324, 4.037397322415172, 2.8828895529636704, 2.8828895529636704, 2.8828895529636704, 4.20433440797917, 3.4172825593245064]\n",
      "all_sum after preprocessing is: [ 1.54266027  0.77042137 -1.13916783  0.77042137  0.77042137 -1.13916783\n",
      " -1.13916783  0.77042137  0.77042137  0.77042137  0.77042137 -0.24305442\n",
      " -1.13916783 -1.13916783 -1.13916783  0.77042137  0.77042137  1.24221402\n",
      " -1.13916783 -0.69253316 -1.13916783  0.77042137  0.77042137 -1.13916783\n",
      "  0.77042137 -1.13916783 -0.69253316 -0.36692894 -1.70600895  0.07970574\n",
      " -1.13916783  0.77042137  0.77042137  0.77042137 -1.13916783  0.77042137\n",
      " -2.15264363  0.77042137  0.77042137  1.54266027  1.21705604  0.52918447\n",
      "  0.77042137  1.21705604  0.52918447 -1.13916783 -1.13916783 -1.13916783\n",
      "  0.77042137 -0.36692894]\n",
      "P is: [0.8238511168008957, 0.6836120373950028, 0.24247318035789264, 0.6836120373950028, 0.6836120373950028, 0.24247318035789264, 0.24247318035789264, 0.6836120373950028, 0.6836120373950028, 0.6836120373950028, 0.6836120373950028, 0.4395337740145422, 0.24247318035789264, 0.24247318035789264, 0.24247318035789264, 0.6836120373950028, 0.6836120373950028, 0.7759491615660842, 0.24247318035789264, 0.33346979643747593, 0.24247318035789264, 0.6836120373950028, 0.6836120373950028, 0.24247318035789264, 0.6836120373950028, 0.24247318035789264, 0.33346979643747593, 0.4092833061657149, 0.15368208986282936, 0.519915891392791, 0.24247318035789264, 0.6836120373950028, 0.6836120373950028, 0.6836120373950028, 0.24247318035789264, 0.6836120373950028, 0.10408444442992654, 0.6836120373950028, 0.6836120373950028, 0.8238511168008957, 0.7715450530520265, 0.6292928830800166, 0.6836120373950028, 0.7715450530520265, 0.6292928830800166, 0.24247318035789264, 0.24247318035789264, 0.24247318035789264, 0.6836120373950028, 0.4092833061657149]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.389\n",
      "(*) epoch 2, cost 1.331\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.088\n",
      "(*) epoch 2, cost 2.188\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.522172752597507, 2.8628902318091662, 0.8353653615907466, 0.8353653615907466, 1.0518570537557326, 0.8353653615907466, 1.9101238185886422, 0.8353653615907466, 0.8353653615907466, 0.8353653615907466, 0.8353653615907466, 0.8353653615907466, 0.522172752597507, 0.522172752597507, 0.522172752597507, 3.176082840802406, 0.8353653615907466, 0.8353653615907466, 2.8628902318091662, 0.8353653615907466, 0.8353653615907466, 1.8134229017603887, 3.176082840802406, 0.8353653615907466, 0.8353653615907466, 0.522172752597507, 0.522172752597507, 0.522172752597507, 3.176082840802406, 0.8353653615907466, 1.9101238185886422, 0.8353653615907466, 1.9101238185886422, 1.9101238185886422, 1.9101238185886422, 0.522172752597507, 0.8353653615907466, 0.8353653615907466, 1.9101238185886422, 0.8353653615907466, 0.8353653615907466, 0.8353653615907466, 0.8353653615907466, 0.8353653615907466, 1.9101238185886422, 1.9101238185886422, 0.8353653615907466, 3.3925745329673918, 4.250841297800301, 1.0518570537557326]\n",
      "all_sum after preprocessing is: [-0.87875848  1.67877387 -0.53655562 -0.53655562 -0.30001083 -0.53655562\n",
      "  0.63775506 -0.53655562 -0.53655562 -0.53655562 -0.53655562 -0.53655562\n",
      " -0.87875848 -0.87875848 -0.87875848  2.02097674 -0.53655562 -0.53655562\n",
      "  1.67877387 -0.53655562 -0.53655562  0.53209698  2.02097674 -0.53655562\n",
      " -0.53655562 -0.87875848 -0.87875848 -0.87875848  2.02097674 -0.53655562\n",
      "  0.63775506 -0.53655562  0.63775506  0.63775506  0.63775506 -0.87875848\n",
      " -0.53655562 -0.53655562  0.63775506 -0.53655562 -0.53655562 -0.53655562\n",
      " -0.53655562 -0.53655562  0.63775506  0.63775506 -0.53655562  2.25752152\n",
      "  3.19528742 -0.30001083]\n",
      "P is: [0.29343511741112344, 0.8427421035378557, 0.3689891964855045, 0.3689891964855045, 0.42555483450963716, 0.3689891964855045, 0.6542458128784658, 0.3689891964855045, 0.3689891964855045, 0.3689891964855045, 0.3689891964855045, 0.3689891964855045, 0.29343511741112344, 0.29343511741112344, 0.29343511741112344, 0.882981968442045, 0.3689891964855045, 0.3689891964855045, 0.8427421035378557, 0.3689891964855045, 0.3689891964855045, 0.629972065581704, 0.882981968442045, 0.3689891964855045, 0.3689891964855045, 0.29343511741112344, 0.29343511741112344, 0.29343511741112344, 0.882981968442045, 0.3689891964855045, 0.6542458128784658, 0.3689891964855045, 0.6542458128784658, 0.6542458128784658, 0.6542458128784658, 0.29343511741112344, 0.3689891964855045, 0.3689891964855045, 0.6542458128784658, 0.3689891964855045, 0.3689891964855045, 0.3689891964855045, 0.3689891964855045, 0.3689891964855045, 0.6542458128784658, 0.6542458128784658, 0.3689891964855045, 0.9052973545779714, 0.9606565488133398, 0.42555483450963716]\n",
      "all_sum before preprocessing is: [7.3353655681763295, 5.078962665459695, 5.853393827859457, 7.3353655681763295, 4.465031611988413, 3.299673818535182, 6.318666328026919, 7.949296621647612, 3.943656134842084, 3.448332371839002, 3.9136048720064642, 3.9136048720064642, 3.448332371839002, 3.299673818535182, 7.48402412148015, 5.2394627743881745, 2.83440131836772, 5.704735274555636, 3.448332371839002, 5.078962665459695, 3.448332371839002, 4.930304112155875, 4.930304112155875, 5.2394627743881745, 5.544235165627158, 3.9136048720064642, 5.544235165627158, 2.83440131836772, 6.318666328026919, 6.318666328026919, 5.704735274555636, 5.704735274555636, 3.9136048720064642, 6.813990091030001, 3.9136048720064642, 3.9136048720064642, 4.930304112155875, 3.299673818535182, 4.930304112155875, 5.574286428462777, 7.3353655681763295, 7.365416831011949, 4.465031611988413, 5.298666362345652, 7.949296621647612, 5.704735274555636, 6.813990091030001, 7.3353655681763295, 5.544235165627158, 3.9136048720064642]\n",
      "all_sum after preprocessing is: [ 1.50383416 -0.06815633  0.47137427  1.50383416 -0.49586974 -1.30775106\n",
      "  0.79552026  1.93154757 -0.85910154 -1.20418364 -0.88003765 -0.88003765\n",
      " -1.20418364 -1.30775106  1.60740158  0.04366087 -1.63189705  0.36780685\n",
      " -1.20418364 -0.06815633 -1.20418364 -0.17172375 -0.17172375  0.04366087\n",
      "  0.25598966 -0.88003765  0.25598966 -1.63189705  0.79552026  0.79552026\n",
      "  0.36780685  0.36780685 -0.88003765  1.14060236 -0.88003765 -0.88003765\n",
      " -0.17172375 -1.30775106 -0.17172375  0.27692577  1.50383416  1.52477027\n",
      " -0.49586974  0.08490681  1.93154757  0.36780685  1.14060236  1.50383416\n",
      "  0.25598966 -0.88003765]\n",
      "P is: [0.818145631537233, 0.4829675102037725, 0.6157089771122548, 0.818145631537233, 0.37851178498779087, 0.21286341619909152, 0.6890154070519223, 0.8734206135840845, 0.2975270933908999, 0.23073180653618022, 0.29316997647979853, 0.29316997647979853, 0.23073180653618022, 0.21286341619909152, 0.8330503178266628, 0.5109134826465812, 0.1635706502451437, 0.5909289304974216, 0.23073180653618022, 0.4829675102037725, 0.23073180653618022, 0.4571742509323499, 0.4571742509323499, 0.5109134826465812, 0.5636502062350418, 0.29316997647979853, 0.5636502062350418, 0.1635706502451437, 0.6890154070519223, 0.6890154070519223, 0.5909289304974216, 0.5909289304974216, 0.29316997647979853, 0.7577902156404654, 0.29316997647979853, 0.29316997647979853, 0.4571742509323499, 0.21286341619909152, 0.4571742509323499, 0.5687923740440747, 0.818145631537233, 0.8212398534687809, 0.37851178498779087, 0.5212139602730631, 0.8734206135840845, 0.5909289304974216, 0.7577902156404654, 0.818145631537233, 0.5636502062350418, 0.29316997647979853]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.230\n",
      "(*) epoch 2, cost 1.915\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.277\n",
      "(*) epoch 2, cost 3.038\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.9310630613137705, 2.2803773878391844, 3.9244921767725742, 2.060094659403874, 3.9244921767725742, 3.273806503297988, 3.9244921767725742, 2.71078033287846, 2.2803773878391844, 2.71078033287846, 3.273806503297988, 3.9244921767725742, 3.9244921767725742, 3.9244921767725742, 2.060094659403874, 2.71078033287846, 2.060094659403874, 2.9310630613137705, 2.71078033287846, 3.494089231733299, 2.71078033287846, 3.9244921767725742, 2.2803773878391844, 3.9244921767725742, 2.060094659403874, 2.71078033287846, 3.494089231733299, 2.732590996602574, 3.9463028404966884, 2.9310630613137705, 3.9244921767725742, 3.9244921767725742, 2.71078033287846, 3.9244921767725742, 3.273806503297988, 3.9244921767725742, 3.9244921767725742, 2.9310630613137705, 3.273806503297988, 2.9310630613137705, 2.71078033287846, 2.9310630613137705, 2.71078033287846, 2.71078033287846, 3.9244921767725742, 3.9244921767725742, 3.273806503297988, 3.9244921767725742, 2.71078033287846, 2.71078033287846]\n",
      "all_sum after preprocessing is: [-0.35976486 -1.38004125  1.1979339  -1.72544499  1.1979339   0.17765751\n",
      "  1.1979339  -0.7051686  -1.38004125 -0.7051686   0.17765751  1.1979339\n",
      "  1.1979339   1.1979339  -1.72544499 -0.7051686  -1.72544499 -0.35976486\n",
      " -0.7051686   0.52306126 -0.7051686   1.1979339  -1.38004125  1.1979339\n",
      " -1.72544499 -0.7051686   0.52306126 -0.67096944  1.23213306 -0.35976486\n",
      "  1.1979339   1.1979339  -0.7051686   1.1979339   0.17765751  1.1979339\n",
      "  1.1979339  -0.35976486  0.17765751 -0.35976486 -0.7051686  -0.35976486\n",
      " -0.7051686  -0.7051686   1.1979339   1.1979339   0.17765751  1.1979339\n",
      " -0.7051686  -0.7051686 ]\n",
      "P is: [0.4110164874027744, 0.2010023749785352, 0.7681570321968335, 0.15117114305053908, 0.7681570321968335, 0.544297928148542, 0.7681570321968335, 0.33066727965844434, 0.2010023749785352, 0.33066727965844434, 0.544297928148542, 0.7681570321968335, 0.7681570321968335, 0.7681570321968335, 0.15117114305053908, 0.33066727965844434, 0.15117114305053908, 0.4110164874027744, 0.33066727965844434, 0.6278633112928872, 0.33066727965844434, 0.7681570321968335, 0.2010023749785352, 0.7681570321968335, 0.15117114305053908, 0.33066727965844434, 0.6278633112928872, 0.33827980068588226, 0.7741916923496504, 0.4110164874027744, 0.7681570321968335, 0.7681570321968335, 0.33066727965844434, 0.7681570321968335, 0.544297928148542, 0.7681570321968335, 0.7681570321968335, 0.4110164874027744, 0.544297928148542, 0.4110164874027744, 0.33066727965844434, 0.4110164874027744, 0.33066727965844434, 0.33066727965844434, 0.7681570321968335, 0.7681570321968335, 0.544297928148542, 0.7681570321968335, 0.33066727965844434, 0.33066727965844434]\n",
      "all_sum before preprocessing is: [2.601889361156978, 1.6145778637478905, 2.601889361156978, 4.130888485637502, 1.6145778637478905, 3.0549560903938335, 4.042267587802922, 3.143576988228415, 1.6145778637478905, 2.5056188762729867, 4.130888485637502, 1.7875842948492404, 1.6145778637478905, 1.7875842948492404, 3.143576988228415, 2.601889361156978, 3.143576988228415, 3.0549560903938335, 3.143576988228415, 1.6145778637478905, 4.042267587802922, 4.7220741481447845, 3.0549560903938335, 3.143576988228415, 4.130888485637502, 2.601889361156978, 1.6145778637478905, 2.513268463322397, 3.1489153788788204, 3.143576988228415, 3.143576988228415, 2.601889361156978, 1.619916254398296, 4.130888485637502, 4.130888485637502, 1.6145778637478905, 3.143576988228415, 1.6145778637478905, 1.6145778637478905, 3.0549560903938335, 3.143576988228415, 3.143576988228415, 4.130888485637502, 2.601889361156978, 3.143576988228415, 4.130888485637502, 1.6145778637478905, 2.601889361156978, 3.143576988228415, 4.130888485637502]\n",
      "all_sum after preprocessing is: [-0.29852952 -1.39635455 -0.29852952  1.40161629 -1.39635455  0.20525069\n",
      "  1.30307572  0.30379126 -1.39635455 -0.40557593  1.40161629 -1.20398285\n",
      " -1.39635455 -1.20398285  0.30379126 -0.29852952  0.30379126  0.20525069\n",
      "  0.30379126 -1.39635455  1.30307572  2.05897561  0.20525069  0.30379126\n",
      "  1.40161629 -0.29852952 -1.39635455 -0.39707009  0.3097272   0.30379126\n",
      "  0.30379126 -0.29852952 -1.39041861  1.40161629  1.40161629 -1.39635455\n",
      "  0.30379126 -1.39635455 -1.39635455  0.20525069  0.30379126  0.30379126\n",
      "  1.40161629 -0.29852952  0.30379126  1.40161629 -1.39635455 -0.29852952\n",
      "  0.30379126  1.40161629]\n",
      "P is: [0.42591699334868915, 0.19839522702118068, 0.42591699334868915, 0.8024402438415885, 0.19839522702118068, 0.5511332871055069, 0.7863521660043457, 0.5753690596297065, 0.19839522702118068, 0.39997340376011165, 0.8024402438415885, 0.23076744773349264, 0.19839522702118068, 0.23076744773349264, 0.5753690596297065, 0.42591699334868915, 0.5753690596297065, 0.5511332871055069, 0.5753690596297065, 0.19839522702118068, 0.7863521660043457, 0.8868514171839942, 0.5511332871055069, 0.5753690596297065, 0.8024402438415885, 0.42591699334868915, 0.19839522702118068, 0.4020164847225521, 0.5768186720281201, 0.5753690596297065, 0.5753690596297065, 0.42591699334868915, 0.19934093649058102, 0.8024402438415885, 0.8024402438415885, 0.19839522702118068, 0.5753690596297065, 0.19839522702118068, 0.19839522702118068, 0.5511332871055069, 0.5753690596297065, 0.5753690596297065, 0.8024402438415885, 0.42591699334868915, 0.5753690596297065, 0.8024402438415885, 0.19839522702118068, 0.42591699334868915, 0.5753690596297065, 0.8024402438415885]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.599\n",
      "(*) epoch 2, cost 2.499\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.977\n",
      "(*) epoch 2, cost 3.140\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.560458830720417, 1.560458830720417, 1.809777116474125, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.809777116474125, 1.560458830720417, 2.0288292522302456, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 2.3060718827185096, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 2.278147537983954, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.809777116474125, 1.809777116474125, 2.226403768334183, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.809777116474125, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.809777116474125, 1.809777116474125, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.560458830720417, 1.809777116474125]\n",
      "all_sum after preprocessing is: [-0.48279927 -0.48279927  0.82781051 -0.48279927 -0.48279927 -0.48279927\n",
      "  0.82781051 -0.48279927  1.97931799 -0.48279927 -0.48279927 -0.48279927\n",
      " -0.48279927  3.43671973 -0.48279927 -0.48279927 -0.48279927 -0.48279927\n",
      " -0.48279927 -0.48279927  3.28992777 -0.48279927 -0.48279927 -0.48279927\n",
      " -0.48279927 -0.48279927  0.82781051  0.82781051  3.01792249 -0.48279927\n",
      " -0.48279927 -0.48279927 -0.48279927 -0.48279927  0.82781051 -0.48279927\n",
      " -0.48279927 -0.48279927 -0.48279927 -0.48279927 -0.48279927  0.82781051\n",
      "  0.82781051 -0.48279927 -0.48279927 -0.48279927 -0.48279927 -0.48279927\n",
      " -0.48279927  0.82781051]\n",
      "P is: [0.3815913377405813, 0.3815913377405813, 0.6958917752627951, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.6958917752627951, 0.3815913377405813, 0.8786084409314023, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.9688326170005528, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.9640816530096673, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.6958917752627951, 0.6958917752627951, 0.9533772690152295, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.6958917752627951, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.6958917752627951, 0.6958917752627951, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.3815913377405813, 0.6958917752627951]\n",
      "all_sum before preprocessing is: [3.474040855453924, 3.474040855453924, 4.111555588503917, 2.564722589079985, 4.111555588503917, 3.474040855453924, 4.111555588503917, 3.474040855453924, 4.111555588503917, 3.1207184245782353, 4.111555588503917, 2.564722589079985, 3.474040855453924, 2.564722589079985, 4.111555588503917, 4.111555588503917, 3.474040855453924, 2.564722589079985, 2.564722589079985, 2.564722589079985, 4.111555588503917, 1.9272078560299928, 4.111555588503917, 1.9272078560299928, 4.111555588503917, 4.111555588503917, 4.111555588503917, 4.111555588503917, 3.474040855453924, 4.111555588503917, 1.9272078560299928, 1.5738854251543049, 4.111555588503917, 4.111555588503917, 3.474040855453924, 4.111555588503917, 3.474040855453924, 1.9272078560299928, 4.111555588503917, 2.564722589079985, 4.111555588503917, 4.111555588503917, 4.111555588503917, 4.111555588503917, 4.111555588503917, 2.564722589079985, 2.564722589079985, 3.474040855453924, 3.474040855453924, 1.5738854251543049]\n",
      "all_sum after preprocessing is: [ 0.09449329  0.09449329  0.87441316 -1.01794434  0.87441316  0.09449329\n",
      "  0.87441316  0.09449329  0.87441316 -0.33775269  0.87441316 -1.01794434\n",
      "  0.09449329 -1.01794434  0.87441316  0.87441316  0.09449329 -1.01794434\n",
      " -1.01794434 -1.01794434  0.87441316 -1.7978642   0.87441316 -1.7978642\n",
      "  0.87441316  0.87441316  0.87441316  0.87441316  0.09449329  0.87441316\n",
      " -1.7978642  -2.23011019  0.87441316  0.87441316  0.09449329  0.87441316\n",
      "  0.09449329 -1.7978642   0.87441316 -1.01794434  0.87441316  0.87441316\n",
      "  0.87441316  0.87441316  0.87441316 -1.01794434 -1.01794434  0.09449329\n",
      "  0.09449329 -2.23011019]\n",
      "P is: [0.5236057615731841, 0.5236057615731841, 0.7056631542373566, 0.2654280120502607, 0.7056631542373566, 0.5236057615731841, 0.7056631542373566, 0.5236057615731841, 0.7056631542373566, 0.4163554788387784, 0.7056631542373566, 0.2654280120502607, 0.5236057615731841, 0.2654280120502607, 0.7056631542373566, 0.7056631542373566, 0.5236057615731841, 0.2654280120502607, 0.2654280120502607, 0.2654280120502607, 0.7056631542373566, 0.14211125302316668, 0.7056631542373566, 0.14211125302316668, 0.7056631542373566, 0.7056631542373566, 0.7056631542373566, 0.7056631542373566, 0.5236057615731841, 0.7056631542373566, 0.14211125302316668, 0.0970789822354559, 0.7056631542373566, 0.7056631542373566, 0.5236057615731841, 0.7056631542373566, 0.5236057615731841, 0.14211125302316668, 0.7056631542373566, 0.2654280120502607, 0.7056631542373566, 0.7056631542373566, 0.7056631542373566, 0.7056631542373566, 0.7056631542373566, 0.2654280120502607, 0.2654280120502607, 0.5236057615731841, 0.5236057615731841, 0.0970789822354559]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.586\n",
      "(*) epoch 2, cost 1.880\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.571\n",
      "(*) epoch 2, cost 2.837\n",
      "(*) epoch 3, cost 2.339\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.0110310192772687, 3.0110310192772687, 0.7377167987208724, 1.2810516571979285, 3.0110310192772687, 3.0110310192772687, 3.0110310192772687, 3.0110310192772687, 2.4676961608002124, 3.0110310192772687, 3.0110310192772687, 3.0110310192772687, 3.0110310192772687, 1.2810516571979285, 3.0110310192772687, 3.0110310192772687, 3.0110310192772687, 0.7377167987208724, 2.4676961608002124, 3.0110310192772687, 0.7377167987208724, 2.4676961608002124, 3.0110310192772687, 1.2810516571979285, 2.4676961608002124, 1.2810516571979285, 3.0110310192772687, 2.4676961608002124, 3.0110310192772687, 3.0110310192772687, 2.4676961608002124, 2.4676961608002124, 3.0110310192772687, 3.0110310192772687, 2.4676961608002124, 1.2810516571979285, 3.0110310192772687, 0.7377167987208724, 1.2810516571979285, 3.0110310192772687, 1.2810516571979285, 2.4676961608002124, 2.4676961608002124, 3.0110310192772687, 3.0110310192772687, 2.4676961608002124, 3.0110310192772687, 2.4676961608002124, 3.0110310192772687, 3.0110310192772687]\n",
      "all_sum after preprocessing is: [ 0.71829363  0.71829363 -2.22673294 -1.52285506  0.71829363  0.71829363\n",
      "  0.71829363  0.71829363  0.01441575  0.71829363  0.71829363  0.71829363\n",
      "  0.71829363 -1.52285506  0.71829363  0.71829363  0.71829363 -2.22673294\n",
      "  0.01441575  0.71829363 -2.22673294  0.01441575  0.71829363 -1.52285506\n",
      "  0.01441575 -1.52285506  0.71829363  0.01441575  0.71829363  0.71829363\n",
      "  0.01441575  0.01441575  0.71829363  0.71829363  0.01441575 -1.52285506\n",
      "  0.71829363 -2.22673294 -1.52285506  0.71829363 -1.52285506  0.01441575\n",
      "  0.01441575  0.71829363  0.71829363  0.01441575  0.71829363  0.01441575\n",
      "  0.71829363  0.71829363]\n",
      "P is: [0.6722311532296548, 0.6722311532296548, 0.09737541655980896, 0.17904148206664391, 0.6722311532296548, 0.6722311532296548, 0.6722311532296548, 0.6722311532296548, 0.5036038758985809, 0.6722311532296548, 0.6722311532296548, 0.6722311532296548, 0.6722311532296548, 0.17904148206664391, 0.6722311532296548, 0.6722311532296548, 0.6722311532296548, 0.09737541655980896, 0.5036038758985809, 0.6722311532296548, 0.09737541655980896, 0.5036038758985809, 0.6722311532296548, 0.17904148206664391, 0.5036038758985809, 0.17904148206664391, 0.6722311532296548, 0.5036038758985809, 0.6722311532296548, 0.6722311532296548, 0.5036038758985809, 0.5036038758985809, 0.6722311532296548, 0.6722311532296548, 0.5036038758985809, 0.17904148206664391, 0.6722311532296548, 0.09737541655980896, 0.17904148206664391, 0.6722311532296548, 0.17904148206664391, 0.5036038758985809, 0.5036038758985809, 0.6722311532296548, 0.6722311532296548, 0.5036038758985809, 0.6722311532296548, 0.5036038758985809, 0.6722311532296548, 0.6722311532296548]\n",
      "all_sum before preprocessing is: [5.062022815813151, 3.5539727313812093, 4.477717954664023, 3.5539727313812093, 3.1785456845615676, 3.5539727313812093, 4.686595768993509, 3.1785456845615676, 3.1785456845615676, 3.5539727313812093, 4.853145001483664, 3.1785456845615676, 5.062022815813151, 4.853145001483664, 3.387423498891054, 4.477717954664023, 4.686595768993509, 4.853145001483664, 4.477717954664023, 3.7628505457106955, 3.387423498891054, 3.387423498891054, 3.387423498891054, 1.7467889267939887, 3.5539727313812093, 1.5802396943038337, 3.254839011225931, 4.853145001483664, 3.045961196896444, 3.5539727313812093, 3.7628505457106955, 1.3713618799743472, 3.1785456845615676, 3.1785456845615676, 3.387423498891054, 4.853145001483664, 4.853145001483664, 3.1785456845615676, 3.1785456845615676, 3.1785456845615676, 3.254839011225931, 3.5539727313812093, 4.853145001483664, 4.853145001483664, 4.477717954664023, 3.5539727313812093, 3.1785456845615676, 3.1785456845615676, 4.853145001483664, 3.5539727313812093]\n",
      "all_sum after preprocessing is: [ 1.51780199 -0.20713111  0.84946424 -0.20713111 -0.6365509  -0.20713111\n",
      "  1.08838221 -0.6365509  -0.6365509  -0.20713111  1.27888402 -0.6365509\n",
      "  1.51780199  1.27888402 -0.39763293  0.84946424  1.08838221  1.27888402\n",
      "  0.84946424  0.03178685 -0.39763293 -0.39763293 -0.39763293 -2.27421841\n",
      " -0.20713111 -2.46472023 -0.5492853   1.27888402 -0.78820327 -0.20713111\n",
      "  0.03178685 -2.70363819 -0.6365509  -0.6365509  -0.39763293  1.27888402\n",
      "  1.27888402 -0.6365509  -0.6365509  -0.6365509  -0.5492853  -0.20713111\n",
      "  1.27888402  1.27888402  0.84946424 -0.20713111 -0.6365509  -0.6365509\n",
      "  1.27888402 -0.20713111]\n",
      "P is: [0.8202145842533667, 0.4484015682563184, 0.7004547427351245, 0.4484015682563184, 0.34602662926996586, 0.4484015682563184, 0.7480769579628754, 0.34602662926996586, 0.34602662926996586, 0.4484015682563184, 0.7822597528570743, 0.34602662926996586, 0.8202145842533667, 0.7822597528570743, 0.4018811857102696, 0.7004547427351245, 0.7480769579628754, 0.7822597528570743, 0.7004547427351245, 0.5079460435259614, 0.4018811857102696, 0.4018811857102696, 0.4018811857102696, 0.09328080871280295, 0.4484015682563184, 0.07836872973798294, 0.3660302396063585, 0.7822597528570743, 0.31255459246437, 0.4484015682563184, 0.5079460435259614, 0.06275901571436535, 0.34602662926996586, 0.34602662926996586, 0.4018811857102696, 0.7822597528570743, 0.7822597528570743, 0.34602662926996586, 0.34602662926996586, 0.34602662926996586, 0.3660302396063585, 0.4484015682563184, 0.7822597528570743, 0.7822597528570743, 0.7004547427351245, 0.4484015682563184, 0.34602662926996586, 0.34602662926996586, 0.7822597528570743, 0.4484015682563184]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.765\n",
      "(*) epoch 2, cost 1.076\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.192\n",
      "(*) epoch 2, cost 4.148\n",
      "(*) epoch 3, cost 2.929\n",
      "(*) epoch 4, cost 2.449\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.3162332709558706, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 1.6077579337549595, 0.8358711215711672, 0.8358711215711672, 1.6077579337549595, 0.8358711215711672, 0.8358711215711672, 1.6090735174544417, 0.8358711215711672, 0.8358711215711672, 1.4097611788451916, 0.8358711215711672, 0.8358711215711672, 1.6077579337549595, 1.3162332709558706, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 1.6077579337549595, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 2.4556206023935196, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 1.3162332709558706, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672, 0.8358711215711672]\n",
      "all_sum after preprocessing is: [ 0.99611519 -0.45188668 -0.45188668 -0.45188668  1.87488605 -0.45188668\n",
      " -0.45188668  1.87488605 -0.45188668 -0.45188668  1.87885174 -0.45188668\n",
      " -0.45188668  1.27804537 -0.45188668 -0.45188668  1.87488605  0.99611519\n",
      " -0.45188668 -0.45188668 -0.45188668 -0.45188668 -0.45188668 -0.45188668\n",
      " -0.45188668 -0.45188668  1.87488605 -0.45188668 -0.45188668 -0.45188668\n",
      " -0.45188668 -0.45188668 -0.45188668 -0.45188668  4.43068011 -0.45188668\n",
      " -0.45188668 -0.45188668 -0.45188668 -0.45188668 -0.45188668 -0.45188668\n",
      " -0.45188668 -0.45188668 -0.45188668  0.99611519 -0.45188668 -0.45188668\n",
      " -0.45188668 -0.45188668]\n",
      "P is: [0.7302940942282088, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.8670226224785784, 0.388912285897845, 0.388912285897845, 0.8670226224785784, 0.388912285897845, 0.388912285897845, 0.8674791792585314, 0.388912285897845, 0.388912285897845, 0.782116871579785, 0.388912285897845, 0.388912285897845, 0.8670226224785784, 0.7302940942282088, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.8670226224785784, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.988233704846622, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.7302940942282088, 0.388912285897845, 0.388912285897845, 0.388912285897845, 0.388912285897845]\n",
      "all_sum before preprocessing is: [3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 2.3866119550424294, 3.351230283276471, 3.351230283276471, 2.840507566092518, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 2.840507566092518, 3.351230283276471, 3.351230283276471, 2.840507566092518, 3.351230283276471, 2.840507566092518, 2.840507566092518, 3.351230283276471, 2.840507566092518, 2.840507566092518, 3.351230283276471, 3.351230283276471, 2.994688472237274, 3.351230283276471, 3.351230283276471, 2.840507566092518, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 3.351230283276471, 2.994688472237274, 3.351230283276471, 3.351230283276471, 2.840507566092518, 3.351230283276471, 2.840507566092518, 3.351230283276471]\n",
      "all_sum after preprocessing is: [ 0.56615784  0.56615784  0.56615784  0.56615784  0.56615784  0.56615784\n",
      "  0.56615784 -3.45839585  0.56615784  0.56615784 -1.56466524  0.56615784\n",
      "  0.56615784  0.56615784  0.56615784 -1.56466524  0.56615784  0.56615784\n",
      " -1.56466524  0.56615784 -1.56466524 -1.56466524  0.56615784 -1.56466524\n",
      " -1.56466524  0.56615784  0.56615784 -0.92139596  0.56615784  0.56615784\n",
      " -1.56466524  0.56615784  0.56615784  0.56615784  0.56615784  0.56615784\n",
      "  0.56615784  0.56615784  0.56615784  0.56615784  0.56615784  0.56615784\n",
      "  0.56615784 -0.92139596  0.56615784  0.56615784 -1.56466524  0.56615784\n",
      " -1.56466524  0.56615784]\n",
      "P is: [0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.030519461086946337, 0.6378761454844162, 0.6378761454844162, 0.17297823447014288, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.17297823447014288, 0.6378761454844162, 0.6378761454844162, 0.17297823447014288, 0.6378761454844162, 0.17297823447014288, 0.17297823447014288, 0.6378761454844162, 0.17297823447014288, 0.17297823447014288, 0.6378761454844162, 0.6378761454844162, 0.28467354300763764, 0.6378761454844162, 0.6378761454844162, 0.17297823447014288, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.6378761454844162, 0.28467354300763764, 0.6378761454844162, 0.6378761454844162, 0.17297823447014288, 0.6378761454844162, 0.17297823447014288, 0.6378761454844162]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.472\n",
      "(*) epoch 2, cost 2.541\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.757\n",
      "(*) epoch 2, cost 1.728\n",
      "(*) epoch 3, cost 1.476\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.4710041639491838, 3.4710041639491838, 3.841966184312493, 3.4710041639491838, 3.841966184312493, 3.4710041639491838, 3.841966184312493, 3.4710041639491838, 3.4710041639491838, 3.841966184312493, 3.841966184312493, 3.841966184312493, 3.4710041639491838, 3.4710041639491838, 3.841966184312493, 3.4710041639491838, 3.841966184312493, 3.841966184312493, 3.841966184312493, 3.841966184312493, 3.4710041639491838, 3.4710041639491838, 3.4710041639491838, 3.4710041639491838, 3.4710041639491838, 3.4710041639491838, 3.4710041639491838, 3.841966184312493, 3.841966184312493, 3.841966184312493, 3.4710041639491838, 3.841966184312493, 3.4710041639491838, 5.361978431919734, 3.4710041639491838, 3.4710041639491838, 3.841966184312493, 3.841966184312493, 3.841966184312493, 3.841966184312493, 3.4710041639491838, 3.4710041639491838, 4.991016411556425, 3.841966184312493, 3.841966184312493, 3.841966184312493, 3.4710041639491838, 3.4710041639491838, 3.841966184312493, 3.4710041639491838]\n",
      "all_sum after preprocessing is: [-0.6784022  -0.6784022   0.37518178 -0.6784022   0.37518178 -0.6784022\n",
      "  0.37518178 -0.6784022  -0.6784022   0.37518178  0.37518178  0.37518178\n",
      " -0.6784022  -0.6784022   0.37518178 -0.6784022   0.37518178  0.37518178\n",
      "  0.37518178  0.37518178 -0.6784022  -0.6784022  -0.6784022  -0.6784022\n",
      " -0.6784022  -0.6784022  -0.6784022   0.37518178  0.37518178  0.37518178\n",
      " -0.6784022   0.37518178 -0.6784022   4.69222897 -0.6784022  -0.6784022\n",
      "  0.37518178  0.37518178  0.37518178  0.37518178 -0.6784022  -0.6784022\n",
      "  3.63864499  0.37518178  0.37518178  0.37518178 -0.6784022  -0.6784022\n",
      "  0.37518178 -0.6784022 ]\n",
      "P is: [0.33661800919312984, 0.33661800919312984, 0.5927104831984358, 0.33661800919312984, 0.5927104831984358, 0.33661800919312984, 0.5927104831984358, 0.33661800919312984, 0.33661800919312984, 0.5927104831984358, 0.5927104831984358, 0.5927104831984358, 0.33661800919312984, 0.33661800919312984, 0.5927104831984358, 0.33661800919312984, 0.5927104831984358, 0.5927104831984358, 0.5927104831984358, 0.5927104831984358, 0.33661800919312984, 0.33661800919312984, 0.33661800919312984, 0.33661800919312984, 0.33661800919312984, 0.33661800919312984, 0.33661800919312984, 0.5927104831984358, 0.5927104831984358, 0.5927104831984358, 0.33661800919312984, 0.5927104831984358, 0.33661800919312984, 0.9909170245247991, 0.33661800919312984, 0.33661800919312984, 0.5927104831984358, 0.5927104831984358, 0.5927104831984358, 0.5927104831984358, 0.33661800919312984, 0.33661800919312984, 0.9743854144750014, 0.5927104831984358, 0.5927104831984358, 0.5927104831984358, 0.33661800919312984, 0.33661800919312984, 0.5927104831984358, 0.33661800919312984]\n",
      "all_sum before preprocessing is: [1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.5946141940437157, 1.938026119034232, 1.4367160927954123, 1.938026119034232, 1.938026119034232, 1.4367160927954123, 2.9640071678955704, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.0462432789614196, 1.0462432789614196, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.5946141940437157, 1.5946141940437157, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.4367160927954123, 1.938026119034232, 1.4367160927954123, 2.9640071678955704, 1.938026119034232, 1.938026119034232, 1.938026119034232, 1.938026119034232]\n",
      "all_sum after preprocessing is: [ 0.17675093  0.17675093  0.17675093  0.17675093  0.17675093  0.17675093\n",
      " -0.92004405  0.17675093 -1.42434175  0.17675093  0.17675093 -1.42434175\n",
      "  3.45354705  0.17675093  0.17675093  0.17675093  0.17675093  0.17675093\n",
      "  0.17675093  0.17675093  0.17675093  0.17675093  0.17675093  0.17675093\n",
      "  0.17675093  0.17675093 -2.67144062 -2.67144062  0.17675093  0.17675093\n",
      "  0.17675093  0.17675093  0.17675093  0.17675093 -0.92004405 -0.92004405\n",
      "  0.17675093  0.17675093  0.17675093  0.17675093  0.17675093  0.17675093\n",
      " -1.42434175  0.17675093 -1.42434175  3.45354705  0.17675093  0.17675093\n",
      "  0.17675093  0.17675093]\n",
      "P is: [0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.28494891910020115, 0.5440730521656995, 0.19398183618694664, 0.5440730521656995, 0.5440730521656995, 0.19398183618694664, 0.9693367453771574, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.06467976201323919, 0.06467976201323919, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.28494891910020115, 0.28494891910020115, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.19398183618694664, 0.5440730521656995, 0.19398183618694664, 0.9693367453771574, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995, 0.5440730521656995]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.448\n",
      "(*) epoch 2, cost 1.119\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.956\n",
      "(*) epoch 2, cost 2.413\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1453478983601646, 0.6697533579976767, 1.1453478983601646, 0.5581178200994985, 0.5581178200994985, 0.5581178200994985, 0.6697533579976767, 1.0493453394323151, 1.524939879794803, 1.1453478983601646, 0.6697533579976767, 0.5581178200994985, 0.937709801534137, 1.1453478983601646, 0.5581178200994985, 1.1453478983601646, 0.6697533579976767, 1.524939879794803, 1.524939879794803, 1.1453478983601646, 1.1453478983601646, 0.6697533579976767, 1.1453478983601646, 1.1453478983601646, 0.5581178200994985, 0.5581178200994985, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 0.701380663832361, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 0.5581178200994985, 1.1453478983601646, 0.6697533579976767, 1.1453478983601646, 1.1453478983601646, 0.5581178200994985, 1.1453478983601646, 0.5581178200994985, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646, 1.1453478983601646]\n",
      "all_sum after preprocessing is: [ 0.58227016 -1.07900446  0.58227016 -1.46895276 -1.46895276 -1.46895276\n",
      " -1.07900446  0.2469286   1.90820322  0.58227016 -1.07900446 -1.46895276\n",
      " -0.1430197   0.58227016 -1.46895276  0.58227016 -1.07900446  1.90820322\n",
      "  1.90820322  0.58227016  0.58227016 -1.07900446  0.58227016  0.58227016\n",
      " -1.46895276 -1.46895276  0.58227016  0.58227016  0.58227016 -0.96852875\n",
      "  0.58227016  0.58227016  0.58227016  0.58227016  0.58227016  0.58227016\n",
      "  0.58227016  0.58227016 -1.46895276  0.58227016 -1.07900446  0.58227016\n",
      "  0.58227016 -1.46895276  0.58227016 -1.46895276  0.58227016  0.58227016\n",
      "  0.58227016  0.58227016]\n",
      "P is: [0.6415896032386068, 0.25369446033406146, 0.6415896032386068, 0.18710184106851013, 0.18710184106851013, 0.18710184106851013, 0.25369446033406146, 0.5614203818015292, 0.8708171546442607, 0.6415896032386068, 0.25369446033406146, 0.18710184106851013, 0.4643058960620032, 0.6415896032386068, 0.18710184106851013, 0.6415896032386068, 0.25369446033406146, 0.8708171546442607, 0.8708171546442607, 0.6415896032386068, 0.6415896032386068, 0.25369446033406146, 0.6415896032386068, 0.6415896032386068, 0.18710184106851013, 0.18710184106851013, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.275173849718796, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.18710184106851013, 0.6415896032386068, 0.25369446033406146, 0.6415896032386068, 0.6415896032386068, 0.18710184106851013, 0.6415896032386068, 0.18710184106851013, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068, 0.6415896032386068]\n",
      "all_sum before preprocessing is: [1.6739865435964694, 3.057617692692963, 1.6739865435964694, 2.3538098922923063, 3.057617692692963, 2.9974592895862817, 2.9974592895862817, 3.057617692692963, 1.6739865435964694, 1.734144946703151, 2.9974592895862817, 2.9974592895862817, 1.6739865435964694, 2.9974592895862817, 2.9974592895862817, 1.734144946703151, 3.057617692692963, 1.6739865435964694, 1.6739865435964694, 1.734144946703151, 2.9974592895862817, 1.734144946703151, 2.9974592895862817, 3.057617692692963, 2.9974592895862817, 1.734144946703151, 2.9974592895862817, 2.413968295398988, 2.9974592895862817, 2.9974592895862817, 3.057617692692963, 1.734144946703151, 1.734144946703151, 3.057617692692963, 3.057617692692963, 1.6739865435964694, 1.6739865435964694, 2.9974592895862817, 1.6739865435964694, 1.6739865435964694, 2.9974592895862817, 2.9974592895862817, 1.030337146302494, 1.734144946703151, 2.9974592895862817, 1.734144946703151, 1.734144946703151, 3.057617692692963, 3.057617692692963, 1.734144946703151]\n",
      "all_sum after preprocessing is: [-1.09746316  0.98551852 -1.09746316 -0.07402596  0.98551852  0.89495331\n",
      "  0.89495331  0.98551852 -1.09746316 -1.00689794  0.89495331  0.89495331\n",
      " -1.09746316  0.89495331  0.89495331 -1.00689794  0.98551852 -1.09746316\n",
      " -1.09746316 -1.00689794  0.89495331 -1.00689794  0.89495331  0.98551852\n",
      "  0.89495331 -1.00689794  0.89495331  0.01653925  0.89495331  0.89495331\n",
      "  0.98551852 -1.00689794 -1.00689794  0.98551852  0.98551852 -1.09746316\n",
      " -1.09746316  0.89495331 -1.09746316 -1.09746316  0.89495331  0.89495331\n",
      " -2.06644243 -1.00689794  0.89495331 -1.00689794 -1.00689794  0.98551852\n",
      "  0.98551852 -1.00689794]\n",
      "P is: [0.2502155238140473, 0.7282018380946015, 0.2502155238140473, 0.48150195527406786, 0.7282018380946015, 0.709911302514671, 0.709911302514671, 0.7282018380946015, 0.2502155238140473, 0.2675873667415209, 0.709911302514671, 0.709911302514671, 0.2502155238140473, 0.709911302514671, 0.709911302514671, 0.2675873667415209, 0.7282018380946015, 0.2502155238140473, 0.2502155238140473, 0.2675873667415209, 0.709911302514671, 0.2675873667415209, 0.709911302514671, 0.7282018380946015, 0.709911302514671, 0.2675873667415209, 0.709911302514671, 0.5041347181680282, 0.709911302514671, 0.709911302514671, 0.7282018380946015, 0.2675873667415209, 0.2675873667415209, 0.7282018380946015, 0.7282018380946015, 0.2502155238140473, 0.2502155238140473, 0.709911302514671, 0.2502155238140473, 0.2502155238140473, 0.709911302514671, 0.709911302514671, 0.1124014789415638, 0.2675873667415209, 0.709911302514671, 0.2675873667415209, 0.2675873667415209, 0.7282018380946015, 0.7282018380946015, 0.2675873667415209]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.367\n",
      "(*) epoch 2, cost 2.126\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.662\n",
      "(*) epoch 2, cost 2.713\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.5809504644854514, 0.5809504644854514, 0.7340320460726693, 0.8705165425468249, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.8705165425468249, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.7209225410984423, 0.5809504644854514, 0.5809504644854514, 0.43135646303706887, 0.5809504644854514, 0.8705165425468249, 0.5809504644854514, 0.43135646303706887, 0.43135646303706887, 0.5809504644854514, 0.7340320460726693, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.8705165425468249, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514, 0.7340320460726693, 0.5809504644854514, 0.43135646303706887, 0.5809504644854514, 0.8705165425468249, 0.5809504644854514, 0.5809504644854514, 0.5809504644854514]\n",
      "all_sum after preprocessing is: [-0.27458899 -0.27458899  1.17620665  2.46970721 -0.27458899 -0.27458899\n",
      " -0.27458899  2.46970721 -0.27458899 -0.27458899 -0.27458899 -0.27458899\n",
      " -0.27458899 -0.27458899 -0.27458899  1.05196432 -0.27458899 -0.27458899\n",
      " -1.69233189 -0.27458899  2.46970721 -0.27458899 -1.69233189 -1.69233189\n",
      " -0.27458899  1.17620665 -0.27458899 -0.27458899 -0.27458899 -0.27458899\n",
      " -0.27458899  2.46970721 -0.27458899 -0.27458899 -0.27458899 -0.27458899\n",
      " -0.27458899 -0.27458899 -0.27458899 -0.27458899 -0.27458899 -0.27458899\n",
      "  1.17620665 -0.27458899 -1.69233189 -0.27458899  2.46970721 -0.27458899\n",
      " -0.27458899 -0.27458899]\n",
      "P is: [0.4317808525339103, 0.4317808525339103, 0.7642650635697211, 0.9219907092378339, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.9219907092378339, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.7411519232907483, 0.4317808525339103, 0.4317808525339103, 0.15546941965964586, 0.4317808525339103, 0.9219907092378339, 0.4317808525339103, 0.15546941965964586, 0.15546941965964586, 0.4317808525339103, 0.7642650635697211, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.9219907092378339, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103, 0.7642650635697211, 0.4317808525339103, 0.15546941965964586, 0.4317808525339103, 0.9219907092378339, 0.4317808525339103, 0.4317808525339103, 0.4317808525339103]\n",
      "all_sum before preprocessing is: [2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.9458994672557828, 2.9458994672557828, 2.7828182660192162, 2.9458994672557828, 2.9458994672557828, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.9458994672557828, 3.2010382536614115, 2.9458994672557828, 2.7828182660192162, 2.9458994672557828, 3.2010382536614115, 2.7828182660192162, 2.7828182660192162, 2.9458994672557828, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 0.9034021092130733, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162, 2.7828182660192162]\n",
      "all_sum after preprocessing is: [-0.01829076 -0.01829076 -0.01829076  0.55167137  0.55167137 -0.01829076\n",
      "  0.55167137  0.55167137 -0.01829076 -0.01829076 -0.01829076 -0.01829076\n",
      " -0.01829076 -0.01829076 -0.01829076  0.55167137  1.44337098  0.55167137\n",
      " -0.01829076  0.55167137  1.44337098 -0.01829076 -0.01829076  0.55167137\n",
      " -0.01829076 -0.01829076 -0.01829076 -0.01829076 -0.01829076 -0.01829076\n",
      " -0.01829076 -0.01829076 -0.01829076 -0.01829076 -0.01829076 -6.5867733\n",
      " -0.01829076 -0.01829076 -0.01829076 -0.01829076 -0.01829076 -0.01829076\n",
      " -0.01829076 -0.01829076 -0.01829076 -0.01829076 -0.01829076 -0.01829076\n",
      " -0.01829076 -0.01829076]\n",
      "P is: [0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.6345232734689886, 0.6345232734689886, 0.4954274378693695, 0.6345232734689886, 0.6345232734689886, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.6345232734689886, 0.8089761244051732, 0.6345232734689886, 0.4954274378693695, 0.6345232734689886, 0.8089761244051732, 0.4954274378693695, 0.4954274378693695, 0.6345232734689886, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.0013765831419276305, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695, 0.4954274378693695]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.900\n",
      "(*) epoch 2, cost 1.625\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.413\n",
      "(*) epoch 2, cost 2.761\n",
      "(*) epoch 3, cost 1.830\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.9259726943912043, 2.649720090074278, 2.9259726943912043, 1.4604319759402844, 1.8738061684349907, 1.8738061684349907, 2.883491973361597, 2.883491973361597, 2.0074305964737498, 3.6594058950008845, 2.6072393690446707, 2.6072393690446707, 3.9356584993178108, 1.8738061684349907, 1.8738061684349907, 3.9356584993178108, 2.9259726943912043, 2.9259726943912043, 1.8738061684349907, 1.8738061684349907, 2.721184786637789, 2.883491973361597, 1.5975535641180645, 1.8738061684349907, 3.6594058950008845, 3.313752084184771, 2.883491973361597, 3.9356584993178108, 1.8738061684349907, 1.5975535641180645, 1.8738061684349907, 1.8738061684349907, 2.6072393690446707, 2.649720090074278, 1.5975535641180645, 2.649720090074278, 1.2518997533019511, 2.883491973361597, 3.9356584993178108, 2.783344518113037, 2.9259726943912043, 3.9356584993178108, 3.6594058950008845, 3.9356584993178108, 1.5975535641180645, 3.3796561305449377, 2.6072393690446707, 2.6072393690446707, 4.06928292735657, 1.5975535641180645]\n",
      "all_sum after preprocessing is: [ 0.34906778  0.00370904  0.34906778 -1.48308615 -0.96630409 -0.96630409\n",
      "  0.29596027  0.29596027 -0.79925276  1.2659734  -0.04939847 -0.04939847\n",
      "  1.61133214 -0.96630409 -0.96630409  1.61133214  0.34906778  0.34906778\n",
      " -0.96630409 -0.96630409  0.09305103  0.29596027 -1.31166283 -0.96630409\n",
      "  1.2659734   0.83385235  0.29596027  1.61133214 -0.96630409 -1.31166283\n",
      " -0.96630409 -0.96630409 -0.04939847  0.00370904 -1.31166283  0.00370904\n",
      " -1.74378388  0.29596027  1.61133214  0.17076037  0.34906778  1.61133214\n",
      "  1.2659734   1.61133214 -1.31166283  0.91624266 -0.04939847 -0.04939847\n",
      "  1.77838346 -1.31166283]\n",
      "P is: [0.5863914992146873, 0.5009272586634086, 0.5863914992146873, 0.18496172692464274, 0.275617787809269, 0.275617787809269, 0.5734546747008814, 0.5734546747008814, 0.31018538237374244, 0.7800526807153678, 0.48765289265159073, 0.48765289265159073, 0.8335962538176303, 0.275617787809269, 0.275617787809269, 0.8335962538176303, 0.5863914992146873, 0.5863914992146873, 0.275617787809269, 0.275617787809269, 0.5232459867694101, 0.5734546747008814, 0.21220872549637465, 0.275617787809269, 0.7800526807153678, 0.6971688725853341, 0.5734546747008814, 0.8335962538176303, 0.275617787809269, 0.21220872549637465, 0.275617787809269, 0.275617787809269, 0.48765289265159073, 0.5009272586634086, 0.21220872549637465, 0.5009272586634086, 0.1488329495087455, 0.5734546747008814, 0.8335962538176303, 0.5425866591642632, 0.5863914992146873, 0.8335962538176303, 0.7800526807153678, 0.8335962538176303, 0.21220872549637465, 0.7142759043591336, 0.48765289265159073, 0.48765289265159073, 0.8554971414293786, 0.21220872549637465]\n",
      "all_sum before preprocessing is: [1.3635643042048033, 3.5511130679326595, 1.7543195953592507, 2.8412837675628326, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 3.5246139525921443, 3.5511130679326595, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 2.4641488957290782, 1.7658892331516571, 2.4641488957290782, 1.0560599327818299, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 2.8412837675628326, 2.8412837675628326, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 2.8412837675628326, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 2.4641488957290782, 2.019848536520459, 1.7543195953592507, 1.7543195953592507, 2.8412837675628326, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 2.8412837675628326, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 1.7543195953592507, 2.4641488957290782, 1.0560599327818299]\n",
      "all_sum after preprocessing is: [-1.14373134e+00  2.67576728e+00 -4.61465726e-01  1.43639284e+00\n",
      " -4.61465726e-01 -4.61465726e-01 -4.61465726e-01 -4.61465726e-01\n",
      "  2.62949936e+00  2.67576728e+00 -4.61465726e-01 -4.61465726e-01\n",
      " -4.61465726e-01  7.77908717e-01 -4.41264935e-01  7.77908717e-01\n",
      " -1.68063938e+00 -4.61465726e-01 -4.61465726e-01 -4.61465726e-01\n",
      " -4.61465726e-01 -4.61465726e-01  1.43639284e+00  1.43639284e+00\n",
      " -4.61465726e-01 -4.61465726e-01 -4.61465726e-01 -4.61465726e-01\n",
      "  1.43639284e+00 -4.61465726e-01 -4.61465726e-01 -4.61465726e-01\n",
      " -4.61465726e-01 -4.61465726e-01  7.77908717e-01  2.15247506e-03\n",
      " -4.61465726e-01 -4.61465726e-01  1.43639284e+00 -4.61465726e-01\n",
      " -4.61465726e-01 -4.61465726e-01  1.43639284e+00 -4.61465726e-01\n",
      " -4.61465726e-01 -4.61465726e-01 -4.61465726e-01 -4.61465726e-01\n",
      "  7.77908717e-01 -1.68063938e+00]\n",
      "P is: [0.24163594184962486, 0.9355814925522096, 0.386638170491772, 0.8078954397953536, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.9327361461699704, 0.9355814925522096, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.6852292195489458, 0.39143960181967963, 0.6852292195489458, 0.1570108232526455, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.8078954397953536, 0.8078954397953536, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.8078954397953536, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.6852292195489458, 0.5005381185570481, 0.386638170491772, 0.386638170491772, 0.8078954397953536, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.8078954397953536, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.386638170491772, 0.6852292195489458, 0.1570108232526455]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.574\n",
      "(*) epoch 2, cost 3.836\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.766\n",
      "(*) epoch 2, cost 2.470\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.1090451546059166, 3.092292933342353, 2.1090451546059166, 2.045764142209375, 2.1090451546059166, 2.1090451546059166, 1.4596428333721048, 1.7119186847067507, 2.442890612108541, 1.4596428333721048, 2.1090451546059166, 3.258647941770202, 2.1090451546059166, 2.1090451546059166, 2.1090451546059166, 3.1952610413615954, 1.4596428333721048, 2.6897976269356283, 2.1090451546059166, 3.092292933342353, 3.092292933342353, 1.4596428333721048, 1.7119186847067507, 3.092292933342353, 2.1090451546059166, 1.4596428333721048, 3.6375674905179998, 1.4596428333721048, 2.0403953057018165, 3.092292933342353, 2.988165169284188, 1.4596428333721048, 2.6897976269356283, 2.1090451546059166, 3.092292933342353, 1.4596428333721048, 1.9651062477980716, 1.4596428333721048, 2.1090451546059166, 2.1090451546059166, 3.092292933342353, 1.4596428333721048, 2.1090451546059166, 2.0403953057018165, 3.092292933342353, 2.1090451546059166, 1.7119186847067507, 3.132104076092033, 2.1090451546059166, 2.1090451546059166]\n",
      "all_sum after preprocessing is: [-0.22750651  1.37078942 -0.22750651 -0.33037151 -0.22750651 -0.22750651\n",
      " -1.2831276  -0.87304636  0.31516834 -1.2831276  -0.22750651  1.641204\n",
      " -0.22750651 -0.22750651 -0.22750651  1.53816688 -1.2831276   0.71652239\n",
      " -0.22750651  1.37078942  1.37078942 -1.2831276  -0.87304636  1.37078942\n",
      " -0.22750651 -1.2831276   2.25714801 -1.2831276  -0.3390987   1.37078942\n",
      "  1.20152692 -1.2831276   0.71652239 -0.22750651  1.37078942 -1.2831276\n",
      " -0.46148311 -1.2831276  -0.22750651 -0.22750651  1.37078942 -1.2831276\n",
      " -0.22750651 -0.3390987   1.37078942 -0.22750651 -0.87304636  1.43550352\n",
      " -0.22750651 -0.22750651]\n",
      "P is: [0.44336743297569753, 0.7975076670697719, 0.44336743297569753, 0.4181502307750476, 0.44336743297569753, 0.44336743297569753, 0.21701830696337973, 0.2946208131496068, 0.5781462892706349, 0.21701830696337973, 0.44336743297569753, 0.8376986998189578, 0.44336743297569753, 0.44336743297569753, 0.44336743297569753, 0.8231980851278696, 0.21701830696337973, 0.6718407635255491, 0.44336743297569753, 0.7975076670697719, 0.7975076670697719, 0.21701830696337973, 0.2946208131496068, 0.7975076670697719, 0.44336743297569753, 0.21701830696337973, 0.9052653267922193, 0.21701830696337973, 0.4160284293376033, 0.7975076670697719, 0.7687963026288684, 0.21701830696337973, 0.6718407635255491, 0.44336743297569753, 0.7975076670697719, 0.21701830696337973, 0.3866340480742835, 0.21701830696337973, 0.44336743297569753, 0.44336743297569753, 0.7975076670697719, 0.21701830696337973, 0.44336743297569753, 0.4160284293376033, 0.7975076670697719, 0.44336743297569753, 0.2946208131496068, 0.8077573794105157, 0.44336743297569753, 0.44336743297569753]\n",
      "all_sum before preprocessing is: [3.007171913262013, 2.2214057594023924, 3.007171913262013, 2.2214057594023924, 3.007171913262013, 5.864443044613744, 2.2214057594023924, 2.2214057594023924, 0.9280142459996118, 3.007171913262013, 4.1427936262501, 4.57599435283688, 2.2214057594023924, 3.5098544511792564, 2.2214057594023924, 4.645476164167343, 3.007171913262013, 4.295620605038877, 4.295620605038877, 3.007171913262013, 4.295620605038877, 3.7902281989772595, 4.295620605038877, 3.007171913262013, 3.007171913262013, 2.2214057594023924, 2.2214057594023924, 4.295620605038877, 3.5098544511792564, 3.5098544511792564, 3.007171913262013, 3.007171913262013, 3.5098544511792564, 2.2214057594023924, 2.2214057594023924, 2.2214057594023924, 3.7902281989772595, 2.2214057594023924, 3.5098544511792564, 3.007171913262013, 2.2214057594023924, 2.2214057594023924, 3.007171913262013, 3.3570274723904787, 2.2214057594023924, 4.295620605038877, 3.007171913262013, 3.007171913262013, 5.0786768907541235, 4.295620605038877]\n",
      "all_sum after preprocessing is: [-0.18637895 -1.01337082 -0.18637895 -1.01337082 -0.18637895  2.82080071\n",
      " -1.01337082 -1.01337082 -2.37462094 -0.18637895  1.00882387  1.46475275\n",
      " -1.01337082  0.34267714 -1.01337082  1.53787996 -0.18637895  1.16966901\n",
      "  1.16966901 -0.18637895  1.16966901  0.63776087  1.16966901 -0.18637895\n",
      " -0.18637895 -1.01337082 -1.01337082  1.16966901  0.34267714  0.34267714\n",
      " -0.18637895 -0.18637895  0.34267714 -1.01337082 -1.01337082 -1.01337082\n",
      "  0.63776087 -1.01337082  0.34267714 -0.18637895 -1.01337082 -1.01337082\n",
      " -0.18637895  0.181832   -1.01337082  1.16966901 -0.18637895 -0.18637895\n",
      "  1.99380884  1.16966901]\n",
      "P is: [0.453539675245458, 0.2663206933077894, 0.453539675245458, 0.2663206933077894, 0.453539675245458, 0.943789559896782, 0.2663206933077894, 0.2663206933077894, 0.08512856218543906, 0.453539675245458, 0.7327899154724334, 0.8122585187093377, 0.2663206933077894, 0.5848406855223961, 0.2663206933077894, 0.8231563229594544, 0.453539675245458, 0.763085182854928, 0.763085182854928, 0.453539675245458, 0.763085182854928, 0.6542471279334348, 0.763085182854928, 0.453539675245458, 0.453539675245458, 0.2663206933077894, 0.2663206933077894, 0.763085182854928, 0.5848406855223961, 0.5848406855223961, 0.453539675245458, 0.453539675245458, 0.5848406855223961, 0.2663206933077894, 0.2663206933077894, 0.2663206933077894, 0.6542471279334348, 0.2663206933077894, 0.5848406855223961, 0.453539675245458, 0.2663206933077894, 0.2663206933077894, 0.453539675245458, 0.5453331645792567, 0.2663206933077894, 0.763085182854928, 0.453539675245458, 0.453539675245458, 0.8801455118368066, 0.763085182854928]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.999\n",
      "(*) epoch 2, cost 2.493\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.840\n",
      "(*) epoch 2, cost 3.394\n",
      "(*) epoch 3, cost 2.943\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0616537103906367, 2.7282828456281036, 2.61538494099692, 1.0616537103906367, 2.61538494099692, 2.61538494099692, 1.1745516150218205, 2.61538494099692, 2.4068326264433337, 2.61538494099692, 1.1745516150218205, 1.0616537103906367, 2.61538494099692, 2.7282828456281036, 2.61538494099692, 2.7282828456281036, 1.1745516150218205, 2.4068326264433337, 1.1745516150218205, 2.61538494099692, 1.0616537103906367, 2.61538494099692, 2.61538494099692, 2.61538494099692, 2.2939347218121497, 2.7282828456281036, 1.0616537103906367, 2.61538494099692, 1.1745516150218205, 1.1745516150218205, 1.0616537103906367, 1.0616537103906367, 1.1745516150218205, 1.0616537103906367, 2.7282828456281036, 2.61538494099692, 1.1745516150218205, 1.1745516150218205, 1.1745516150218205, 1.0616537103906367, 2.61538494099692, 1.0616537103906367, 2.7282828456281036, 2.2939347218121497, 0.7402034912058667, 2.61538494099692, 2.61538494099692, 1.0616537103906367, 2.61538494099692, 3.5955543604739346]\n",
      "all_sum after preprocessing is: [-1.14672304  0.98106694  0.83692988 -1.14672304  0.83692988  0.83692988\n",
      " -1.00258597  0.83692988  0.57067057  0.83692988 -1.00258597 -1.14672304\n",
      "  0.83692988  0.98106694  0.83692988  0.98106694 -1.00258597  0.57067057\n",
      " -1.00258597  0.83692988 -1.14672304  0.83692988  0.83692988  0.83692988\n",
      "  0.4265335   0.98106694 -1.14672304  0.83692988 -1.00258597 -1.00258597\n",
      " -1.14672304 -1.14672304 -1.00258597 -1.14672304  0.98106694  0.83692988\n",
      " -1.00258597 -1.00258597 -1.00258597 -1.14672304  0.83692988 -1.14672304\n",
      "  0.98106694  0.4265335  -1.55711941  0.83692988  0.83692988 -1.14672304\n",
      "  0.83692988  2.08831485]\n",
      "P is: [0.2410881429055802, 0.7273198691741097, 0.6978182186859998, 0.2410881429055802, 0.6978182186859998, 0.6978182186859998, 0.2684332923302231, 0.6978182186859998, 0.6389178902635487, 0.6978182186859998, 0.2684332923302231, 0.2410881429055802, 0.6978182186859998, 0.7273198691741097, 0.6978182186859998, 0.7273198691741097, 0.2684332923302231, 0.6389178902635487, 0.2684332923302231, 0.6978182186859998, 0.2410881429055802, 0.6978182186859998, 0.6978182186859998, 0.6978182186859998, 0.6050455976369274, 0.7273198691741097, 0.2410881429055802, 0.6978182186859998, 0.2684332923302231, 0.2684332923302231, 0.2410881429055802, 0.2410881429055802, 0.2684332923302231, 0.2410881429055802, 0.7273198691741097, 0.6978182186859998, 0.2684332923302231, 0.2684332923302231, 0.2684332923302231, 0.2410881429055802, 0.6978182186859998, 0.2410881429055802, 0.7273198691741097, 0.6050455976369274, 0.17406038166113996, 0.6978182186859998, 0.6978182186859998, 0.2410881429055802, 0.6978182186859998, 0.8897622460174627]\n",
      "all_sum before preprocessing is: [5.076991093965157, 4.781805040349659, 3.2729816129488514, 3.3779524433370014, 3.008614934170043, 4.781805040349659, 3.061709985443734, 3.2729816129488514, 6.871237604422542, 3.061709985443734, 3.326076664222543, 3.2729816129488514, 3.3568960390592317, 6.871237604422542, 1.2885198792641182, 5.046171719128468, 6.840418229585853, 5.076991093965157, 5.63570727530751, 3.3568960390592317, 5.076991093965157, 3.326076664222543, 5.076991093965157, 5.098047498242926, 7.429953785764896, 3.3568960390592317, 3.061709985443734, 4.75098566551297, 3.061709985443734, 3.061709985443734, 3.061709985443734, 1.5837059328796157, 5.046171719128468, 3.2729816129488514, 3.3568960390592317, 4.781805040349659, 4.75098566551297, 3.3568960390592317, 7.346039359654515, 3.061709985443734, 5.63570727530751, 5.076991093965157, 4.85595649590112, 3.3568960390592317, 6.871237604422542, 4.75098566551297, 1.5837059328796157, 5.046171719128468, 4.781805040349659, 3.326076664222543]\n",
      "all_sum after preprocessing is: [ 0.56459909  0.36137464 -0.67739329 -0.60512484 -0.85939976  0.36137464\n",
      " -0.82284582 -0.67739329  1.79987003 -0.82284582 -0.64083935 -0.67739329\n",
      " -0.61962137  1.79987003 -2.04362022  0.54338112  1.77865206  0.56459909\n",
      "  0.94925408 -0.61962137  0.56459909 -0.64083935  0.56459909  0.57909563\n",
      "  2.18452502 -0.61962137 -0.82284582  0.34015667 -0.82284582 -0.82284582\n",
      " -0.82284582 -1.84039578  0.54338112 -0.67739329 -0.61962137  0.36137464\n",
      "  0.34015667 -0.61962137  2.1267531  -0.82284582  0.94925408  0.56459909\n",
      "  0.41242512 -0.61962137  1.79987003  0.34015667 -1.84039578  0.54338112\n",
      "  0.36137464 -0.64083935]\n",
      "P is: [0.6375160119133277, 0.5893731558909879, 0.3368433420948508, 0.3531720893137833, 0.29746476865493493, 0.5893731558909879, 0.3051599052180605, 0.3368433420948508, 0.8581331134582119, 0.3051599052180605, 0.3450568279095432, 0.3368433420948508, 0.3498675688166303, 0.8581331134582119, 0.1146986112081555, 0.6325986002702796, 0.8555303424186506, 0.6375160119133277, 0.7209651417709649, 0.3498675688166303, 0.6375160119133277, 0.3450568279095432, 0.6375160119133277, 0.6408592842302742, 0.8988512193464427, 0.3498675688166303, 0.3051599052180605, 0.5842285791916838, 0.3051599052180605, 0.3051599052180605, 0.3051599052180605, 0.1370044914932865, 0.6325986002702796, 0.3368433420948508, 0.3498675688166303, 0.5893731558909879, 0.5842285791916838, 0.3498675688166303, 0.893476375214397, 0.3051599052180605, 0.7209651417709649, 0.6375160119133277, 0.6016692343691503, 0.3498675688166303, 0.8581331134582119, 0.5842285791916838, 0.1370044914932865, 0.6325986002702796, 0.5893731558909879, 0.3450568279095432]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.095\n",
      "(*) epoch 2, cost 1.717\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.032\n",
      "(*) epoch 2, cost 4.725\n",
      "(*) epoch 3, cost 4.194\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.5790052952353366, 2.5790052952353366, 1.7755904055675047, 1.7755904055675047, 2.5790052952353366, 1.7755904055675047, 2.4622687415720477, 2.5790052952353366, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 2.5790052952353366, 1.7755904055675047, 1.7755904055675047, 2.5790052952353366, 1.7755904055675047, 1.7755904055675047, 2.5790052952353366, 1.8583404501868186, 2.5790052952353366, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 2.5790052952353366, 2.5790052952353366, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 1.7755904055675047, 2.5790052952353366, 2.5790052952353366, 2.5790052952353366, 1.7755904055675047, 2.5790052952353366, 1.7755904055675047, 1.7755904055675047, 2.5790052952353366, 2.5790052952353366, 2.5790052952353366, 1.7755904055675047, 2.5790052952353366, 2.5790052952353366, 2.5790052952353366, 1.7755904055675047, 3.637644434509822, 1.7755904055675047]\n",
      "all_sum after preprocessing is: [ 0.96693034  0.96693034 -0.84213194 -0.84213194  0.96693034 -0.84213194\n",
      "  0.70407276  0.96693034 -0.84213194 -0.84213194 -0.84213194 -0.84213194\n",
      " -0.84213194 -0.84213194  0.96693034 -0.84213194 -0.84213194  0.96693034\n",
      " -0.84213194 -0.84213194  0.96693034 -0.65580233  0.96693034 -0.84213194\n",
      " -0.84213194 -0.84213194  0.96693034  0.96693034 -0.84213194 -0.84213194\n",
      " -0.84213194 -0.84213194 -0.84213194  0.96693034  0.96693034  0.96693034\n",
      " -0.84213194  0.96693034 -0.84213194 -0.84213194  0.96693034  0.96693034\n",
      "  0.96693034 -0.84213194  0.96693034  0.96693034  0.96693034 -0.84213194\n",
      "  3.3506852  -0.84213194]\n",
      "P is: [0.7245072276311666, 0.7245072276311666, 0.30108596185890624, 0.30108596185890624, 0.7245072276311666, 0.30108596185890624, 0.6690901361202335, 0.7245072276311666, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.7245072276311666, 0.30108596185890624, 0.30108596185890624, 0.7245072276311666, 0.30108596185890624, 0.30108596185890624, 0.7245072276311666, 0.34168318880566934, 0.7245072276311666, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.7245072276311666, 0.7245072276311666, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.30108596185890624, 0.7245072276311666, 0.7245072276311666, 0.7245072276311666, 0.30108596185890624, 0.7245072276311666, 0.30108596185890624, 0.30108596185890624, 0.7245072276311666, 0.7245072276311666, 0.7245072276311666, 0.30108596185890624, 0.7245072276311666, 0.7245072276311666, 0.7245072276311666, 0.30108596185890624, 0.9661272664213539, 0.30108596185890624]\n",
      "all_sum before preprocessing is: [0.6686676019178195, 2.2835119180162535, 2.2835119180162535, 0.8150206238418842, 0.8150206238418842, 0.8150206238418842, 0.8150206238418842, 0.8346045228516945, 0.8150206238418842, 0.8150206238418842, 0.8346045228516945, 0.6843580585018014, 0.6882515009276298, 0.8150206238418842, 0.8346045228516945, 0.8150206238418842, 0.8150206238418842, 0.8150206238418842, 0.8150206238418842, 0.8150206238418842, 2.303095817026064, 2.303095817026064, 2.2835119180162535, 0.8150206238418842, 0.8346045228516945, 0.8150206238418842, 0.8150206238418842, 0.8150206238418842, 0.6882515009276298, 0.8150206238418842, 0.8150206238418842, 2.2835119180162535, 0.6686676019178195, 0.8346045228516945, 0.8346045228516945, 2.2835119180162535, 0.8150206238418842, 0.8150206238418842, 0.8150206238418842, 0.8346045228516945, 0.8150206238418842, 0.8150206238418842, 2.303095817026064, 0.6686676019178195, 0.8150206238418842, 2.2835119180162535, 0.8346045228516945, 0.8150206238418842, 0.8150206238418842, 0.8346045228516945]\n",
      "all_sum after preprocessing is: [-0.6942263   2.11605529  2.11605529 -0.43953103 -0.43953103 -0.43953103\n",
      " -0.43953103 -0.40544956 -0.43953103 -0.43953103 -0.40544956 -0.66692051\n",
      " -0.66014483 -0.43953103 -0.40544956 -0.43953103 -0.43953103 -0.43953103\n",
      " -0.43953103 -0.43953103  2.15013676  2.15013676  2.11605529 -0.43953103\n",
      " -0.40544956 -0.43953103 -0.43953103 -0.43953103 -0.66014483 -0.43953103\n",
      " -0.43953103  2.11605529 -0.6942263  -0.40544956 -0.40544956  2.11605529\n",
      " -0.43953103 -0.43953103 -0.43953103 -0.40544956 -0.43953103 -0.43953103\n",
      "  2.15013676 -0.6942263  -0.43953103  2.11605529 -0.40544956 -0.43953103\n",
      " -0.43953103 -0.40544956]\n",
      "P is: [0.3330935719503666, 0.8924539022994205, 0.8924539022994205, 0.39185272002496385, 0.39185272002496385, 0.39185272002496385, 0.39185272002496385, 0.40000373089203395, 0.39185272002496385, 0.39185272002496385, 0.40000373089203395, 0.3391867326990876, 0.3407070784231066, 0.39185272002496385, 0.40000373089203395, 0.39185272002496385, 0.39185272002496385, 0.39185272002496385, 0.39185272002496385, 0.39185272002496385, 0.895681556125834, 0.895681556125834, 0.8924539022994205, 0.39185272002496385, 0.40000373089203395, 0.39185272002496385, 0.39185272002496385, 0.39185272002496385, 0.3407070784231066, 0.39185272002496385, 0.39185272002496385, 0.8924539022994205, 0.3330935719503666, 0.40000373089203395, 0.40000373089203395, 0.8924539022994205, 0.39185272002496385, 0.39185272002496385, 0.39185272002496385, 0.40000373089203395, 0.39185272002496385, 0.39185272002496385, 0.895681556125834, 0.3330935719503666, 0.39185272002496385, 0.8924539022994205, 0.40000373089203395, 0.39185272002496385, 0.39185272002496385, 0.40000373089203395]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.300\n",
      "(*) epoch 2, cost 2.479\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.988\n",
      "(*) epoch 2, cost 3.958\n",
      "(*) epoch 3, cost 3.523\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.6223853780170163, 3.1556417733520434, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.1556417733520434, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 2.5801814960388194, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.1556417733520434, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 1.8598325211703632, 1.8598325211703632, 3.6223853780170163, 1.8598325211703632, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 3.6223853780170163, 2.5801814960388194, 3.6223853780170163, 3.6223853780170163]\n",
      "all_sum after preprocessing is: [ 0.38092494 -0.63246002  0.38092494  0.38092494  0.38092494  0.38092494\n",
      "  0.38092494  0.38092494  0.38092494  0.38092494  0.38092494 -0.63246002\n",
      "  0.38092494  0.38092494  0.38092494  0.38092494  0.38092494  0.38092494\n",
      " -1.88188858  0.38092494  0.38092494  0.38092494  0.38092494  0.38092494\n",
      "  0.38092494  0.38092494  0.38092494  0.38092494  0.38092494 -0.63246002\n",
      "  0.38092494  0.38092494  0.38092494  0.38092494 -3.44589677 -3.44589677\n",
      "  0.38092494 -3.44589677  0.38092494  0.38092494  0.38092494  0.38092494\n",
      "  0.38092494  0.38092494  0.38092494  0.38092494  0.38092494 -1.88188858\n",
      "  0.38092494  0.38092494]\n",
      "P is: [0.5940961681484109, 0.3469529450784656, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.3469529450784656, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.13217209754546835, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.3469529450784656, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.030891462353618563, 0.030891462353618563, 0.5940961681484109, 0.030891462353618563, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.5940961681484109, 0.13217209754546835, 0.5940961681484109, 0.5940961681484109]\n",
      "all_sum before preprocessing is: [1.472502453333313, 1.4657546990173258, 1.4657546990173258, 1.4657546990173258, 1.4657546990173258, 1.4657546990173258, 2.213547075042817, 1.472502453333313, 1.4657546990173258, 1.472502453333313, 1.4657546990173258, 1.4657546990173258, 1.4657546990173258, 1.472502453333313, 1.472502453333313, 1.4657546990173258, 1.472502453333313, 1.4657546990173258, 1.4657546990173258, 1.4657546990173258, 1.4657546990173258, 0.3750221762248193, 1.4657546990173258, 1.472502453333313, 1.472502453333313, 0.3750221762248193, 1.4657546990173258, 1.472502453333313, 1.4657546990173258, 1.472502453333313, 1.4657546990173258, 1.4657546990173258, 1.472502453333313, 1.4657546990173258, 1.472502453333313, 1.4657546990173258, 3.3110273521513105, 1.4657546990173258, 1.4657546990173258, 1.4657546990173258, 0.3750221762248193, 1.4657546990173258, 1.472502453333313, 1.4657546990173258, 3.029878261690453, 0.3750221762248193, 1.4657546990173258, 1.472502453333313, 1.472502453333313, 1.4657546990173258]\n",
      "all_sum after preprocessing is: [ 0.01869932  0.00442293  0.00442293  0.00442293  0.00442293  0.00442293\n",
      "  1.58654577  0.01869932  0.00442293  0.01869932  0.00442293  0.00442293\n",
      "  0.00442293  0.01869932  0.01869932  0.00442293  0.01869932  0.00442293\n",
      "  0.00442293  0.00442293  0.00442293 -2.30326687  0.00442293  0.01869932\n",
      "  0.01869932 -2.30326687  0.00442293  0.01869932  0.00442293  0.01869932\n",
      "  0.00442293  0.00442293  0.01869932  0.00442293  0.01869932  0.00442293\n",
      "  3.90851196  0.00442293  0.00442293  0.00442293 -2.30326687  0.00442293\n",
      "  0.01869932  0.00442293  3.31367787 -2.30326687  0.00442293  0.01869932\n",
      "  0.01869932  0.00442293]\n",
      "P is: [0.5046746940970397, 0.5011057307994226, 0.5011057307994226, 0.5011057307994226, 0.5011057307994226, 0.5011057307994226, 0.8301295620497154, 0.5046746940970397, 0.5011057307994226, 0.5046746940970397, 0.5011057307994226, 0.5011057307994226, 0.5011057307994226, 0.5046746940970397, 0.5046746940970397, 0.5011057307994226, 0.5046746940970397, 0.5011057307994226, 0.5011057307994226, 0.5011057307994226, 0.5011057307994226, 0.09085276163947885, 0.5011057307994226, 0.5046746940970397, 0.5046746940970397, 0.09085276163947885, 0.5011057307994226, 0.5046746940970397, 0.5011057307994226, 0.5046746940970397, 0.5011057307994226, 0.5011057307994226, 0.5046746940970397, 0.5011057307994226, 0.5046746940970397, 0.5011057307994226, 0.9803245487387253, 0.5011057307994226, 0.5011057307994226, 0.5011057307994226, 0.09085276163947885, 0.5011057307994226, 0.5046746940970397, 0.5011057307994226, 0.9648950729107416, 0.09085276163947885, 0.5011057307994226, 0.5046746940970397, 0.5046746940970397, 0.5011057307994226]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.173\n",
      "(*) epoch 2, cost 0.757\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.324\n",
      "(*) epoch 2, cost 1.376\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.5503475616258724, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943, 1.1616037414801943]\n",
      "all_sum after preprocessing is: [-0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714  7.         -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714]\n",
      "P is: [0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.9990889488055994, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286, 0.4643463291660286]\n",
      "all_sum before preprocessing is: [3.6653874785747984, 5.639345878438673, 4.350865539583795, 4.026341307221237, 5.639345878438673, 4.026341307221237, 5.639345878438673, 5.958292748849247, 4.026341307221237, 6.281841916511404, 5.958292748849247, 5.639345878438673, 4.350865539583795, 5.96289504610083, 4.026341307221237, 5.957317684148846, 5.3148216460761155, 3.560240567503084, 5.638370813738272, 4.026341307221237, 5.446159905155854, 5.3148216460761155, 6.281841916511404, 4.674414707245952, 5.770684137518412, 4.157679566300976, 4.674414707245952, 4.350865539583795, 4.026341307221237, 4.026341307221237, 4.524196673995404, 4.350865539583795, 5.639345878438673, 4.350865539583795, 4.350865539583795, 5.639345878438673, 4.350865539583795, 6.281841916511404, 3.048107723809691, 4.350865539583795, 4.350865539583795, 2.8747765893980817, 4.674414707245952, 5.415366259896246, 4.026341307221237, 4.350865539583795, 4.026341307221237, 3.560240567503084, 5.958292748849247, 5.3148216460761155]\n",
      "all_sum after preprocessing is: [-1.26768155  0.94358017 -0.49979739 -0.86333494  0.94358017 -0.86333494\n",
      "  0.94358017  1.30086987 -0.86333494  1.66331514  1.30086987  0.94358017\n",
      " -0.49979739  1.30602544 -0.86333494  1.29977758  0.58004261 -1.3854689\n",
      "  0.94248788 -0.86333494  0.72716996  0.58004261  1.66331514 -0.13735211\n",
      "  1.09070752 -0.71620759 -0.13735211 -0.49979739 -0.86333494 -0.86333494\n",
      " -0.30562891 -0.49979739  0.94358017 -0.49979739 -0.49979739  0.94358017\n",
      " -0.49979739  1.66331514 -1.95916881 -0.49979739 -0.49979739 -2.15333729\n",
      " -0.13735211  0.6926744  -0.86333494 -0.49979739 -0.86333494 -1.3854689\n",
      "  1.30086987  0.58004261]\n",
      "P is: [0.21965439090452227, 0.7198222670276962, 0.3775882849909592, 0.2966430520163196, 0.7198222670276962, 0.2966430520163196, 0.7198222670276962, 0.7859813439537033, 0.2966430520163196, 0.8406825192512639, 0.7859813439537033, 0.7198222670276962, 0.3775882849909592, 0.7868473080284605, 0.2966430520163196, 0.7857975483599137, 0.6410772113614219, 0.20013210574642518, 0.7196019242973862, 0.2966430520163196, 0.674183932866816, 0.6410772113614219, 0.8406825192512639, 0.4657158536520598, 0.7485149280149829, 0.3282286426752778, 0.4657158536520598, 0.3775882849909592, 0.2966430520163196, 0.2966430520163196, 0.42418203026734935, 0.3775882849909592, 0.7198222670276962, 0.3775882849909592, 0.3775882849909592, 0.7198222670276962, 0.3775882849909592, 0.8406825192512639, 0.12355702931478726, 0.3775882849909592, 0.3775882849909592, 0.10401977733813814, 0.4657158536520598, 0.6665615951370888, 0.2966430520163196, 0.3775882849909592, 0.2966430520163196, 0.20013210574642518, 0.7859813439537033, 0.6410772113614219]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.127\n",
      "(*) epoch 2, cost 1.651\n",
      "(*) epoch 3, cost 0.883\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.30 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.776\n",
      "(*) epoch 2, cost 3.635\n",
      "(*) epoch 3, cost 3.131\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.4404574283351865, 1.4404574283351865, 1.8955144541776956, 1.4404574283351865, 1.8955144541776956, 1.8955144541776956, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.8147581499819567, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.8955144541776956, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.8955144541776956, 1.4404574283351865, 1.8955144541776956, 1.4404574283351865, 1.4404574283351865, 1.8955144541776956, 1.4404574283351865, 1.8955144541776956, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.8955144541776956, 1.8955144541776956, 1.8955144541776956, 1.4404574283351865, 1.4404574283351865, 1.8955144541776956, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865, 1.4404574283351865]\n",
      "all_sum after preprocessing is: [-0.59183053 -0.59183053  1.71594439 -0.59183053  1.71594439  1.71594439\n",
      " -0.59183053 -0.59183053 -0.59183053 -0.59183053 -0.59183053 -0.59183053\n",
      "  1.30639709 -0.59183053 -0.59183053 -0.59183053 -0.59183053 -0.59183053\n",
      " -0.59183053  1.71594439 -0.59183053 -0.59183053 -0.59183053  1.71594439\n",
      " -0.59183053  1.71594439 -0.59183053 -0.59183053  1.71594439 -0.59183053\n",
      "  1.71594439 -0.59183053 -0.59183053 -0.59183053 -0.59183053 -0.59183053\n",
      " -0.59183053 -0.59183053  1.71594439  1.71594439  1.71594439 -0.59183053\n",
      " -0.59183053  1.71594439 -0.59183053 -0.59183053 -0.59183053 -0.59183053\n",
      " -0.59183053 -0.59183053]\n",
      "P is: [0.3562149553939698, 0.3562149553939698, 0.8476057096735301, 0.3562149553939698, 0.8476057096735301, 0.8476057096735301, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.7869096344259766, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.8476057096735301, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.8476057096735301, 0.3562149553939698, 0.8476057096735301, 0.3562149553939698, 0.3562149553939698, 0.8476057096735301, 0.3562149553939698, 0.8476057096735301, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.8476057096735301, 0.8476057096735301, 0.8476057096735301, 0.3562149553939698, 0.3562149553939698, 0.8476057096735301, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698, 0.3562149553939698]\n",
      "all_sum before preprocessing is: [4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.111533421266228, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.111533421266228, 4.913886536957659, 4.111533421266228, 4.351449832512154, 4.351449832512154, 1.8710383654887652, 4.351449832512154, 2.1109547767346917, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.351449832512154, 2.1109547767346917, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.111533421266228, 4.351449832512154, 2.1109547767346917, 4.351449832512154, 4.594543433518187, 4.111533421266228, 4.351449832512154, 4.351449832512154, 4.351449832512154, 2.1109547767346917, 4.111533421266228, 4.351449832512154, 4.111533421266228, 4.351449832512154, 4.351449832512154, 4.351449832512154, 4.111533421266228, 4.351449832512154]\n",
      "all_sum after preprocessing is: [ 0.36311372  0.36311372  0.36311372  0.36311372  0.01620545  0.36311372\n",
      "  0.36311372  0.36311372  0.36311372  0.36311372  0.36311372  0.01620545\n",
      "  1.17637172  0.01620545  0.36311372  0.36311372 -3.22344892  0.36311372\n",
      " -2.87654066  0.36311372  0.36311372  0.36311372  0.36311372  0.36311372\n",
      "  0.36311372  0.36311372  0.36311372  0.36311372 -2.87654066  0.36311372\n",
      "  0.36311372  0.36311372  0.01620545  0.36311372 -2.87654066  0.36311372\n",
      "  0.71461605  0.01620545  0.36311372  0.36311372  0.36311372 -2.87654066\n",
      "  0.01620545  0.36311372  0.01620545  0.36311372  0.36311372  0.36311372\n",
      "  0.01620545  0.36311372]\n",
      "P is: [0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5040512748091139, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5040512748091139, 0.7642948021306551, 0.5040512748091139, 0.5897939679052023, 0.5897939679052023, 0.03829277163393548, 0.5897939679052023, 0.053325501054801966, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.053325501054801966, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5040512748091139, 0.5897939679052023, 0.053325501054801966, 0.5897939679052023, 0.671420335746405, 0.5040512748091139, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.053325501054801966, 0.5040512748091139, 0.5897939679052023, 0.5040512748091139, 0.5897939679052023, 0.5897939679052023, 0.5897939679052023, 0.5040512748091139, 0.5897939679052023]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.152\n",
      "(*) epoch 2, cost 1.837\n",
      "(*) epoch 3, cost 1.404\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.662\n",
      "(*) epoch 2, cost 2.674\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.29531422747134, 3.925093080971615, 3.925093080971615, 3.9691037797972992, 3.925093080971615, 3.9691037797972992, 4.339324926297024, 3.925093080971615, 3.9691037797972992, 3.925093080971615, 3.925093080971615, 4.29531422747134, 3.925093080971615, 3.3569569652378273, 0.9737926857564025, 3.3569569652378273, 3.9691037797972992, 4.29531422747134, 3.3569569652378273, 4.339324926297024, 3.925093080971615, 4.29531422747134, 3.925093080971615, 4.29531422747134, 4.29531422747134, 3.9691037797972992, 3.9691037797972992, 4.29531422747134, 3.925093080971615, 4.29531422747134, 4.29531422747134, 3.925093080971615, 3.9691037797972992, 4.29531422747134, 3.9691037797972992, 3.925093080971615, 3.925093080971615, 3.925093080971615, 4.29531422747134, 3.925093080971615, 3.9691037797972992, 3.925093080971615, 3.925093080971615, 3.9691037797972992, 3.925093080971615, 4.29531422747134, 3.771188810563236, 4.29531422747134, 3.727178111737552, 4.29531422747134]\n",
      "all_sum after preprocessing is: [ 0.69730357 -0.05900322 -0.05900322  0.0309041  -0.05900322  0.0309041\n",
      "  0.78721089 -0.05900322  0.0309041  -0.05900322 -0.05900322  0.69730357\n",
      " -0.05900322 -1.21962088 -6.08807137 -1.21962088  0.0309041   0.69730357\n",
      " -1.21962088  0.78721089 -0.05900322  0.69730357 -0.05900322  0.69730357\n",
      "  0.69730357  0.0309041   0.0309041   0.69730357 -0.05900322  0.69730357\n",
      "  0.69730357 -0.05900322  0.0309041   0.69730357  0.0309041  -0.05900322\n",
      " -0.05900322 -0.05900322  0.69730357 -0.05900322  0.0309041  -0.05900322\n",
      " -0.05900322  0.0309041  -0.05900322  0.69730357 -0.37340677  0.69730357\n",
      " -0.46331409  0.69730357]\n",
      "P is: [0.6675896682219179, 0.48525347361251653, 0.48525347361251653, 0.5077254102755796, 0.48525347361251653, 0.5077254102755796, 0.6872321407633195, 0.48525347361251653, 0.5077254102755796, 0.48525347361251653, 0.48525347361251653, 0.6675896682219179, 0.48525347361251653, 0.2280031759259313, 0.0022646420290650835, 0.2280031759259313, 0.5077254102755796, 0.6675896682219179, 0.2280031759259313, 0.6872321407633195, 0.48525347361251653, 0.6675896682219179, 0.48525347361251653, 0.6675896682219179, 0.6675896682219179, 0.5077254102755796, 0.5077254102755796, 0.6675896682219179, 0.48525347361251653, 0.6675896682219179, 0.6675896682219179, 0.48525347361251653, 0.5077254102755796, 0.6675896682219179, 0.5077254102755796, 0.48525347361251653, 0.48525347361251653, 0.48525347361251653, 0.6675896682219179, 0.48525347361251653, 0.5077254102755796, 0.48525347361251653, 0.48525347361251653, 0.5077254102755796, 0.48525347361251653, 0.6675896682219179, 0.407718082586226, 0.6675896682219179, 0.3861999247460607, 0.6675896682219179]\n",
      "all_sum before preprocessing is: [1.5419088128801897, 1.6498195009717973, 1.5419088128801897, 1.6498195009717973, 1.024450429542326, 1.024450429542326, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.6498195009717973, 1.1323611176339337, 1.6498195009717973, 1.5419088128801897, 1.024450429542326, 1.1323611176339337, 1.5419088128801897, 1.5419088128801897, 1.024450429542326, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.6498195009717973, 1.5419088128801897, 1.5419088128801897, 1.6498195009717973, 1.5419088128801897, 1.024450429542326, 1.024450429542326, 1.5419088128801897, 1.5419088128801897, 1.5419088128801897, 1.6498195009717973, 1.5419088128801897, 1.1323611176339337, 1.5419088128801897, 1.5419088128801897, 1.1323611176339337, 1.024450429542326, 1.6498195009717973, 1.5419088128801897, 1.6498195009717973, 1.6498195009717973, 1.5419088128801897, 1.024450429542326, 1.5419088128801897]\n",
      "all_sum after preprocessing is: [ 0.42128943  0.90505237  0.42128943  0.90505237 -1.89847329 -1.89847329\n",
      "  0.42128943  0.42128943  0.42128943  0.42128943  0.42128943  0.42128943\n",
      "  0.42128943  0.42128943  0.90505237 -1.41471035  0.90505237  0.42128943\n",
      " -1.89847329 -1.41471035  0.42128943  0.42128943 -1.89847329  0.42128943\n",
      "  0.42128943  0.42128943  0.90505237  0.42128943  0.42128943  0.90505237\n",
      "  0.42128943 -1.89847329 -1.89847329  0.42128943  0.42128943  0.42128943\n",
      "  0.90505237  0.42128943 -1.41471035  0.42128943  0.42128943 -1.41471035\n",
      " -1.89847329  0.90505237  0.42128943  0.90505237  0.90505237  0.42128943\n",
      " -1.89847329  0.42128943]\n",
      "P is: [0.6037917574495512, 0.7119866591150866, 0.6037917574495512, 0.7119866591150866, 0.13028136533915957, 0.13028136533915957, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.7119866591150866, 0.19549217402915928, 0.7119866591150866, 0.6037917574495512, 0.13028136533915957, 0.19549217402915928, 0.6037917574495512, 0.6037917574495512, 0.13028136533915957, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.7119866591150866, 0.6037917574495512, 0.6037917574495512, 0.7119866591150866, 0.6037917574495512, 0.13028136533915957, 0.13028136533915957, 0.6037917574495512, 0.6037917574495512, 0.6037917574495512, 0.7119866591150866, 0.6037917574495512, 0.19549217402915928, 0.6037917574495512, 0.6037917574495512, 0.19549217402915928, 0.13028136533915957, 0.7119866591150866, 0.6037917574495512, 0.7119866591150866, 0.7119866591150866, 0.6037917574495512, 0.13028136533915957, 0.6037917574495512]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.477\n",
      "(*) epoch 2, cost 2.876\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.597\n",
      "(*) epoch 2, cost 1.383\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [4.350619592580172, 4.350619592580172, 4.350619592580172, 4.247992397386076, 4.350619592580172, 4.350619592580172, 4.350619592580172, 4.350619592580172, 4.350619592580172, 4.350619592580172, 4.247992397386076, 4.247992397386076, 4.247992397386076, 4.350619592580172, 4.350619592580172, 4.350619592580172, 6.868146703596757, 4.350619592580172, 5.341058193820531, 4.350619592580172, 4.350619592580172, 4.350619592580172, 5.443685389014625, 4.350619592580172, 4.350619592580172, 4.350619592580172, 4.247992397386076, 4.247992397386076, 4.350619592580172, 6.2244847214049175, 4.350619592580172, 4.350619592580172, 5.443685389014625, 4.350619592580172, 5.341058193820531, 4.350619592580172, 4.247992397386076, 4.350619592580172, 6.327111916599012, 4.247992397386076, 4.350619592580172, 4.350619592580172, 4.247992397386076, 4.350619592580172, 4.247992397386076, 4.350619592580172, 4.350619592580172, 4.350619592580172, 4.350619592580172, 4.350619592580172]\n",
      "all_sum after preprocessing is: [-0.33201089 -0.33201089 -0.33201089 -0.51118169 -0.33201089 -0.33201089\n",
      " -0.33201089 -0.33201089 -0.33201089 -0.33201089 -0.51118169 -0.51118169\n",
      " -0.51118169 -0.33201089 -0.33201089 -0.33201089  4.06319204 -0.33201089\n",
      "  1.39713778 -0.33201089 -0.33201089 -0.33201089  1.57630858 -0.33201089\n",
      " -0.33201089 -0.33201089 -0.51118169 -0.51118169 -0.33201089  2.93946034\n",
      " -0.33201089 -0.33201089  1.57630858 -0.33201089  1.39713778 -0.33201089\n",
      " -0.51118169 -0.33201089  3.11863114 -0.51118169 -0.33201089 -0.33201089\n",
      " -0.51118169 -0.33201089 -0.51118169 -0.33201089 -0.33201089 -0.33201089\n",
      " -0.33201089 -0.33201089]\n",
      "P is: [0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.374916550770923, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.374916550770923, 0.374916550770923, 0.374916550770923, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.9830965907015005, 0.4177514235628331, 0.8017293039549538, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.8286810869549508, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.374916550770923, 0.374916550770923, 0.4177514235628331, 0.9497629839962202, 0.4177514235628331, 0.4177514235628331, 0.8286810869549508, 0.4177514235628331, 0.8017293039549538, 0.4177514235628331, 0.374916550770923, 0.4177514235628331, 0.9576547526687215, 0.374916550770923, 0.4177514235628331, 0.4177514235628331, 0.374916550770923, 0.4177514235628331, 0.374916550770923, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331, 0.4177514235628331]\n",
      "all_sum before preprocessing is: [3.2992507027455544, 1.078723399653077, 4.365193062794427, 1.0756036318963322, 1.078723399653077, 1.078723399653077, 3.2992507027455544, 2.147785527458694, 1.078723399653077, 1.078723399653077, 1.0756036318963322, 1.0756036318963322, 1.078723399653077, 2.147785527458694, 1.078723399653077, 4.368312830551171, 3.2961309349888097, 1.078723399653077, 1.0756036318963322, 1.078723399653077, 3.2992507027455544, 3.2961309349888097, 1.078723399653077, 3.2961309349888097, 1.0756036318963322, 2.147785527458694, 1.078723399653077, 1.078723399653077, 1.078723399653077, 1.078723399653077, 1.078723399653077, 1.0756036318963322, 3.2992507027455544, 4.365193062794427, 1.078723399653077, 3.2992507027455544, 1.078723399653077, 1.0756036318963322, 3.2992507027455544, 1.078723399653077, 3.2961309349888097, 2.147785527458694, 3.2992507027455544, 3.2992507027455544, 1.078723399653077, 3.2992507027455544, 3.2961309349888097, 1.0756036318963322, 3.2961309349888097, 1.078723399653077]\n",
      "all_sum after preprocessing is: [ 1.10811177 -0.82560615  2.0363741  -0.82832296 -0.82560615 -0.82560615\n",
      "  1.10811177  0.10537299 -0.82560615 -0.82560615 -0.82832296 -0.82832296\n",
      " -0.82560615  0.10537299 -0.82560615  2.03909091  1.10539496 -0.82560615\n",
      " -0.82832296 -0.82560615  1.10811177  1.10539496 -0.82560615  1.10539496\n",
      " -0.82832296  0.10537299 -0.82560615 -0.82560615 -0.82560615 -0.82560615\n",
      " -0.82560615 -0.82832296  1.10811177  2.0363741  -0.82560615  1.10811177\n",
      " -0.82560615 -0.82832296  1.10811177 -0.82560615  1.10539496  0.10537299\n",
      "  1.10811177  1.10811177 -0.82560615  1.10811177  1.10539496 -0.82832296\n",
      "  1.10539496 -0.82560615]\n",
      "P is: [0.7517769200315377, 0.3045749264140997, 0.8845635405374754, 0.3039997872028179, 0.3045749264140997, 0.3045749264140997, 0.7517769200315377, 0.526318898660158, 0.3045749264140997, 0.3045749264140997, 0.3039997872028179, 0.3039997872028179, 0.3045749264140997, 0.526318898660158, 0.3045749264140997, 0.8848406667010289, 0.7512695937924149, 0.3045749264140997, 0.3039997872028179, 0.3045749264140997, 0.7517769200315377, 0.7512695937924149, 0.3045749264140997, 0.7512695937924149, 0.3039997872028179, 0.526318898660158, 0.3045749264140997, 0.3045749264140997, 0.3045749264140997, 0.3045749264140997, 0.3045749264140997, 0.3039997872028179, 0.7517769200315377, 0.8845635405374754, 0.3045749264140997, 0.7517769200315377, 0.3045749264140997, 0.3039997872028179, 0.7517769200315377, 0.3045749264140997, 0.7512695937924149, 0.526318898660158, 0.7517769200315377, 0.7517769200315377, 0.3045749264140997, 0.7517769200315377, 0.7512695937924149, 0.3039997872028179, 0.7512695937924149, 0.3045749264140997]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.258\n",
      "(*) epoch 2, cost 2.976\n",
      "(*) epoch 3, cost 2.481\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.761\n",
      "(*) epoch 2, cost 1.547\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.8423852780221717, 7.217817220424135, 6.673717541602133, 2.1950919748883155, 2.1950919748883155, 4.598332313606766, 4.5382671140453175, 3.7733773398693105, 7.30295268449658, 3.6492820915202184, 4.453131649972873, 5.023867975507979, 4.814576881705684, 5.63953185544314, 8.325639369103863, 6.176617678587761, 6.514921528723607, 5.227567456501213, 4.5452809697226995, 6.604685517163927, 3.9185780035032036, 4.598332313606766, 4.598332313606766, 4.598332313606766, 3.9185780035032036, 3.9185780035032036, 1.9257960629053303, 5.496863368484199, 6.176617678587761, 7.284439827267488, 3.858512803941755, 5.496863368484199, 4.598332313606766, 6.176617678587761, 3.2362915167246893, 2.874846284991878, 4.598332313606766, 4.453131649972873, 4.5382671140453175, 4.453131649972873, 4.936636163742612, 2.874846284991878, 3.9185780035032036, 6.176617678587761, 5.63953185544314, 5.496863368484199, 8.318625513426483, 3.8423852780221717, 4.598332313606766, 7.30295268449658]\n",
      "all_sum after preprocessing is: [-0.74357204  1.53742845  1.16974465 -1.85675605 -1.85675605 -0.23272911\n",
      " -0.2733191  -0.79020523  1.59496006 -0.87406452 -0.33085071  0.05483322\n",
      " -0.08659849  0.47087763  2.28605645  0.83382171  1.06243579  0.1924863\n",
      " -0.26857938  1.12309519 -0.69208363 -0.23272911 -0.23272911 -0.23272911\n",
      " -0.69208363 -0.69208363 -2.03873694  0.37446719  0.83382171  1.58244971\n",
      " -0.73267362  0.37446719 -0.23272911  0.83382171 -1.1531493  -1.39740153\n",
      " -0.23272911 -0.33085071 -0.2733191  -0.33085071 -0.00411503 -1.39740153\n",
      " -0.69208363  0.83382171  0.47087763  0.37446719  2.28131673 -0.74357204\n",
      " -0.23272911  1.59496006]\n",
      "P is: [0.3222235305863761, 0.8230905869038887, 0.7630988577046374, 0.13508160941251604, 0.13508160941251604, 0.44207891826142665, 0.43209244349575093, 0.3121246046713524, 0.8313128052538593, 0.2944092649263764, 0.41803364710435886, 0.5137048705814056, 0.47836389805699037, 0.6155914596129934, 0.9077156380291044, 0.6971624035464343, 0.7431557518197278, 0.5479735444595325, 0.4332558893069034, 0.7545623915226382, 0.3335697204023964, 0.44207891826142665, 0.44207891826142665, 0.44207891826142665, 0.3335697204023964, 0.3335697204023964, 0.11519540779155048, 0.5925379666661885, 0.6971624035464343, 0.8295511772888172, 0.32460829487268256, 0.5925379666661885, 0.44207891826142665, 0.6971624035464343, 0.23991431993524678, 0.19822877370256234, 0.44207891826142665, 0.41803364710435886, 0.43209244349575093, 0.41803364710435886, 0.49897124321673314, 0.19822877370256234, 0.3335697204023964, 0.6971624035464343, 0.6155914596129934, 0.5925379666661885, 0.9073178332154405, 0.3222235305863761, 0.44207891826142665, 0.8313128052538593]\n",
      "all_sum before preprocessing is: [3.9713888758718734, 4.620605259065539, 5.746148243832391, 4.4752153025138055, 7.3901688388109825, 4.634014508720646, 5.256149438472762, 4.725329808632515, 4.725329808632515, 4.96368680505418, 5.65760218065448, 6.353171917222043, 3.0857301903459424, 5.256149438472762, 4.725329808632515, 3.8666643263048983, 5.256149438472762, 4.620605259065539, 5.717627737814821, 6.2931463600617015, 4.2681170684866165, 5.256149438472762, 4.725329808632515, 4.4752153025138055, 2.4501860109387206, 4.4752153025138055, 4.620605259065539, 5.717627737814821, 5.256149438472762, 3.0857301903459424, 5.256149438472762, 5.256149438472762, 5.256149438472762, 4.4752153025138055, 3.8666643263048983, 7.16262655919857, 7.16262655919857, 4.620605259065539, 5.717627737814821, 5.256149438472762, 4.4752153025138055, 7.16262655919857, 4.4752153025138055, 5.256149438472762, 4.579939852080781, 3.8666643263048983, 3.8666643263048983, 3.839671123106583, 5.256149438472762, 4.620605259065539]\n",
      "all_sum after preprocessing is: [-0.95889038 -0.31750581  0.79445919 -0.46114186  2.41864716 -0.30425833\n",
      "  0.31037148 -0.21404461 -0.21404461  0.02143697  0.70698131  1.39416004\n",
      " -1.83386493  0.31037148 -0.21404461 -1.06235159  0.31037148 -0.31750581\n",
      "  0.76628274  1.3348586  -0.66574176  0.31037148 -0.21404461 -0.46114186\n",
      " -2.46174223 -0.46114186 -0.31750581  0.76628274  0.31037148 -1.83386493\n",
      "  0.31037148  0.31037148  0.31037148 -0.46114186 -1.06235159  2.19384983\n",
      "  2.19384983 -0.31750581  0.76628274  0.31037148 -0.46114186  2.19384983\n",
      " -0.46114186  0.31037148 -0.35768065 -1.06235159 -1.06235159 -1.08901916\n",
      "  0.31037148 -0.31750581]\n",
      "P is: [0.27710041441933775, 0.42128372039982165, 0.6887880030430662, 0.3867149782361628, 0.9182382350899513, 0.4245168316242662, 0.5769759337647793, 0.4466922181454886, 0.4466922181454886, 0.5053590377631554, 0.6697337958097257, 0.8012555397443459, 0.13777849364208206, 0.5769759337647793, 0.4466922181454886, 0.2568603202553393, 0.5769759337647793, 0.42128372039982165, 0.6827162287026509, 0.7916431689896153, 0.3394509856362162, 0.5769759337647793, 0.4466922181454886, 0.3867149782361628, 0.07858409231347428, 0.3867149782361628, 0.42128372039982165, 0.6827162287026509, 0.5769759337647793, 0.13777849364208206, 0.5769759337647793, 0.5769759337647793, 0.5769759337647793, 0.3867149782361628, 0.2568603202553393, 0.8996958628719425, 0.8996958628719425, 0.42128372039982165, 0.6827162287026509, 0.5769759337647793, 0.3867149782361628, 0.8996958628719425, 0.3867149782361628, 0.5769759337647793, 0.41152113021434317, 0.2568603202553393, 0.2568603202553393, 0.25180302269901406, 0.5769759337647793, 0.42128372039982165]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.717\n",
      "(*) epoch 2, cost 4.282\n",
      "(*) epoch 3, cost 3.613\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.008\n",
      "(*) epoch 2, cost 3.946\n",
      "(*) epoch 3, cost 3.482\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.208468290704396, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 4.208468290704396, 1.000355732101223, 1.000355732101223, 1.274590923447406, 1.274590923447406, 1.4322107964885427, 1.000355732101223, 1.4322107964885427, 1.4322107964885427, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.4322107964885427, 1.000355732101223, 1.274590923447406, 1.000355732101223, 1.000355732101223, 1.000355732101223, 4.6403233550917165, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.000355732101223, 1.4322107964885427, 1.000355732101223, 1.000355732101223, 1.4322107964885427, 1.4322107964885427, 1.000355732101223, 1.274590923447406, 1.000355732101223, 2.905335547120941, 4.208468290704396, 1.000355732101223, 1.000355732101223, 1.4322107964885427, 1.000355732101223, 1.000355732101223, 1.000355732101223]\n",
      "all_sum after preprocessing is: [ 3.07847837 -0.43153901 -0.43153901 -0.43153901 -0.43153901 -0.43153901\n",
      " -0.43153901 -0.43153901  3.07847837 -0.43153901 -0.43153901 -0.13149645\n",
      " -0.13149645  0.0409565  -0.43153901  0.0409565   0.0409565  -0.43153901\n",
      " -0.43153901 -0.43153901  0.0409565  -0.43153901 -0.13149645 -0.43153901\n",
      " -0.43153901 -0.43153901  3.55097388 -0.43153901 -0.43153901 -0.43153901\n",
      " -0.43153901 -0.43153901 -0.43153901 -0.43153901  0.0409565  -0.43153901\n",
      " -0.43153901  0.0409565   0.0409565  -0.43153901 -0.13149645 -0.43153901\n",
      "  1.65271213  3.07847837 -0.43153901 -0.43153901  0.0409565  -0.43153901\n",
      " -0.43153901 -0.43153901]\n",
      "P is: [0.9559962177623359, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.9559962177623359, 0.3937588903843237, 0.3937588903843237, 0.4671731743022284, 0.4671731743022284, 0.5102376942272575, 0.3937588903843237, 0.5102376942272575, 0.5102376942272575, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.5102376942272575, 0.3937588903843237, 0.4671731743022284, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.9721038479057459, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237, 0.5102376942272575, 0.3937588903843237, 0.3937588903843237, 0.5102376942272575, 0.5102376942272575, 0.3937588903843237, 0.4671731743022284, 0.3937588903843237, 0.8392572655747532, 0.9559962177623359, 0.3937588903843237, 0.3937588903843237, 0.5102376942272575, 0.3937588903843237, 0.3937588903843237, 0.3937588903843237]\n",
      "all_sum before preprocessing is: [4.497437324002209, 2.3628026584669457, 3.2075026214545552, 2.5579564458356328, 2.5579564458356328, 3.5655563690541303, 3.2751943564209967, 2.3628026584669457, 2.5579564458356328, 2.3628026584669457, 2.5579564458356328, 2.3628026584669457, 3.2751943564209967, 2.3628026584669457, 2.3628026584669457, 3.2751943564209967, 2.5579564458356328, 2.5579564458356328, 2.3628026584669457, 3.2751943564209967, 2.3628026584669457, 5.309883459852019, 3.4703481437896837, 2.3628026584669457, 3.4703481437896837, 2.3628026584669457, 2.5579564458356328, 3.3704025816854433, 3.4703481437896837, 4.282794279639495, 2.5579564458356328, 3.2751943564209967, 4.497437324002209, 2.3628026584669457, 3.3704025816854433, 3.5655563690541303, 3.5655563690541303, 3.5655563690541303, 2.3628026584669457, 2.3628026584669457, 2.3628026584669457, 3.5655563690541303, 3.3704025816854433, 3.3704025816854433, 4.497437324002209, 2.3628026584669457, 3.3704025816854433, 3.4703481437896837, 3.5655563690541303, 2.3628026584669457]\n",
      "all_sum after preprocessing is: [ 2.01136053 -0.9782159   0.20479454 -0.70490114 -0.70490114  0.70625227\n",
      "  0.29959747 -0.9782159  -0.70490114 -0.9782159  -0.70490114 -0.9782159\n",
      "  0.29959747 -0.9782159  -0.9782159   0.29959747 -0.70490114 -0.70490114\n",
      " -0.9782159   0.29959747 -0.9782159   3.14919918  0.57291223 -0.9782159\n",
      "  0.57291223 -0.9782159  -0.70490114  0.43293751  0.57291223  1.71075088\n",
      " -0.70490114  0.29959747  2.01136053 -0.9782159   0.43293751  0.70625227\n",
      "  0.70625227  0.70625227 -0.9782159  -0.9782159  -0.9782159   0.70625227\n",
      "  0.43293751  0.43293751  2.01136053 -0.9782159   0.43293751  0.57291223\n",
      "  0.70625227 -0.9782159 ]\n",
      "P is: [0.8819847104947569, 0.2732459307321529, 0.5510204399183092, 0.330726478618884, 0.330726478618884, 0.6695725197680255, 0.5743441117360181, 0.2732459307321529, 0.330726478618884, 0.2732459307321529, 0.330726478618884, 0.2732459307321529, 0.5743441117360181, 0.2732459307321529, 0.2732459307321529, 0.5743441117360181, 0.330726478618884, 0.330726478618884, 0.2732459307321529, 0.5743441117360181, 0.2732459307321529, 0.958877155723042, 0.6394348851127972, 0.2732459307321529, 0.6394348851127972, 0.2732459307321529, 0.330726478618884, 0.6065748992437353, 0.6394348851127972, 0.8469336513162796, 0.330726478618884, 0.5743441117360181, 0.8819847104947569, 0.2732459307321529, 0.6065748992437353, 0.6695725197680255, 0.6695725197680255, 0.6695725197680255, 0.2732459307321529, 0.2732459307321529, 0.2732459307321529, 0.6695725197680255, 0.6065748992437353, 0.6065748992437353, 0.8819847104947569, 0.2732459307321529, 0.6065748992437353, 0.6394348851127972, 0.6695725197680255, 0.2732459307321529]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.859\n",
      "(*) epoch 2, cost 1.976\n",
      "(*) epoch 3, cost 1.505\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.177\n",
      "(*) epoch 2, cost 1.715\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.921925839110765, 2.614746358925508, 2.614746358925508, 0.25831321938307256, 3.9125108531116717, 2.614746358925508, 1.9511337391978156, 2.614746358925508, 0.921925839110765, 2.614746358925508, 0.25831321938307256, 2.614746358925508, 1.9511337391978156, 3.9125108531116717, 2.614746358925508, 2.614746358925508, 0.25831321938307256, 3.9125108531116717, 4.566862060799413, 2.614746358925508, 3.2488982333839793, 2.614746358925508, 2.614746358925508, 2.614746358925508, 2.614746358925508, 2.614746358925508, 1.9511337391978156, 2.614746358925508, 2.614746358925508, 2.614746358925508, 1.9511337391978156, 2.614746358925508, 1.9511337391978156, 4.566862060799413, 2.0313067444792283, 3.2488982333839793, 1.9511337391978156, 2.614746358925508, 1.9511337391978156, 2.614746358925508, 2.614746358925508, 2.614746358925508, 1.9511337391978156, 4.566862060799413, 2.614746358925508, 2.614746358925508, 2.614746358925508, 1.9511337391978156, 2.614746358925508, 1.9511337391978156]\n",
      "all_sum after preprocessing is: [-1.67145598  0.14267137  0.14267137 -2.3826228   1.53343313  0.14267137\n",
      " -0.56849546  0.14267137 -1.67145598  0.14267137 -2.3826228   0.14267137\n",
      " -0.56849546  1.53343313  0.14267137  0.14267137 -2.3826228   1.53343313\n",
      "  2.23467488  0.14267137  0.82226631  0.14267137  0.14267137  0.14267137\n",
      "  0.14267137  0.14267137 -0.56849546  0.14267137  0.14267137  0.14267137\n",
      " -0.56849546  0.14267137 -0.56849546  2.23467488 -0.48257729  0.82226631\n",
      " -0.56849546  0.14267137 -0.56849546  0.14267137  0.14267137  0.14267137\n",
      " -0.56849546  2.23467488  0.14267137  0.14267137  0.14267137 -0.56849546\n",
      "  0.14267137 -0.56849546]\n",
      "P is: [0.15823015606203908, 0.5356074631214495, 0.5356074631214495, 0.08450742888328969, 0.8225080675394422, 0.5356074631214495, 0.3615840622024396, 0.5356074631214495, 0.15823015606203908, 0.5356074631214495, 0.08450742888328969, 0.5356074631214495, 0.3615840622024396, 0.8225080675394422, 0.5356074631214495, 0.5356074631214495, 0.08450742888328969, 0.8225080675394422, 0.9033203992800543, 0.5356074631214495, 0.6947172021535544, 0.5356074631214495, 0.5356074631214495, 0.5356074631214495, 0.5356074631214495, 0.5356074631214495, 0.3615840622024396, 0.5356074631214495, 0.5356074631214495, 0.5356074631214495, 0.3615840622024396, 0.5356074631214495, 0.3615840622024396, 0.9033203992800543, 0.3816437208604484, 0.6947172021535544, 0.3615840622024396, 0.5356074631214495, 0.3615840622024396, 0.5356074631214495, 0.5356074631214495, 0.5356074631214495, 0.3615840622024396, 0.9033203992800543, 0.5356074631214495, 0.5356074631214495, 0.5356074631214495, 0.3615840622024396, 0.5356074631214495, 0.3615840622024396]\n",
      "all_sum before preprocessing is: [2.441932370914173, 1.792157606028344, 1.792157606028344, 3.076285622026202, 3.076285622026202, 3.076285622026202, 2.4418820353579935, 1.792157606028344, 1.792157606028344, 1.792157606028344, 1.792157606028344, 3.0916568002438223, 2.4418820353579935, 1.792157606028344, 3.076285622026202, 1.792157606028344, 3.076285622026202, 1.8576250881848688, 2.441932370914173, 2.441932370914173, 2.441932370914173, 1.792157606028344, 3.1417531041827265, 1.8576250881848688, 2.441932370914173, 4.427541646362754, 1.792157606028344, 1.792157606028344, 1.792157606028344, 1.792157606028344, 3.076285622026202, 1.792157606028344, 1.792157606028344, 3.076285622026202, 3.076285622026202, 1.792157606028344, 1.8576250881848688, 2.4418820353579935, 1.792157606028344, 1.792157606028344, 1.792157606028344, 3.076285622026202, 1.792157606028344, 2.4418820353579935, 3.076285622026202, 1.792157606028344, 3.726060386912031, 3.076285622026202, 1.792157606028344, 3.076285622026202]\n",
      "all_sum after preprocessing is: [ 0.11680434 -0.87747836 -0.87747836  1.0874891   1.0874891   1.0874891\n",
      "  0.11672732 -0.87747836 -0.87747836 -0.87747836 -0.87747836  1.11101001\n",
      "  0.11672732 -0.87747836  1.0874891  -0.87747836  1.0874891  -0.77730028\n",
      "  0.11680434  0.11680434  0.11680434 -0.87747836  1.18766717 -0.77730028\n",
      "  0.11680434  3.15517556 -0.87747836 -0.87747836 -0.87747836 -0.87747836\n",
      "  1.0874891  -0.87747836 -0.87747836  1.0874891   1.0874891  -0.87747836\n",
      " -0.77730028  0.11672732 -0.87747836 -0.87747836 -0.87747836  1.0874891\n",
      " -0.87747836  0.11672732  1.0874891  -0.87747836  2.08177179  1.0874891\n",
      " -0.87747836  1.0874891 ]\n",
      "P is: [0.5291679303701142, 0.29370059783411817, 0.29370059783411817, 0.7479086076475908, 0.7479086076475908, 0.7479086076475908, 0.5291487400402387, 0.29370059783411817, 0.29370059783411817, 0.29370059783411817, 0.29370059783411817, 0.752317361060344, 0.5291487400402387, 0.29370059783411817, 0.7479086076475908, 0.29370059783411817, 0.7479086076475908, 0.31490202857273797, 0.5291679303701142, 0.5291679303701142, 0.5291679303701142, 0.29370059783411817, 0.7663235803222618, 0.31490202857273797, 0.5291679303701142, 0.9591121695231671, 0.29370059783411817, 0.29370059783411817, 0.29370059783411817, 0.29370059783411817, 0.7479086076475908, 0.29370059783411817, 0.29370059783411817, 0.7479086076475908, 0.7479086076475908, 0.29370059783411817, 0.31490202857273797, 0.5291487400402387, 0.29370059783411817, 0.29370059783411817, 0.29370059783411817, 0.7479086076475908, 0.29370059783411817, 0.5291487400402387, 0.7479086076475908, 0.29370059783411817, 0.8891188288344752, 0.7479086076475908, 0.29370059783411817, 0.7479086076475908]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.789\n",
      "(*) epoch 2, cost 1.669\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.961\n",
      "(*) epoch 2, cost 3.228\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [5.189806437918119, 5.189806437918119, 4.983619480522645, 4.983619480522645, 6.346342400216919, 6.346342400216919, 5.189806437918119, 6.346342400216919, 5.189806437918119, 6.346342400216919, 6.346342400216919, 6.346342400216919, 6.346342400216919, 5.189806437918119, 4.983619480522645, 6.346342400216919, 5.189806437918119, 5.189806437918119, 4.983619480522645, 5.189806437918119, 6.140155442821445, 6.346342400216919, 5.0575273160287715, 5.189806437918119, 5.189806437918119, 5.189806437918119, 5.189806437918119, 6.346342400216919, 5.189806437918119, 5.189806437918119, 6.005149115496247, 5.189806437918119, 5.189806437918119, 6.346342400216919, 5.189806437918119, 6.346342400216919, 5.189806437918119, 5.189806437918119, 6.6152358136529905, 4.6424261958019715, 6.346342400216919, 5.189806437918119, 5.189806437918119, 6.346342400216919, 6.346342400216919, 5.189806437918119, 5.189806437918119, 5.189806437918119, 5.189806437918119, 5.189806437918119]\n",
      "all_sum after preprocessing is: [-0.65473473 -0.65473473 -1.00934338 -1.00934338  1.33432247  1.33432247\n",
      " -0.65473473  1.33432247 -0.65473473  1.33432247  1.33432247  1.33432247\n",
      "  1.33432247 -0.65473473 -1.00934338  1.33432247 -0.65473473 -0.65473473\n",
      " -1.00934338 -0.65473473  0.97971382  1.33432247 -0.8822337  -0.65473473\n",
      " -0.65473473 -0.65473473 -0.65473473  1.33432247 -0.65473473 -0.65473473\n",
      "  0.74752449 -0.65473473 -0.65473473  1.33432247 -0.65473473  1.33432247\n",
      " -0.65473473 -0.65473473  1.79677621 -1.59614135  1.33432247 -0.65473473\n",
      " -0.65473473  1.33432247  1.33432247 -0.65473473 -0.65473473 -0.65473473\n",
      " -0.65473473 -0.65473473]\n",
      "P is: [0.3419233712108722, 0.3419233712108722, 0.2671083726477222, 0.2671083726477222, 0.7915547229198814, 0.7915547229198814, 0.3419233712108722, 0.7915547229198814, 0.3419233712108722, 0.7915547229198814, 0.7915547229198814, 0.7915547229198814, 0.7915547229198814, 0.3419233712108722, 0.2671083726477222, 0.7915547229198814, 0.3419233712108722, 0.3419233712108722, 0.2671083726477222, 0.3419233712108722, 0.7270514287157539, 0.7915547229198814, 0.29271511531102623, 0.3419233712108722, 0.3419233712108722, 0.3419233712108722, 0.3419233712108722, 0.7915547229198814, 0.3419233712108722, 0.3419233712108722, 0.6786390598823661, 0.3419233712108722, 0.3419233712108722, 0.7915547229198814, 0.3419233712108722, 0.7915547229198814, 0.3419233712108722, 0.3419233712108722, 0.8577560516419275, 0.16852160549183326, 0.7915547229198814, 0.3419233712108722, 0.3419233712108722, 0.7915547229198814, 0.7915547229198814, 0.3419233712108722, 0.3419233712108722, 0.3419233712108722, 0.3419233712108722, 0.3419233712108722]\n",
      "all_sum before preprocessing is: [2.7771691448520768, 1.1980489776584504, 2.01448181754493, 2.87283927172376, 2.9255555355518448, 2.0564064318372797, 2.120943593952348, 2.9793010481311777, 2.120943593952348, 2.0564064318372797, 3.6355265990309062, 1.3045107540658685, 2.7771691448520768, 3.741988375438324, 2.7771691448520768, 2.9793010481311777, 2.01448181754493, 2.7771691448520768, 2.01448181754493, 2.7771691448520768, 2.9793010481311777, 2.120943593952348, 2.87283927172376, 2.87283927172376, 2.9793010481311777, 2.0671980813730153, 1.1980489776584504, 2.0564064318372797, 2.01448181754493, 2.0564064318372797, 2.01448181754493, 1.9607363049655975, 2.87283927172376, 2.0564064318372797, 2.01448181754493, 2.120943593952348, 2.01448181754493, 2.0564064318372797, 2.162868208244698, 3.6355265990309062, 2.9793010481311777, 2.87283927172376, 2.7771691448520768, 2.01448181754493, 1.9607363049655975, 2.9793010481311777, 2.87283927172376, 2.01448181754493, 3.6355265990309062, 2.01448181754493]\n",
      "all_sum after preprocessing is: [ 0.55755671 -2.08020867 -0.71643767  0.71736428  0.80542163 -0.64640672\n",
      " -0.53860372  0.89519824 -0.53860372 -0.64640672  1.99135867 -1.90237471\n",
      "  0.55755671  2.16919262  0.55755671  0.89519824 -0.71643767  0.55755671\n",
      " -0.71643767  0.55755671  0.89519824 -0.53860372  0.71736428  0.71736428\n",
      "  0.89519824 -0.62838032 -2.08020867 -0.64640672 -0.71643767 -0.64640672\n",
      " -0.71643767 -0.80621428  0.71736428 -0.64640672 -0.71643767 -0.53860372\n",
      " -0.71643767 -0.64640672 -0.46857276  1.99135867  0.89519824  0.71736428\n",
      "  0.55755671 -0.71643767 -0.80621428  0.89519824  0.71736428 -0.71643767\n",
      "  1.99135867 -0.71643767]\n",
      "P is: [0.6358870226284757, 0.11103536798666297, 0.3281779132010689, 0.6720263493586173, 0.6911330237113018, 0.3437997316153622, 0.36851245307567043, 0.7099617399455301, 0.36851245307567043, 0.3437997316153622, 0.8798868036306525, 0.12983993981009379, 0.6358870226284757, 0.8974486838274461, 0.6358870226284757, 0.7099617399455301, 0.3281779132010689, 0.6358870226284757, 0.3281779132010689, 0.6358870226284757, 0.7099617399455301, 0.36851245307567043, 0.6720263493586173, 0.6720263493586173, 0.7099617399455301, 0.34787788485531695, 0.11103536798666297, 0.3437997316153622, 0.3281779132010689, 0.3437997316153622, 0.3281779132010689, 0.30869779536116226, 0.6720263493586173, 0.3437997316153622, 0.3281779132010689, 0.36851245307567043, 0.3281779132010689, 0.3437997316153622, 0.38495410778186717, 0.8798868036306525, 0.7099617399455301, 0.6720263493586173, 0.6358870226284757, 0.3281779132010689, 0.30869779536116226, 0.7099617399455301, 0.6720263493586173, 0.3281779132010689, 0.8798868036306525, 0.3281779132010689]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.264\n",
      "(*) epoch 2, cost 3.766\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.680\n",
      "(*) epoch 2, cost 3.167\n",
      "(*) epoch 3, cost 2.590\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.260508289537454, 0.5332349216922285, 3.7310361543497246, 0.5332349216922285, 1.4783617741037895, 0.6087775297668121, 0.6087775297668121, 2.829768561845717, 1.581037964116707, 0.5332349216922285, 1.6565805721912905, 1.15029823642497, 2.2127052471129756, 2.9053111699203007, 1.15029823642497, 2.683233111925246, 1.6565805721912905, 2.288247855187559, 0.5332349216922285, 0.6087775297668121, 2.7587757199998295, 0.6087775297668121, 0.6087775297668121, 1.2258408444995537, 2.7587757199998295, 1.15029823642497, 3.7310361543497246, 2.1981012788494487, 3.260508289537454, 0.5332349216922285, 0.5332349216922285, 0.5332349216922285, 1.581037964116707, 4.362703437345993, 0.5332349216922285, 2.7587757199998295, 4.362703437345993, 1.6565805721912905, 3.260508289537454, 2.2127052471129756, 1.581037964116707, 1.2258408444995537, 1.2258408444995537, 3.375839034732571, 2.288247855187559, 2.683233111925246, 1.581037964116707, 0.5332349216922285, 0.5332349216922285, 2.2127052471129756]\n",
      "all_sum after preprocessing is: [ 1.29406103 -1.13611985  1.71333246 -1.13611985 -0.29394934 -1.06880639\n",
      " -1.06880639  0.91024345 -0.20245807 -1.13611985 -0.13514461 -0.58627564\n",
      "  0.36039924  0.97755691 -0.58627564  0.77967068 -0.13514461  0.4277127\n",
      " -1.13611985 -1.06880639  0.84698414 -1.06880639 -1.06880639 -0.51896218\n",
      "  0.84698414 -0.58627564  1.71333246  0.34738614  1.29406103 -1.13611985\n",
      " -1.13611985 -1.13611985 -0.20245807  2.27618977 -1.13611985  0.84698414\n",
      "  2.27618977 -0.13514461  1.29406103  0.36039924 -0.20245807 -0.51896218\n",
      " -0.51896218  1.39682835  0.4277127   0.77967068 -0.20245807 -1.13611985\n",
      " -1.13611985  0.36039924]\n",
      "P is: [0.7848337669378576, 0.24303347371115752, 0.8472680204416874, 0.24303347371115752, 0.4270372796958254, 0.255630142096154, 0.255630142096154, 0.7130499781538441, 0.44955766564541244, 0.24303347371115752, 0.4662651771745636, 0.3574898511008199, 0.5891370764449341, 0.7266231851839644, 0.3574898511008199, 0.685609133448009, 0.4662651771745636, 0.6053273508434449, 0.24303347371115752, 0.255630142096154, 0.6999341140246476, 0.255630142096154, 0.255630142096154, 0.3730949423991948, 0.6999341140246476, 0.3574898511008199, 0.8472680204416874, 0.5859835822816791, 0.7848337669378576, 0.24303347371115752, 0.24303347371115752, 0.24303347371115752, 0.44955766564541244, 0.9068857945768651, 0.24303347371115752, 0.6999341140246476, 0.9068857945768651, 0.4662651771745636, 0.7848337669378576, 0.5891370764449341, 0.44955766564541244, 0.3730949423991948, 0.3730949423991948, 0.8016801125191501, 0.6053273508434449, 0.685609133448009, 0.44955766564541244, 0.24303347371115752, 0.24303347371115752, 0.5891370764449341]\n",
      "all_sum before preprocessing is: [3.039495261221366, 1.9690692465280173, 3.7817676773332787, 3.039495261221366, 3.039495261221366, 3.7817676773332787, 2.7113416626399296, 2.7113416626399296, 3.039495261221366, 3.039495261221366, 3.7817676773332787, 3.7817676773332787, 3.039495261221366, 3.7817676773332787, 1.9690692465280173, 3.039495261221366, 3.039495261221366, 3.7817676773332787, 3.7817676773332787, 3.039495261221366, 3.039495261221366, 3.7817676773332787, 3.7817676773332787, 3.7817676773332787, 3.7817676773332787, 3.039495261221366, 3.039495261221366, 3.039495261221366, 3.039495261221366, 3.7817676773332787, 3.7817676773332787, 3.7817676773332787, 3.039495261221366, 3.7817676773332787, 3.039495261221366, 3.7817676773332787, 3.039495261221366, 3.7817676773332787, 3.039495261221366, 4.4911742801712, 3.039495261221366, 4.580751037024271, 3.7817676773332787, 3.039495261221366, 3.039495261221366, 3.7817676773332787, 3.7817676773332787, 3.7817676773332787, 4.4911742801712, 3.039495261221366]\n",
      "all_sum after preprocessing is: [-0.63515642 -2.60754121  0.73256709 -0.63515642 -0.63515642  0.73256709\n",
      " -1.2398177  -1.2398177  -0.63515642 -0.63515642  0.73256709  0.73256709\n",
      " -0.63515642  0.73256709 -2.60754121 -0.63515642 -0.63515642  0.73256709\n",
      "  0.73256709 -0.63515642 -0.63515642  0.73256709  0.73256709  0.73256709\n",
      "  0.73256709 -0.63515642 -0.63515642 -0.63515642 -0.63515642  0.73256709\n",
      "  0.73256709  0.73256709 -0.63515642  0.73256709 -0.63515642  0.73256709\n",
      " -0.63515642  0.73256709 -0.63515642  2.03973151 -0.63515642  2.20478713\n",
      "  0.73256709 -0.63515642 -0.63515642  0.73256709  0.73256709  0.73256709\n",
      "  2.03973151 -0.63515642]\n",
      "P is: [0.34634225666913543, 0.06865465493287022, 0.675368349979575, 0.34634225666913543, 0.34634225666913543, 0.675368349979575, 0.22446771891311834, 0.22446771891311834, 0.34634225666913543, 0.34634225666913543, 0.675368349979575, 0.675368349979575, 0.34634225666913543, 0.675368349979575, 0.06865465493287022, 0.34634225666913543, 0.34634225666913543, 0.675368349979575, 0.675368349979575, 0.34634225666913543, 0.34634225666913543, 0.675368349979575, 0.675368349979575, 0.675368349979575, 0.675368349979575, 0.34634225666913543, 0.34634225666913543, 0.34634225666913543, 0.34634225666913543, 0.675368349979575, 0.675368349979575, 0.675368349979575, 0.34634225666913543, 0.675368349979575, 0.34634225666913543, 0.675368349979575, 0.34634225666913543, 0.675368349979575, 0.34634225666913543, 0.8849059253299486, 0.34634225666913543, 0.9006785737154233, 0.675368349979575, 0.34634225666913543, 0.34634225666913543, 0.675368349979575, 0.675368349979575, 0.675368349979575, 0.8849059253299486, 0.34634225666913543]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.845\n",
      "(*) epoch 2, cost 1.560\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.658\n",
      "(*) epoch 2, cost 3.161\n",
      "(*) epoch 3, cost 2.571\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.7374141845064242, 0.7374141845064242, 1.4883330860408075, 0.13897248182987273, 0.7374141845064242, 0.46397430925682615, 0.13897248182987273, 0.13897248182987273, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 0.13897248182987273, 0.8888958214571805, 0.7374141845064242, 0.13897248182987273, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 1.0318921525262554, 0.13897248182987273, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 0.13897248182987273, 0.7374141845064242, 2.1915609315901463, 0.7374141845064242, 0.7374141845064242, 0.13897248182987273, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 1.0318921525262554, 0.7374141845064242, 0.7374141845064242, 1.3568939799532087, 0.7374141845064242, 0.7374141845064242, 0.7374141845064242, 1.3568939799532087, 1.0318921525262554, 0.7374141845064242, 0.7374141845064242, 1.0624160119333776, 1.3909778910459032, 0.7374141845064242, 0.7374141845064242]\n",
      "all_sum after preprocessing is: [-0.02090131 -0.02090131  1.9581517  -1.59809939 -0.02090131 -0.74155438\n",
      " -1.59809939 -1.59809939 -0.02090131 -0.02090131 -0.02090131 -1.59809939\n",
      "  0.3783298  -0.02090131 -1.59809939 -0.02090131 -0.02090131 -0.02090131\n",
      "  0.75519782 -1.59809939 -0.02090131 -0.02090131 -0.02090131 -0.02090131\n",
      " -0.02090131 -0.02090131 -1.59809939 -0.02090131  3.81151453 -0.02090131\n",
      " -0.02090131 -1.59809939 -0.02090131 -0.02090131 -0.02090131  0.75519782\n",
      " -0.02090131 -0.02090131  1.61174284 -0.02090131 -0.02090131 -0.02090131\n",
      "  1.61174284  0.75519782 -0.02090131 -0.02090131  0.83564371  1.70157127\n",
      " -0.02090131 -0.02090131]\n",
      "P is: [0.49477486253221914, 0.49477486253221914, 0.876332784401515, 0.16824741852344158, 0.49477486253221914, 0.3226643382576497, 0.16824741852344158, 0.16824741852344158, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.16824741852344158, 0.5934702085924751, 0.49477486253221914, 0.16824741852344158, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.6803102222048513, 0.16824741852344158, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.16824741852344158, 0.49477486253221914, 0.9783638165834018, 0.49477486253221914, 0.49477486253221914, 0.16824741852344158, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.6803102222048513, 0.49477486253221914, 0.49477486253221914, 0.8336532162697396, 0.49477486253221914, 0.49477486253221914, 0.49477486253221914, 0.8336532162697396, 0.6803102222048513, 0.49477486253221914, 0.49477486253221914, 0.6975469379438264, 0.8457398405615131, 0.49477486253221914, 0.49477486253221914]\n",
      "all_sum before preprocessing is: [1.0774668225201447, 1.0774668225201447, 1.564746436694862, 1.564746436694862, 1.0774668225201447, 1.0774668225201447, 1.0774668225201447, 1.0774668225201447, 1.564746436694862, 0.7846789260141642, 1.564746436694862, 1.0774668225201447, 0.7846789260141642, 1.564746436694862, 1.564746436694862, 1.564746436694862, 1.564746436694862, 1.564746436694862, 1.110159193495884, 1.5974388076706014, 1.0774668225201447, 1.564746436694862, 1.0774668225201447, 1.564746436694862, 1.564746436694862, 2.7616621935818872, 1.564746436694862, 1.0774668225201447, 1.564746436694862, 1.0774668225201447, 1.5974388076706014, 1.564746436694862, 1.110159193495884, 1.5974388076706014, 1.5974388076706014, 1.564746436694862, 1.110159193495884, 1.0774668225201447, 1.564746436694862, 0.7846789260141642, 1.0774668225201447, 1.5974388076706014, 1.110159193495884, 1.564746436694862, 1.0774668225201447, 1.564746436694862, 1.564746436694862, 1.9815946829011897, 1.564746436694862, 1.564746436694862]\n",
      "all_sum after preprocessing is: [-0.88314046 -0.88314046  0.53610534  0.53610534 -0.88314046 -0.88314046\n",
      " -0.88314046 -0.88314046  0.53610534 -1.7359116   0.53610534 -0.88314046\n",
      " -1.7359116   0.53610534  0.53610534  0.53610534  0.53610534  0.53610534\n",
      " -0.78792099  0.63132481 -0.88314046  0.53610534 -0.88314046  0.53610534\n",
      "  0.53610534  4.02223036  0.53610534 -0.88314046  0.53610534 -0.88314046\n",
      "  0.63132481  0.53610534 -0.78792099  0.63132481  0.63132481  0.53610534\n",
      " -0.78792099 -0.88314046  0.53610534 -1.7359116  -0.88314046  0.63132481\n",
      " -0.78792099  0.53610534 -0.88314046  0.53610534  0.53610534  1.75021343\n",
      "  0.53610534  0.53610534]\n",
      "P is: [0.2925274207510731, 0.2925274207510731, 0.6309059553047316, 0.6309059553047316, 0.2925274207510731, 0.2925274207510731, 0.2925274207510731, 0.2925274207510731, 0.6309059553047316, 0.14983298182699567, 0.6309059553047316, 0.2925274207510731, 0.14983298182699567, 0.6309059553047316, 0.6309059553047316, 0.6309059553047316, 0.6309059553047316, 0.6309059553047316, 0.312615248309958, 0.6527897987444473, 0.2925274207510731, 0.6309059553047316, 0.2925274207510731, 0.6309059553047316, 0.6309059553047316, 0.9824022598528563, 0.6309059553047316, 0.2925274207510731, 0.6309059553047316, 0.2925274207510731, 0.6527897987444473, 0.6309059553047316, 0.312615248309958, 0.6527897987444473, 0.6527897987444473, 0.6309059553047316, 0.312615248309958, 0.2925274207510731, 0.6309059553047316, 0.14983298182699567, 0.2925274207510731, 0.6527897987444473, 0.312615248309958, 0.6309059553047316, 0.2925274207510731, 0.6309059553047316, 0.6309059553047316, 0.851979719239712, 0.6309059553047316, 0.6309059553047316]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.710\n",
      "(*) epoch 2, cost 1.679\n",
      "(*) epoch 3, cost 1.342\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.557\n",
      "(*) epoch 2, cost 3.278\n",
      "(*) epoch 3, cost 2.632\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.000099423091513, 3.6223015903503866, 3.047044167244951, 3.047044167244951, 2.980811915595448, 3.047044167244951, 3.360958800023588, 3.047044167244951, 3.047044167244951, 2.6692463345038253, 3.047044167244951, 3.047044167244951, 3.047044167244951, 3.047044167244951, 4.000099423091513, 3.047044167244951, 3.047044167244951, 3.047044167244951, 3.047044167244951, 3.047044167244951, 3.047044167244951, 3.047044167244951, 3.047044167244951, 2.4079035441770267, 2.6692463345038253, 2.980811915595448, 4.000099423091513, 3.047044167244951, 3.047044167244951, 3.047044167244951, 2.6030140828543225, 3.047044167244951, 2.6692463345038253, 2.4079035441770267, 3.047044167244951, 3.047044167244951, 2.980811915595448, 3.047044167244951, 4.000099423091513, 3.047044167244951, 3.047044167244951, 4.000099423091513, 2.980811915595448, 2.980811915595448, 4.000099423091513, 2.980811915595448, 3.047044167244951, 2.980811915595448, 3.047044167244951, 3.047044167244951]\n",
      "all_sum after preprocessing is: [ 2.34865267  1.34862552 -0.17407523 -0.17407523 -0.34939135 -0.17407523\n",
      "  0.65685372 -0.17407523 -0.17407523 -1.17410239 -0.17407523 -0.17407523\n",
      " -0.17407523 -0.17407523  2.34865267 -0.17407523 -0.17407523 -0.17407523\n",
      " -0.17407523 -0.17407523 -0.17407523 -0.17407523 -0.17407523 -1.86587419\n",
      " -1.17410239 -0.34939135  2.34865267 -0.17407523 -0.17407523 -0.17407523\n",
      " -1.34941851 -0.17407523 -1.17410239 -1.86587419 -0.17407523 -0.17407523\n",
      " -0.34939135 -0.17407523  2.34865267 -0.17407523 -0.17407523  2.34865267\n",
      " -0.34939135 -0.34939135  2.34865267 -0.34939135 -0.17407523 -0.34939135\n",
      " -0.17407523 -0.17407523]\n",
      "P is: [0.912827075177948, 0.7939048263915518, 0.4565907526902425, 0.4565907526902425, 0.4135300242073231, 0.4565907526902425, 0.6585532661008303, 0.4565907526902425, 0.4565907526902425, 0.2361142591913332, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.912827075177948, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.13401983563932987, 0.2361142591913332, 0.4135300242073231, 0.912827075177948, 0.4565907526902425, 0.4565907526902425, 0.4565907526902425, 0.2059654550590921, 0.4565907526902425, 0.2361142591913332, 0.13401983563932987, 0.4565907526902425, 0.4565907526902425, 0.4135300242073231, 0.4565907526902425, 0.912827075177948, 0.4565907526902425, 0.4565907526902425, 0.912827075177948, 0.4135300242073231, 0.4135300242073231, 0.912827075177948, 0.4135300242073231, 0.4565907526902425, 0.4135300242073231, 0.4565907526902425, 0.4565907526902425]\n",
      "all_sum before preprocessing is: [1.0317201863841474, 1.0317201863841474, 1.3330309301342251, 1.0317201863841474, 1.0317201863841474, 1.3330309301342251, 1.0317201863841474, 1.3330309301342251, 1.0317201863841474, 1.0317201863841474, 1.0317201863841474, 1.3330309301342251, 1.3330309301342251, 1.8143962659052004, 1.0317201863841474, 1.0317201863841474, 1.3330309301342251, 1.3330309301342251, 1.0317201863841474, 1.3330309301342251, 1.0317201863841474, 1.0317201863841474, 1.0317201863841474, 1.0317201863841474, 1.0317201863841474, 1.3330309301342251, 1.3330309301342251, 1.0317201863841474, 1.5130855221551227, 1.8143962659052004, 1.5130855221551227, 1.0317201863841474, 1.0317201863841474, 1.5130855221551227, 1.0317201863841474, 1.3330309301342251, 1.8143962659052004, 1.5130855221551227, 1.3330309301342251, 1.0317201863841474, 1.3330309301342251, 1.3330309301342251, 1.3330309301342251, 1.3330309301342251, 1.0317201863841474, 1.5130855221551227, 1.8143962659052004, 1.5130855221551227, 1.3330309301342251, 1.3330309301342251]\n",
      "all_sum after preprocessing is: [-0.95750899 -0.95750899  0.30317707 -0.95750899 -0.95750899  0.30317707\n",
      " -0.95750899  0.30317707 -0.95750899 -0.95750899 -0.95750899  0.30317707\n",
      "  0.30317707  2.31721269 -0.95750899 -0.95750899  0.30317707  0.30317707\n",
      " -0.95750899  0.30317707 -0.95750899 -0.95750899 -0.95750899 -0.95750899\n",
      " -0.95750899  0.30317707  0.30317707 -0.95750899  1.05652663  2.31721269\n",
      "  1.05652663 -0.95750899 -0.95750899  1.05652663 -0.95750899  0.30317707\n",
      "  2.31721269  1.05652663  0.30317707 -0.95750899  0.30317707  0.30317707\n",
      "  0.30317707  0.30317707 -0.95750899  1.05652663  2.31721269  1.05652663\n",
      "  0.30317707  0.30317707]\n",
      "P is: [0.27737721349223154, 0.27737721349223154, 0.5752189940574627, 0.27737721349223154, 0.27737721349223154, 0.5752189940574627, 0.27737721349223154, 0.5752189940574627, 0.27737721349223154, 0.27737721349223154, 0.27737721349223154, 0.5752189940574627, 0.5752189940574627, 0.9102925889991483, 0.27737721349223154, 0.27737721349223154, 0.5752189940574627, 0.5752189940574627, 0.27737721349223154, 0.5752189940574627, 0.27737721349223154, 0.27737721349223154, 0.27737721349223154, 0.27737721349223154, 0.27737721349223154, 0.5752189940574627, 0.5752189940574627, 0.27737721349223154, 0.7420262197397555, 0.9102925889991483, 0.7420262197397555, 0.27737721349223154, 0.27737721349223154, 0.7420262197397555, 0.27737721349223154, 0.5752189940574627, 0.9102925889991483, 0.7420262197397555, 0.5752189940574627, 0.27737721349223154, 0.5752189940574627, 0.5752189940574627, 0.5752189940574627, 0.5752189940574627, 0.27737721349223154, 0.7420262197397555, 0.9102925889991483, 0.7420262197397555, 0.5752189940574627, 0.5752189940574627]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 9.122\n",
      "(*) epoch 2, cost 4.709\n",
      "(*) epoch 3, cost 3.394\n",
      "(*) epoch 4, cost 2.735\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.919\n",
      "(*) epoch 2, cost 2.009\n",
      "(*) epoch 3, cost 1.406\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.6264380092435955, 3.9717407619105245, 5.324700716053574, 3.9717407619105245, 4.460846866765478, 3.9717407619105245, 3.9717407619105245, 3.9717407619105245, 3.9717407619105245, 3.9717407619105245, 2.137331904388642, 3.9717407619105245, 4.460846866765478, 3.9717407619105245, 2.137331904388642, 3.9717407619105245, 4.6550834098548775, 3.9717407619105245, 4.460846866765478, 3.9717407619105245, 2.137331904388642, 2.6264380092435955, 4.460846866765478, 2.137331904388642, 2.7304050128142516, 3.9717407619105245, 4.460846866765478, 3.9717407619105245, 3.9717407619105245, 3.9717407619105245, 4.460846866765478, 2.6264380092435955, 4.83559461119862, 4.460846866765478, 3.9717407619105245, 3.9717407619105245, 2.137331904388642, 2.6264380092435955, 4.460846866765478, 3.9717407619105245, 3.9717407619105245, 2.137331904388642, 3.9717407619105245, 4.460846866765478, 2.7304050128142516, 3.2195111176692053, 3.9717407619105245, 3.9717407619105245, 2.137331904388642, 3.9717407619105245]\n",
      "all_sum after preprocessing is: [-1.25826976  0.33535198  1.9380443   0.33535198  0.91473838  0.33535198\n",
      "  0.33535198  0.33535198  0.33535198  0.33535198 -1.83765616  0.33535198\n",
      "  0.91473838  0.33535198 -1.83765616  0.33535198  1.14482754  0.33535198\n",
      "  0.91473838  0.33535198 -1.83765616 -1.25826976  0.91473838 -1.83765616\n",
      " -1.13511229  0.33535198  0.91473838  0.33535198  0.33535198  0.33535198\n",
      "  0.91473838 -1.25826976  1.3586579   0.91473838  0.33535198  0.33535198\n",
      " -1.83765616 -1.25826976  0.91473838  0.33535198  0.33535198 -1.83765616\n",
      "  0.33535198  0.91473838 -1.13511229 -0.55572589  0.33535198  0.33535198\n",
      " -1.83765616  0.33535198]\n",
      "P is: [0.2212718873802664, 0.5830610229625351, 0.8741371320765466, 0.5830610229625351, 0.7139688023744234, 0.5830610229625351, 0.5830610229625351, 0.5830610229625351, 0.5830610229625351, 0.5830610229625351, 0.137328730256198, 0.5830610229625351, 0.7139688023744234, 0.5830610229625351, 0.137328730256198, 0.5830610229625351, 0.7585648777772165, 0.5830610229625351, 0.7139688023744234, 0.5830610229625351, 0.137328730256198, 0.2212718873802664, 0.7139688023744234, 0.137328730256198, 0.24321887960300517, 0.5830610229625351, 0.7139688023744234, 0.5830610229625351, 0.5830610229625351, 0.5830610229625351, 0.7139688023744234, 0.2212718873802664, 0.7955414845956359, 0.7139688023744234, 0.5830610229625351, 0.5830610229625351, 0.137328730256198, 0.2212718873802664, 0.7139688023744234, 0.5830610229625351, 0.5830610229625351, 0.137328730256198, 0.5830610229625351, 0.7139688023744234, 0.24321887960300517, 0.3645369813280784, 0.5830610229625351, 0.5830610229625351, 0.137328730256198, 0.5830610229625351]\n",
      "all_sum before preprocessing is: [5.034078413304446, 3.0972557449017386, 6.169387807867443, 3.0972557449017386, 6.169387807867443, 3.0972557449017386, 3.0972557449017386, 3.0972557449017386, 5.034078413304446, 3.846864781574092, 3.0972557449017386, 5.034078413304446, 5.034078413304446, 5.034078413304446, 5.034078413304446, 3.0972557449017386, 4.9821741761370895, 3.0972557449017386, 6.169387807867443, 3.0972557449017386, 5.034078413304446, 5.034078413304446, 5.432442542561482, 4.111653355227468, 3.0972557449017386, 3.3101400813877575, 6.169387807867443, 6.815105759129299, 3.0972557449017386, 5.034078413304446, 4.232565139464736, 3.0972557449017386, 6.169387807867443, 5.034078413304446, 4.111653355227468, 6.169387807867443, 5.034078413304446, 5.034078413304446, 3.0972557449017386, 4.232565139464736, 3.0972557449017386, 5.034078413304446, 5.034078413304446, 4.232565139464736, 6.169387807867443, 3.0972557449017386, 6.169387807867443, 6.169387807867443, 4.111653355227468, 3.0972557449017386]\n",
      "all_sum after preprocessing is: [ 0.45329354 -1.18915394  1.41604872 -1.18915394  1.41604872 -1.18915394\n",
      " -1.18915394 -1.18915394  0.45329354 -0.55347701 -1.18915394  0.45329354\n",
      "  0.45329354  0.45329354  0.45329354 -1.18915394  0.40927816 -1.18915394\n",
      "  1.41604872 -1.18915394  0.45329354  0.45329354  0.79111082 -0.32893332\n",
      " -1.18915394 -1.00862562  1.41604872  1.96362483 -1.18915394  0.45329354\n",
      " -0.22639876 -1.18915394  1.41604872  0.45329354 -0.32893332  1.41604872\n",
      "  0.45329354  0.45329354 -1.18915394 -0.22639876 -1.18915394  0.45329354\n",
      "  0.45329354 -0.22639876  1.41604872 -1.18915394  1.41604872  1.41604872\n",
      " -0.32893332 -1.18915394]\n",
      "P is: [0.6114220168764272, 0.2334102877093145, 0.8047182326358131, 0.2334102877093145, 0.8047182326358131, 0.2334102877093145, 0.2334102877093145, 0.2334102877093145, 0.6114220168764272, 0.36505809181401516, 0.2334102877093145, 0.6114220168764272, 0.6114220168764272, 0.6114220168764272, 0.6114220168764272, 0.2334102877093145, 0.6009147830579155, 0.2334102877093145, 0.8047182326358131, 0.2334102877093145, 0.6114220168764272, 0.6114220168764272, 0.6880697948890003, 0.4185001862501401, 0.2334102877093145, 0.2672489058534906, 0.8047182326358131, 0.8769247067238961, 0.2334102877093145, 0.6114220168764272, 0.4436408354189961, 0.2334102877093145, 0.8047182326358131, 0.6114220168764272, 0.4185001862501401, 0.8047182326358131, 0.6114220168764272, 0.6114220168764272, 0.2334102877093145, 0.4436408354189961, 0.2334102877093145, 0.6114220168764272, 0.6114220168764272, 0.4436408354189961, 0.8047182326358131, 0.2334102877093145, 0.8047182326358131, 0.8047182326358131, 0.4185001862501401, 0.2334102877093145]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.360\n",
      "(*) epoch 2, cost 2.756\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.917\n",
      "(*) epoch 2, cost 3.559\n",
      "(*) epoch 3, cost 3.150\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.9512419746810665, 1.8586794518487118, 3.3469242158051626, 1.9768123015769175, 0.9512419746810665, 2.5487364630066147, 3.3469242158051626, 1.8586794518487118, 1.8586794518487118, 1.8586794518487118, 1.8586794518487118, 2.5487364630066147, 1.8586794518487118, 2.5487364630066147, 1.8586794518487118, 1.8586794518487118, 1.8586794518487118, 3.3469242158051626, 4.036981226963066, 0.9512419746810665, 3.3469242158051626, 1.8586794518487118, 1.970035228122546, 1.8586794518487118, 1.8586794518487118, 4.036981226963066, 2.6668693127348204, 3.4650570655333683, 3.3469242158051626, 0.9512419746810665, 1.8586794518487118, 4.036981226963066, 3.3469242158051626, 1.8586794518487118, 1.8586794518487118, 2.5487364630066147, 1.8586794518487118, 3.3469242158051626, 1.6412989858389695, 1.9796307141396015, 2.4394867386375174, 1.8586794518487118, 4.036981226963066, 3.3469242158051626, 2.5487364630066147, 3.3469242158051626, 2.5487364630066147, 3.3469242158051626, 1.8586794518487118, 3.3469242158051626]\n",
      "all_sum after preprocessing is: [-1.73079245 -0.67094349  1.06726406 -0.53296927 -1.73079245  0.1350142\n",
      "  1.06726406 -0.67094349 -0.67094349 -0.67094349 -0.67094349  0.1350142\n",
      " -0.67094349  0.1350142  -0.67094349 -0.67094349 -0.67094349  1.06726406\n",
      "  1.87322175 -1.73079245  1.06726406 -0.67094349 -0.5408846  -0.67094349\n",
      " -0.67094349  1.87322175  0.27298842  1.20523828  1.06726406 -1.73079245\n",
      " -0.67094349  1.87322175  1.06726406 -0.67094349 -0.67094349  0.1350142\n",
      " -0.67094349  1.06726406 -0.92483476 -0.52967748  0.0074151  -0.67094349\n",
      "  1.87322175  1.06726406  0.1350142   1.06726406  0.1350142   1.06726406\n",
      " -0.67094349  1.06726406]\n",
      "P is: [0.15048624490118598, 0.3382856108256039, 0.7440762677514223, 0.3698246207344659, 0.15048624490118598, 0.5337023691070103, 0.7440762677514223, 0.3382856108256039, 0.3382856108256039, 0.3382856108256039, 0.3382856108256039, 0.5337023691070103, 0.3382856108256039, 0.5337023691070103, 0.3382856108256039, 0.3382856108256039, 0.3382856108256039, 0.7440762677514223, 0.866830620331997, 0.15048624490118598, 0.7440762677514223, 0.3382856108256039, 0.36798182504135607, 0.3382856108256039, 0.3382856108256039, 0.866830620331997, 0.567826409970777, 0.7694553335319296, 0.7440762677514223, 0.15048624490118598, 0.3382856108256039, 0.866830620331997, 0.7440762677514223, 0.3382856108256039, 0.3382856108256039, 0.5337023691070103, 0.3382856108256039, 0.7440762677514223, 0.28397380279719237, 0.37059211445824547, 0.5018537658257177, 0.3382856108256039, 0.866830620331997, 0.7440762677514223, 0.5337023691070103, 0.7440762677514223, 0.5337023691070103, 0.7440762677514223, 0.3382856108256039, 0.7440762677514223]\n",
      "all_sum before preprocessing is: [2.9250950841739716, 0.9951528743764486, 3.8891787123065793, 0.9951528743764486, 1.5408260655336043, 0.9951528743764486, 0.5705272007273119, 1.5408260655336043, 0.5705272007273119, 1.4472091794967825, 0.5705272007273119, 0.5705272007273119, 0.5705272007273119, 0.9889376377027639, 1.8656196164722345, 1.8718348531459192, 1.085913326766848, 1.4472091794967825, 0.5705272007273119, 1.4472091794967825, 0.5705272007273119, 0.5705272007273119, 0.9951528743764486, 0.5705272007273119, 0.5705272007273119, 2.500469410524835, 2.500469410524835, 1.8656196164722345, 2.500469410524835, 2.9250950841739716, 0.9889376377027639, 0.5705272007273119, 0.5705272007273119, 0.9951528743764486, 0.5705272007273119, 0.9951528743764486, 0.9951528743764486, 1.4135633113519006, 0.9889376377027639, 3.3771513892943053, 0.5705272007273119, 2.500469410524835, 0.9951528743764486, 0.5705272007273119, 1.4135633113519006, 0.9889376377027639, 0.5705272007273119, 1.5408260655336043, 0.5705272007273119, 0.5705272007273119]\n",
      "all_sum after preprocessing is: [ 1.99954897 -0.34010741  3.16830127 -0.34010741  0.32140864 -0.34010741\n",
      " -0.85487836  0.32140864 -0.85487836  0.2079175  -0.85487836 -0.85487836\n",
      " -0.85487836 -0.34764211  0.71515375  0.72268844 -0.23007911  0.2079175\n",
      " -0.85487836  0.2079175  -0.85487836 -0.85487836 -0.34010741 -0.85487836\n",
      " -0.85487836  1.48477803  1.48477803  0.71515375  1.48477803  1.99954897\n",
      " -0.34764211 -0.85487836 -0.85487836 -0.34010741 -0.85487836 -0.34010741\n",
      " -0.34010741  0.16712884 -0.34764211  2.54757388 -0.85487836  1.48477803\n",
      " -0.34010741 -0.85487836  0.16712884 -0.34764211 -0.85487836  0.32140864\n",
      " -0.85487836 -0.85487836]\n",
      "P is: [0.8807497141814413, 0.4157833849963142, 0.9596238172043893, 0.4157833849963142, 0.5796675110053312, 0.4157833849963142, 0.298410513490372, 0.5796675110053312, 0.298410513490372, 0.5517929271316964, 0.298410513490372, 0.298410513490372, 0.298410513490372, 0.41395432086294404, 0.6715389488187242, 0.6731987555351426, 0.4427326275307001, 0.5517929271316964, 0.298410513490372, 0.5517929271316964, 0.298410513490372, 0.298410513490372, 0.4157833849963142, 0.298410513490372, 0.298410513490372, 0.8152931887500839, 0.8152931887500839, 0.6715389488187242, 0.8152931887500839, 0.8807497141814413, 0.41395432086294404, 0.298410513490372, 0.298410513490372, 0.4157833849963142, 0.298410513490372, 0.4157833849963142, 0.4157833849963142, 0.5416852244322002, 0.41395432086294404, 0.9274103567582724, 0.298410513490372, 0.8152931887500839, 0.4157833849963142, 0.298410513490372, 0.5416852244322002, 0.41395432086294404, 0.298410513490372, 0.5796675110053312, 0.298410513490372, 0.298410513490372]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.754\n",
      "(*) epoch 2, cost 3.052\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.319\n",
      "(*) epoch 2, cost 1.769\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7935386051354245, 3.837550880967478, 3.837550880967478, 3.837550880967478, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 3.837550880967478, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 3.837550880967478, 1.7935386051354245, 1.7935386051354245, 3.837550880967478, 1.7935386051354245, 2.0061331254157597, 3.837550880967478, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 3.837550880967478, 3.837550880967478, 3.837550880967478, 1.7935386051354245, 3.837550880967478, 2.0061331254157597, 3.837550880967478, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 1.7935386051354245, 3.837550880967478, 1.7935386051354245, 3.837550880967478, 1.7935386051354245, 1.7935386051354245, 3.837550880967478, 1.7935386051354245, 2.0061331254157597]\n",
      "all_sum after preprocessing is: [-0.67331496  1.52533267  1.52533267  1.52533267 -0.67331496 -0.67331496\n",
      " -0.67331496 -0.67331496 -0.67331496 -0.67331496 -0.67331496 -0.67331496\n",
      "  1.52533267 -0.67331496 -0.67331496 -0.67331496  1.52533267 -0.67331496\n",
      " -0.67331496  1.52533267 -0.67331496 -0.44463706  1.52533267 -0.67331496\n",
      " -0.67331496 -0.67331496 -0.67331496 -0.67331496 -0.67331496  1.52533267\n",
      "  1.52533267  1.52533267 -0.67331496  1.52533267 -0.44463706  1.52533267\n",
      " -0.67331496 -0.67331496 -0.67331496 -0.67331496 -0.67331496 -0.67331496\n",
      "  1.52533267 -0.67331496  1.52533267 -0.67331496 -0.67331496  1.52533267\n",
      " -0.67331496 -0.44463706]\n",
      "P is: [0.33775496264139576, 0.8213224015456047, 0.8213224015456047, 0.8213224015456047, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.8213224015456047, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.8213224015456047, 0.33775496264139576, 0.33775496264139576, 0.8213224015456047, 0.33775496264139576, 0.3906366064771479, 0.8213224015456047, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.8213224015456047, 0.8213224015456047, 0.8213224015456047, 0.33775496264139576, 0.8213224015456047, 0.3906366064771479, 0.8213224015456047, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.33775496264139576, 0.8213224015456047, 0.33775496264139576, 0.8213224015456047, 0.33775496264139576, 0.33775496264139576, 0.8213224015456047, 0.33775496264139576, 0.3906366064771479]\n",
      "all_sum before preprocessing is: [2.33453858812434, 2.6024678836105504, 3.6968402676385907, 2.6024678836105504, 2.004071666044204, 3.6968402676385907, 3.6968402676385907, 2.6024678836105504, 2.6024678836105504, 2.004071666044204, 2.004071666044204, 2.6024678836105504, 1.893830602237918, 2.004071666044204, 2.6024678836105504, 2.004071666044204, 3.4289109721523805, 2.6024678836105504, 3.0984440500722443, 2.004071666044204, 2.33453858812434, 2.004071666044204, 3.0984440500722443, 2.6024678836105504, 1.397854435776224, 2.004071666044204, 3.0984440500722443, 2.6024678836105504, 3.6968402676385907, 2.6024678836105504, 2.004071666044204, 3.6968402676385907, 3.6968402676385907, 2.004071666044204, 2.004071666044204, 2.6024678836105504, 2.6024678836105504, 2.004071666044204, 2.33453858812434, 2.004071666044204, 2.004071666044204, 3.0984440500722443, 3.0984440500722443, 2.6024678836105504, 2.6024678836105504, 2.6024678836105504, 2.004071666044204, 3.0984440500722443, 2.6024678836105504, 3.0984440500722443]\n",
      "all_sum after preprocessing is: [-0.42960379  0.02831911  1.89873116  0.02831911 -0.99441091  1.89873116\n",
      "  1.89873116  0.02831911  0.02831911 -0.99441091 -0.99441091  0.02831911\n",
      " -1.18282595 -0.99441091  0.02831911 -0.99441091  1.44080825  0.02831911\n",
      "  0.87600114 -0.99441091 -0.42960379 -0.99441091  0.87600114  0.02831911\n",
      " -2.03050797 -0.99441091  0.87600114  0.02831911  1.89873116  0.02831911\n",
      " -0.99441091  1.89873116  1.89873116 -0.99441091 -0.99441091  0.02831911\n",
      "  0.02831911 -0.99441091 -0.42960379 -0.99441091 -0.99441091  0.87600114\n",
      "  0.87600114  0.02831911  0.02831911  0.02831911 -0.99441091  0.87600114\n",
      "  0.02831911  0.87600114]\n",
      "P is: [0.39422094610425973, 0.507079305044174, 0.8697478505096777, 0.507079305044174, 0.2700417210551951, 0.8697478505096777, 0.8697478505096777, 0.507079305044174, 0.507079305044174, 0.2700417210551951, 0.2700417210551951, 0.507079305044174, 0.23454446368499907, 0.2700417210551951, 0.507079305044174, 0.2700417210551951, 0.8085797829501001, 0.507079305044174, 0.7059928733792742, 0.2700417210551951, 0.39422094610425973, 0.2700417210551951, 0.7059928733792742, 0.507079305044174, 0.11603680810611472, 0.2700417210551951, 0.7059928733792742, 0.507079305044174, 0.8697478505096777, 0.507079305044174, 0.2700417210551951, 0.8697478505096777, 0.8697478505096777, 0.2700417210551951, 0.2700417210551951, 0.507079305044174, 0.507079305044174, 0.2700417210551951, 0.39422094610425973, 0.2700417210551951, 0.2700417210551951, 0.7059928733792742, 0.7059928733792742, 0.507079305044174, 0.507079305044174, 0.507079305044174, 0.2700417210551951, 0.7059928733792742, 0.507079305044174, 0.7059928733792742]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.676\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.954\n",
      "(*) epoch 2, cost 1.806\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.5974486922948856, 2.0420530652109443, 1.5974486922948856, 1.5623969467644028, 0.9451790877443116, 1.5623969467644028, 1.5623969467644028, 0.9451790877443116, 0.9451790877443116, 1.5974486922948856, 0.9451790877443116, 0.9451790877443116, 1.5623969467644028, 1.5623969467644028, 1.5623969467644028, 1.7036693332317934, 0.9451790877443116, 1.5623969467644028, 1.5623969467644028, 1.5623969467644028, 0.9451790877443116, 0.9451790877443116, 1.5974486922948856, 0.9451790877443116, 1.5623969467644028, 0.9451790877443116, 0.9451790877443116, 0.9451790877443116, 0.9010615052632716, 1.5533311098138456, 1.5623969467644028, 0.9451790877443116, 1.5623969467644028, 0.9010615052632716, 0.9010615052632716, 0.9451790877443116, 2.214666551314977, 0.9451790877443116, 2.9731567968024586, 0.9451790877443116, 0.9451790877443116, 0.9010615052632716, 1.5623969467644028, 1.5182793642833627, 1.5623969467644028, 0.9451790877443116, 1.5533311098138456, 1.5623969467644028, 0.9451790877443116, 1.5974486922948856]\n",
      "all_sum after preprocessing is: [ 0.62892934  1.67793377  0.62892934  0.54622787 -0.9100427   0.54622787\n",
      "  0.54622787 -0.9100427  -0.9100427   0.62892934 -0.9100427  -0.9100427\n",
      "  0.54622787  0.54622787  0.54622787  0.87954749 -0.9100427   0.54622787\n",
      "  0.54622787  0.54622787 -0.9100427  -0.9100427   0.62892934 -0.9100427\n",
      "  0.54622787 -0.9100427  -0.9100427  -0.9100427  -1.01413421  0.52483784\n",
      "  0.54622787 -0.9100427   0.54622787 -1.01413421 -1.01413421 -0.9100427\n",
      "  2.08519992 -0.9100427   3.87479011 -0.9100427  -0.9100427  -1.01413421\n",
      "  0.54622787  0.44213637  0.54622787 -0.9100427   0.52483784  0.54622787\n",
      " -0.9100427   0.62892934]\n",
      "P is: [0.652246654800086, 0.8426307342714527, 0.652246654800086, 0.6332599866850606, 0.2869910994585906, 0.6332599866850606, 0.6332599866850606, 0.2869910994585906, 0.2869910994585906, 0.652246654800086, 0.2869910994585906, 0.2869910994585906, 0.6332599866850606, 0.6332599866850606, 0.6332599866850606, 0.7067284407238766, 0.2869910994585906, 0.6332599866850606, 0.6332599866850606, 0.6332599866850606, 0.2869910994585906, 0.2869910994585906, 0.652246654800086, 0.2869910994585906, 0.6332599866850606, 0.2869910994585906, 0.2869910994585906, 0.2869910994585906, 0.26617155947926885, 0.6282783169902472, 0.6332599866850606, 0.2869910994585906, 0.6332599866850606, 0.26617155947926885, 0.26617155947926885, 0.2869910994585906, 0.8894563451483711, 0.2869910994585906, 0.979663465391189, 0.2869910994585906, 0.2869910994585906, 0.26617155947926885, 0.6332599866850606, 0.6087679660457191, 0.6332599866850606, 0.2869910994585906, 0.6282783169902472, 0.6332599866850606, 0.2869910994585906, 0.652246654800086]\n",
      "all_sum before preprocessing is: [5.188960997070298, 2.9956676832201117, 3.7785042113201968, 5.497954403073182, 4.230606935580675, 3.6143934003596736, 3.7118252352809153, 5.877871373135913, 5.595897324641291, 3.7785042113201968, 5.183572139446616, 5.183572139446616, 3.8963674488542956, 2.661428196493733, 4.293392766482653, 4.056672594169334, 6.660707901235998, 4.849332652720236, 5.261657837914912, 2.6609171098468662, 4.67920397695438, 5.703937031724572, 3.8963674488542956, 4.67920397695438, 3.8963674488542956, 3.9486328870860525, 6.660707901235998, 6.928268411923096, 4.67920397695438, 3.7785042113201968, 4.1685179668981, 4.15791009473606, 3.6143934003596736, 5.595897324641291, 3.7785042113201968, 5.281003974367858, 3.7785042113201968, 4.060478259814818, 6.496597090275474, 6.660707901235998, 2.661428196493733, 5.975303208057155, 5.425768648875435, 4.230606935580675, 4.230606935580675, 4.060478259814818, 4.230606935580675, 3.7785042113201968, 4.67920397695438, 3.8963674488542956]\n",
      "all_sum after preprocessing is: [ 0.57862211 -1.47768292 -0.74374064  0.86831646 -0.31987526 -0.89760145\n",
      " -0.806255    1.22450465  0.96014208 -0.74374064  0.57356983  0.57356983\n",
      " -0.63323889 -1.79104654 -0.2610109  -0.48294605  1.95844693  0.2602062\n",
      "  0.64677846 -1.79152571  0.10070339  1.06143387 -0.63323889  0.10070339\n",
      " -0.63323889 -0.58423783  1.95844693  2.2092962   0.10070339 -0.74374064\n",
      " -0.37808629 -0.38803162 -0.89760145  0.96014208 -0.74374064  0.66491628\n",
      " -0.74374064 -0.47937808  1.80458612  1.95844693 -1.79104654  1.31585111\n",
      "  0.80063927 -0.31987526 -0.31987526 -0.47937808 -0.31987526 -0.74374064\n",
      "  0.10070339 -0.63323889]\n",
      "P is: [0.6407502915163997, 0.1857776556517326, 0.32218671016909056, 0.7043952681901149, 0.42070614744888335, 0.28954364872303795, 0.30868910675016437, 0.7728553129137066, 0.7231502518669533, 0.32218671016909056, 0.6395864849978434, 0.6395864849978434, 0.3467764936127761, 0.14294446230148786, 0.43511522343816916, 0.3815567007706809, 0.8763647762271118, 0.5646869804922643, 0.6562841297776071, 0.14288576916034512, 0.5251545933450071, 0.7429644640462558, 0.3467764936127761, 0.5251545933450071, 0.3467764936127761, 0.3579580527499408, 0.8763647762271118, 0.9010812118879719, 0.5251545933450071, 0.32218671016909056, 0.4065885431441282, 0.4041912380307676, 0.28954364872303795, 0.7231502518669533, 0.32218671016909056, 0.660363896689869, 0.32218671016909056, 0.38239899444141073, 0.8587062839360761, 0.8763647762271118, 0.14294446230148786, 0.7884906109820039, 0.6901112110543519, 0.42070614744888335, 0.42070614744888335, 0.38239899444141073, 0.42070614744888335, 0.32218671016909056, 0.5251545933450071, 0.3467764936127761]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.131\n",
      "(*) epoch 2, cost 2.387\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 8.444\n",
      "(*) epoch 2, cost 5.411\n",
      "(*) epoch 3, cost 4.477\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.144875654027253, 1.752120757582495, 1.752120757582495, 2.2539353411310676, 2.154337670309822, 1.752120757582495, 1.8517184284037407, 1.2444733248484987, 1.8517184284037407, 1.752120757582495, 1.8517184284037407, 1.752120757582495, 1.752120757582495, 1.752120757582495, 1.8517184284037407, 2.2542750490254457, 1.752120757582495, 1.2444733248484987, 1.8517184284037407, 1.144875654027253, 1.8517184284037407, 1.752120757582495, 1.752120757582495, 1.144875654027253, 1.752120757582495, 1.8517184284037407, 1.752120757582495, 1.8517184284037407, 1.8517184284037407, 1.752120757582495, 1.752120757582495, 1.8517184284037407, 1.752120757582495, 1.8517184284037407, 1.144875654027253, 1.752120757582495, 1.752120757582495, 1.8517184284037407, 1.752120757582495, 1.752120757582495, 1.144875654027253, 1.752120757582495, 1.752120757582495, 1.752120757582495, 1.8517184284037407, 1.8517184284037407, 1.8517184284037407, 1.752120757582495, 1.8517184284037407, 1.8517184284037407]\n",
      "all_sum after preprocessing is: [-2.33405906  0.07556697  0.07556697  2.06683126  1.67161499  0.07556697\n",
      "  0.47078324 -1.9388428   0.47078324  0.07556697  0.47078324  0.07556697\n",
      "  0.07556697  0.07556697  0.47078324  2.06817926  0.07556697 -1.9388428\n",
      "  0.47078324 -2.33405906  0.47078324  0.07556697  0.07556697 -2.33405906\n",
      "  0.07556697  0.47078324  0.07556697  0.47078324  0.47078324  0.07556697\n",
      "  0.07556697  0.47078324  0.07556697  0.47078324 -2.33405906  0.07556697\n",
      "  0.07556697  0.47078324  0.07556697  0.07556697 -2.33405906  0.07556697\n",
      "  0.07556697  0.07556697  0.47078324  0.47078324  0.47078324  0.07556697\n",
      "  0.47078324  0.47078324]\n",
      "P is: [0.08834121149551002, 0.5188827585409614, 0.5188827585409614, 0.8876373075825379, 0.8417910230409748, 0.5188827585409614, 0.6155691212856287, 0.12577504202991305, 0.6155691212856287, 0.5188827585409614, 0.6155691212856287, 0.5188827585409614, 0.5188827585409614, 0.5188827585409614, 0.6155691212856287, 0.8877716836751578, 0.5188827585409614, 0.12577504202991305, 0.6155691212856287, 0.08834121149551002, 0.6155691212856287, 0.5188827585409614, 0.5188827585409614, 0.08834121149551002, 0.5188827585409614, 0.6155691212856287, 0.5188827585409614, 0.6155691212856287, 0.6155691212856287, 0.5188827585409614, 0.5188827585409614, 0.6155691212856287, 0.5188827585409614, 0.6155691212856287, 0.08834121149551002, 0.5188827585409614, 0.5188827585409614, 0.6155691212856287, 0.5188827585409614, 0.5188827585409614, 0.08834121149551002, 0.5188827585409614, 0.5188827585409614, 0.5188827585409614, 0.6155691212856287, 0.6155691212856287, 0.6155691212856287, 0.5188827585409614, 0.6155691212856287, 0.6155691212856287]\n",
      "all_sum before preprocessing is: [3.4112272162804733, 2.761518166474636, 2.761518166474636, 3.4112272162804733, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 3.4112272162804733, 2.761518166474636, 3.4112272162804733, 3.4112272162804733, 2.761518166474636, 2.2203888733752457, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 2.761518166474636, 3.4112272162804733]\n",
      "all_sum after preprocessing is: [ 2.55465148 -0.29443106 -0.29443106  2.55465148 -0.29443106 -0.29443106\n",
      " -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106\n",
      " -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106\n",
      " -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106\n",
      " -0.29443106 -0.29443106 -0.29443106 -0.29443106  2.55465148 -0.29443106\n",
      "  2.55465148  2.55465148 -0.29443106 -2.66737326 -0.29443106 -0.29443106\n",
      " -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106\n",
      " -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106 -0.29443106\n",
      " -0.29443106  2.55465148]\n",
      "P is: [0.9278853841254582, 0.42691941782917153, 0.42691941782917153, 0.9278853841254582, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.9278853841254582, 0.42691941782917153, 0.9278853841254582, 0.9278853841254582, 0.42691941782917153, 0.06492625830835726, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.42691941782917153, 0.9278853841254582]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.316\n",
      "(*) epoch 2, cost 1.915\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.761\n",
      "(*) epoch 2, cost 1.808\n",
      "(*) epoch 3, cost 1.187\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 0.8925426028850902, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 0.8925426028850902, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 0.8925426028850902, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 2.3469298634540734, 0.8925426028850902]\n",
      "all_sum after preprocessing is: [ 0.29488391  0.29488391  0.29488391 -3.39116499  0.29488391  0.29488391\n",
      "  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391\n",
      "  0.29488391 -3.39116499  0.29488391  0.29488391  0.29488391  0.29488391\n",
      "  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391\n",
      "  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391\n",
      "  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391\n",
      "  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391\n",
      " -3.39116499  0.29488391  0.29488391  0.29488391  0.29488391  0.29488391\n",
      "  0.29488391 -3.39116499]\n",
      "P is: [0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.03257272439556667, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.03257272439556667, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.03257272439556667, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.5731913728777112, 0.03257272439556667]\n",
      "all_sum before preprocessing is: [2.5250566223327455, 3.416624187946483, 3.416624187946483, 1.8367808215642893, 1.8367808215642893, 1.8367808215642893, 1.8367808215642893, 1.8367808215642893, 2.728348387178027, 2.5250566223327455, 2.728348387178027, 1.8367808215642893, 3.416624187946483, 2.5250566223327455, 2.5250566223327455, 2.728348387178027, 2.728348387178027, 1.8367808215642893, 2.645490713554405, 1.8367808215642893, 1.8367808215642893, 2.728348387178027, 1.6081819211180168, 1.8367808215642893, 2.2964577218864726, 1.8367808215642893, 3.416624187946483, 2.728348387178027, 2.5250566223327455, 1.8367808215642893, 2.5250566223327455, 2.728348387178027, 2.728348387178027, 1.8367808215642893, 2.5250566223327455, 1.8367808215642893, 2.728348387178027, 2.728348387178027, 1.8367808215642893, 2.728348387178027, 1.8367808215642893, 1.8367808215642893, 2.4997494867317545, 1.8367808215642893, 2.728348387178027, 2.728348387178027, 1.8367808215642893, 2.5250566223327455, 2.5250566223327455, 1.8367808215642893]\n",
      "all_sum after preprocessing is: [ 0.34266085  2.11745122  2.11745122 -1.02744874 -1.02744874 -1.02744874\n",
      " -1.02744874 -1.02744874  0.74734164  0.34266085  0.74734164 -1.02744874\n",
      "  2.11745122  0.34266085  0.34266085  0.74734164  0.74734164 -1.02744874\n",
      "  0.58240181 -1.02744874 -1.02744874  0.74734164 -1.48250693 -1.02744874\n",
      " -0.11239735 -1.02744874  2.11745122  0.74734164  0.34266085 -1.02744874\n",
      "  0.34266085  0.74734164  0.74734164 -1.02744874  0.34266085 -1.02744874\n",
      "  0.74734164  0.74734164 -1.02744874  0.74734164 -1.02744874 -1.02744874\n",
      "  0.29228344 -1.02744874  0.74734164  0.74734164 -1.02744874  0.34266085\n",
      "  0.34266085 -1.02744874]\n",
      "P is: [0.5848367290185437, 0.8925878098037084, 0.8925878098037084, 0.26357901889210356, 0.26357901889210356, 0.26357901889210356, 0.26357901889210356, 0.26357901889210356, 0.6785991791940237, 0.5848367290185437, 0.6785991791940237, 0.26357901889210356, 0.8925878098037084, 0.5848367290185437, 0.5848367290185437, 0.6785991791940237, 0.6785991791940237, 0.26357901889210356, 0.6416198746895303, 0.26357901889210356, 0.26357901889210356, 0.6785991791940237, 0.1850490608005292, 0.26357901889210356, 0.47193020724324214, 0.26357901889210356, 0.8925878098037084, 0.6785991791940237, 0.5848367290185437, 0.26357901889210356, 0.5848367290185437, 0.6785991791940237, 0.6785991791940237, 0.26357901889210356, 0.5848367290185437, 0.26357901889210356, 0.6785991791940237, 0.6785991791940237, 0.26357901889210356, 0.6785991791940237, 0.26357901889210356, 0.26357901889210356, 0.5725550648160377, 0.26357901889210356, 0.6785991791940237, 0.6785991791940237, 0.26357901889210356, 0.5848367290185437, 0.5848367290185437, 0.26357901889210356]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.862\n",
      "(*) epoch 2, cost 0.881\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.727\n",
      "(*) epoch 2, cost 1.968\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.144720157681647, 2.970252738026121, 2.970252738026121, 5.011065976342557, 4.144720157681647, 4.144720157681647, 2.970252738026121, 1.5717323476900091, 2.970252738026121, 2.970252738026121, 5.011065976342557, 4.034643412025461, 2.970252738026121, 2.970252738026121, 6.185533395998084, 3.256319141166076, 2.970252738026121, 2.970252738026121, 4.144720157681647, 1.5717323476900091, 2.970252738026121, 2.970252738026121, 1.5717323476900091, 4.144720157681647, 2.970252738026121, 2.970252738026121, 2.970252738026121, 2.025982587563907, 2.7461997673455354, 2.7461997673455354, 5.011065976342557, 1.5717323476900091, 2.970252738026121, 2.970252738026121, 2.970252738026121, 2.970252738026121, 1.5717323476900091, 4.144720157681647, 4.144720157681647, 2.970252738026121, 2.970252738026121, 4.144720157681647, 3.424502977900018, 5.011065976342557, 2.970252738026121, 2.970252738026121, 2.970252738026121, 2.970252738026121, 4.144720157681647, 2.970252738026121]\n",
      "all_sum after preprocessing is: [ 0.89548038 -0.31743039 -0.31743039  1.79018393  0.89548038  0.89548038\n",
      " -0.31743039 -1.76172795 -0.31743039 -0.31743039  1.79018393  0.78180054\n",
      " -0.31743039 -0.31743039  3.0030947  -0.02200029 -0.31743039 -0.31743039\n",
      "  0.89548038 -1.76172795 -0.31743039 -0.31743039 -1.76172795  0.89548038\n",
      " -0.31743039 -0.31743039 -0.31743039 -1.29260893 -0.54881719 -0.54881719\n",
      "  1.79018393 -1.76172795 -0.31743039 -0.31743039 -0.31743039 -0.31743039\n",
      " -1.76172795  0.89548038  0.89548038 -0.31743039 -0.31743039  0.89548038\n",
      "  0.15168864  1.79018393 -0.31743039 -0.31743039 -0.31743039 -0.31743039\n",
      "  0.89548038 -0.31743039]\n",
      "P is: [0.7100198346764472, 0.42130210979936356, 0.42130210979936356, 0.8569498256085374, 0.7100198346764472, 0.7100198346764472, 0.42130210979936356, 0.1465740577324591, 0.42130210979936356, 0.42130210979936356, 0.8569498256085374, 0.6860680415685755, 0.42130210979936356, 0.42130210979936356, 0.9527137393073977, 0.4945001488595263, 0.42130210979936356, 0.42130210979936356, 0.7100198346764472, 0.1465740577324591, 0.42130210979936356, 0.42130210979936356, 0.1465740577324591, 0.7100198346764472, 0.42130210979936356, 0.42130210979936356, 0.42130210979936356, 0.21541154916755692, 0.366138873896211, 0.366138873896211, 0.8569498256085374, 0.1465740577324591, 0.42130210979936356, 0.42130210979936356, 0.42130210979936356, 0.42130210979936356, 0.1465740577324591, 0.7100198346764472, 0.7100198346764472, 0.42130210979936356, 0.42130210979936356, 0.7100198346764472, 0.5378496118149066, 0.8569498256085374, 0.42130210979936356, 0.42130210979936356, 0.42130210979936356, 0.42130210979936356, 0.7100198346764472, 0.42130210979936356]\n",
      "all_sum before preprocessing is: [1.0665173064602333, 0.6374215146417707, 1.5156351029945538, 1.03675646657536, 1.5156351029945538, 0.1883037181074502, 2.4793576542917286, 1.5156351029945538, 2.3640878514624637, 0.6374215146417707, 3.1898069061900367, 1.5156351029945538, 1.3478707665400789, 1.5156351029945538, 1.0665173064602333, 0.1883037181074502, 1.5156351029945538, 1.0665173064602333, 4.294067002461081, 0.6374215146417707, 2.030239857757408, 0.6374215146417707, 2.4521308628111234, 1.4858742631096804, 1.5156351029945538, 0.6374215146417707, 3.3278104027596385, 1.5156351029945538, 1.5156351029945538, 1.0665173064602333, 0.6374215146417707, 1.5156351029945538, 1.5156351029945538, 1.0665173064602333, 0.6374215146417707, 1.4858742631096804, 0.1883037181074502, 0.6374215146417707, 1.5156351029945538, 1.5156351029945538, 2.030239857757408, 1.0665173064602333, 1.5156351029945538, 0.9187749747216163, 2.030239857757408, 1.0665173064602333, 1.5156351029945538, 0.6374215146417707, 0.6374215146417707, 0.1883037181074502]\n",
      "all_sum after preprocessing is: [-0.35830609 -0.88939176  0.19756052 -0.39514066  0.19756052 -1.44525837\n",
      "  1.39034601  0.19756052  1.24767824 -0.88939176  2.26965879  0.19756052\n",
      " -0.01007898  0.19756052 -0.35830609 -1.44525837  0.19756052 -0.35830609\n",
      "  3.63638557 -0.88939176  0.8344794  -0.88939176  1.3566478   0.16072596\n",
      "  0.19756052 -0.88939176  2.44046373  0.19756052  0.19756052 -0.35830609\n",
      " -0.88939176  0.19756052  0.19756052 -0.35830609 -0.88939176  0.16072596\n",
      " -1.44525837 -0.88939176  0.19756052  0.19756052  0.8344794  -0.35830609\n",
      "  0.19756052 -0.54116464  0.8344794  -0.35830609  0.19756052 -0.88939176\n",
      " -0.88939176 -1.44525837]\n",
      "P is: [0.4113696746346012, 0.2912353625662178, 0.5492301123846992, 0.4024804074399531, 0.5492301123846992, 0.1907323796548482, 0.8006474758234835, 0.5492301123846992, 0.7768976943781237, 0.2912353625662178, 0.9063328254344787, 0.5492301123846992, 0.4974802768893811, 0.5492301123846992, 0.4113696746346012, 0.1907323796548482, 0.5492301123846992, 0.4113696746346012, 0.9743289623315352, 0.2912353625662178, 0.6973012406234776, 0.2912353625662178, 0.7952143376143946, 0.5400952121661126, 0.5492301123846992, 0.2912353625662178, 0.9198612788943041, 0.5492301123846992, 0.5492301123846992, 0.4113696746346012, 0.2912353625662178, 0.5492301123846992, 0.5492301123846992, 0.4113696746346012, 0.2912353625662178, 0.5400952121661126, 0.1907323796548482, 0.2912353625662178, 0.5492301123846992, 0.5492301123846992, 0.6973012406234776, 0.4113696746346012, 0.5492301123846992, 0.36791669777614333, 0.6973012406234776, 0.4113696746346012, 0.5492301123846992, 0.2912353625662178, 0.2912353625662178, 0.1907323796548482]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.005\n",
      "(*) epoch 2, cost 2.638\n",
      "(*) epoch 3, cost 2.208\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.517\n",
      "(*) epoch 2, cost 2.988\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "    female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "    trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s = \\\n",
    "    run_proc_multi(simulate_wrapper, custom_train_reps, svm.SVC , n_times = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = \"../outputs/sim1_svm_scores.csv\"\n",
    "save_scores(male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "        female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "        trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans female to female accuracy increment is 9.3%\n",
      "median trans female to female accuracy increment is 9.0%\n",
      "average trans female to female accuracy f1 is 10.7%\n",
      "median trans female to female accuracy f1 is 7.6%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Larger is better (>0)\n",
    "\"\"\"\n",
    "hist_plot(score_path, filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans female to female accuracy increment is 15.4%\n",
      "median trans female to female accuracy increment is 14.0%\n",
      "average trans female to female accuracy f1 is 16.5%\n",
      "median trans female to female accuracy f1 is 12.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "female accuracy > 0.7 filtered out \n",
    "\"\"\"\n",
    "\n",
    "hist_plot(score_path, filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
