{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation goals\n",
    "\n",
    "* Categorical response variable\n",
    "\n",
    "* Different feature distribution for different domains\n",
    "\n",
    "Simulation\n",
    "\n",
    "* $D$: total number of features\n",
    "\n",
    "* $d_{1}$: number of features with higher frequency in a domain 1\n",
    "\n",
    "* $d_{2}$: number of features with higher frequency in a domain 2\n",
    "\n",
    "\n",
    "* $d_{1} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$\n",
    "\n",
    "* $d_{2} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$ ($d_{1} + d_{2} \\le D$)\n",
    "\n",
    "* $k \\in [D]$ for indexing feature\n",
    "\n",
    "* Let $\\Delta_{r} = \\{j \\in [D]: \\textrm{feature } j \\textrm{ is more frequent in a domain } r \\}$\n",
    "\n",
    "* Sample $\\Delta_{1} \\subseteq [D]$ such that $|\\Delta_{1}| = d_{1}$ \n",
    "\n",
    "* Sample $\\Delta_{2} \\subseteq [D]\\backslash \\Delta_{1}$ such that $|\\Delta_{2}| = d_{2}$\n",
    "\n",
    "* Let $\\alpha_{1} \\overset{\\Delta}{=} \\left( \\alpha_{11}, \\ldots, \\alpha_{1D} \\right)$ be a feature frequency vector for a domain 1\n",
    "\n",
    "* Let $\\alpha_{2} \\overset{\\Delta}{=} \\left( \\alpha_{21}, \\ldots, \\alpha_{2D} \\right)$ be a feature frequency vector for a domain 2\n",
    "\n",
    "\n",
    "* For each $k \\in [D]$: \n",
    "\n",
    "    * If $k \\in \\Delta_{1}$, $\\alpha_{1k} > \\alpha_{2k}$\n",
    "\n",
    "    * If $k \\in \\Delta_{2}$, $\\alpha_{2k} > \\alpha_{1k}$\n",
    "\n",
    "    * Otherwise $\\alpha_{1k} = \\alpha_{2k}$\n",
    "\n",
    "\n",
    "* Sample $\\rho_{1} \\sim \\operatorname{Dir}(\\alpha_{1})$\n",
    "\n",
    "* Sample $\\rho_{2} \\sim \\operatorname{Dir}(\\alpha_{2})$\n",
    "\n",
    "* Sample a code-specific contribution to mortality: $W_{k} \\sim  \\max\\{ \\mathcal{N}\\!\\left(0,1\\right), 0\\}$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "    * $\\tilde{X}_{i} \\sim \\operatorname{Multi}(n_{i}; \\rho_{r})$ where $\\tilde{X}_{i}$ is a vector of counts for each diagnosis code/feature, $n_i = 3k$.\n",
    "\n",
    "\t* We set $X_{ik} = \\min \\left\\{ \\tilde{X}_{ik}, 1 \\right\\}$ where $\\tilde{X}_{ik}$ is a count for a diagnosis code/feature $k$, $k \\in [D]$\n",
    "\n",
    "* For all patient $i$ in a domain $r$\n",
    "\n",
    "    * $b = -\\operatorname{Mean}(\\sum_{k} W_{k} X_{ik})$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "\t* pathogenic score $\\bar{p}_{i} = \\operatorname{sigmoid}(\\sum_{k} W_{k} X_{ik} + b)$ (aka a liability model)\n",
    "\n",
    "    <!-- * If $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; else $Y_{i} = 0$. -->\n",
    "\n",
    "\t* Sample $Y_{i} \\sim \\operatorname{Bern}(\\bar{p}_{i})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/deep_patient/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from deep_patient.sda import SDA\n",
    "from math import floor, exp, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "base_dir = \"/home/wanxinli/deep_patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    unit_1 = 1/(2*d_1-2*d_2+3*D)\n",
    "    alpha_1 = [5*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([3*unit_1]*(D-d_1-d_2))\n",
    "  \n",
    "    unit_2 = 1/(-2*d_1+2*d_2+3*D)\n",
    "    alpha_2 = [unit_2]*d_1\n",
    "    alpha_2.extend([5*unit_2]*d_2)\n",
    "    alpha_2.extend([3*unit_2]*(D-d_1-d_2))  \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [max(0, W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            cur_sum = np.sum(np.multiply(W, X_i))\n",
    "            all_sum.append(cur_sum)\n",
    "\n",
    "        all_sum = np.array(all_sum)\n",
    "        b = -np.mean(all_sum) \n",
    "        \n",
    "        P = []\n",
    "        for cur_sum in all_sum:\n",
    "            p_i = sigmoid(3*(cur_sum+b))\n",
    "            P.append(p_i)\n",
    "            Y_i = 0\n",
    "            if p_i >= 0.5: # TODO: mimic exact logistic regression, change to np.random.binomial later\n",
    "                Y_i = 1\n",
    "            # Y_i = np.random.binomial(1, p_i) # too much noise, domain 1 data cannot learn well\n",
    "            Y.append(int(Y_i))\n",
    "        # print(\"P is:\", P)\n",
    "\n",
    "            \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), label_1, np.array(feature_2), label_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Wrapper function with different set ups for simulate()\n",
    "\"\"\"\n",
    "def simulate_wrapper(num_patient):\n",
    "    D = 20\n",
    "    d_1 = 5\n",
    "    d_2 = 5\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train deep patient model and generate representations for males and females\n",
    "\"\"\"\n",
    "\n",
    "def custom_train_reps(male_seqs, female_seqs):\n",
    "    \"\"\" \n",
    "    Customized training algorithm for generating male representations and female representations\n",
    "    \n",
    "    :returns: male representations, female representations\n",
    "    \"\"\"\n",
    "\n",
    "    # customized parameters\n",
    "    nhidden = 3\n",
    "    nlayer = 1\n",
    "\n",
    "    # for males\n",
    "    # initiate the model\n",
    "    male_sda = SDA(male_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    male_sda.train(male_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    male_reps = male_sda.apply(male_seqs)\n",
    "\n",
    "    # for females\n",
    "    # initiate the model\n",
    "    female_sda = SDA(female_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    female_sda.train(female_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    female_reps = female_sda.apply(female_seqs)\n",
    "    return male_reps, female_reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(male_reps, male_labels, female_reps, female_labels, trans_female_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=130)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\", s=130)\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=100)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\", s=100)\n",
    "\n",
    "    ax.scatter(trans_female_reps[female_0,0], trans_female_reps[female_0,1], trans_female_reps[female_0,2], color='green', label=\"trans female 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_female_reps[female_1,0], trans_female_reps[female_1,1], trans_female_reps[female_1,2], color='green', label=\"trans female 1\",  alpha=0.5, marker=\"x\", s=70)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_opp(male_reps, male_labels, female_reps, female_labels, trans_male_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(trans_male_reps[male_0,0], trans_male_reps[male_0,1], trans_male_reps[male_0,2], color='green', label=\"trans male 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_male_reps[male_1,0], trans_male_reps[male_1,1], trans_male_reps[male_1,2], color='green', label=\"trans male 1\",  alpha=0.5, marker=\"x\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.472\n",
      "(*) epoch 2, cost 2.203\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 1.41 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.256\n",
      "(*) epoch 2, cost 4.369\n",
      "(*) epoch 3, cost 3.747\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/ot/bregman.py:492: UserWarning: Warning: numerical errors at iteration 0\n",
      "  warnings.warn('Warning: numerical errors at iteration %d' % ii)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.441\n",
      "(*) epoch 2, cost 3.114\n",
      "(*) epoch 3, cost 2.597\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.013\n",
      "(*) epoch 2, cost 4.613\n",
      "(*) epoch 3, cost 4.136\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "It.  |Loss        |Relative loss|Absolute loss\n",
      "------------------------------------------------\n",
      "    0|2.284276e-01|0.000000e+00|0.000000e+00\n",
      "    1|2.284276e-01|0.000000e+00|0.000000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/ot/bregman.py:492: UserWarning: Warning: numerical errors at iteration 0\n",
      "  warnings.warn('Warning: numerical errors at iteration %d' % ii)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Does not work well\n",
    "\"\"\"\n",
    "\n",
    "male_seqs, male_labels, female_seqs, female_labels = simulate_1(num_patient=50)\n",
    "\n",
    "ot_emds = [ ot.da.SinkhornLpl1Transport(reg_e=0, reg_cl=0), ot.da.SinkhornL1l2Transport(reg_e=0, reg_cl=0, max_iter=20, verbose=True)]\n",
    "titles = [\"Sinkhorn lasso\", \"Sinkhorn l1l2\"]\n",
    "\n",
    "for i in range(len(ot_emds)):\n",
    "    ot_emd = ot_emds[i]\n",
    "    male_reps, female_reps = custom_train_reps(male_seqs, female_seqs)\n",
    "    ot_emd = ot_emds[i]\n",
    "    ot_emd.fit(Xs=male_reps, ys=np.array(male_labels), Xt=female_reps)\n",
    "    trans_male_reps = ot_emd.transform(Xs=male_reps)\n",
    "\n",
    "    plot_scatter_opp(male_reps, male_labels, female_reps, female_labels, trans_male_reps, titles[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling run_proc_multi\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.315\n",
      "(*) epoch 2, cost 4.151\n",
      "(*) epoch 3, cost 3.529\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.019\n",
      "(*) epoch 2, cost 2.458\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.04807981 0.47131956 0.34397994]\n",
      " [0.0612539  0.12113885 0.18488533]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.04807981 0.47131956 0.34397994]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.063215   0.11019377 0.19224491]\n",
      " [0.06346487 0.35156513 0.27804156]\n",
      " [0.063215   0.11019377 0.19224491]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.04992665 0.4739284  0.34439387]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.0612539  0.12113885 0.18488533]\n",
      " [0.0552288  0.48584781 0.35515651]\n",
      " [0.09891555 0.0943214  0.29817373]\n",
      " [0.04807981 0.47131956 0.34397994]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.06146051 0.13429584 0.1858912 ]\n",
      " [0.09891555 0.0943214  0.29817373]\n",
      " [0.05697593 0.09477735 0.18329248]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.0612539  0.12113885 0.18488533]\n",
      " [0.063215   0.11019377 0.19224491]\n",
      " [0.0552288  0.48584781 0.35515651]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.09891555 0.0943214  0.29817373]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.0612539  0.12113885 0.18488533]\n",
      " [0.0612539  0.12113885 0.18488533]\n",
      " [0.0552288  0.48584781 0.35515651]\n",
      " [0.063215   0.11019377 0.19224491]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.063215   0.11019377 0.19224491]\n",
      " [0.0552288  0.48584781 0.35515651]\n",
      " [0.06146051 0.13429584 0.1858912 ]\n",
      " [0.0612539  0.12113885 0.18488533]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.0552288  0.48584781 0.35515651]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05775994 0.46670799 0.34452187]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.05728301 0.47863506 0.35171179]\n",
      " [0.063215   0.11019377 0.19224491]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.247\n",
      "(*) epoch 2, cost 1.957\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.634\n",
      "(*) epoch 2, cost 2.898\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.63740962 0.22525346 0.03896561]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.60170972 0.16614129 0.03141874]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.5942312  0.15338757 0.03121067]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.82746066 0.21870627 0.06534565]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.60170972 0.16614129 0.03141874]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.63949852 0.18902468 0.03179265]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.81494979 0.22751547 0.04260593]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63949852 0.18902468 0.03179265]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.5942312  0.15338757 0.03121067]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.73714326 0.24000524 0.03809733]\n",
      " [0.5942312  0.15338757 0.03121067]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.8012461  0.23247975 0.05443749]\n",
      " [0.63740962 0.22525346 0.03896561]\n",
      " [0.63740962 0.22525346 0.03896561]]\n",
      "female_labels are: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.550\n",
      "(*) epoch 2, cost 2.936\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.239\n",
      "(*) epoch 2, cost 1.584\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.11168357 0.05516876 0.08512408]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.0616977  0.06311256 0.13916671]\n",
      " [0.0616977  0.06311256 0.13916671]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.11168357 0.05516876 0.08512408]\n",
      " [0.11168357 0.05516876 0.08512408]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.11168357 0.05516876 0.08512408]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.11168357 0.05516876 0.08512408]\n",
      " [0.0616977  0.06311256 0.13916671]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.09594316 0.12401013 0.24508892]\n",
      " [0.11168357 0.05516876 0.08512408]\n",
      " [0.0616977  0.06311256 0.13916671]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.683\n",
      "(*) epoch 2, cost 3.171\n",
      "(*) epoch 3, cost 2.504\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.465\n",
      "(*) epoch 2, cost 2.571\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.24027132 0.94252305 0.14524036]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.24027132 0.94252305 0.14524036]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.23152331 0.94839063 0.16959274]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.24027132 0.94252305 0.14524036]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.24027132 0.94252305 0.14524036]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.23152331 0.94839063 0.16959274]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.22518101 0.95808115 0.14451365]\n",
      " [0.24992865 0.93005228 0.16242078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.32338505 0.80647758 0.50173078]\n",
      " [0.24027132 0.94252305 0.14524036]\n",
      " [0.22518101 0.95808115 0.14451365]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0\n",
      " 1 1 0 0 0 0 1 1 1 0 0 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0\n",
      " 1 1 0 0 0 0 1 1 1 0 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.631\n",
      "(*) epoch 2, cost 2.645\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.366\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.02948324 0.78067266 0.15150241]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.57975762 0.5423937  0.08170272]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.57975762 0.5423937  0.08170272]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.44609266 0.61474794 0.09983602]\n",
      " [0.02948324 0.78067266 0.15150241]\n",
      " [0.02948324 0.78067266 0.15150241]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.486\n",
      "(*) epoch 2, cost 3.003\n",
      "(*) epoch 3, cost 2.515\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.788\n",
      "(*) epoch 2, cost 1.375\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.49534702 0.07540163 0.95459295]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.49534702 0.07540163 0.95459295]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.49101209 0.08302064 0.95662944]\n",
      " [0.49534702 0.07540163 0.95459295]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.49534702 0.07540163 0.95459295]\n",
      " [0.49177524 0.07844335 0.95622871]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.49177524 0.07844335 0.95622871]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.49101209 0.08302064 0.95662944]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.49177524 0.07844335 0.95622871]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.49177524 0.07844335 0.95622871]\n",
      " [0.49534702 0.07540163 0.95459295]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.37215123 0.15126418 0.95684511]\n",
      " [0.49177524 0.07844335 0.95622871]\n",
      " [0.49177524 0.07844335 0.95622871]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.49101209 0.08302064 0.95662944]\n",
      " [0.18486606 0.45048247 0.95462282]\n",
      " [0.18486606 0.45048247 0.95462282]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1\n",
      " 1 0 1 1 1 0 0 0 0 0 1 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.201\n",
      "(*) epoch 2, cost 1.519\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.409\n",
      "(*) epoch 2, cost 1.909\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.87001873 0.15266891 0.38104278]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.76359799 0.10195923 0.69081674]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87024302 0.15250941 0.38051659]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.86610261 0.60590351 0.23024561]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.86566416 0.62010629 0.22490633]\n",
      " [0.86884742 0.15223887 0.38422086]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.87001873 0.15266891 0.38104278]\n",
      " [0.87185163 0.56176351 0.23238578]\n",
      " [0.86884742 0.15223887 0.38422086]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
      "trans_female_pred_labels are: [1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.482\n",
      "(*) epoch 2, cost 4.396\n",
      "(*) epoch 3, cost 3.670\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 1\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.005\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]\n",
      " [0.72445793 0.53284121 0.16677976]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.948\n",
      "(*) epoch 2, cost 1.466\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.172\n",
      "(*) epoch 2, cost 1.928\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.32196886 0.50036415 0.52708257]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.30579463 0.48014782 0.55222666]\n",
      " [0.32196886 0.50036415 0.52708257]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.27364459 0.46625954 0.57635053]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.04014631 0.11411045 0.96905907]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.0391754  0.11109486 0.97126197]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.14002329 0.26543124 0.80933262]\n",
      " [0.23861238 0.42196195 0.63156394]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.04014631 0.11411045 0.96905907]\n",
      " [0.16481423 0.25449373 0.80732765]\n",
      " [0.03868714 0.11029306 0.9719753 ]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]\n",
      " [0.20118571 0.34653789 0.71445822]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.531\n",
      "(*) epoch 2, cost 2.958\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.460\n",
      "(*) epoch 2, cost 3.583\n",
      "(*) epoch 3, cost 2.877\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.05656362 0.49103239 0.07409345]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.07498707 0.77151161 0.04332848]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.07498707 0.77151161 0.04332848]\n",
      " [0.07498707 0.77151161 0.04332848]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.07476457 0.92169843 0.04363377]\n",
      " [0.07498707 0.77151161 0.04332848]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.12536151 0.61583895 0.05862411]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05423555 0.49278116 0.07334216]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16518675 0.81010703 0.04074479]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.12536151 0.61583895 0.05862411]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.05423555 0.49278116 0.07334216]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05147798 0.50330095 0.07018175]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05423555 0.49278116 0.07334216]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16518675 0.81010703 0.04074479]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.16910346 0.70059839 0.04960416]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.05656362 0.49103239 0.07409345]\n",
      " [0.05656362 0.49103239 0.07409345]]\n",
      "female_labels are: [1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.373\n",
      "(*) epoch 2, cost 2.090\n",
      "(*) epoch 3, cost 1.708\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.398\n",
      "(*) epoch 2, cost 3.440\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.09155326 0.94134735 0.98632312]\n",
      " [0.29822631 0.91670491 0.96379804]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.26194117 0.91713759 0.96618779]\n",
      " [0.29340322 0.93608322 0.99030146]\n",
      " [0.09217441 0.94087465 0.98572634]\n",
      " [0.14937107 0.91509121 0.9569354 ]\n",
      " [0.08210566 0.94329035 0.98895206]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.26194117 0.91713759 0.96618779]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.26194117 0.91713759 0.96618779]\n",
      " [0.09611251 0.9334674  0.97618649]\n",
      " [0.09611251 0.9334674  0.97618649]\n",
      " [0.26194117 0.91713759 0.96618779]\n",
      " [0.09611251 0.9334674  0.97618649]\n",
      " [0.14937107 0.91509121 0.9569354 ]\n",
      " [0.29822631 0.91670491 0.96379804]\n",
      " [0.08657591 0.94315492 0.98924152]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.08769182 0.94291405 0.98806878]\n",
      " [0.29340322 0.93608322 0.99030146]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.08405278 0.94322407 0.98890939]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.26194117 0.91713759 0.96618779]\n",
      " [0.08405278 0.94322407 0.98890939]\n",
      " [0.29340322 0.93608322 0.99030146]\n",
      " [0.08210566 0.94329035 0.98895206]\n",
      " [0.29822631 0.91670491 0.96379804]\n",
      " [0.08405278 0.94322407 0.98890939]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.08405278 0.94322407 0.98890939]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.26194117 0.91713759 0.96618779]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.14937107 0.91509121 0.9569354 ]\n",
      " [0.08225083 0.9432822  0.98893045]\n",
      " [0.26194117 0.91713759 0.96618779]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.1995581  0.92919959 0.98034082]\n",
      " [0.29340322 0.93608322 0.99030146]\n",
      " [0.26894719 0.91752746 0.96643576]\n",
      " [0.26894719 0.91752746 0.96643576]\n",
      " [0.09155326 0.94134735 0.98632312]\n",
      " [0.08769182 0.94291405 0.98806878]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.352\n",
      "(*) epoch 2, cost 2.647\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.001\n",
      "(*) epoch 2, cost 3.095\n",
      "(*) epoch 3, cost 2.321\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.31143728 0.14653803 0.9044537 ]\n",
      " [0.31143728 0.14653803 0.9044537 ]\n",
      " [0.25224546 0.13008735 0.91485418]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.31143728 0.14653803 0.9044537 ]\n",
      " [0.29623438 0.18718161 0.87931889]\n",
      " [0.29623438 0.18718161 0.87931889]\n",
      " [0.29487543 0.14133    0.90986014]\n",
      " [0.29623438 0.18718161 0.87931889]\n",
      " [0.22867434 0.10496834 0.93153853]\n",
      " [0.31143728 0.14653803 0.9044537 ]\n",
      " [0.16384268 0.09375    0.91742722]\n",
      " [0.28134263 0.18144564 0.88333477]\n",
      " [0.31143728 0.14653803 0.9044537 ]\n",
      " [0.27974673 0.18604843 0.88091696]\n",
      " [0.3043544  0.17018282 0.88828751]\n",
      " [0.3471451  0.15978766 0.88617057]\n",
      " [0.27974673 0.18604843 0.88091696]\n",
      " [0.27974673 0.18604843 0.88091696]\n",
      " [0.29988373 0.1801572  0.88281874]\n",
      " [0.16150275 0.09028299 0.92002012]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.28215771 0.17896886 0.88467802]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.15545214 0.093322   0.91485647]\n",
      " [0.29988373 0.1801572  0.88281874]\n",
      " [0.31143728 0.14653803 0.9044537 ]\n",
      " [0.29487543 0.14133    0.90986014]\n",
      " [0.27974673 0.18604843 0.88091696]\n",
      " [0.3471451  0.15978766 0.88617057]\n",
      " [0.29988373 0.1801572  0.88281874]\n",
      " [0.27974673 0.18604843 0.88091696]\n",
      " [0.29623438 0.18718161 0.87931889]\n",
      " [0.16384268 0.09375    0.91742722]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.29623438 0.18718161 0.87931889]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.3471451  0.15978766 0.88617057]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.16384268 0.09375    0.91742722]\n",
      " [0.28215771 0.17896886 0.88467802]\n",
      " [0.27974673 0.18604843 0.88091696]\n",
      " [0.15498355 0.09368169 0.91403334]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.31143728 0.14653803 0.9044537 ]\n",
      " [0.28646481 0.16559082 0.89249348]\n",
      " [0.15545214 0.093322   0.91485647]\n",
      " [0.28646481 0.16559082 0.89249348]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "female_pred_labels are: [1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.532\n",
      "(*) epoch 2, cost 2.210\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.949\n",
      "(*) epoch 2, cost 1.607\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.06959661 0.07599033 0.66202926]\n",
      " [0.98772317 0.30964429 0.07420286]\n",
      " [0.51043039 0.16451717 0.46051883]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.48781158 0.16179577 0.4653529 ]\n",
      " [0.92059672 0.28813735 0.12251595]\n",
      " [0.98772317 0.30964429 0.07420286]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.98772317 0.30964429 0.07420286]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.48781158 0.16179577 0.4653529 ]\n",
      " [0.9957693  0.31412279 0.06430672]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.98772317 0.30964429 0.07420286]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.48781158 0.16179577 0.4653529 ]\n",
      " [0.48781158 0.16179577 0.4653529 ]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.98772317 0.30964429 0.07420286]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.90483685 0.2870278  0.08678759]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.99857647 0.31595678 0.06178389]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.06959661 0.07599033 0.66202926]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.5661919  0.17694444 0.42902505]\n",
      " [0.06959661 0.07599033 0.66202926]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.573\n",
      "(*) epoch 2, cost 1.862\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.317\n",
      "(*) epoch 2, cost 3.231\n",
      "(*) epoch 3, cost 2.830\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.43461571 0.03223744 0.36505823]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.163707   0.04371751 0.6710422 ]\n",
      " [0.69963684 0.08254195 0.10951326]\n",
      " [0.51762522 0.03564032 0.27643707]\n",
      " [0.163707   0.04371751 0.6710422 ]\n",
      " [0.163707   0.04371751 0.6710422 ]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.23717647 0.05985967 0.60130504]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.71409304 0.04489265 0.06745311]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.163707   0.04371751 0.6710422 ]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.69963684 0.08254195 0.10951326]\n",
      " [0.71047883 0.0431139  0.06992823]\n",
      " [0.71063099 0.04141849 0.06853488]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.7178538  0.04286537 0.06217161]\n",
      " [0.71024056 0.03898686 0.0673422 ]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.7102064  0.03611929 0.06490157]\n",
      " [0.77629807 0.13015015 0.05667415]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.11556755 0.03235405 0.71662916]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.163707   0.04371751 0.6710422 ]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.71063099 0.04141849 0.06853488]\n",
      " [0.55968508 0.03584107 0.23026021]\n",
      " [0.163707   0.04371751 0.6710422 ]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.43461571 0.03223744 0.36505823]\n",
      " [0.71409304 0.04489265 0.06745311]\n",
      " [0.11580721 0.03212112 0.71620812]\n",
      " [0.47289176 0.03397685 0.32435495]\n",
      " [0.7024405  0.03499469 0.07249751]\n",
      " [0.7238878  0.04821524 0.06006611]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.099\n",
      "(*) epoch 2, cost 2.689\n",
      "(*) epoch 3, cost 2.096\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.794\n",
      "(*) epoch 2, cost 3.639\n",
      "(*) epoch 3, cost 3.028\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.06077865 0.40518656 0.85176353]\n",
      " [0.05453635 0.50855903 0.81819073]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.07389396 0.11494004 0.94704514]\n",
      " [0.06629993 0.13947943 0.94414156]\n",
      " [0.11475347 0.07663978 0.93661175]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.07620249 0.11311792 0.94619503]\n",
      " [0.12909515 0.0756081  0.93288588]\n",
      " [0.11811071 0.06943519 0.93574229]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.11605357 0.07118752 0.93626391]\n",
      " [0.06077865 0.40518656 0.85176353]\n",
      " [0.06629993 0.13947943 0.94414156]\n",
      " [0.05453635 0.50855903 0.81819073]\n",
      " [0.06239802 0.20346603 0.92567914]\n",
      " [0.11934145 0.06649862 0.93507471]\n",
      " [0.11605357 0.07118752 0.93626391]\n",
      " [0.06239802 0.20346603 0.92567914]\n",
      " [0.10967409 0.07700163 0.93791605]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.07389396 0.11494004 0.94704514]\n",
      " [0.12909515 0.0756081  0.93288588]\n",
      " [0.06629993 0.13947943 0.94414156]\n",
      " [0.11365564 0.07288188 0.93697518]\n",
      " [0.11468011 0.07214989 0.93663917]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.06239802 0.20346603 0.92567914]\n",
      " [0.07473682 0.46471421 0.82169241]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.12909515 0.0756081  0.93288588]\n",
      " [0.11468011 0.07214989 0.93663917]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.06239802 0.20346603 0.92567914]\n",
      " [0.12909515 0.0756081  0.93288588]\n",
      " [0.11468011 0.07214989 0.93663917]\n",
      " [0.41453381 0.03727399 0.88571118]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.06077865 0.40518656 0.85176353]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.07389396 0.11494004 0.94704514]\n",
      " [0.06629993 0.13947943 0.94414156]\n",
      " [0.06239802 0.20346603 0.92567914]\n",
      " [0.07473682 0.46471421 0.82169241]\n",
      " [0.11605357 0.07118752 0.93626391]\n",
      " [0.05157541 0.49791591 0.82506586]\n",
      " [0.06524402 0.25812183 0.90441746]\n",
      " [0.11475347 0.07663978 0.93661175]\n",
      " [0.06239802 0.20346603 0.92567914]\n",
      " [0.06838322 0.14244289 0.94182054]]\n",
      "female_labels are: [0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 1 0 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.405\n",
      "(*) epoch 2, cost 3.713\n",
      "(*) epoch 3, cost 3.103\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.101\n",
      "(*) epoch 2, cost 1.551\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.04443037 0.16635155 0.10025329]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.07608027 0.09962518 0.15720256]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.06622755 0.75204998 0.24891472]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.06622755 0.75204998 0.24891472]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.06622755 0.75204998 0.24891472]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.04443037 0.16635155 0.10025329]\n",
      " [0.18673958 0.41730065 0.33513291]\n",
      " [0.18673958 0.41730065 0.33513291]]\n",
      "female_labels are: [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1\n",
      " 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1\n",
      " 1 0 1 1 0 0 1 1 1 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.173\n",
      "(*) epoch 2, cost 2.585\n",
      "(*) epoch 3, cost 2.201\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.763\n",
      "(*) epoch 2, cost 3.070\n",
      "(*) epoch 3, cost 2.290\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.66545841 0.50681195 0.86184946]\n",
      " [0.53113608 0.34695045 0.92300344]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.67803057 0.43093352 0.48594178]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.53113608 0.34695045 0.92300344]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.54707469 0.352768   0.91926963]\n",
      " [0.54707469 0.352768   0.91926963]\n",
      " [0.53113608 0.34695045 0.92300344]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66545841 0.50681195 0.86184946]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.53113608 0.34695045 0.92300344]\n",
      " [0.66545841 0.50681195 0.86184946]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.53113608 0.34695045 0.92300344]\n",
      " [0.6539235  0.48564128 0.87151405]\n",
      " [0.66980701 0.45467607 0.51989556]\n",
      " [0.53113608 0.34695045 0.92300344]\n",
      " [0.6539235  0.48564128 0.87151405]]\n",
      "female_labels are: [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.223\n",
      "(*) epoch 2, cost 2.735\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.624\n",
      "(*) epoch 2, cost 2.223\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.4646311  0.88076572 0.11872716]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.4646311  0.88076572 0.11872716]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.71460939 0.78278882 0.18325175]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.65912723 0.89261026 0.08432603]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.32186156 0.34599569 0.1049975 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.44111853 0.86571763 0.12831761]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]\n",
      " [0.79515939 0.75332008 0.0527875 ]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.296\n",
      "(*) epoch 2, cost 2.354\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.981\n",
      "(*) epoch 2, cost 2.519\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.45786564 0.44267333 0.18639301]\n",
      " [0.09863867 0.24660604 0.22287545]\n",
      " [0.04490545 0.0843262  0.62816891]\n",
      " [0.04490545 0.0843262  0.62816891]\n",
      " [0.17612902 0.28829354 0.21305039]\n",
      " [0.17612902 0.28829354 0.21305039]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.04781852 0.11367143 0.5468235 ]\n",
      " [0.06325005 0.18369024 0.3657097 ]\n",
      " [0.09863867 0.24660604 0.22287545]\n",
      " [0.04490545 0.0843262  0.62816891]\n",
      " [0.09458773 0.18096703 0.41836493]\n",
      " [0.04781852 0.11367143 0.5468235 ]\n",
      " [0.04490545 0.0843262  0.62816891]\n",
      " [0.05199664 0.10201026 0.58686327]\n",
      " [0.06967525 0.20798007 0.30343438]\n",
      " [0.04770073 0.11241456 0.55083226]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.05199664 0.10201026 0.58686327]\n",
      " [0.0358313  0.05831047 0.6907813 ]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.16775047 0.28392986 0.21264025]\n",
      " [0.04490545 0.0843262  0.62816891]\n",
      " [0.09863867 0.24660604 0.22287545]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.16775047 0.28392986 0.21264025]\n",
      " [0.34651937 0.38128364 0.19603135]\n",
      " [0.04490545 0.0843262  0.62816891]\n",
      " [0.17612902 0.28829354 0.21305039]\n",
      " [0.0358313  0.05831047 0.6907813 ]\n",
      " [0.09863867 0.24660604 0.22287545]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.09863867 0.24660604 0.22287545]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.09863867 0.24660604 0.22287545]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.36127241 0.38867504 0.18623279]\n",
      " [0.06325005 0.18369024 0.3657097 ]\n",
      " [0.45786564 0.44267333 0.18639301]\n",
      " [0.0358313  0.05831047 0.6907813 ]\n",
      " [0.34651937 0.38128364 0.19603135]\n",
      " [0.45786564 0.44267333 0.18639301]]\n",
      "female_labels are: [0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "female_pred_labels are: [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.288\n",
      "(*) epoch 2, cost 2.099\n",
      "(*) epoch 3, cost 1.513\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.293\n",
      "(*) epoch 2, cost 4.715\n",
      "(*) epoch 3, cost 3.222\n",
      "(*) epoch 4, cost 2.721\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.64108303 0.61525233 0.22561206]\n",
      " [0.32403707 0.74028695 0.28895908]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.62775924 0.62093547 0.22581804]\n",
      " [0.30277179 0.74638409 0.2981546 ]\n",
      " [0.71166539 0.57415307 0.15734691]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.71166539 0.57415307 0.15734691]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.4455375  0.6765388  0.25959957]\n",
      " [0.62775924 0.62093547 0.22581804]\n",
      " [0.71166539 0.57415307 0.15734691]\n",
      " [0.71166539 0.57415307 0.15734691]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.42305123 0.73209137 0.65811581]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.30110784 0.74728201 0.29841345]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.71166539 0.57415307 0.15734691]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.42305123 0.73209137 0.65811581]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.64108303 0.61525233 0.22561206]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.35543595 0.72789614 0.27947831]\n",
      " [0.71166539 0.57415307 0.15734691]\n",
      " [0.35543595 0.72789614 0.27947831]]\n",
      "female_labels are: [1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0\n",
      " 1 1 1 1 0 0 1 1 0 1 1 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.427\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.793\n",
      "(*) epoch 2, cost 2.200\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98771648 0.19062089 0.98022152]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.46323161 0.33223214 0.39176708]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.83016    0.23316124 0.80344843]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.98688025 0.19084668 0.9792833 ]\n",
      " [0.970081   0.19538248 0.9604351 ]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.176\n",
      "(*) epoch 2, cost 2.106\n",
      "(*) epoch 3, cost 1.800\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.068\n",
      "(*) epoch 2, cost 3.443\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.42409912 0.67352206 0.29275717]\n",
      " [0.32598068 0.67273628 0.35105695]\n",
      " [0.32598068 0.67273628 0.35105695]\n",
      " [0.28265891 0.70826259 0.28668127]\n",
      " [0.30490028 0.58047541 0.5217367 ]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.28265891 0.70826259 0.28668127]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.30490028 0.58047541 0.5217367 ]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.36190636 0.56447682 0.52200779]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.30490028 0.58047541 0.5217367 ]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.32598068 0.67273628 0.35105695]\n",
      " [0.32598068 0.67273628 0.35105695]\n",
      " [0.28265891 0.70826259 0.28668127]\n",
      " [0.30490028 0.58047541 0.5217367 ]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.32598068 0.67273628 0.35105695]\n",
      " [0.30490028 0.58047541 0.5217367 ]\n",
      " [0.29620232 0.56121861 0.55695634]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.29023662 0.68980949 0.32005171]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.30490028 0.58047541 0.5217367 ]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.30490028 0.58047541 0.5217367 ]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.42409912 0.67352206 0.29275717]\n",
      " [0.53604551 0.61320987 0.29594311]\n",
      " [0.42409912 0.67352206 0.29275717]]\n",
      "female_labels are: [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n",
      "female_pred_labels are: [1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0\n",
      " 1 0 1 1 1 1 0 1 0 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.848\n",
      "(*) epoch 2, cost 2.617\n",
      "(*) epoch 3, cost 2.507\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.039\n",
      "(*) epoch 2, cost 4.401\n",
      "(*) epoch 3, cost 2.982\n",
      "(*) epoch 4, cost 2.612\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.87202384 0.12488409 0.68720207]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.95196485 0.63612774 0.17417284]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.85485526 0.19343795 0.64973235]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.95196485 0.63612774 0.17417284]\n",
      " [0.94841439 0.29128872 0.45967493]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.95196485 0.63612774 0.17417284]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.81591    0.16383677 0.71524665]\n",
      " [0.96073976 0.60190274 0.22823466]\n",
      " [0.95196485 0.63612774 0.17417284]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 0 1 1 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.232\n",
      "(*) epoch 2, cost 4.569\n",
      "(*) epoch 3, cost 3.220\n",
      "(*) epoch 4, cost 2.879\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.061\n",
      "(*) epoch 2, cost 1.991\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.43060124 0.93806883 0.06334766]\n",
      " [0.37587212 0.79456794 0.09704323]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.37587212 0.79456794 0.09704323]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.32963279 0.54698146 0.09952979]\n",
      " [0.37587212 0.79456794 0.09704323]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.32963279 0.54698146 0.09952979]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.37587212 0.79456794 0.09704323]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.37587212 0.79456794 0.09704323]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.37587212 0.79456794 0.09704323]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.32963279 0.54698146 0.09952979]\n",
      " [0.32963279 0.54698146 0.09952979]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.32963279 0.54698146 0.09952979]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.43060124 0.93806883 0.06334766]\n",
      " [0.42282163 0.57949532 0.3597011 ]\n",
      " [0.37587212 0.79456794 0.09704323]\n",
      " [0.42282163 0.57949532 0.3597011 ]]\n",
      "female_labels are: [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.526\n",
      "(*) epoch 2, cost 2.083\n",
      "(*) epoch 3, cost 1.262\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 7.247\n",
      "(*) epoch 2, cost 4.930\n",
      "(*) epoch 3, cost 4.127\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.16862581 0.29339001 0.28379174]\n",
      " [0.1805224  0.27242566 0.26365797]\n",
      " [0.18125365 0.27113704 0.26242041]\n",
      " [0.1802355  0.27293125 0.26414352]\n",
      " [0.18125365 0.27113704 0.26242041]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.18126703 0.27111347 0.26239777]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.1805224  0.27242566 0.26365797]\n",
      " [0.17609609 0.28022577 0.27114905]\n",
      " [0.1628173  0.30362584 0.29362204]\n",
      " [0.18125365 0.27113704 0.26242041]\n",
      " [0.17998684 0.27336943 0.26456435]\n",
      " [0.1802355  0.27293125 0.26414352]\n",
      " [0.17939755 0.2744079  0.26556167]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.1802355  0.27293125 0.26414352]\n",
      " [0.17610441 0.28021111 0.27113497]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.17998684 0.27336943 0.26456435]\n",
      " [0.18125365 0.27113704 0.26242041]\n",
      " [0.17610441 0.28021111 0.27113497]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.1628173  0.30362584 0.29362204]\n",
      " [0.17998684 0.27336943 0.26456435]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.17998684 0.27336943 0.26456435]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.17884072 0.27538914 0.26650404]\n",
      " [0.17290999 0.28584035 0.27654119]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.1805224  0.27242566 0.26365797]\n",
      " [0.17426294 0.28345616 0.27425146]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.17290999 0.28584035 0.27654119]\n",
      " [0.1805224  0.27242566 0.26365797]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.18277438 0.26845719 0.25984672]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.18126703 0.27111347 0.26239777]\n",
      " [0.17998684 0.27336943 0.26456435]\n",
      " [0.1628173  0.30362584 0.29362204]\n",
      " [0.16862581 0.29339001 0.28379174]\n",
      " [0.17290999 0.28584035 0.27654119]\n",
      " [0.1628173  0.30362584 0.29362204]\n",
      " [0.18125365 0.27113704 0.26242041]\n",
      " [0.18125365 0.27113704 0.26242041]\n",
      " [0.1802355  0.27293125 0.26414352]\n",
      " [0.18125365 0.27113704 0.26242041]]\n",
      "female_labels are: [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 6.087\n",
      "(*) epoch 2, cost 4.184\n",
      "(*) epoch 3, cost 3.497\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.020\n",
      "(*) epoch 2, cost 0.687\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.3142117  0.71293474 0.7622228 ]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.11334133 0.15078873 0.41176466]\n",
      " [0.42358281 0.20643725 0.31382935]]\n",
      "female_labels are: [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1]\n",
      "female_pred_labels are: [0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1\n",
      " 1 0 0 0 1 0 0 0 1 0 1 1 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.197\n",
      "(*) epoch 2, cost 1.963\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.882\n",
      "(*) epoch 2, cost 2.590\n",
      "(*) epoch 3, cost 2.149\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.1768212  0.68330042 0.54214076]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.0642969  0.11053949 0.97270454]\n",
      " [0.21350105 0.60298272 0.66188743]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.2280073  0.64875519 0.60423215]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21350105 0.60298272 0.66188743]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.21350105 0.60298272 0.66188743]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.2280073  0.64875519 0.60423215]\n",
      " [0.1768212  0.68330042 0.54214076]\n",
      " [0.16321695 0.96019174 0.41337159]\n",
      " [0.0927951  0.34163557 0.79135037]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.09213085 0.32902672 0.80140092]\n",
      " [0.17095    0.91358335 0.41786588]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.17095    0.91358335 0.41786588]\n",
      " [0.10843345 0.48984834 0.68892242]\n",
      " [0.06449463 0.11096531 0.97268815]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.21484981 0.59196058 0.67140662]\n",
      " [0.1768212  0.68330042 0.54214076]\n",
      " [0.1768212  0.68330042 0.54214076]]\n",
      "female_labels are: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.438\n",
      "(*) epoch 2, cost 2.117\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.137\n",
      "(*) epoch 2, cost 2.912\n",
      "(*) epoch 3, cost 2.410\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.75777111 0.56379627 0.24503968]\n",
      " [0.72775048 0.75186098 0.11457032]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.60027609 0.63385246 0.58484418]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.72775048 0.75186098 0.11457032]\n",
      " [0.87577552 0.20236082 0.18953067]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.76741307 0.52689394 0.23901806]\n",
      " [0.60027609 0.63385246 0.58484418]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.83895529 0.35616299 0.28702631]\n",
      " [0.72738779 0.75414556 0.11193115]\n",
      " [0.87577552 0.20236082 0.18953067]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.60027609 0.63385246 0.58484418]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.87577552 0.20236082 0.18953067]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.87577552 0.20236082 0.18953067]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.87577552 0.20236082 0.18953067]\n",
      " [0.72775048 0.75186098 0.11457032]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.72738779 0.75414556 0.11193115]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.80181499 0.14786664 0.17807767]\n",
      " [0.68957059 0.51197341 0.4794933 ]\n",
      " [0.60027609 0.63385246 0.58484418]\n",
      " [0.75777111 0.56379627 0.24503968]\n",
      " [0.87577552 0.20236082 0.18953067]\n",
      " [0.87577552 0.20236082 0.18953067]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "female_pred_labels are: [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.546\n",
      "(*) epoch 2, cost 1.854\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.727\n",
      "(*) epoch 2, cost 1.995\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.73411935 0.67184211 0.50587413]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.73411935 0.67184211 0.50587413]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.92375397 0.61764428 0.28630104]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.73411935 0.67184211 0.50587413]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.92375397 0.61764428 0.28630104]\n",
      " [0.73411935 0.67184211 0.50587413]\n",
      " [0.79935638 0.78914737 0.05987464]\n",
      " [0.73411935 0.67184211 0.50587413]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.92375397 0.61764428 0.28630104]\n",
      " [0.79935638 0.78914737 0.05987464]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.73411935 0.67184211 0.50587413]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.89064157 0.6032496  0.41118259]\n",
      " [0.65474952 0.75949684 0.90246648]\n",
      " [0.89064157 0.6032496  0.41118259]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 0 0 1 1 1 0 1]\n",
      "trans_female_pred_labels are: [0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 0 1 0 0 1 1 1 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.384\n",
      "(*) epoch 2, cost 1.902\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.636\n",
      "(*) epoch 2, cost 1.346\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.68393961 0.4271535  0.40757094]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.68393961 0.4271535  0.40757094]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.44175502 0.60680792 0.21407958]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.7839614  0.37472303 0.08943272]\n",
      " [0.44175502 0.60680792 0.21407958]]\n",
      "female_labels are: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 1 1 0 0 0 0 0 0 1 1 1 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.007\n",
      "(*) epoch 2, cost 2.456\n",
      "(*) epoch 3, cost 1.855\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.875\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.15058893 0.58889585 0.53088   ]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.04180499 0.20669317 0.06817616]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.04180499 0.20669317 0.06817616]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]\n",
      " [0.08201518 0.68955649 0.28210192]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.243\n",
      "(*) epoch 2, cost 3.672\n",
      "(*) epoch 3, cost 2.898\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.552\n",
      "(*) epoch 2, cost 1.185\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1259394  0.31199521 0.11771859]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1259394  0.31199521 0.11771859]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.11806786 0.40153695 0.19239765]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.1354584  0.48150712 0.21618981]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.13625878 0.27364167 0.07277001]\n",
      " [0.1354584  0.48150712 0.21618981]]\n",
      "female_labels are: [0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "female_pred_labels are: [0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0]\n",
      "trans_female_pred_labels are: [0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 1 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.722\n",
      "(*) epoch 2, cost 2.147\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.228\n",
      "(*) epoch 2, cost 3.695\n",
      "(*) epoch 3, cost 3.149\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.83060222 0.16999715 0.11538782]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.88380304 0.17149273 0.14968055]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.82518561 0.33547239 0.86967475]\n",
      " [0.84137874 0.16969882 0.12377982]\n",
      " [0.88131293 0.17151342 0.14752026]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.84137874 0.16969882 0.12377982]\n",
      " [0.80925779 0.16766412 0.1094716 ]\n",
      " [0.81673084 0.27484366 0.55282816]\n",
      " [0.88131293 0.17151342 0.14752026]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.88131293 0.17151342 0.14752026]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.82518561 0.33547239 0.86967475]\n",
      " [0.34822291 0.16643436 0.04165901]\n",
      " [0.80900634 0.30212311 0.72543489]\n",
      " [0.88131293 0.17151342 0.14752026]\n",
      " [0.34822291 0.16643436 0.04165901]\n",
      " [0.86853475 0.17152291 0.13739577]\n",
      " [0.82553231 0.33629704 0.87389075]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.88380304 0.17149273 0.14968055]\n",
      " [0.85012494 0.17054281 0.12701327]\n",
      " [0.88664152 0.17784869 0.13773174]\n",
      " [0.88380304 0.17149273 0.14968055]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.88380304 0.17149273 0.14968055]\n",
      " [0.84137874 0.16969882 0.12377982]\n",
      " [0.87698479 0.19844287 0.13828206]\n",
      " [0.87698479 0.19844287 0.13828206]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.39272975 0.17255928 0.05353528]\n",
      " [0.41518334 0.17238094 0.04846238]\n",
      " [0.36071717 0.16716811 0.04432457]\n",
      " [0.88380304 0.17149273 0.14968055]\n",
      " [0.80900634 0.30212311 0.72543489]\n",
      " [0.82553231 0.33629704 0.87389075]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.86740747 0.186814   0.13574507]\n",
      " [0.86853475 0.17152291 0.13739577]\n",
      " [0.87698479 0.19844287 0.13828206]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.83060222 0.16999715 0.11538782]\n",
      " [0.85012494 0.17054281 0.12701327]\n",
      " [0.83060222 0.16999715 0.11538782]]\n",
      "female_labels are: [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 0 1]\n",
      "trans_female_pred_labels are: [1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
      " 0 0 0 1 1 1 1 0 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.576\n",
      "(*) epoch 2, cost 1.667\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.109\n",
      "(*) epoch 2, cost 3.707\n",
      "(*) epoch 3, cost 3.331\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.90134248 0.76750013 0.12463431]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.76002976 0.58474066 0.35790108]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.55990602 0.2508774  0.72981776]\n",
      " [0.92514671 0.86644675 0.05365561]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.92514671 0.86644675 0.05365561]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.55990602 0.2508774  0.72981776]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.92514671 0.86644675 0.05365561]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.76002976 0.58474066 0.35790108]\n",
      " [0.55990602 0.2508774  0.72981776]\n",
      " [0.55990602 0.2508774  0.72981776]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.8353685  0.20611484 0.51430325]\n",
      " [0.92514671 0.86644675 0.05365561]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.76002976 0.58474066 0.35790108]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.55990602 0.2508774  0.72981776]\n",
      " [0.76002976 0.58474066 0.35790108]\n",
      " [0.92514671 0.86644675 0.05365561]\n",
      " [0.69943858 0.27201713 0.58852667]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.92514671 0.86644675 0.05365561]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.8375223  0.72256993 0.21202785]\n",
      " [0.76002976 0.58474066 0.35790108]\n",
      " [0.76255491 0.31160222 0.50565005]\n",
      " [0.88872906 0.74882815 0.14647509]\n",
      " [0.76255491 0.31160222 0.50565005]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 0 1 1 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.217\n",
      "(*) epoch 2, cost 2.352\n",
      "(*) epoch 3, cost 1.779\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.598\n",
      "(*) epoch 2, cost 1.776\n",
      "(*) epoch 3, cost 1.143\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23482108 0.8215499  0.41524043]\n",
      " [0.21836484 0.82437771 0.38877121]\n",
      " [0.21836484 0.82437771 0.38877121]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23441641 0.80793512 0.3972976 ]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23482108 0.8215499  0.41524043]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23482108 0.8215499  0.41524043]\n",
      " [0.35478062 0.76090843 0.15467642]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23482108 0.8215499  0.41524043]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23482108 0.8215499  0.41524043]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23482108 0.8215499  0.41524043]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.23482108 0.8215499  0.41524043]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]\n",
      " [0.10124195 0.8261601  0.18764191]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.102\n",
      "(*) epoch 2, cost 4.123\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.732\n",
      "(*) epoch 2, cost 1.278\n",
      "(*) epoch 3, cost 0.879\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.1068984  0.17924683 0.3105167 ]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.04867039 0.19406973 0.46497535]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.1068984  0.17924683 0.3105167 ]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.51306081 0.07980917 0.16171118]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]\n",
      " [0.28730286 0.34072091 0.23825838]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.109\n",
      "(*) epoch 2, cost 2.918\n",
      "(*) epoch 3, cost 2.108\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.964\n",
      "(*) epoch 2, cost 1.430\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.82863469 0.88390044 0.74936848]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84873104 0.89854625 0.70153984]\n",
      " [0.82605157 0.88224307 0.76206949]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.82863469 0.88390044 0.74936848]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]\n",
      " [0.84729231 0.50201776 0.71839625]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 6.139\n",
      "(*) epoch 2, cost 3.383\n",
      "(*) epoch 3, cost 1.523\n",
      "(*) epoch 4, cost 0.904\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.837\n",
      "(*) epoch 2, cost 1.220\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.83871882 0.20780945 0.47992572]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]\n",
      " [0.84279187 0.19460121 0.46763706]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.8712347  0.22668848 0.55839841]\n",
      " [0.86666061 0.24985989 0.58404171]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.331\n",
      "(*) epoch 2, cost 3.606\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.831\n",
      "(*) epoch 2, cost 1.426\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.24250089 0.25255104 0.14951335]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.5559905  0.73637582 0.0310012 ]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.5559905  0.73637582 0.0310012 ]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.5559905  0.73637582 0.0310012 ]\n",
      " [0.24349742 0.28633583 0.12132631]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.5559905  0.73637582 0.0310012 ]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24349742 0.28633583 0.12132631]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.5559905  0.73637582 0.0310012 ]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.26437461 0.32825637 0.11888131]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24872587 0.26240099 0.14359932]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.5559905  0.73637582 0.0310012 ]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.30796083 0.55826851 0.05791567]\n",
      " [0.24250089 0.25255104 0.14951335]\n",
      " [0.30796083 0.55826851 0.05791567]]\n",
      "female_labels are: [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.572\n",
      "(*) epoch 2, cost 2.790\n",
      "(*) epoch 3, cost 2.263\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.079\n",
      "(*) epoch 2, cost 1.174\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.11964305 0.60476496 0.11089515]\n",
      " [0.03876774 0.3782112  0.07028571]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.03876774 0.3782112  0.07028571]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.1430118  0.65342239 0.1124109 ]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.107535   0.60793174 0.09744044]\n",
      " [0.03853555 0.47554441 0.0744335 ]\n",
      " [0.02656649 0.39981392 0.06932762]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.11964305 0.60476496 0.11089515]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.27974587 0.81570199 0.10274867]\n",
      " [0.02861804 0.36036613 0.06948834]\n",
      " [0.27974587 0.81570199 0.10274867]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.120\n",
      "(*) epoch 2, cost 1.766\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.574\n",
      "(*) epoch 2, cost 2.085\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.7196307  0.64759849 0.3059826 ]\n",
      " [0.72600201 0.64978124 0.30518863]\n",
      " [0.93747589 0.77553896 0.15142446]\n",
      " [0.71382369 0.64310681 0.31229013]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.93747589 0.77553896 0.15142446]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.98568001 0.76258425 0.21169338]\n",
      " [0.98568001 0.76258425 0.21169338]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.98568001 0.76258425 0.21169338]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.93747589 0.77553896 0.15142446]\n",
      " [0.76775395 0.54226889 0.60328472]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.93747589 0.77553896 0.15142446]\n",
      " [0.98568001 0.76258425 0.21169338]\n",
      " [0.93747589 0.77553896 0.15142446]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.98568001 0.76258425 0.21169338]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.29444695 0.4320271  0.53630567]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.76775395 0.54226889 0.60328472]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.98209392 0.72178385 0.31413508]\n",
      " [0.93747589 0.77553896 0.15142446]\n",
      " [0.76775395 0.54226889 0.60328472]\n",
      " [0.98568001 0.76258425 0.21169338]\n",
      " [0.7196307  0.64759849 0.3059826 ]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.7196307  0.64759849 0.3059826 ]\n",
      " [0.80686456 0.51470865 0.69868553]\n",
      " [0.76775395 0.54226889 0.60328472]\n",
      " [0.93747589 0.77553896 0.15142446]\n",
      " [0.85409376 0.70927813 0.24833167]\n",
      " [0.80686456 0.51470865 0.69868553]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0\n",
      " 1 1 0 1 1 0 0 1 0 0 1 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.370\n",
      "(*) epoch 2, cost 2.035\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.205\n",
      "(*) epoch 2, cost 2.380\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.24397297 0.06062997 0.0154344 ]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.24397297 0.06062997 0.0154344 ]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.86846978 0.20100089 0.06385625]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.86846978 0.20100089 0.06385625]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.86846978 0.20100089 0.06385625]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]\n",
      " [0.37780296 0.08654659 0.02456883]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.618\n",
      "(*) epoch 2, cost 1.999\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.087\n",
      "(*) epoch 2, cost 2.594\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.57859666 0.04570933 0.64326937]\n",
      " [0.57180187 0.04240728 0.68941344]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.15556045 0.37345163 0.1703418 ]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.57180187 0.04240728 0.68941344]\n",
      " [0.58497328 0.04957915 0.6391435 ]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.21294827 0.28206579 0.24469561]\n",
      " [0.15556045 0.37345163 0.1703418 ]\n",
      " [0.57150247 0.04259451 0.69716291]\n",
      " [0.58108707 0.04650324 0.63745548]\n",
      " [0.57438603 0.04336627 0.68998811]\n",
      " [0.57150247 0.04259451 0.69716291]\n",
      " [0.57438603 0.04336627 0.68998811]\n",
      " [0.33133986 0.0445795  0.45517022]\n",
      " [0.57438603 0.04336627 0.68998811]\n",
      " [0.58497328 0.04957915 0.6391435 ]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.57150247 0.04259451 0.69716291]\n",
      " [0.58497328 0.04957915 0.6391435 ]\n",
      " [0.57438603 0.04336627 0.68998811]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.57150247 0.04259451 0.69716291]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.58497328 0.04957915 0.6391435 ]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.58497328 0.04957915 0.6391435 ]\n",
      " [0.57180187 0.04240728 0.68941344]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.40309695 0.06039892 0.57146606]\n",
      " [0.40309695 0.06039892 0.57146606]\n",
      " [0.58497328 0.04957915 0.6391435 ]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.40309695 0.06039892 0.57146606]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.58108707 0.04650324 0.63745548]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.34694933 0.03971901 0.47867968]\n",
      " [0.37981549 0.06129458 0.36048724]\n",
      " [0.11041589 0.57321855 0.06029549]\n",
      " [0.57438603 0.04336627 0.68998811]\n",
      " [0.58108707 0.04650324 0.63745548]\n",
      " [0.57150247 0.04259451 0.69716291]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.58412748 0.0446147  0.66975097]\n",
      " [0.58108707 0.04650324 0.63745548]\n",
      " [0.37981549 0.06129458 0.36048724]]\n",
      "female_labels are: [1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.795\n",
      "(*) epoch 2, cost 2.329\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.832\n",
      "(*) epoch 2, cost 2.915\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.49123583 0.33266575 0.14711127]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.2622165  0.15971629 0.18806039]\n",
      " [0.49123583 0.33266575 0.14711127]\n",
      " [0.49123583 0.33266575 0.14711127]\n",
      " [0.20161974 0.04977447 0.0789304 ]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.18216428 0.11943372 0.29339608]\n",
      " [0.20161974 0.04977447 0.0789304 ]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.26369113 0.16379311 0.20146826]\n",
      " [0.30066055 0.17538164 0.13322443]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.26369113 0.16379311 0.20146826]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.14801766 0.10492534 0.36166802]\n",
      " [0.49123583 0.33266575 0.14711127]\n",
      " [0.20161974 0.04977447 0.0789304 ]\n",
      " [0.48792845 0.32893096 0.14621355]\n",
      " [0.11922472 0.08924265 0.40282327]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.48792845 0.32893096 0.14621355]\n",
      " [0.49086279 0.33289168 0.14750845]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.49123583 0.33266575 0.14711127]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.26369113 0.16379311 0.20146826]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.11922472 0.08924265 0.40282327]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.20161974 0.04977447 0.0789304 ]\n",
      " [0.49123583 0.33266575 0.14711127]\n",
      " [0.26369113 0.16379311 0.20146826]\n",
      " [0.20161974 0.04977447 0.0789304 ]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.07750355 0.0597082  0.4730356 ]\n",
      " [0.26640462 0.14670608 0.12146526]\n",
      " [0.26369113 0.16379311 0.20146826]\n",
      " [0.28567829 0.16264419 0.12768645]\n",
      " [0.20161974 0.04977447 0.0789304 ]\n",
      " [0.1716895  0.12044308 0.34453173]\n",
      " [0.49123583 0.33266575 0.14711127]\n",
      " [0.28567829 0.16264419 0.12768645]]\n",
      "female_labels are: [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "trans_female_pred_labels are: [1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 0 1 1 0 1 1 1 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.540\n",
      "(*) epoch 2, cost 2.653\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.759\n",
      "(*) epoch 2, cost 2.019\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.05418509 0.95812341 0.5415805 ]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.78006706 0.96083281 0.63848558]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.77916029 0.96046004 0.63711184]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.77981246 0.96112299 0.63939247]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.77916029 0.96046004 0.63711184]\n",
      " [0.77981246 0.96112299 0.63939247]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.04306114 0.96307151 0.53723267]\n",
      " [0.77916029 0.96046004 0.63711184]\n",
      " [0.04306114 0.96307151 0.53723267]\n",
      " [0.07110971 0.9495038  0.54819774]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.04306114 0.96307151 0.53723267]\n",
      " [0.77916029 0.96046004 0.63711184]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.78006706 0.96083281 0.63848558]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.07110971 0.9495038  0.54819774]\n",
      " [0.23617178 0.82364052 0.62122059]\n",
      " [0.05418509 0.95812341 0.5415805 ]\n",
      " [0.77916029 0.96046004 0.63711184]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.23617178 0.82364052 0.62122059]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.07110971 0.9495038  0.54819774]\n",
      " [0.78185185 0.96057213 0.63795947]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.77700336 0.96125052 0.6392975 ]\n",
      " [0.77700336 0.96125052 0.6392975 ]]\n",
      "female_labels are: [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.602\n",
      "(*) epoch 2, cost 1.939\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.562\n",
      "(*) epoch 2, cost 2.922\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.25248892 0.45777698 0.59064731]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.15630447 0.32095539 0.71555759]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.15630447 0.32095539 0.71555759]\n",
      " [0.27315169 0.42746355 0.5831315 ]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.02992087 0.74732195 0.68429094]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.06755613 0.54373831 0.73268145]\n",
      " [0.27315169 0.42746355 0.5831315 ]\n",
      " [0.27315169 0.42746355 0.5831315 ]\n",
      " [0.27315169 0.42746355 0.5831315 ]\n",
      " [0.03713231 0.65302212 0.72875666]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.26382988 0.44174853 0.58631744]\n",
      " [0.06026569 0.57316344 0.72879007]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.02927756 0.7471806  0.68502413]\n",
      " [0.05956531 0.55123387 0.72167699]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.25248892 0.45777698 0.59064731]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.06755613 0.54373831 0.73268145]\n",
      " [0.06026569 0.57316344 0.72879007]\n",
      " [0.06755613 0.54373831 0.73268145]\n",
      " [0.26382988 0.44174853 0.58631744]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.27315169 0.42746355 0.5831315 ]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.05956531 0.55123387 0.72167699]\n",
      " [0.26382988 0.44174853 0.58631744]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.4171931  0.26207529 0.51471982]\n",
      " [0.15630447 0.32095539 0.71555759]\n",
      " [0.1631175  0.30108444 0.71527695]\n",
      " [0.06026569 0.57316344 0.72879007]\n",
      " [0.1631175  0.30108444 0.71527695]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1\n",
      " 0 0 1 0 0 1 1 0 1 0 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.820\n",
      "(*) epoch 2, cost 4.285\n",
      "(*) epoch 3, cost 3.329\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.063\n",
      "(*) epoch 2, cost 2.089\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.52280388 0.84930657 0.63876825]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.7526507  0.86760168 0.88219743]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.79291545 0.7997469  0.74440758]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]\n",
      " [0.52280388 0.84930657 0.63876825]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.388\n",
      "(*) epoch 2, cost 2.361\n",
      "(*) epoch 3, cost 2.036\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.644\n",
      "(*) epoch 2, cost 3.201\n",
      "(*) epoch 3, cost 2.698\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.58824885 0.37614772 0.69057691]\n",
      " [0.58595637 0.37468539 0.69466716]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.60864909 0.35461127 0.67902658]\n",
      " [0.44605237 0.52669019 0.51729499]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.56240079 0.39609384 0.71728852]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.60498978 0.36299907 0.67645683]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.58595637 0.37468539 0.69466716]\n",
      " [0.44605237 0.52669019 0.51729499]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.4338372  0.48114674 0.47373641]\n",
      " [0.60864909 0.35461127 0.67902658]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.44318395 0.55686368 0.54024458]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.58529483 0.37639435 0.70196101]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.44818538 0.42983644 0.49615665]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.44605237 0.52669019 0.51729499]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.45011857 0.54192657 0.49108487]\n",
      " [0.60864909 0.35461127 0.67902658]\n",
      " [0.44901928 0.51095452 0.60822355]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.44315004 0.55757218 0.5303857 ]\n",
      " [0.60864909 0.35461127 0.67902658]\n",
      " [0.44605237 0.52669019 0.51729499]\n",
      " [0.58824885 0.37614772 0.69057691]\n",
      " [0.72491887 0.25242862 0.61154403]\n",
      " [0.58824885 0.37614772 0.69057691]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 1 0 1 0 1 0 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.684\n",
      "(*) epoch 2, cost 3.746\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.246\n",
      "(*) epoch 2, cost 1.746\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.00996959 0.9184739  0.75414907]\n",
      " [0.00996959 0.9184739  0.75414907]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.00996959 0.9184739  0.75414907]\n",
      " [0.01238084 0.90548196 0.77267825]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.01238084 0.90548196 0.77267825]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.01238084 0.90548196 0.77267825]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.01238084 0.90548196 0.77267825]\n",
      " [0.01238084 0.90548196 0.77267825]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.00996959 0.9184739  0.75414907]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.04220224 0.66047765 0.09037451]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.00996959 0.9184739  0.75414907]\n",
      " [0.01238084 0.90548196 0.77267825]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]\n",
      " [0.03001052 0.84665236 0.4858469 ]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.404\n",
      "(*) epoch 2, cost 1.611\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.315\n",
      "(*) epoch 2, cost 1.978\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.95916199 0.08368326 0.4735896 ]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.95916199 0.08368326 0.4735896 ]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.53977514 0.76667529 0.65464715]\n",
      " [0.95916199 0.08368326 0.4735896 ]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.5498684  0.73504265 0.59155492]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.53977514 0.76667529 0.65464715]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.95681552 0.08731763 0.47383547]\n",
      " [0.5498684  0.73504265 0.59155492]\n",
      " [0.5498684  0.73504265 0.59155492]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.5498684  0.73504265 0.59155492]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.95916199 0.08368326 0.4735896 ]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.53977514 0.76667529 0.65464715]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.5498684  0.73504265 0.59155492]\n",
      " [0.53107436 0.77239702 0.6678902 ]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.53977514 0.76667529 0.65464715]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.95916199 0.08368326 0.4735896 ]\n",
      " [0.5498684  0.73504265 0.59155492]\n",
      " [0.64835751 0.7549478  0.61406983]\n",
      " [0.55523331 0.76248058 0.64289185]\n",
      " [0.53977514 0.76667529 0.65464715]\n",
      " [0.64835751 0.7549478  0.61406983]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.849\n",
      "(*) epoch 2, cost 0.869\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.165\n",
      "(*) epoch 2, cost 1.540\n",
      "(*) epoch 3, cost 1.011\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.15279031 0.73476417 0.85496446]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.15167704 0.73655034 0.86162409]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.15181253 0.73633295 0.86081356]\n",
      " [0.15105007 0.73755627 0.86537465]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.15181253 0.73633295 0.86081356]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.15080546 0.73794873 0.86683789]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.14444415 0.74815503 0.90489148]\n",
      " [0.15167704 0.73655034 0.86162409]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.636\n",
      "(*) epoch 2, cost 0.897\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.972\n",
      "(*) epoch 2, cost 1.815\n",
      "(*) epoch 3, cost 1.387\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.76702526 0.89883494 0.86609005]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.76702526 0.89883494 0.86609005]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.40585268 0.33890237 0.91250676]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.40585268 0.33890237 0.91250676]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.40585268 0.33890237 0.91250676]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.39387564 0.32619071 0.91444483]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.40585268 0.33890237 0.91250676]\n",
      " [0.40585268 0.33890237 0.91250676]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.74379276 0.86722948 0.86955124]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.77495189 0.91089916 0.86459499]\n",
      " [0.74379276 0.86722948 0.86955124]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.242\n",
      "(*) epoch 2, cost 3.677\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.368\n",
      "(*) epoch 2, cost 3.816\n",
      "(*) epoch 3, cost 3.245\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.82188877 0.57575688 0.24393847]\n",
      " [0.82188877 0.57575688 0.24393847]\n",
      " [0.54170974 0.2986494  0.48227174]\n",
      " [0.78879248 0.68592514 0.1734216 ]\n",
      " [0.82188877 0.57575688 0.24393847]\n",
      " [0.78879248 0.68592514 0.1734216 ]\n",
      " [0.33716842 0.37618252 0.51220662]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.4139147  0.46425826 0.46409067]\n",
      " [0.23201064 0.57090384 0.57521004]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.78879248 0.68592514 0.1734216 ]\n",
      " [0.33716842 0.37618252 0.51220662]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.54170974 0.2986494  0.48227174]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.33716842 0.37618252 0.51220662]\n",
      " [0.04454496 0.63007311 0.76546722]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.54170974 0.2986494  0.48227174]\n",
      " [0.82188877 0.57575688 0.24393847]\n",
      " [0.33716842 0.37618252 0.51220662]\n",
      " [0.23201064 0.57090384 0.57521004]\n",
      " [0.78879248 0.68592514 0.1734216 ]\n",
      " [0.42592515 0.52985685 0.43555315]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.61192482 0.70048206 0.21572776]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.71230414 0.69700454 0.18360243]\n",
      " [0.54170974 0.2986494  0.48227174]\n",
      " [0.37508269 0.35467583 0.48934113]\n",
      " [0.78879248 0.68592514 0.1734216 ]\n",
      " [0.78879248 0.68592514 0.1734216 ]\n",
      " [0.10979783 0.61871596 0.69237347]\n",
      " [0.61192482 0.70048206 0.21572776]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.23201064 0.57090384 0.57521004]\n",
      " [0.71230414 0.69700454 0.18360243]\n",
      " [0.4139147  0.46425826 0.46409067]\n",
      " [0.82188877 0.57575688 0.24393847]\n",
      " [0.23201064 0.57090384 0.57521004]\n",
      " [0.54170974 0.2986494  0.48227174]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.23201064 0.57090384 0.57521004]\n",
      " [0.73819779 0.3268903  0.38354094]\n",
      " [0.78879248 0.68592514 0.1734216 ]\n",
      " [0.74786019 0.70524547 0.16811008]\n",
      " [0.82188877 0.57575688 0.24393847]\n",
      " [0.82188877 0.57575688 0.24393847]\n",
      " [0.33716842 0.37618252 0.51220662]]\n",
      "female_labels are: [1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0\n",
      " 0 1 1 0 1 1 0 1 1 0 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.424\n",
      "(*) epoch 2, cost 2.540\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.027\n",
      "(*) epoch 2, cost 2.217\n",
      "(*) epoch 3, cost 1.548\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.53647299 0.25176561 0.24869842]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.67242885 0.2116608  0.29560619]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.53647299 0.25176561 0.24869842]\n",
      " [0.68053577 0.19751624 0.30376643]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.53647299 0.25176561 0.24869842]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.53647299 0.25176561 0.24869842]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.53647299 0.25176561 0.24869842]\n",
      " [0.53647299 0.25176561 0.24869842]\n",
      " [0.55444807 0.26849081 0.24749317]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.53647299 0.25176561 0.24869842]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]\n",
      " [0.46508295 0.1915159  0.25459305]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.295\n",
      "(*) epoch 2, cost 3.117\n",
      "(*) epoch 3, cost 2.614\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.802\n",
      "(*) epoch 2, cost 3.522\n",
      "(*) epoch 3, cost 2.959\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.49406132 0.48377778 0.908863  ]\n",
      " [0.35703336 0.37670477 0.71034637]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.3098254  0.38936381 0.70645897]\n",
      " [0.35703336 0.37670477 0.71034637]\n",
      " [0.65667469 0.57309498 0.92931343]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.4259916  0.37583426 0.72728529]\n",
      " [0.58287302 0.51957187 0.91095092]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.35703336 0.37670477 0.71034637]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.42037517 0.38747218 0.8079026 ]\n",
      " [0.35703336 0.37670477 0.71034637]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.56425621 0.50566549 0.90457169]\n",
      " [0.33388911 0.41073361 0.78928065]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.36325987 0.40936041 0.88573333]\n",
      " [0.66463331 0.57762076 0.91877032]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.36325987 0.40936041 0.88573333]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.35703336 0.37670477 0.71034637]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.4259916  0.37583426 0.72728529]\n",
      " [0.53602576 0.50195432 0.91551742]\n",
      " [0.35703336 0.37670477 0.71034637]\n",
      " [0.35703336 0.37670477 0.71034637]\n",
      " [0.33388911 0.41073361 0.78928065]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.31993928 0.40680341 0.756485  ]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.34115927 0.40802425 0.79291009]\n",
      " [0.33388911 0.41073361 0.78928065]\n",
      " [0.53842757 0.50009947 0.91026573]\n",
      " [0.31993928 0.40680341 0.756485  ]\n",
      " [0.49406132 0.48377778 0.908863  ]\n",
      " [0.33837372 0.40549655 0.78091086]\n",
      " [0.31993928 0.40680341 0.756485  ]\n",
      " [0.31993928 0.40680341 0.756485  ]\n",
      " [0.31993928 0.40680341 0.756485  ]\n",
      " [0.68037344 0.58967428 0.9482563 ]\n",
      " [0.35703336 0.37670477 0.71034637]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.638\n",
      "(*) epoch 2, cost 2.182\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.176\n",
      "(*) epoch 2, cost 5.074\n",
      "(*) epoch 3, cost 4.467\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.06074436 0.05437036 0.38162424]\n",
      " [0.04372775 0.04434645 0.23366105]\n",
      " [0.02161713 0.02083923 0.39088024]\n",
      " [0.84990495 0.7183129  0.48779069]\n",
      " [0.02031049 0.02476791 0.2262426 ]\n",
      " [0.01302138 0.01455745 0.35765441]\n",
      " [0.08647939 0.07431702 0.44489127]\n",
      " [0.00649944 0.01305868 0.22703737]\n",
      " [0.08561444 0.07595779 0.36291789]\n",
      " [0.02658499 0.02635283 0.34941184]\n",
      " [0.02161713 0.02083923 0.39088024]\n",
      " [0.01522089 0.01637175 0.3594942 ]\n",
      " [0.03536524 0.03295627 0.37733988]\n",
      " [0.16936885 0.14266636 0.50772688]\n",
      " [0.01841243 0.01844084 0.38030861]\n",
      " [0.02169902 0.02270359 0.3330586 ]\n",
      " [0.04373512 0.03835274 0.432917  ]\n",
      " [0.00529097 0.01035082 0.28131901]\n",
      " [0.03816494 0.03913035 0.25070662]\n",
      " [0.01475839 0.01744816 0.31214977]\n",
      " [0.03220401 0.02932192 0.40778871]\n",
      " [0.02031049 0.02476791 0.2262426 ]\n",
      " [0.063099   0.05831121 0.31505177]\n",
      " [0.04373512 0.03835274 0.432917  ]\n",
      " [0.04360828 0.04130668 0.33256277]\n",
      " [0.08647939 0.07431702 0.44489127]\n",
      " [0.01302138 0.01455745 0.35765441]\n",
      " [0.02779099 0.02939872 0.28273424]\n",
      " [0.00599464 0.01276703 0.22261071]\n",
      " [0.03039059 0.03315013 0.23095028]\n",
      " [0.01302138 0.01455745 0.35765441]\n",
      " [0.04373512 0.03835274 0.432917  ]\n",
      " [0.03816494 0.03913035 0.25070662]\n",
      " [0.02161713 0.02083923 0.39088024]\n",
      " [0.01510124 0.01976663 0.24588716]\n",
      " [0.04372775 0.04434645 0.23366105]\n",
      " [0.02314184 0.02392193 0.33333868]\n",
      " [0.01510124 0.01976663 0.24588716]\n",
      " [0.04372775 0.04434645 0.23366105]\n",
      " [0.04893344 0.04728433 0.28271   ]\n",
      " [0.03816494 0.03913035 0.25070662]\n",
      " [0.03816494 0.03913035 0.25070662]\n",
      " [0.04373512 0.03835274 0.432917  ]\n",
      " [0.01841243 0.01844084 0.38030861]\n",
      " [0.04372775 0.04434645 0.23366105]\n",
      " [0.02658499 0.02635283 0.34941184]\n",
      " [0.03256636 0.03307394 0.29501915]\n",
      " [0.06249461 0.05331972 0.46493928]\n",
      " [0.03816494 0.03913035 0.25070662]\n",
      " [0.54552905 0.4584111  0.58685017]]\n",
      "female_labels are: [1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.187\n",
      "(*) epoch 2, cost 2.797\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.353\n",
      "(*) epoch 2, cost 3.189\n",
      "(*) epoch 3, cost 2.328\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.59688559 0.37057004 0.80839401]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.672942   0.36800604 0.216432  ]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.44354409 0.79751127 0.92988423]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.70012282 0.23598403 0.59475562]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.672942   0.36800604 0.216432  ]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.59688559 0.37057004 0.80839401]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.439815   0.79806899 0.93255084]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.44354409 0.79751127 0.92988423]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.53067606 0.74784585 0.8007483 ]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.59688559 0.37057004 0.80839401]\n",
      " [0.71988061 0.32175662 0.19796854]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.59688559 0.37057004 0.80839401]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.59688559 0.37057004 0.80839401]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.73002485 0.4032526  0.26832216]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.51727352 0.76060667 0.83159398]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.59597053 0.36393835 0.785729  ]\n",
      " [0.672942   0.36800604 0.216432  ]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.672942   0.36800604 0.216432  ]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.54784052 0.60397993 0.51797505]\n",
      " [0.59597053 0.36393835 0.785729  ]\n",
      " [0.54784052 0.60397993 0.51797505]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "female_pred_labels are: [0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 0 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.658\n",
      "(*) epoch 2, cost 3.076\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.059\n",
      "(*) epoch 2, cost 1.835\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.91925574 0.45285419 0.83962121]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.79766319 0.6782093  0.85370069]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.93288227 0.11852218 0.71953589]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.8834106  0.57815622 0.86215022]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.8834106  0.57815622 0.86215022]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.8834106  0.57815622 0.86215022]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.8834106  0.57815622 0.86215022]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.91925574 0.45285419 0.83962121]\n",
      " [0.86452627 0.70960896 0.89395519]\n",
      " [0.86786586 0.44178796 0.81206646]\n",
      " [0.86452627 0.70960896 0.89395519]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.211\n",
      "(*) epoch 2, cost 2.551\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.583\n",
      "(*) epoch 2, cost 4.134\n",
      "(*) epoch 3, cost 3.554\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.18515099 0.30978143 0.07631466]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.22457591 0.32532802 0.14111861]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.22457591 0.32532802 0.14111861]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.40178259 0.66343387 0.02059413]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.19072721 0.30943114 0.07994158]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19686942 0.31088827 0.08132861]\n",
      " [0.18515099 0.30978143 0.07631466]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.19527501 0.31409    0.10702408]\n",
      " [0.25050129 0.3276784  0.1801894 ]\n",
      " [0.25050129 0.3276784  0.1801894 ]]\n",
      "female_labels are: [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.444\n",
      "(*) epoch 2, cost 1.235\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.411\n",
      "(*) epoch 2, cost 2.022\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.1449989  0.0173028  0.01684902]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.37620292 0.02715866 0.03559125]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.62778566 0.03687667 0.05466218]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.62778566 0.03687667 0.05466218]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.37620292 0.02715866 0.03559125]\n",
      " [0.62778566 0.03687667 0.05466218]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.62778566 0.03687667 0.05466218]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.37620292 0.02715866 0.03559125]\n",
      " [0.36829174 0.02947449 0.03843781]\n",
      " [0.37620292 0.02715866 0.03559125]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.62778566 0.03687667 0.05466218]\n",
      " [0.62778566 0.03687667 0.05466218]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.1790282  0.0191444  0.02012157]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.14411128 0.01720705 0.01670092]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.38450439 0.04775356 0.06287407]\n",
      " [0.37620292 0.02715866 0.03559125]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.380\n",
      "(*) epoch 2, cost 3.645\n",
      "(*) epoch 3, cost 2.743\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.537\n",
      "(*) epoch 2, cost 1.895\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.45907202 0.95760404 0.44052581]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.4656147  0.95992228 0.48230143]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.4656147  0.95992228 0.48230143]\n",
      " [0.40429259 0.96312972 0.75320138]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.40429259 0.96312972 0.75320138]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.4656147  0.95992228 0.48230143]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.40429259 0.96312972 0.75320138]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.40429259 0.96312972 0.75320138]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.40429259 0.96312972 0.75320138]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.40429259 0.96312972 0.75320138]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.4057623  0.94587861 0.50556847]\n",
      " [0.45907202 0.95760404 0.44052581]\n",
      " [0.40429259 0.96312972 0.75320138]\n",
      " [0.4656147  0.95992228 0.48230143]\n",
      " [0.40429259 0.96312972 0.75320138]]\n",
      "female_labels are: [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "female_pred_labels are: [1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 0 1 0 1 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.945\n",
      "(*) epoch 2, cost 3.786\n",
      "(*) epoch 3, cost 3.263\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.216\n",
      "(*) epoch 2, cost 1.658\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.11887611 0.33478813 0.68814041]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.11887611 0.33478813 0.68814041]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.03075899 0.6155666  0.74778486]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.11887611 0.33478813 0.68814041]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.03075899 0.6155666  0.74778486]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.3167208  0.08969431 0.52426261]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.11887611 0.33478813 0.68814041]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.11887611 0.33478813 0.68814041]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.11887611 0.33478813 0.68814041]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.05333721 0.69140278 0.74414596]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.03075899 0.6155666  0.74778486]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]\n",
      " [0.09409391 0.10790379 0.75468357]]\n",
      "female_labels are: [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 0 0 1 1 0 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.151\n",
      "(*) epoch 2, cost 2.402\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.236\n",
      "(*) epoch 2, cost 1.321\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.52012929 0.3812465  0.70042618]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.5326203  0.38374905 0.6957522 ]\n",
      " [0.60254121 0.39943437 0.66637714]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.57937309 0.39420698 0.67608847]\n",
      " [0.52012929 0.3812465  0.70042618]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.52012929 0.3812465  0.70042618]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.25535546 0.32724771 0.29731363]\n",
      " [0.60254121 0.39943437 0.66637714]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.5912081  0.3969914  0.67087547]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.5326203  0.38374905 0.6957522 ]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.52012929 0.3812465  0.70042618]\n",
      " [0.5326203  0.38374905 0.6957522 ]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.36794173 0.36381162 0.72801315]\n",
      " [0.57937309 0.39420698 0.67608847]\n",
      " [0.59956385 0.39885241 0.66743166]\n",
      " [0.36794173 0.36381162 0.72801315]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.138\n",
      "(*) epoch 2, cost 1.884\n",
      "(*) epoch 3, cost 0.933\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.757\n",
      "(*) epoch 2, cost 4.015\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.38668827 0.66897646 0.67269779]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.2797662  0.77506051 0.86614266]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.38873682 0.66756304 0.67059326]\n",
      " [0.4979848  0.57139138 0.50455776]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.38873682 0.66756304 0.67059326]\n",
      " [0.3687939  0.68400013 0.69800793]\n",
      " [0.31271436 0.73494997 0.78733277]\n",
      " [0.27884591 0.77614259 0.86824493]\n",
      " [0.46024002 0.60236815 0.55610043]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.31145081 0.73605422 0.78923226]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.52368394 0.54974103 0.46801695]\n",
      " [0.3635851  0.68841932 0.70549442]\n",
      " [0.31461614 0.73363619 0.78537482]\n",
      " [0.31461614 0.73363619 0.78537482]\n",
      " [0.3687939  0.68400013 0.69800793]\n",
      " [0.3127716  0.73390865 0.78468192]\n",
      " [0.31153359 0.73578471 0.7885977 ]\n",
      " [0.3635851  0.68841932 0.70549442]\n",
      " [0.31451659 0.73227647 0.78178135]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.31153359 0.73578471 0.7885977 ]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.28707003 0.76698064 0.85077248]\n",
      " [0.3687939  0.68400013 0.69800793]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.38668827 0.66897646 0.67269779]\n",
      " [0.4192415  0.64281471 0.62967881]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.52368394 0.54974103 0.46801695]\n",
      " [0.38873352 0.66716045 0.66954914]\n",
      " [0.31461614 0.73363619 0.78537482]\n",
      " [0.31139671 0.73500486 0.78647622]\n",
      " [0.38207616 0.67313783 0.67996938]\n",
      " [0.31153359 0.73578471 0.7885977 ]\n",
      " [0.27926485 0.77578516 0.86763762]\n",
      " [0.38668827 0.66897646 0.67269779]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.29062647 0.7632526  0.84382201]\n",
      " [0.27940409 0.77546945 0.86692629]\n",
      " [0.29969517 0.75828541 0.83784287]\n",
      " [0.31271436 0.73494997 0.78733277]\n",
      " [0.27882885 0.77616686 0.86829479]\n",
      " [0.27884591 0.77614259 0.86824493]\n",
      " [0.31461614 0.73363619 0.78537482]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.860\n",
      "(*) epoch 2, cost 3.315\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.677\n",
      "(*) epoch 2, cost 2.050\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.63873013 0.71952461 0.09396716]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.63873013 0.71952461 0.09396716]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.63873013 0.71952461 0.09396716]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.30234654 0.35809531 0.28480968]\n",
      " [0.30234654 0.35809531 0.28480968]\n",
      " [0.30234654 0.35809531 0.28480968]\n",
      " [0.36752823 0.69616745 0.09043645]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.40554205 0.72321877 0.08886717]\n",
      " [0.06214297 0.16813018 0.05118066]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.30234654 0.35809531 0.28480968]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.63873013 0.71952461 0.09396716]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.74872324 0.54933896 0.09671244]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.75461268 0.58485572 0.09617093]\n",
      " [0.64786589 0.74119256 0.09288399]\n",
      " [0.74872324 0.54933896 0.09671244]\n",
      " [0.75461268 0.58485572 0.09617093]]\n",
      "female_labels are: [1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 0 1 0 1 0 1 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.477\n",
      "(*) epoch 2, cost 2.464\n",
      "(*) epoch 3, cost 2.043\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.101\n",
      "(*) epoch 2, cost 4.897\n",
      "(*) epoch 3, cost 4.541\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.38553116 0.91528482 0.6587448 ]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.27536132 0.93740312 0.65909723]\n",
      " [0.38553116 0.91528482 0.6587448 ]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.03694109 0.89545027 0.84992864]\n",
      " [0.28017375 0.94606365 0.6957632 ]\n",
      " [0.09061615 0.91283427 0.76400718]\n",
      " [0.07239868 0.91719404 0.84776859]\n",
      " [0.02645698 0.89540272 0.88423001]\n",
      " [0.12935544 0.93989491 0.78248507]\n",
      " [0.05983348 0.90769738 0.84342245]\n",
      " [0.03555307 0.89388006 0.84585807]\n",
      " [0.28017375 0.94606365 0.6957632 ]\n",
      " [0.1109141  0.91619611 0.71642029]\n",
      " [0.08209755 0.91309888 0.79786619]\n",
      " [0.04803178 0.85567611 0.58025713]\n",
      " [0.09938274 0.92686715 0.8050123 ]\n",
      " [0.28017375 0.94606365 0.6957632 ]\n",
      " [0.04181198 0.90086408 0.85909317]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.08227567 0.91348786 0.79910472]\n",
      " [0.07239868 0.91719404 0.84776859]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.02819577 0.89590266 0.8813826 ]\n",
      " [0.1109141  0.91619611 0.71642029]\n",
      " [0.28017375 0.94606365 0.6957632 ]\n",
      " [0.12208928 0.93593053 0.77609282]\n",
      " [0.05292603 0.89539442 0.79167165]\n",
      " [0.08227567 0.91348786 0.79910472]\n",
      " [0.06221349 0.90840279 0.83953045]\n",
      " [0.47682396 0.90187778 0.67913803]\n",
      " [0.12935544 0.93989491 0.78248507]\n",
      " [0.08119207 0.92061673 0.83769467]\n",
      " [0.28017375 0.94606365 0.6957632 ]\n",
      " [0.07239868 0.91719404 0.84776859]\n",
      " [0.3104189  0.92920887 0.655361  ]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.1109141  0.91619611 0.71642029]\n",
      " [0.38553116 0.91528482 0.6587448 ]\n",
      " [0.1109141  0.91619611 0.71642029]\n",
      " [0.1109141  0.91619611 0.71642029]\n",
      " [0.05999867 0.90766308 0.84283121]\n",
      " [0.08209755 0.91309888 0.79786619]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.11103061 0.93179136 0.79590526]\n",
      " [0.04578949 0.8936438  0.80727068]\n",
      " [0.10328759 0.92885343 0.80653138]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.640\n",
      "(*) epoch 2, cost 2.474\n",
      "(*) epoch 3, cost 2.161\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.985\n",
      "(*) epoch 2, cost 1.842\n",
      "(*) epoch 3, cost 1.327\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.72459574 0.75506253 0.14239137]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.40766907 0.87844909 0.2117991 ]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.40766907 0.87844909 0.2117991 ]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.40766907 0.87844909 0.2117991 ]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.37319666 0.89313939 0.22467266]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.40766907 0.87844909 0.2117991 ]\n",
      " [0.46251535 0.85371323 0.19625444]\n",
      " [0.47658428 0.33885091 0.17683863]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.40766907 0.87844909 0.2117991 ]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.72459574 0.75506253 0.14239137]\n",
      " [0.37319666 0.89313939 0.22467266]\n",
      " [0.42324698 0.87147646 0.20693374]\n",
      " [0.40766907 0.87844909 0.2117991 ]]\n",
      "female_labels are: [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1\n",
      " 0 1 0 1 1 1 0 1 1 0 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.235\n",
      "(*) epoch 2, cost 1.961\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.532\n",
      "(*) epoch 2, cost 4.195\n",
      "(*) epoch 3, cost 3.631\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.68572779 0.63726041 0.40991234]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.28225451 0.81722762 0.24875476]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.76117512 0.51916058 0.48878044]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.56709855 0.2662716  0.83405282]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.25230686 0.79806607 0.28702715]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.58366332 0.56472124 0.55244487]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.25230686 0.79806607 0.28702715]\n",
      " [0.77175836 0.51695943 0.48694205]\n",
      " [0.28225451 0.81722762 0.24875476]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.35517197 0.78166054 0.28403651]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.20363784 0.84690914 0.22743204]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.25230686 0.79806607 0.28702715]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.25230686 0.79806607 0.28702715]\n",
      " [0.56709855 0.2662716  0.83405282]\n",
      " [0.70433295 0.58424786 0.46173463]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.46843272 0.45303739 0.73547723]\n",
      " [0.56709855 0.2662716  0.83405282]\n",
      " [0.68572779 0.63726041 0.40991234]\n",
      " [0.28225451 0.81722762 0.24875476]\n",
      " [0.56709855 0.2662716  0.83405282]\n",
      " [0.25230686 0.79806607 0.28702715]\n",
      " [0.68572779 0.63726041 0.40991234]]\n",
      "female_labels are: [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 0 0 1 0 1 0 0 1 0 1 0]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.923\n",
      "(*) epoch 2, cost 1.481\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.499\n",
      "(*) epoch 2, cost 4.310\n",
      "(*) epoch 3, cost 3.868\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.19992446 0.60254726 0.42013826]\n",
      " [0.37415239 0.53935591 0.27301795]\n",
      " [0.30480031 0.52254839 0.35538714]\n",
      " [0.25792166 0.49691587 0.41466372]\n",
      " [0.42691754 0.5149266  0.24321698]\n",
      " [0.08205182 0.58585455 0.40856788]\n",
      " [0.42538491 0.51245598 0.24588364]\n",
      " [0.2719807  0.51539399 0.39020068]\n",
      " [0.44302916 0.50173603 0.23400994]\n",
      " [0.43405005 0.51077625 0.23798585]\n",
      " [0.14914403 0.55461225 0.47842902]\n",
      " [0.30480031 0.52254839 0.35538714]\n",
      " [0.30480031 0.52254839 0.35538714]\n",
      " [0.37200465 0.5252429  0.2869784 ]\n",
      " [0.41583126 0.51520679 0.25010928]\n",
      " [0.06171317 0.50043489 0.60058354]\n",
      " [0.44302916 0.50173603 0.23400994]\n",
      " [0.20476917 0.62624925 0.40138118]\n",
      " [0.23653307 0.50875805 0.4276906 ]\n",
      " [0.43030508 0.51355954 0.24030655]\n",
      " [0.09868395 0.62278895 0.48326103]\n",
      " [0.35779284 0.5725191  0.28074665]\n",
      " [0.43581879 0.50918831 0.23736273]\n",
      " [0.43581879 0.50918831 0.23736273]\n",
      " [0.0717646  0.50851898 0.58526888]\n",
      " [0.41583126 0.51520679 0.25010928]\n",
      " [0.42691754 0.5149266  0.24321698]\n",
      " [0.43030508 0.51355954 0.24030655]\n",
      " [0.43857337 0.50721767 0.23562588]\n",
      " [0.41583126 0.51520679 0.25010928]\n",
      " [0.43581879 0.50918831 0.23736273]\n",
      " [0.37590125 0.5265987  0.28403552]\n",
      " [0.43231925 0.50557737 0.24228491]\n",
      " [0.37200465 0.5252429  0.2869784 ]\n",
      " [0.44302916 0.50173603 0.23400994]\n",
      " [0.09868395 0.62278895 0.48326103]\n",
      " [0.29187012 0.5695229  0.34258747]\n",
      " [0.07755929 0.53859207 0.56188964]\n",
      " [0.09868395 0.62278895 0.48326103]\n",
      " [0.05970934 0.45911347 0.62746395]\n",
      " [0.36296558 0.52534542 0.29648865]\n",
      " [0.08733316 0.48726888 0.58187558]\n",
      " [0.44302916 0.50173603 0.23400994]\n",
      " [0.25876028 0.63029185 0.34786022]\n",
      " [0.43857337 0.50721767 0.23562588]\n",
      " [0.30883253 0.50723371 0.35917639]\n",
      " [0.43405005 0.51077625 0.23798585]\n",
      " [0.44302916 0.50173603 0.23400994]\n",
      " [0.33436222 0.53464888 0.32058268]\n",
      " [0.38670172 0.52493994 0.27465931]]\n",
      "female_labels are: [0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.042\n",
      "(*) epoch 2, cost 1.925\n",
      "(*) epoch 3, cost 1.195\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.356\n",
      "(*) epoch 2, cost 2.071\n",
      "(*) epoch 3, cost 1.704\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.52475173 0.64902727 0.43226917]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.62906763 0.82910466 0.29074866]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.62906763 0.82910466 0.29074866]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.62906763 0.82910466 0.29074866]\n",
      " [0.62906763 0.82910466 0.29074866]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.62906763 0.82910466 0.29074866]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.52475173 0.64902727 0.43226917]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89601168 0.59831405 0.03936993]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.52475173 0.64902727 0.43226917]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.62906763 0.82910466 0.29074866]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]\n",
      " [0.89311753 0.59990584 0.04303483]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.967\n",
      "(*) epoch 2, cost 2.055\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.420\n",
      "(*) epoch 2, cost 3.114\n",
      "(*) epoch 3, cost 2.727\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.21831361 0.32562482 0.29124269]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.24834621 0.30265724 0.23241551]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.20209523 0.42953576 0.32756366]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.2285599  0.27509882 0.26900207]\n",
      " [0.18286839 0.46652504 0.36634546]\n",
      " [0.20209523 0.42953576 0.32756366]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.20209523 0.42953576 0.32756366]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.22608264 0.28045446 0.27403246]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.22608264 0.28045446 0.27403246]\n",
      " [0.20209523 0.42953576 0.32756366]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.17373864 0.46484166 0.38381058]\n",
      " [0.21831361 0.32562482 0.29124269]\n",
      " [0.2285599  0.27509882 0.26900207]\n",
      " [0.17373864 0.46484166 0.38381058]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.504\n",
      "(*) epoch 2, cost 2.117\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.166\n",
      "(*) epoch 2, cost 3.540\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.08119222 0.52773137 0.74624762]\n",
      " [0.10078457 0.4839998  0.77970595]\n",
      " [0.0692645  0.4262079  0.6131958 ]\n",
      " [0.0692645  0.4262079  0.6131958 ]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.10078457 0.4839998  0.77970595]\n",
      " [0.05240691 0.53878257 0.59161884]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.05949896 0.46520593 0.71217072]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.0890195  0.49874724 0.91660488]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.10078457 0.4839998  0.77970595]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.05972374 0.44534869 0.6235098 ]\n",
      " [0.06889676 0.42806913 0.60312018]\n",
      " [0.0848792  0.4464124  0.58961689]\n",
      " [0.06096309 0.48084813 0.78024563]\n",
      " [0.10078457 0.4839998  0.77970595]\n",
      " [0.0692645  0.4262079  0.6131958 ]\n",
      " [0.06260395 0.47957579 0.78123463]\n",
      " [0.1142065  0.49522095 0.95391371]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.05240691 0.53878257 0.59161884]\n",
      " [0.0692645  0.4262079  0.6131958 ]\n",
      " [0.06541639 0.47705319 0.78396897]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.10078457 0.4839998  0.77970595]\n",
      " [0.10347805 0.46495114 0.69363638]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.06260395 0.47957579 0.78123463]\n",
      " [0.14095154 0.34889175 0.56733016]\n",
      " [0.0692645  0.4262079  0.6131958 ]\n",
      " [0.1124142  0.4956064  0.95143683]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.12196307 0.49407116 0.96499102]\n",
      " [0.0692645  0.4262079  0.6131958 ]\n",
      " [0.10078457 0.4839998  0.77970595]\n",
      " [0.0692645  0.4262079  0.6131958 ]\n",
      " [0.10347805 0.46495114 0.69363638]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.03192647 0.61065208 0.48748338]\n",
      " [0.10347805 0.46495114 0.69363638]\n",
      " [0.10078457 0.4839998  0.77970595]\n",
      " [0.13471529 0.37855236 0.60749112]\n",
      " [0.10347805 0.46495114 0.69363638]\n",
      " [0.10309752 0.48195944 0.79565954]\n",
      " [0.10347805 0.46495114 0.69363638]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.034\n",
      "(*) epoch 2, cost 2.697\n",
      "(*) epoch 3, cost 2.040\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.316\n",
      "(*) epoch 2, cost 3.504\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.32064756 0.94038245 0.0048642 ]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.32607107 0.93848627 0.00513752]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.17701769 0.95092863 0.00564874]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.17701769 0.95092863 0.00564874]\n",
      " [0.22612045 0.94934956 0.00492066]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.26841422 0.95009807 0.00401688]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.32607107 0.93848627 0.00513752]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.22612045 0.94934956 0.00492066]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.22612045 0.94934956 0.00492066]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.17701769 0.95092863 0.00564874]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.05250592 0.95230412 0.00799806]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.17701769 0.95092863 0.00564874]\n",
      " [0.05250592 0.95230412 0.00799806]\n",
      " [0.32607107 0.93848627 0.00513752]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.17701769 0.95092863 0.00564874]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.26841422 0.95009807 0.00401688]\n",
      " [0.26968576 0.94818783 0.00430667]\n",
      " [0.17701769 0.95092863 0.00564874]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.17701769 0.95092863 0.00564874]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.35029461 0.94949741 0.00266175]\n",
      " [0.33759673 0.9423099  0.00421344]\n",
      " [0.32064756 0.94038245 0.0048642 ]\n",
      " [0.32064756 0.94038245 0.0048642 ]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.623\n",
      "(*) epoch 2, cost 1.987\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.411\n",
      "(*) epoch 2, cost 2.992\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.1353896  0.81112032 0.89257552]\n",
      " [0.68816952 0.69203369 0.47427255]\n",
      " [0.19281463 0.93057926 0.87812205]\n",
      " [0.86135645 0.79574067 0.43534502]\n",
      " [0.16744511 0.9280317  0.88284468]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.16744511 0.9280317  0.88284468]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.14908789 0.92951521 0.89027863]\n",
      " [0.82874295 0.81185067 0.47192726]\n",
      " [0.77609377 0.83146173 0.52172724]\n",
      " [0.82874295 0.81185067 0.47192726]\n",
      " [0.16744511 0.9280317  0.88284468]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.19281463 0.93057926 0.87812205]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.86135645 0.79574067 0.43534502]\n",
      " [0.19281463 0.93057926 0.87812205]\n",
      " [0.14908789 0.92951521 0.89027863]\n",
      " [0.13493015 0.80476074 0.8925836 ]\n",
      " [0.77609377 0.83146173 0.52172724]\n",
      " [0.14908789 0.92951521 0.89027863]\n",
      " [0.14908789 0.92951521 0.89027863]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.17040896 0.91584557 0.87552686]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.14908789 0.92951521 0.89027863]\n",
      " [0.86915388 0.78939059 0.4219862 ]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.16744511 0.9280317  0.88284468]\n",
      " [0.82874295 0.81185067 0.47192726]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.85705323 0.79891832 0.44198171]\n",
      " [0.77609377 0.83146173 0.52172724]\n",
      " [0.1090733  0.91800395 0.90916542]\n",
      " [0.17040896 0.91584557 0.87552686]\n",
      " [0.17040896 0.91584557 0.87552686]\n",
      " [0.22836877 0.90500613 0.8427712 ]\n",
      " [0.22836877 0.90500613 0.8427712 ]]\n",
      "female_labels are: [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "female_pred_labels are: [0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 1 0 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1\n",
      " 1 1 0 0 1 1 1 1 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.014\n",
      "(*) epoch 2, cost 4.336\n",
      "(*) epoch 3, cost 3.719\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.302\n",
      "(*) epoch 2, cost 2.262\n",
      "(*) epoch 3, cost 1.822\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.72717803 0.43418292 0.53930209]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.69542065 0.30686651 0.75495766]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.80578623 0.96362445 0.20599254]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.80578623 0.96362445 0.20599254]\n",
      " [0.79851283 0.96269641 0.20681136]\n",
      " [0.73508051 0.88100152 0.38587619]\n",
      " [0.73508051 0.88100152 0.38587619]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.78669638 0.63054862 0.34864586]\n",
      " [0.76588764 0.83950924 0.40819709]\n",
      " [0.78669638 0.63054862 0.34864586]]\n",
      "female_labels are: [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.049\n",
      "(*) epoch 2, cost 2.298\n",
      "(*) epoch 3, cost 1.615\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.396\n",
      "(*) epoch 2, cost 3.850\n",
      "(*) epoch 3, cost 2.469\n",
      "(*) epoch 4, cost 2.124\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.85640299 0.68604951 0.30114229]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.93750638 0.09769835 0.04425344]\n",
      " [0.68789666 0.78072751 0.51629303]\n",
      " [0.85842266 0.67598112 0.29594698]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.68789666 0.78072751 0.51629303]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.88396238 0.52034727 0.22271096]\n",
      " [0.85842266 0.67598112 0.29594698]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.87541547 0.58392809 0.25013333]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.89531655 0.41105202 0.17975601]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.87587059 0.55374615 0.2418407 ]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.87627958 0.57396491 0.24630776]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85842266 0.67598112 0.29594698]\n",
      " [0.88396238 0.52034727 0.22271096]\n",
      " [0.90287719 0.28724163 0.1372725 ]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.85578504 0.69227936 0.30354471]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.85842266 0.67598112 0.29594698]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.89332191 0.45127783 0.19293755]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.85640299 0.68604951 0.30114229]\n",
      " [0.87627958 0.57396491 0.24630776]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.68789666 0.78072751 0.51629303]\n",
      " [0.90287719 0.28724163 0.1372725 ]\n",
      " [0.9183048  0.20874946 0.09728915]\n",
      " [0.88782722 0.4657575  0.20357753]\n",
      " [0.88396238 0.52034727 0.22271096]\n",
      " [0.9183048  0.20874946 0.09728915]]\n",
      "female_labels are: [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.655\n",
      "(*) epoch 2, cost 3.961\n",
      "(*) epoch 3, cost 2.197\n",
      "(*) epoch 4, cost 1.643\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.102\n",
      "(*) epoch 2, cost 2.686\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.32598482 0.22036754 0.33460795]\n",
      " [0.18445639 0.10026666 0.28852597]\n",
      " [0.39464539 0.28052672 0.35031489]\n",
      " [0.39464539 0.28052672 0.35031489]\n",
      " [0.6121337  0.47616067 0.40905981]\n",
      " [0.18445639 0.10026666 0.28852597]\n",
      " [0.27024531 0.17538811 0.30988182]\n",
      " [0.19904329 0.11302025 0.29303475]\n",
      " [0.53572959 0.40776462 0.38817441]\n",
      " [0.33006164 0.22954613 0.32488881]\n",
      " [0.19904329 0.11302025 0.29303475]\n",
      " [0.59833337 0.46430102 0.40596226]\n",
      " [0.63246927 0.49512421 0.41612534]\n",
      " [0.34030627 0.2388433  0.32748746]\n",
      " [0.18933589 0.10454956 0.28996203]\n",
      " [0.27024531 0.17538811 0.30988182]\n",
      " [0.34030627 0.2388433  0.32748746]\n",
      " [0.59558889 0.46158517 0.40484436]\n",
      " [0.53572959 0.40776462 0.38817441]\n",
      " [0.52163006 0.39640154 0.37952848]\n",
      " [0.19904329 0.11302025 0.29303475]\n",
      " [0.33006164 0.22954613 0.32488881]\n",
      " [0.27024531 0.17538811 0.30988182]\n",
      " [0.52163006 0.39640154 0.37952848]\n",
      " [0.59833337 0.46430102 0.40596226]\n",
      " [0.27024531 0.17538811 0.30988182]\n",
      " [0.11543049 0.03306159 0.28578853]\n",
      " [0.52163006 0.39640154 0.37952848]\n",
      " [0.21221106 0.12447914 0.29737316]\n",
      " [0.40395871 0.2884375  0.35200229]\n",
      " [0.1621938  0.07989289 0.28539695]\n",
      " [0.53572959 0.40776462 0.38817441]\n",
      " [0.52163006 0.39640154 0.37952848]\n",
      " [0.51068638 0.38662009 0.37615515]\n",
      " [0.63246927 0.49512421 0.41612534]\n",
      " [0.12143734 0.03803711 0.28661121]\n",
      " [0.51068638 0.38662009 0.37615515]\n",
      " [0.27024531 0.17538811 0.30988182]\n",
      " [0.53572959 0.40776462 0.38817441]\n",
      " [0.39313873 0.2833681  0.34255518]\n",
      " [0.12143734 0.03803711 0.28661121]\n",
      " [0.52163006 0.39640154 0.37952848]\n",
      " [0.12143734 0.03803711 0.28661121]\n",
      " [0.39313873 0.2833681  0.34255518]\n",
      " [0.1621938  0.07989289 0.28539695]\n",
      " [0.27024531 0.17538811 0.30988182]\n",
      " [0.38017297 0.27183903 0.33881134]\n",
      " [0.39313873 0.2833681  0.34255518]\n",
      " [0.39464539 0.28052672 0.35031489]\n",
      " [0.21221106 0.12447914 0.29737316]]\n",
      "female_labels are: [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.037\n",
      "(*) epoch 2, cost 3.140\n",
      "(*) epoch 3, cost 2.341\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.323\n",
      "(*) epoch 2, cost 3.242\n",
      "(*) epoch 3, cost 2.110\n",
      "(*) epoch 4, cost 1.708\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.49071068 0.10986774 0.2317757 ]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.28484168 0.6222215  0.1007733 ]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.13686397 0.52269178 0.0765829 ]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.28484168 0.6222215  0.1007733 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.20769108 0.32843895 0.17552749]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.28484168 0.6222215  0.1007733 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.28484168 0.6222215  0.1007733 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.1617711  0.47721705 0.11630648]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]\n",
      " [0.49071068 0.10986774 0.2317757 ]]\n",
      "female_labels are: [0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 0 1 0 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.247\n",
      "(*) epoch 2, cost 2.264\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.628\n",
      "(*) epoch 2, cost 4.124\n",
      "(*) epoch 3, cost 2.806\n",
      "(*) epoch 4, cost 2.393\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.44873634 0.39874367 0.59708131]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.51846499 0.06395809 0.89744224]\n",
      " [0.50048332 0.12180505 0.86743286]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.48916326 0.16176364 0.84190473]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.50476256 0.10705174 0.8765503 ]\n",
      " [0.51686668 0.067903   0.89450374]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.50340969 0.11163171 0.87399566]\n",
      " [0.50340969 0.11163171 0.87399566]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.51572115 0.07099433 0.89243776]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.5168208  0.06796467 0.89432007]\n",
      " [0.51687812 0.06792126 0.89461655]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.51506079 0.07287064 0.89134108]\n",
      " [0.49845424 0.12873247 0.86386686]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.50340969 0.11163171 0.87399566]\n",
      " [0.5168208  0.06796467 0.89432007]\n",
      " [0.50340969 0.11163171 0.87399566]\n",
      " [0.50048332 0.12180505 0.86743286]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.47967696 0.19606251 0.81615865]\n",
      " [0.50476256 0.10705174 0.8765503 ]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.51845015 0.06491675 0.89840374]\n",
      " [0.50340969 0.11163171 0.87399566]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.50476256 0.10705174 0.8765503 ]\n",
      " [0.44873634 0.39874367 0.59708131]\n",
      " [0.48625614 0.17224642 0.83433824]\n",
      " [0.50048332 0.12180505 0.86743286]\n",
      " [0.44873634 0.39874367 0.59708131]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0\n",
      " 1 0 0 1 1 0 0 0 1 0 0 1 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.258\n",
      "(*) epoch 2, cost 3.041\n",
      "(*) epoch 3, cost 2.535\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.514\n",
      "(*) epoch 2, cost 5.569\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.92185682 0.44849562 0.34365941]\n",
      " [0.92185682 0.44849562 0.34365941]\n",
      " [0.67026344 0.24089706 0.61289043]\n",
      " [0.59158203 0.17741104 0.82404878]\n",
      " [0.4739885  0.52693735 0.90918057]\n",
      " [0.35117947 0.2121679  0.87353801]\n",
      " [0.7855756  0.57655665 0.64034036]\n",
      " [0.75630041 0.30637549 0.64019719]\n",
      " [0.92185682 0.44849562 0.34365941]\n",
      " [0.84398918 0.53351691 0.50552405]\n",
      " [0.55852124 0.16629479 0.84668383]\n",
      " [0.63299857 0.21070111 0.66653193]\n",
      " [0.84132922 0.50094885 0.53475707]\n",
      " [0.42190987 0.1017175  0.89892317]\n",
      " [0.47942882 0.12033082 0.88890266]\n",
      " [0.9601954  0.38432084 0.28319069]\n",
      " [0.95960829 0.38651592 0.28108853]\n",
      " [0.4739885  0.52693735 0.90918057]\n",
      " [0.67026344 0.24089706 0.61289043]\n",
      " [0.55852124 0.16629479 0.84668383]\n",
      " [0.67026344 0.24089706 0.61289043]\n",
      " [0.92629131 0.43213596 0.35143516]\n",
      " [0.53403085 0.14438819 0.86378437]\n",
      " [0.95803533 0.38968396 0.28040748]\n",
      " [0.4739885  0.52693735 0.90918057]\n",
      " [0.57305858 0.18106956 0.8299629 ]\n",
      " [0.79523504 0.56866039 0.62066653]\n",
      " [0.63936515 0.37754914 0.71682004]\n",
      " [0.92185682 0.44849562 0.34365941]\n",
      " [0.94283486 0.36547851 0.32353677]\n",
      " [0.75630041 0.30637549 0.64019719]\n",
      " [0.47372232 0.12391732 0.88775036]\n",
      " [0.47538617 0.12665667 0.88824355]\n",
      " [0.75630041 0.30637549 0.64019719]\n",
      " [0.79593316 0.63657304 0.58219964]\n",
      " [0.75630041 0.30637549 0.64019719]\n",
      " [0.92185682 0.44849562 0.34365941]\n",
      " [0.55852124 0.16629479 0.84668383]\n",
      " [0.55852124 0.16629479 0.84668383]\n",
      " [0.46842037 0.13109219 0.88699943]\n",
      " [0.83442063 0.55132601 0.52128742]\n",
      " [0.55004429 0.1847405  0.84821551]\n",
      " [0.67562393 0.6325464  0.75804661]\n",
      " [0.95960829 0.38651592 0.28108853]\n",
      " [0.92185682 0.44849562 0.34365941]\n",
      " [0.47274736 0.11187261 0.89201524]\n",
      " [0.94283486 0.36547851 0.32353677]\n",
      " [0.45476945 0.13675681 0.89008848]\n",
      " [0.95803533 0.38968396 0.28040748]\n",
      " [0.48329977 0.53639666 0.90806774]]\n",
      "female_labels are: [1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "female_pred_labels are: [1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1\n",
      " 0 0 0 1 0 1 1 1 0 1 0 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1\n",
      " 0 0 0 1 0 1 1 1 0 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.114\n",
      "(*) epoch 2, cost 3.538\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.612\n",
      "(*) epoch 2, cost 4.518\n",
      "(*) epoch 3, cost 2.874\n",
      "(*) epoch 4, cost 2.218\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.07956597 0.10250361 0.07712244]\n",
      " [0.16412814 0.09706308 0.08137385]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.16412814 0.09706308 0.08137385]\n",
      " [0.16412814 0.09706308 0.08137385]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.06852639 0.08865487 0.05203705]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.07694596 0.09505424 0.0484825 ]\n",
      " [0.26504968 0.10564439 0.20381024]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.16412814 0.09706308 0.08137385]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.16412814 0.09706308 0.08137385]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.16412814 0.09706308 0.08137385]\n",
      " [0.0869251  0.12357056 0.12301205]\n",
      " [0.07956597 0.10250361 0.07712244]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.06707694 0.09295535 0.04434072]\n",
      " [0.06852639 0.08865487 0.05203705]\n",
      " [0.18806331 0.21069124 0.47662174]\n",
      " [0.16412814 0.09706308 0.08137385]]\n",
      "female_labels are: [0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 1 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.918\n",
      "(*) epoch 2, cost 1.607\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.796\n",
      "(*) epoch 2, cost 2.364\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25826949 0.73069236 0.56592432]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.29044338 0.87157031 0.13320229]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25166908 0.8430534  0.14507373]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25166908 0.8430534  0.14507373]\n",
      " [0.22265216 0.70962664 0.41991971]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.22265216 0.70962664 0.41991971]\n",
      " [0.29044338 0.87157031 0.13320229]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.29044338 0.87157031 0.13320229]\n",
      " [0.25166908 0.8430534  0.14507373]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.25566054 0.85739213 0.13757075]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.21883814 0.706452   0.40627331]\n",
      " [0.25166908 0.8430534  0.14507373]\n",
      " [0.25566054 0.85739213 0.13757075]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.393\n",
      "(*) epoch 2, cost 1.939\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.737\n",
      "(*) epoch 2, cost 2.612\n",
      "(*) epoch 3, cost 1.780\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.138455   0.03617433 0.977614  ]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.6234019  0.75097893 0.92150247]\n",
      " [0.13199754 0.02795141 0.9814213 ]\n",
      " [0.13679407 0.02834377 0.98182021]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.20215096 0.11851201 0.96543454]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.13199754 0.02795141 0.9814213 ]\n",
      " [0.6234019  0.75097893 0.92150247]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.54485143 0.60613329 0.91710602]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.6234019  0.75097893 0.92150247]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.6234019  0.75097893 0.92150247]\n",
      " [0.6234019  0.75097893 0.92150247]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.6234019  0.75097893 0.92150247]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.6234019  0.75097893 0.92150247]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.138455   0.03617433 0.977614  ]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.44934293 0.32397954 0.86136478]\n",
      " [0.13199754 0.02795141 0.9814213 ]\n",
      " [0.138455   0.03617433 0.977614  ]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1\n",
      " 0 1 1 0 1 0 0 0 0 1 1 1 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.321\n",
      "(*) epoch 2, cost 1.940\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.710\n",
      "(*) epoch 2, cost 3.010\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.21902907 0.89431021 0.26348838]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.21902907 0.89431021 0.26348838]\n",
      " [0.13153901 0.94221988 0.31877058]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.21902907 0.89431021 0.26348838]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.21902907 0.89431021 0.26348838]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.13153901 0.94221988 0.31877058]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.27216285 0.87381778 0.29017579]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.27216285 0.87381778 0.29017579]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.27216285 0.87381778 0.29017579]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.16382005 0.8849317  0.38999471]\n",
      " [0.27216285 0.87381778 0.29017579]\n",
      " [0.16382005 0.8849317  0.38999471]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.196\n",
      "(*) epoch 2, cost 1.064\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.244\n",
      "(*) epoch 2, cost 1.269\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05928714 0.47320483 0.78150154]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.03598288 0.26368685 0.81179777]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.03621406 0.36417707 0.80867255]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.03598288 0.26368685 0.81179777]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05202207 0.11929493 0.78430641]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]\n",
      " [0.05813355 0.46339312 0.78168369]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.243\n",
      "(*) epoch 2, cost 2.614\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.680\n",
      "(*) epoch 2, cost 3.076\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.5281494  0.76567393 0.49441734]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.33312106 0.34542662 0.47627899]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.14179826 0.33189697 0.60792898]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.71067093 0.83893944 0.42213307]\n",
      " [0.47744945 0.41835596 0.40460593]\n",
      " [0.47744945 0.41835596 0.40460593]\n",
      " [0.49882297 0.17580986 0.29119169]\n",
      " [0.54715076 0.46262999 0.37345024]\n",
      " [0.55091955 0.78947264 0.47663924]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.47744945 0.41835596 0.40460593]\n",
      " [0.67874073 0.83691303 0.42320613]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.5281494  0.76567393 0.49441734]\n",
      " [0.67780184 0.84298367 0.4131983 ]\n",
      " [0.69468945 0.84037277 0.41805241]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.18972728 0.39919011 0.60655215]\n",
      " [0.5281494  0.76567393 0.49441734]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.773\n",
      "(*) epoch 2, cost 2.290\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.508\n",
      "(*) epoch 2, cost 2.333\n",
      "(*) epoch 3, cost 1.816\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.12994202 0.70610829 0.62896757]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.07054371 0.84419995 0.59751268]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.08758575 0.95075858 0.43827872]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.08654537 0.94594127 0.44677207]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.08654537 0.94594127 0.44677207]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.07054371 0.84419995 0.59751268]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.08604072 0.95336515 0.43812345]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.07054371 0.84419995 0.59751268]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.10309151 0.94431823 0.41961389]\n",
      " [0.08758575 0.95075858 0.43827872]\n",
      " [0.12994202 0.70610829 0.62896757]\n",
      " [0.10309151 0.94431823 0.41961389]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.07054371 0.84419995 0.59751268]\n",
      " [0.07054371 0.84419995 0.59751268]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.08755492 0.95004211 0.43931381]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.24084232 0.4131865  0.85394539]\n",
      " [0.13625769 0.60848589 0.74089446]\n",
      " [0.12994202 0.70610829 0.62896757]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "trans_female_pred_labels are: [0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0\n",
      " 1 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.054\n",
      "(*) epoch 2, cost 2.418\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.881\n",
      "(*) epoch 2, cost 1.111\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.13325219 0.57699801 0.68095026]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]\n",
      " [0.32407141 0.31160388 0.44187177]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.503\n",
      "(*) epoch 2, cost 1.994\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.880\n",
      "(*) epoch 2, cost 2.257\n",
      "(*) epoch 3, cost 1.260\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.43277771 0.39877971 0.36621558]\n",
      " [0.57132238 0.67042204 0.36726002]\n",
      " [0.57132238 0.67042204 0.36726002]]\n",
      "female_labels are: [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n",
      "female_pred_labels are: [0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 1 1 0 1 1 1 0 1 1]\n",
      "trans_female_pred_labels are: [0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 1 1 0 1 1 1 0 1 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.738\n",
      "(*) epoch 2, cost 1.595\n",
      "(*) epoch 3, cost 1.077\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.071\n",
      "(*) epoch 2, cost 2.278\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.13127533 0.66911106 0.92164713]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.13936642 0.66274881 0.91997961]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.90883506 0.05769334 0.7613963 ]\n",
      " [0.04436156 0.73745388 0.93955959]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.0452504  0.73675496 0.93937641]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.29363456 0.5414433  0.88818578]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.91732667 0.05101614 0.75964623]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.04427194 0.73752435 0.93957806]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.13936642 0.66274881 0.91997961]\n",
      " [0.90883506 0.05769334 0.7613963 ]\n",
      " [0.92221769 0.04717019 0.75863821]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.90883506 0.05769334 0.7613963 ]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.29363456 0.5414433  0.88818578]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.13936642 0.66274881 0.91997961]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.90883506 0.05769334 0.7613963 ]\n",
      " [0.13936642 0.66274881 0.91997961]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.91531227 0.05260012 0.76006138]\n",
      " [0.29363456 0.5414433  0.88818578]\n",
      " [0.25603984 0.57100512 0.89593385]\n",
      " [0.67690264 0.24006852 0.80919631]\n",
      " [0.12408918 0.67476174 0.92312816]\n",
      " [0.25603984 0.57100512 0.89593385]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.622\n",
      "(*) epoch 2, cost 3.152\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.291\n",
      "(*) epoch 2, cost 3.039\n",
      "(*) epoch 3, cost 2.489\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.74667165 0.17121404 0.12205675]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.72451458 0.21131076 0.12493177]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.75249263 0.15351878 0.11951979]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.72451458 0.21131076 0.12493177]\n",
      " [0.76408416 0.14115908 0.10849181]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.76408416 0.14115908 0.10849181]\n",
      " [0.74374531 0.17886756 0.12261817]\n",
      " [0.72451458 0.21131076 0.12493177]\n",
      " [0.53507736 0.27186264 0.18170237]\n",
      " [0.738703   0.19099812 0.12328703]\n",
      " [0.72451458 0.21131076 0.12493177]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.72451458 0.21131076 0.12493177]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.74374531 0.17886756 0.12261817]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.58490813 0.24688316 0.173911  ]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.76408416 0.14115908 0.10849181]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.75083044 0.15987072 0.12062976]\n",
      " [0.69673177 0.20290692 0.14246062]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.75416443 0.14790993 0.11836667]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.10972682 0.41743238 0.19002885]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.75416443 0.14790993 0.11836667]\n",
      " [0.68553099 0.18976451 0.14671245]\n",
      " [0.58490813 0.24688316 0.173911  ]\n",
      " [0.74774377 0.1682383  0.12175085]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.73604313 0.19819015 0.12312479]\n",
      " [0.72451458 0.21131076 0.12493177]\n",
      " [0.74667165 0.17121404 0.12205675]\n",
      " [0.74374531 0.17886756 0.12261817]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.974\n",
      "(*) epoch 2, cost 2.172\n",
      "(*) epoch 3, cost 1.738\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.973\n",
      "(*) epoch 2, cost 3.450\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.13328768 0.96380799 0.37011578]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.24563612 0.98658357 0.11497838]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.17362525 0.99354943 0.11148508]\n",
      " [0.12710085 0.98157645 0.22691531]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.17362525 0.99354943 0.11148508]\n",
      " [0.24563612 0.98658357 0.11497838]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.12772408 0.98326965 0.21249769]\n",
      " [0.17362525 0.99354943 0.11148508]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.18550596 0.99156975 0.10888132]\n",
      " [0.24563612 0.98658357 0.11497838]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.18550596 0.99156975 0.10888132]\n",
      " [0.24563612 0.98658357 0.11497838]\n",
      " [0.18550596 0.99156975 0.10888132]\n",
      " [0.13164659 0.95595235 0.43362988]\n",
      " [0.18550596 0.99156975 0.10888132]\n",
      " [0.12636543 0.98065548 0.23694834]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.18550596 0.99156975 0.10888132]\n",
      " [0.13235295 0.99009954 0.15423323]\n",
      " [0.17362525 0.99354943 0.11148508]\n",
      " [0.18550596 0.99156975 0.10888132]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.12636543 0.98065548 0.23694834]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.24563612 0.98658357 0.11497838]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.17362525 0.99354943 0.11148508]\n",
      " [0.13235295 0.99009954 0.15423323]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.17362525 0.99354943 0.11148508]\n",
      " [0.13813349 0.97480504 0.2770682 ]\n",
      " [0.13328768 0.96380799 0.37011578]\n",
      " [0.24563612 0.98658357 0.11497838]\n",
      " [0.18550596 0.99156975 0.10888132]\n",
      " [0.26307333 0.92820106 0.55278873]\n",
      " [0.26307333 0.92820106 0.55278873]]\n",
      "female_labels are: [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n",
      "female_pred_labels are: [1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0\n",
      " 0 1 1 0 0 0 1 1 1 1 1 0 0]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 1 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.803\n",
      "(*) epoch 2, cost 3.450\n",
      "(*) epoch 3, cost 2.812\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.337\n",
      "(*) epoch 2, cost 1.041\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04801271 0.05147586 0.44627277]\n",
      " [0.06576608 0.05491387 0.39316101]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.05746581 0.05257234 0.41673809]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.06576608 0.05491387 0.39316101]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.05306004 0.0520578  0.43078662]\n",
      " [0.04801271 0.05147586 0.44627277]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.01978538 0.05728414 0.66440705]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.04076569 0.22687713 0.55730759]\n",
      " [0.06576608 0.05491387 0.39316101]\n",
      " [0.04076569 0.22687713 0.55730759]]\n",
      "female_labels are: [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "female_pred_labels are: [1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.015\n",
      "(*) epoch 2, cost 2.272\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.317\n",
      "(*) epoch 2, cost 2.087\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.06879959 0.05017136 0.05812073]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06879188 0.05016803 0.05811082]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879336 0.05016843 0.05811264]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06879188 0.05016803 0.05811082]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06879878 0.0501709  0.05811965]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06879188 0.05016803 0.05811082]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06879188 0.05016803 0.05811082]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06884433 0.05017941 0.05817445]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.06881189 0.0501737  0.05813555]\n",
      " [0.06884433 0.05017941 0.05817445]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06879959 0.05017136 0.05812073]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06884433 0.05017941 0.05817445]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06879188 0.05016803 0.05811082]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879803 0.0501699  0.05811846]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.43541173 0.13813672 0.50382683]\n",
      " [0.06879188 0.05016803 0.05811082]\n",
      " [0.06883837 0.05017933 0.05816762]\n",
      " [0.06879959 0.05017136 0.05812073]]\n",
      "female_labels are: [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.733\n",
      "(*) epoch 2, cost 4.534\n",
      "(*) epoch 3, cost 4.048\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.963\n",
      "(*) epoch 2, cost 3.848\n",
      "(*) epoch 3, cost 3.324\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.38260177 0.00238332 0.00101718]\n",
      " [0.32184788 0.00238129 0.0010026 ]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.44410053 0.00251599 0.00109271]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.5680319  0.00294108 0.00128352]\n",
      " [0.47661733 0.00256085 0.00111871]\n",
      " [0.37970748 0.00241103 0.00103049]\n",
      " [0.5680319  0.00294108 0.00128352]\n",
      " [0.32897026 0.00238199 0.00100461]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.30189139 0.00235847 0.00098526]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.32537929 0.00238156 0.00100358]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.37970748 0.00241103 0.00103049]\n",
      " [0.38260177 0.00238332 0.00101718]\n",
      " [0.37970748 0.00241103 0.00103049]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.32897026 0.00238199 0.00100461]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.44410053 0.00251599 0.00109271]\n",
      " [0.44410053 0.00251599 0.00109271]\n",
      " [0.44410053 0.00251599 0.00109271]\n",
      " [0.32897026 0.00238199 0.00100461]\n",
      " [0.47661733 0.00256085 0.00111871]\n",
      " [0.4326705  0.00249201 0.00107966]\n",
      " [0.47516928 0.00244263 0.00106556]\n",
      " [0.32537929 0.00238156 0.00100358]\n",
      " [0.30189139 0.00235847 0.00098526]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.37970748 0.00241103 0.00103049]\n",
      " [0.37970748 0.00241103 0.00103049]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.32344171 0.00238117 0.00100288]\n",
      " [0.44410053 0.00251599 0.00109271]\n",
      " [0.44410053 0.00251599 0.00109271]\n",
      " [0.42452213 0.00247746 0.00107167]\n",
      " [0.39906702 0.00240759 0.00103429]\n",
      " [0.38260177 0.00238332 0.00101718]\n",
      " [0.37970748 0.00241103 0.00103049]\n",
      " [0.40124393 0.00240573 0.00103228]\n",
      " [0.40124393 0.00240573 0.00103228]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.412\n",
      "(*) epoch 2, cost 2.829\n",
      "(*) epoch 3, cost 2.419\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.700\n",
      "(*) epoch 2, cost 1.553\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.14558278 0.85231415 0.49132152]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14470296 0.92522044 0.51324417]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14470296 0.92522044 0.51324417]\n",
      " [0.1685864  0.3049758  0.42705385]\n",
      " [0.17279784 0.14038095 0.61362898]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17279784 0.14038095 0.61362898]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.14470296 0.92522044 0.51324417]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14470296 0.92522044 0.51324417]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17279784 0.14038095 0.61362898]\n",
      " [0.14470296 0.92522044 0.51324417]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14558278 0.85231415 0.49132152]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14558278 0.85231415 0.49132152]\n",
      " [0.15569315 0.5355812  0.38376137]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.15569315 0.5355812  0.38376137]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.14464925 0.83133391 0.4710239 ]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]\n",
      " [0.17476077 0.90799521 0.53041361]]\n",
      "female_labels are: [1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1\n",
      " 1 0 0 1 1 0 1 1 0 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.264\n",
      "(*) epoch 2, cost 1.999\n",
      "(*) epoch 3, cost 1.449\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.141\n",
      "(*) epoch 2, cost 4.195\n",
      "(*) epoch 3, cost 3.564\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.69165346 0.19820922 0.35843026]\n",
      " [0.90229194 0.08684281 0.20892266]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.89754196 0.08989642 0.21227086]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.89790038 0.08956758 0.21220757]\n",
      " [0.69165346 0.19820922 0.35843026]\n",
      " [0.7451891  0.1716178  0.31943189]\n",
      " [0.89790038 0.08956758 0.21220757]\n",
      " [0.66592913 0.21109509 0.37750908]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.89754196 0.08989642 0.21227086]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.89790038 0.08956758 0.21220757]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.7451891  0.1716178  0.31943189]\n",
      " [0.8900512  0.09616205 0.21979923]\n",
      " [0.5306253  0.29288963 0.47492488]\n",
      " [0.89840395 0.08898509 0.21156838]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.7335177  0.19232025 0.36871065]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.88104084 0.10101301 0.22643436]\n",
      " [0.90229194 0.08684281 0.20892266]\n",
      " [0.87871696 0.10316739 0.2288651 ]\n",
      " [0.62901764 0.23055388 0.40476532]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.66592913 0.21109509 0.37750908]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.89754196 0.08989642 0.21227086]\n",
      " [0.57547523 0.45623962 0.64191989]\n",
      " [0.88104084 0.10101301 0.22643436]\n",
      " [0.86627436 0.1083556  0.23673729]\n",
      " [0.69165346 0.19820922 0.35843026]\n",
      " [0.89754196 0.08989642 0.21227086]\n",
      " [0.90229194 0.08684281 0.20892266]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.49202568 0.36430818 0.50557293]\n",
      " [0.89790038 0.08956758 0.21220757]\n",
      " [0.89754196 0.08989642 0.21227086]\n",
      " [0.71325947 0.18757315 0.34258813]\n",
      " [0.35470716 0.13219947 0.89889677]\n",
      " [0.90465194 0.08505402 0.20692619]\n",
      " [0.71325947 0.18757315 0.34258813]]\n",
      "female_labels are: [1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "female_pred_labels are: [1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1\n",
      " 0 0 1 0 0 1 1 0 0 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 1 0 1 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.859\n",
      "(*) epoch 2, cost 4.168\n",
      "(*) epoch 3, cost 3.633\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.659\n",
      "(*) epoch 2, cost 2.974\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.5792998  0.02579975 0.26105924]\n",
      " [0.52822914 0.02808412 0.27461384]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.56506324 0.02603457 0.26095581]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.5792998  0.02579975 0.26105924]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.5792998  0.02579975 0.26105924]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.74148523 0.05985554 0.42915832]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]\n",
      " [0.62674869 0.05190432 0.48552271]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 6.444\n",
      "(*) epoch 2, cost 3.201\n",
      "(*) epoch 3, cost 2.493\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.936\n",
      "(*) epoch 2, cost 4.666\n",
      "(*) epoch 3, cost 3.780\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.48061425 0.3694403  0.19364619]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.64273628 0.30214934 0.23904706]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.67192392 0.30124581 0.24836346]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.51170105 0.35186538 0.20265122]\n",
      " [0.47128521 0.37087925 0.19020076]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.41552511 0.45056907 0.31810716]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.5753376  0.33479631 0.22307637]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.46702483 0.38998485 0.22036214]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.64273628 0.30214934 0.23904706]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.43935124 0.38531589 0.18093667]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.47128521 0.37087925 0.19020076]\n",
      " [0.47102118 0.38224621 0.20645909]\n",
      " [0.48061425 0.3694403  0.19364619]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.42057065 0.44040021 0.29271844]\n",
      " [0.56778937 0.34472035 0.22098697]\n",
      " [0.5753376  0.33479631 0.22307637]\n",
      " [0.48061425 0.3694403  0.19364619]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n",
      "female_pred_labels are: [0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 1 1 0 1 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.181\n",
      "(*) epoch 2, cost 2.882\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.898\n",
      "(*) epoch 2, cost 2.783\n",
      "(*) epoch 3, cost 2.216\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.30 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.93161345 0.86168264 0.21238613]\n",
      " [0.95994942 0.93817511 0.14982461]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.95994942 0.93817511 0.14982461]\n",
      " [0.95258612 0.87429942 0.16941244]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.9647645  0.20137435 0.55551963]\n",
      " [0.95258612 0.87429942 0.16941244]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.96811451 0.29117301 0.49338741]\n",
      " [0.95258612 0.87429942 0.16941244]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.95994942 0.93817511 0.14982461]\n",
      " [0.95994942 0.93817511 0.14982461]\n",
      " [0.95258612 0.87429942 0.16941244]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.95258612 0.87429942 0.16941244]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.95258612 0.87429942 0.16941244]\n",
      " [0.95994942 0.93817511 0.14982461]\n",
      " [0.93161345 0.86168264 0.21238613]\n",
      " [0.94661198 0.31336798 0.4996807 ]\n",
      " [0.94661198 0.31336798 0.4996807 ]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "    female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "    trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s = \\\n",
    "    run_proc_multi(simulate_wrapper, custom_train_reps, svm.SVC , n_times = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = \"../outputs/sim1_svm_scores.csv\"\n",
    "save_scores(male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "        female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "        trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans female to female accuracy increment is '13.7%\n",
      "median trans female to female accuracy increment is '2.0%\n",
      "average trans female to female accuracy f1 is '15.1%\n",
      "median trans female to female accuracy f1 is '2.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Larger is better (>0)\n",
    "\"\"\"\n",
    "hist_plot(score_path, filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans female to female accuracy increment is '18.2%\n",
      "median trans female to female accuracy increment is '7.0%\n",
      "average trans female to female accuracy f1 is '19.6%\n",
      "median trans female to female accuracy f1 is '6.7%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "female accuracy > 0.7 filtered out \n",
    "\"\"\"\n",
    "\n",
    "hist_plot(score_path, filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
