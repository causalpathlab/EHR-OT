{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation goals\n",
    "\n",
    "* Categorical response variable\n",
    "\n",
    "* Different feature distribution for different domains\n",
    "\n",
    "Simulation\n",
    "\n",
    "* $D$: total number of features\n",
    "\n",
    "* $d_{1}$: number of features with higher frequency in a domain 1\n",
    "\n",
    "* $d_{2}$: number of features with higher frequency in a domain 2\n",
    "\n",
    "\n",
    "* $d_{1} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$\n",
    "\n",
    "* $d_{2} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$ ($d_{1} + d_{2} \\le D$)\n",
    "\n",
    "* $k \\in [D]$ for indexing feature\n",
    "\n",
    "* Let $\\Delta_{r} = \\{j \\in [D]: \\textrm{feature } j \\textrm{ is more frequent in a domain } r \\}$\n",
    "\n",
    "* Sample $\\Delta_{1} \\subseteq [D]$ such that $|\\Delta_{1}| = d_{1}$ \n",
    "\n",
    "* Sample $\\Delta_{2} \\subseteq [D]\\backslash \\Delta_{1}$ such that $|\\Delta_{2}| = d_{2}$\n",
    "\n",
    "* Let $\\alpha_{1} \\overset{\\Delta}{=} \\left( \\alpha_{11}, \\ldots, \\alpha_{1D} \\right)$ be a feature frequency vector for a domain 1\n",
    "\n",
    "* Let $\\alpha_{2} \\overset{\\Delta}{=} \\left( \\alpha_{21}, \\ldots, \\alpha_{2D} \\right)$ be a feature frequency vector for a domain 2\n",
    "\n",
    "\n",
    "* For each $k \\in [D]$: \n",
    "\n",
    "    * If $k \\in \\Delta_{1}$, $\\alpha_{1k} > \\alpha_{2k}$\n",
    "\n",
    "    * If $k \\in \\Delta_{2}$, $\\alpha_{2k} > \\alpha_{1k}$\n",
    "\n",
    "    * Otherwise $\\alpha_{1k} = \\alpha_{2k}$\n",
    "\n",
    "\n",
    "* Sample $\\rho_{1} \\sim \\operatorname{Dir}(\\alpha_{1})$\n",
    "\n",
    "* Sample $\\rho_{2} \\sim \\operatorname{Dir}(\\alpha_{2})$\n",
    "\n",
    "* Sample a code-specific contribution to mortality: $W_{k} \\sim  \\max\\{ \\mathcal{N}\\!\\left(0,1\\right), 0\\}$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "    * $\\tilde{X}_{i} \\sim \\operatorname{Multi}(n_{i}; \\rho_{r})$ where $\\tilde{X}_{i}$ is a vector of counts for each diagnosis code/feature, $n_i = 3k$.\n",
    "\n",
    "\t* We set $X_{ik} = \\min \\left\\{ \\tilde{X}_{ik}, 1 \\right\\}$ where $\\tilde{X}_{ik}$ is a count for a diagnosis code/feature $k$, $k \\in [D]$\n",
    "\n",
    "* For all patient $i$ in a domain $r$\n",
    "\n",
    "    * $b = -\\operatorname{Mean}(\\sum_{k} W_{k} X_{ik})$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "\t* pathogenic score $\\bar{p}_{i} = \\operatorname{sigmoid}(\\sum_{k} W_{k} X_{ik} + b)$ (aka a liability model)\n",
    "\n",
    "    <!-- * If $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; else $Y_{i} = 0$. -->\n",
    "\n",
    "\t* Sample $Y_{i} \\sim \\operatorname{Bern}(\\bar{p}_{i})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/deep_patient/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from deep_patient.sda import SDA\n",
    "from math import floor, exp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "base_dir = \"/home/wanxinli/deep_patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    # We set the proportions of d_1 codes, d_2 codes, and (D-d_1-d_2) codes to be 2:1:1.5\n",
    "    # unit_1 = 1/(0.5*d_1-0.5*d_2+1.5*D)\n",
    "    # alpha_1 = [2*unit_1]*d_1\n",
    "    # alpha_1.extend([unit_1]*d_2)\n",
    "    # alpha_1.extend([1.5*unit_1]*(D-d_1-d_2))\n",
    "    unit_1 = 1/(2*d_1-2*d_2+3*D)\n",
    "    alpha_1 = [5*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([3*unit_1]*(D-d_1-d_2))\n",
    "\n",
    "    # We set the proportions of d_1 codes, d_2 codes, and (D-d_1-d_2) codes to be 1:2:1.5\n",
    "    # unit_2 = 1/(-0.5*d_1+0.5*d_2+1.5*D)\n",
    "    # alpha_2 = [2*unit_2]*d_1\n",
    "    # alpha_2.extend([unit_2]*d_2)\n",
    "    # alpha_2.extend([1.5*unit_2]*(D-d_1-d_2))    \n",
    "    unit_2 = 1/(-2*d_1+2*d_2+3*D)\n",
    "    alpha_2 = [unit_2]*d_1\n",
    "    alpha_2.extend([5*unit_2]*d_2)\n",
    "    alpha_2.extend([3*unit_2]*(D-d_1-d_2))  \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [max(0, W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            cur_sum = np.sum(np.multiply(W, X_i))\n",
    "            all_sum.append(cur_sum)\n",
    "\n",
    "        all_sum = np.array(all_sum)\n",
    "        b = -np.mean(all_sum) \n",
    "        \n",
    "        P = []\n",
    "        for cur_sum in all_sum:\n",
    "            p_i = sigmoid(3*(cur_sum+b))\n",
    "            P.append(p_i)\n",
    "            Y_i = 0\n",
    "            if p_i >= 0.5: # TODO: mimic exact logistic regression, change to np.random.binomial later\n",
    "                Y_i = 1\n",
    "            # Y_i = np.random.binomial(1, p_i) # too much noise, domain 1 data cannot learn well\n",
    "            Y.append(int(Y_i))\n",
    "        # print(\"P is:\", P)\n",
    "\n",
    "            \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), label_1, np.array(feature_2), label_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Wrapper function with different set ups for simulate()\n",
    "\"\"\"\n",
    "def simulate_1(num_patient):\n",
    "    D = 20\n",
    "    d_1 = 5\n",
    "    d_2 = 5\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train deep patient model and generate representations for males and females\n",
    "\"\"\"\n",
    "\n",
    "def custom_train_reps(male_seqs, female_seqs):\n",
    "    \"\"\" \n",
    "    Customized training algorithm for generating male representations and female representations\n",
    "    \n",
    "    :returns: male representations, female representations\n",
    "    \"\"\"\n",
    "\n",
    "    # customized parameters\n",
    "    nhidden = 3\n",
    "    nlayer = 1\n",
    "\n",
    "    # for males\n",
    "    # initiate the model\n",
    "    male_sda = SDA(male_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    male_sda.train(male_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    male_reps = male_sda.apply(male_seqs)\n",
    "\n",
    "    # for females\n",
    "    # initiate the model\n",
    "    female_sda = SDA(female_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    female_sda.train(female_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    female_reps = female_sda.apply(female_seqs)\n",
    "    return male_reps, female_reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(male_reps, male_labels, female_reps, female_labels, trans_female_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=130)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\", s=130)\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=100)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\", s=100)\n",
    "\n",
    "    ax.scatter(trans_female_reps[female_0,0], trans_female_reps[female_0,1], trans_female_reps[female_0,2], color='green', label=\"trans female 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_female_reps[female_1,0], trans_female_reps[female_1,1], trans_female_reps[female_1,2], color='green', label=\"trans female 1\",  alpha=0.5, marker=\"x\", s=70)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_stats = []\n",
    "# for _ in range(100):\n",
    "#     male_seqs, male_labels, female_seqs, female_labels = simulate_1(num_patient=100)\n",
    "#     ot_emds = [ot.da.SinkhornTransport(reg_e=1e-1)]\n",
    "#     titles = [\"Sinkhorn\"]\n",
    "#     male_reps, female_reps = custom_train_reps(male_seqs, female_seqs)\n",
    "#     ot_emd = ot_emds[0]\n",
    "#     try:\n",
    "#         ot_emd.fit(Xs=female_reps, Xt=male_reps)\n",
    "#     except Exception:\n",
    "#         continue\n",
    "#     trans_female_reps = ot_emd.transform(Xs=female_reps)\n",
    "\n",
    "#     # plot_scatter(male_reps, male_labels, female_reps, female_labels, trans_female_reps, titles[i])\n",
    "\n",
    "#     # print(\"print only accuracies\")\n",
    "#     stats = None\n",
    "#     try:\n",
    "#         stats = cal_stats_binary(male_reps, male_labels, female_reps, female_labels, \\\n",
    "#             trans_female_reps, svm.SVC, 100000)\n",
    "#     except Exception:\n",
    "#         continue\n",
    "#     # print(stats)\n",
    "#     if stats[4] >= stats[0] or stats[4] > 0.7:\n",
    "#         continue\n",
    "#     all_stats.append([stats[0], stats[4], stats[8]])\n",
    "# print(all_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_opp(male_reps, male_labels, female_reps, female_labels, trans_male_reps, title):\n",
    "    male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "    male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "    female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "    female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(male_reps[male_0,0], male_reps[male_0,1], male_reps[male_0,2], color='red', label=\"male 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(male_reps[male_1,0], male_reps[male_1,1], male_reps[male_1,2], color='red', label=\"male 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(female_reps[female_0,0], female_reps[female_0,1], female_reps[female_0,2], color='blue', label=\"female 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(female_reps[female_1,0], female_reps[female_1,1], female_reps[female_1,2], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(trans_male_reps[male_0,0], trans_male_reps[male_0,1], trans_male_reps[male_0,2], color='green', label=\"trans male 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_male_reps[male_1,0], trans_male_reps[male_1,1], trans_male_reps[male_1,2], color='green', label=\"trans male 1\",  alpha=0.5, marker=\"x\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Does not work well\n",
    "\"\"\"\n",
    "\n",
    "male_seqs, male_labels, female_seqs, female_labels = simulate_1(num_patient=50)\n",
    "\n",
    "ot_emds = [ ot.da.SinkhornLpl1Transport(reg_e=0, reg_cl=0), ot.da.SinkhornL1l2Transport(reg_e=0, reg_cl=0, max_iter=20, verbose=True)]\n",
    "titles = [\"Sinkhorn lasso\", \"Sinkhorn l1l2\"]\n",
    "\n",
    "for i in range(len(ot_emds)):\n",
    "    ot_emd = ot_emds[i]\n",
    "    male_reps, female_reps = custom_train_reps(male_seqs, female_seqs)\n",
    "    ot_emd = ot_emds[i]\n",
    "    ot_emd.fit(Xs=male_reps, ys=np.array(male_labels), Xt=female_reps)\n",
    "    trans_male_reps = ot_emd.transform(Xs=male_reps)\n",
    "\n",
    "    plot_scatter_opp(male_reps, male_labels, female_reps, female_labels, trans_male_reps, titles[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_func = svm.SVC\n",
    "# male_model = model_func(kernel=\"rbf\")\n",
    "# male_model.fit(male_reps, male_labels)\n",
    "# male_pred_labels = male_model.predict(male_reps)\n",
    "# print(male_model.predict(male_reps))\n",
    "# print(accuracy_score(male_labels, male_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import svm, datasets\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# def plot_SVC(X, Y, clf):\n",
    "#     #make it binary classification problem\n",
    "#     Y = np.array(Y)\n",
    "#     X = X[np.logical_or(Y==0,Y==1)]\n",
    "#     Y = Y[np.logical_or(Y==0,Y==1)]\n",
    "\n",
    "#     # The equation of the separating plane is given by all x so that np.dot(svc.coef_[0], x) + b = 0.\n",
    "#     # Solve for w3 (z)\n",
    "#     z = lambda x,y: (-clf.intercept_[0]-clf.coef_[0][0]*x -clf.coef_[0][1]*y) / clf.coef_[0][2]\n",
    "\n",
    "#     tmp = np.linspace(-5,5,30)\n",
    "#     x,y = np.meshgrid(tmp,tmp)\n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     ax  = fig.add_subplot(111, projection='3d')\n",
    "#     ax.plot3D(X[Y==0,0], X[Y==0,1], X[Y==0,2],'ob')\n",
    "#     ax.plot3D(X[Y==1,0], X[Y==1,1], X[Y==1,2],'sr')\n",
    "#     ax.plot_surface(x, y, z(x,y))\n",
    "#     ax.view_init(30, 60)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_SVC(male_reps, male_labels, male_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ot_sinkhorn = ot.da.SinkhornTransport(reg_e=0.0001)\n",
    "# ot_sinkhorn.fit(Xs=female_reps, Xt=male_reps)\n",
    "# np.savetxt(\"../outputs/coupling.txt\", ot_sinkhorn.coupling_)\n",
    "# trans_female_reps = ot_sinkhorn.transform(Xs=female_reps)\n",
    "\n",
    "# np.savetxt(\"../outputs/female_seqs.txt\", female_seqs, fmt=\"%d\")\n",
    "# np.savetxt(\"../outputs/male_reps.txt\", male_reps)\n",
    "# np.savetxt(\"../outputs/female_reps.txt\", female_reps)\n",
    "# np.savetxt(\"../outputs/trans_female_reps.txt\", trans_female_reps)\n",
    "\n",
    "# print(\"printing sinkhorn OT accuracies\")\n",
    "# print(cal_stats_binary(male_reps, male_labels, female_reps, female_labels, \\\n",
    "#     trans_female_reps, svm.SVC, max_iter=100000))\n",
    "\n",
    "# # by EMD OT\n",
    "# ot_emd = ot.da.EMDTransport(max_iter=100000)\n",
    "# ot_emd.fit(Xs=female_reps, Xt=male_reps)\n",
    "# trans_female_reps = ot_emd.transform(Xs=female_reps)\n",
    "# np.savetxt(\"../outputs/trans_balanced_female_reps.txt\", trans_female_reps)\n",
    "# print(\"printing balanced OT accuracies\")\n",
    "# print(cal_stats_binary(male_reps, male_labels, female_reps, female_labels, \\\n",
    "#     trans_female_reps, linear_model.LogisticRegression, max_iter=100000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Plot representations in 2D\n",
    "\"\"\"\n",
    "\n",
    "# male_1 = [i for i, x in enumerate(male_labels) if x == 1]\n",
    "# male_0 = [i for i, x in enumerate(male_labels) if x == 0]\n",
    "# female_1 = [i for i, x in enumerate(female_labels) if x == 1]\n",
    "# female_0 = [i for i, x in enumerate(female_labels) if x == 0]\n",
    "\n",
    "# plt.scatter(male_reps[male_0,0], male_reps[male_0,1], color='red', label=\"male 0\", alpha=0.5)\n",
    "# plt.scatter(male_reps[male_1,0], male_reps[male_1,1], color='red', label=\"male 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "# plt.scatter(female_reps[female_0,0], female_reps[female_0,1], color='blue', label=\"female 0\", alpha=0.5)\n",
    "# plt.scatter(female_reps[female_1,0], female_reps[female_1,1], color='blue', label=\"female 1\", alpha=0.5, marker=\"x\")\n",
    "# plt.scatter(trans_female_reps[female_0,0], trans_female_reps[female_0,1], color='green', label=\"trans female 0\",  alpha=0.5)\n",
    "# plt.scatter(trans_female_reps[female_1,0], trans_female_reps[female_1,1], color='green', label=\"trans female 1\",  alpha=0.5, marker=\"x\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\"\"\" \n",
    "https://stackoverflow.com/questions/67455143/plot-svm-decision-boundary\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling run_proc_multi\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.733\n",
      "(*) epoch 2, cost 3.641\n",
      "(*) epoch 3, cost 3.229\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 1.40 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.510\n",
      "(*) epoch 2, cost 2.029\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.8762237  0.02666885 0.19330049]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.1347373  0.17914014 0.74570393]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.91926119 0.02137793 0.18341861]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.1347373  0.17914014 0.74570393]\n",
      " [0.00899016 0.79196809 0.35334847]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.9050079  0.02317885 0.18690605]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.1347373  0.17914014 0.74570393]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.8762237  0.02666885 0.19330049]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.1347373  0.17914014 0.74570393]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.91926119 0.02137793 0.18341861]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.1347373  0.17914014 0.74570393]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.1347373  0.17914014 0.74570393]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]\n",
      " [0.55579898 0.1608782  0.32854664]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.328\n",
      "(*) epoch 2, cost 0.600\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.068\n",
      "(*) epoch 2, cost 2.676\n",
      "(*) epoch 3, cost 1.990\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.53004286 0.66149377 0.89029614]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.69594812 0.76503477 0.86100192]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.70498158 0.77233698 0.85942088]\n",
      " [0.53004286 0.66149377 0.89029614]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.66965102 0.75609554 0.86534843]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.51138767 0.64496022 0.89366838]\n",
      " [0.66965102 0.75609554 0.86534843]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.954\n",
      "(*) epoch 2, cost 2.557\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.580\n",
      "(*) epoch 2, cost 2.217\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.08771787 0.95062743 0.74172718]\n",
      " [0.10834244 0.95527301 0.62500593]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.10834244 0.95527301 0.62500593]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.08771787 0.95062743 0.74172718]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.11348949 0.92391037 0.40952293]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.08771787 0.95062743 0.74172718]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.08771787 0.95062743 0.74172718]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.08771787 0.95062743 0.74172718]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.08771787 0.95062743 0.74172718]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.11348949 0.92391037 0.40952293]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.08771787 0.95062743 0.74172718]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.08771787 0.95062743 0.74172718]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.0807168  0.95030396 0.79515564]\n",
      " [0.11348949 0.92391037 0.40952293]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.10834244 0.95527301 0.62500593]\n",
      " [0.12012923 0.94170003 0.36144182]\n",
      " [0.09744334 0.86642787 0.30039703]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09830724 0.92009327 0.29299772]\n",
      " [0.09744334 0.86642787 0.30039703]]\n",
      "female_labels are: [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "female_pred_labels are: [1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 1 1 1 0 1 1 1 0 1 0 0 0 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.761\n",
      "(*) epoch 2, cost 1.960\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.745\n",
      "(*) epoch 2, cost 4.022\n",
      "(*) epoch 3, cost 3.058\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.03606255 0.24001918 0.02623682]\n",
      " [0.00996429 0.63896481 0.00964914]\n",
      " [0.01220574 0.62485391 0.01215102]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.00996429 0.63896481 0.00964914]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.07772891 0.35126964 0.08792748]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.0182453  0.45175779 0.01718848]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.00996429 0.63896481 0.00964914]\n",
      " [0.03445068 0.20964125 0.01995989]\n",
      " [0.05950761 0.31234498 0.06237757]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.07772891 0.35126964 0.08792748]\n",
      " [0.07772891 0.35126964 0.08792748]\n",
      " [0.05950761 0.31234498 0.06237757]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.00996429 0.63896481 0.00964914]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.02802498 0.22485829 0.01556599]\n",
      " [0.00996429 0.63896481 0.00964914]\n",
      " [0.03445068 0.20964125 0.01995989]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.03445068 0.20964125 0.01995989]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.01205786 0.35441859 0.00760276]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.00996429 0.63896481 0.00964914]\n",
      " [0.01422092 0.56059562 0.01418473]\n",
      " [0.00996429 0.63896481 0.00964914]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.01080904 0.6836545  0.01097058]\n",
      " [0.01081003 0.38589212 0.00707551]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.03606255 0.24001918 0.02623682]\n",
      " [0.01422092 0.56059562 0.01418473]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.106\n",
      "(*) epoch 2, cost 2.981\n",
      "(*) epoch 3, cost 2.514\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.655\n",
      "(*) epoch 2, cost 1.408\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.08336162 0.65844159 0.18629233]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.1859551  0.53527235 0.52498664]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.1859551  0.53527235 0.52498664]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.01290449 0.72679609 0.10872137]\n",
      " [0.1859551  0.53527235 0.52498664]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.1859551  0.53527235 0.52498664]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.1859551  0.53527235 0.52498664]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.01387975 0.70832335 0.16865928]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.08336162 0.65844159 0.18629233]\n",
      " [0.16577479 0.59244387 0.28826109]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]\n",
      " [0.16218129 0.59611417 0.28004849]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.571\n",
      "(*) epoch 2, cost 1.157\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.891\n",
      "(*) epoch 2, cost 2.011\n",
      "(*) epoch 3, cost 1.103\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.08817636 0.16568712 0.23738702]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.12158149 0.20986251 0.20708402]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.12158149 0.20986251 0.20708402]\n",
      " [0.03900919 0.10978069 0.44432502]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.12158149 0.20986251 0.20708402]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.12158149 0.20986251 0.20708402]\n",
      " [0.24290919 0.36667672 0.05520492]\n",
      " [0.24290919 0.36667672 0.05520492]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.346\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.100\n",
      "(*) epoch 2, cost 2.407\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74241453 0.01529201 0.88546327]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.59716667 0.43795406 0.5191376 ]\n",
      " [0.74241453 0.01529201 0.88546327]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241453 0.01529201 0.88546327]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74241868 0.01527994 0.88547373]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74242861 0.01525103 0.88549878]\n",
      " [0.74242861 0.01525103 0.88549878]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241453 0.01529201 0.88546327]\n",
      " [0.59716667 0.43795406 0.5191376 ]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241453 0.01529201 0.88546327]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74242859 0.0152511  0.88549873]\n",
      " [0.74242861 0.01525103 0.88549878]\n",
      " [0.74242583 0.01525913 0.88549177]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74241067 0.01530325 0.88545353]\n",
      " [0.74242583 0.01525913 0.88549177]]\n",
      "female_labels are: [0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.774\n",
      "(*) epoch 2, cost 3.381\n",
      "(*) epoch 3, cost 2.967\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.484\n",
      "(*) epoch 2, cost 3.029\n",
      "(*) epoch 3, cost 1.882\n",
      "(*) epoch 4, cost 1.517\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.23875874 0.50253686 0.04044465]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.20467675 0.68729442 0.0192086 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.20467675 0.68729442 0.0192086 ]\n",
      " [0.23875874 0.50253686 0.04044465]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.23875874 0.50253686 0.04044465]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.20467675 0.68729442 0.0192086 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.20383937 0.44324362 0.04508943]\n",
      " [0.20383937 0.44324362 0.04508943]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.20383937 0.44324362 0.04508943]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.25780097 0.41444976 0.06689497]\n",
      " [0.23875874 0.50253686 0.04044465]\n",
      " [0.14516578 0.47710789 0.0116227 ]\n",
      " [0.14516578 0.47710789 0.0116227 ]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 1 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 10\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 11.336\n",
      "(*) epoch 2, cost 6.458\n",
      "(*) epoch 3, cost 4.840\n",
      "(*) epoch 4, cost 4.263\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.539\n",
      "(*) epoch 2, cost 1.354\n",
      "(*) epoch 3, cost 0.778\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.0912903  0.51629894 0.66400181]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.0912903  0.51629894 0.66400181]\n",
      " [0.0912903  0.51629894 0.66400181]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.0912903  0.51629894 0.66400181]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.0912903  0.51629894 0.66400181]\n",
      " [0.0912903  0.51629894 0.66400181]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.0912903  0.51629894 0.66400181]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]\n",
      " [0.40125041 0.21214883 0.4557423 ]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.438\n",
      "(*) epoch 2, cost 2.989\n",
      "(*) epoch 3, cost 2.412\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.671\n",
      "(*) epoch 2, cost 3.164\n",
      "(*) epoch 3, cost 2.197\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.75504065 0.34138248 0.41813203]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.69367758 0.27647383 0.34588209]\n",
      " [0.51866729 0.63873047 0.64908266]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.75504065 0.34138248 0.41813203]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.77931836 0.42730498 0.5071474 ]\n",
      " [0.78017728 0.41051939 0.58162416]\n",
      " [0.77931836 0.42730498 0.5071474 ]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.972\n",
      "(*) epoch 2, cost 1.655\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.212\n",
      "(*) epoch 2, cost 0.556\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.92349228 0.2060302  0.09390643]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.53417072 0.52782432 0.50230819]\n",
      " [0.92349228 0.2060302  0.09390643]\n",
      " [0.53417072 0.52782432 0.50230819]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.148\n",
      "(*) epoch 2, cost 1.630\n",
      "(*) epoch 3, cost 1.256\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.420\n",
      "(*) epoch 2, cost 2.641\n",
      "(*) epoch 3, cost 2.173\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.81193444 0.26340815 0.19099722]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.71986555 0.85465636 0.68990937]\n",
      " [0.657596   0.95957572 0.80773944]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.82330325 0.27423398 0.17586463]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.71986555 0.85465636 0.68990937]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.71986555 0.85465636 0.68990937]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.78076852 0.6569045  0.47786135]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.71986555 0.85465636 0.68990937]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.71986555 0.85465636 0.68990937]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.71986555 0.85465636 0.68990937]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]\n",
      " [0.42256812 0.93426544 0.85378168]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.538\n",
      "(*) epoch 2, cost 2.496\n",
      "(*) epoch 3, cost 1.848\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.086\n",
      "(*) epoch 2, cost 2.441\n",
      "(*) epoch 3, cost 1.887\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.27038596 0.76799878 0.38552319]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.25864315 0.77418425 0.36670131]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.25857364 0.77548368 0.36527088]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.25857364 0.77548368 0.36527088]\n",
      " [0.20587719 0.83069675 0.25208681]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.25864315 0.77418425 0.36670131]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.25864315 0.77418425 0.36670131]\n",
      " [0.23374766 0.78836889 0.32598952]\n",
      " [0.10921861 0.85427067 0.1348617 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.23374766 0.78836889 0.32598952]\n",
      " [0.27038596 0.76799878 0.38552319]\n",
      " [0.25864315 0.77418425 0.36670131]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.23374766 0.78836889 0.32598952]\n",
      " [0.27038596 0.76799878 0.38552319]\n",
      " [0.27038596 0.76799878 0.38552319]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.27038596 0.76799878 0.38552319]\n",
      " [0.25857364 0.77548368 0.36527088]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.30605477 0.78468047 0.39771311]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.12899622 0.89464046 0.13618827]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.25737115 0.80580341 0.3262865 ]\n",
      " [0.30605477 0.78468047 0.39771311]\n",
      " [0.27038596 0.76799878 0.38552319]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.29087703 0.79112535 0.3752277 ]\n",
      " [0.27038596 0.76799878 0.38552319]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.266\n",
      "(*) epoch 2, cost 0.917\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.584\n",
      "(*) epoch 2, cost 3.430\n",
      "(*) epoch 3, cost 2.820\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.62366854 0.15461061 0.11047817]\n",
      " [0.58544559 0.33368007 0.49834459]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.63534805 0.28045988 0.37916455]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.60163416 0.14970572 0.10215867]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.6245595  0.29200457 0.40509603]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.58544559 0.33368007 0.49834459]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.63534805 0.28045988 0.37916455]\n",
      " [0.6245595  0.29200457 0.40509603]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.58544559 0.33368007 0.49834459]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.58544559 0.33368007 0.49834459]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.60621738 0.31047546 0.44639833]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.61868244 0.28762151 0.39596451]\n",
      " [0.62366854 0.15461061 0.11047817]\n",
      " [0.62849603 0.28284397 0.3848247 ]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 1 0 1 0]\n",
      "trans_female_pred_labels are: [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 0 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.880\n",
      "(*) epoch 2, cost 2.261\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.123\n",
      "(*) epoch 2, cost 2.526\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.436446   0.03363467 0.59813124]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.39783855 0.0384837  0.52436956]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.39783855 0.0384837  0.52436956]\n",
      " [0.3409094  0.03127637 0.56282914]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.89986059 0.10197085 0.21159507]\n",
      " [0.33096249 0.02336277 0.66382127]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.89986059 0.10197085 0.21159507]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.89986059 0.10197085 0.21159507]\n",
      " [0.3409094  0.03127637 0.56282914]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.436446   0.03363467 0.59813124]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.3409094  0.03127637 0.56282914]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.3409094  0.03127637 0.56282914]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.39783855 0.0384837  0.52436956]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.89986059 0.10197085 0.21159507]\n",
      " [0.39783855 0.0384837  0.52436956]\n",
      " [0.39783855 0.0384837  0.52436956]\n",
      " [0.28182468 0.02335552 0.68461218]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.80228833 0.08877255 0.24950955]\n",
      " [0.59874648 0.04887275 0.4890024 ]\n",
      " [0.59874648 0.04887275 0.4890024 ]]\n",
      "female_labels are: [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1\n",
      " 1 0 0 1 0 1 1 0 1 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.199\n",
      "(*) epoch 2, cost 2.783\n",
      "(*) epoch 3, cost 2.408\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.133\n",
      "(*) epoch 2, cost 1.569\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.15416753 0.49491201 0.85875128]\n",
      " [0.12739536 0.47246871 0.91507563]\n",
      " [0.12039084 0.47711411 0.91576285]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.12854304 0.47628787 0.91448671]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.12739536 0.47246871 0.91507563]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.12039084 0.47711411 0.91576285]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.12854304 0.47628787 0.91448671]\n",
      " [0.12039084 0.47711411 0.91576285]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.12039084 0.47711411 0.91576285]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.09976074 0.58128872 0.83231505]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.09976074 0.58128872 0.83231505]\n",
      " [0.09976074 0.58128872 0.83231505]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]\n",
      " [0.15416753 0.49491201 0.85875128]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.652\n",
      "(*) epoch 2, cost 2.643\n",
      "(*) epoch 3, cost 2.219\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.710\n",
      "(*) epoch 2, cost 3.606\n",
      "(*) epoch 3, cost 2.922\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.21707844 0.58288368 0.61737405]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.66963131 0.69435002 0.77151426]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.66963131 0.69435002 0.77151426]\n",
      " [0.65247397 0.68894305 0.77731795]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.40517189 0.62986244 0.7554564 ]\n",
      " [0.58169997 0.67063208 0.78666326]\n",
      " [0.58169997 0.67063208 0.78666326]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.40517189 0.62986244 0.7554564 ]\n",
      " [0.66963131 0.69435002 0.77151426]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.65215816 0.70369011 0.78222628]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.5603542  0.66530427 0.78945646]\n",
      " [0.65247397 0.68894305 0.77731795]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.65247397 0.68894305 0.77731795]\n",
      " [0.67388713 0.70763283 0.77588292]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.63511408 0.68378364 0.78325625]\n",
      " [0.49452668 0.66519032 0.89775445]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.50597157 0.67437872 0.89755109]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.66963131 0.69435002 0.77151426]\n",
      " [0.65247397 0.68894305 0.77731795]\n",
      " [0.66963131 0.69435002 0.77151426]\n",
      " [0.65247397 0.68894305 0.77731795]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.63511408 0.68378364 0.78325625]\n",
      " [0.66963131 0.69435002 0.77151426]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.40517189 0.62986244 0.7554564 ]\n",
      " [0.30159255 0.59501549 0.69740064]\n",
      " [0.30159255 0.59501549 0.69740064]]\n",
      "female_labels are: [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1\n",
      " 0 0 0 0 1 0 0 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.896\n",
      "(*) epoch 2, cost 2.543\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.124\n",
      "(*) epoch 2, cost 1.851\n",
      "(*) epoch 3, cost 1.480\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06867119 0.11030896 0.01452504]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.06867119 0.11030896 0.01452504]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.07602031 0.11006614 0.01499732]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.3813512  0.12156415 0.12439725]\n",
      " [0.22423336 0.10534636 0.02540777]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.07113011 0.11022746 0.01467974]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.3813512  0.12156415 0.12439725]\n",
      " [0.06990857 0.11026758 0.0146014 ]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]\n",
      " [0.50594819 0.19377852 0.26948172]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 0 1 1 0 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.214\n",
      "(*) epoch 2, cost 3.393\n",
      "(*) epoch 3, cost 2.538\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.273\n",
      "(*) epoch 2, cost 4.135\n",
      "(*) epoch 3, cost 2.670\n",
      "(*) epoch 4, cost 2.000\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.12524931 0.58881892 0.60539545]\n",
      " [0.03298553 0.61565701 0.78226303]\n",
      " [0.12524931 0.58881892 0.60539545]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.03298553 0.61565701 0.78226303]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.18364764 0.5236554  0.51270574]\n",
      " [0.12524931 0.58881892 0.60539545]\n",
      " [0.18364764 0.5236554  0.51270574]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.28506639 0.32566084 0.27649366]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.12524931 0.58881892 0.60539545]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.28506639 0.32566084 0.27649366]\n",
      " [0.03298553 0.61565701 0.78226303]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.18364764 0.5236554  0.51270574]\n",
      " [0.18364764 0.5236554  0.51270574]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.12524931 0.58881892 0.60539545]\n",
      " [0.18364764 0.5236554  0.51270574]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.03298553 0.61565701 0.78226303]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.18364764 0.5236554  0.51270574]\n",
      " [0.18364764 0.5236554  0.51270574]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.26391391 0.43278637 0.38824183]\n",
      " [0.12524931 0.58881892 0.60539545]\n",
      " [0.26391391 0.43278637 0.38824183]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 1 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.137\n",
      "(*) epoch 2, cost 1.547\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.372\n",
      "(*) epoch 2, cost 2.266\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.28606465 0.27748879 0.28508281]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.28606465 0.27748879 0.28508281]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.0610901  0.67451967 0.01990488]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.0691381  0.40037806 0.30200581]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.28606465 0.27748879 0.28508281]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.0691381  0.40037806 0.30200581]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.27494653 0.37211603 0.22109902]\n",
      " [0.28606465 0.27748879 0.28508281]\n",
      " [0.27494653 0.37211603 0.22109902]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.433\n",
      "(*) epoch 2, cost 2.848\n",
      "(*) epoch 3, cost 1.836\n",
      "(*) epoch 4, cost 1.494\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.083\n",
      "(*) epoch 2, cost 1.742\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.69797212 0.08869431 0.58854026]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.79407248 0.09769387 0.56948567]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.79407248 0.09769387 0.56948567]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.60316959 0.1154857  0.46086081]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.60316959 0.1154857  0.46086081]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.60316959 0.1154857  0.46086081]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.81280743 0.11907209 0.48653886]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.60316959 0.1154857  0.46086081]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.54282209 0.09605145 0.52823286]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.60316959 0.1154857  0.46086081]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.60316959 0.1154857  0.46086081]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.54282209 0.09605145 0.52823286]\n",
      " [0.76591099 0.06926267 0.67859757]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]\n",
      " [0.69797212 0.08869431 0.58854026]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.973\n",
      "(*) epoch 2, cost 3.730\n",
      "(*) epoch 3, cost 3.201\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.515\n",
      "(*) epoch 2, cost 3.994\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.92022138 0.08436516 0.65917797]\n",
      " [0.92207592 0.25474136 0.23242884]\n",
      " [0.90957469 0.26773141 0.23169224]\n",
      " [0.92847124 0.24910942 0.22465933]\n",
      " [0.91912103 0.06820781 0.69569252]\n",
      " [0.91701838 0.04660403 0.74143942]\n",
      " [0.90957469 0.26773141 0.23169224]\n",
      " [0.93596287 0.21252431 0.29789554]\n",
      " [0.92022138 0.08436516 0.65917797]\n",
      " [0.93347143 0.16854171 0.41806755]\n",
      " [0.92050658 0.25726262 0.22985937]\n",
      " [0.89829112 0.27421881 0.26248032]\n",
      " [0.90171805 0.27471529 0.24566943]\n",
      " [0.92089012 0.25736779 0.22490311]\n",
      " [0.92410008 0.25446538 0.2222947 ]\n",
      " [0.90171805 0.27471529 0.24566943]\n",
      " [0.89204789 0.26744514 0.30980669]\n",
      " [0.92289941 0.25586528 0.22230762]\n",
      " [0.92022138 0.08436516 0.65917797]\n",
      " [0.9208885  0.09420739 0.63384216]\n",
      " [0.92022138 0.08436516 0.65917797]\n",
      " [0.89829112 0.27421881 0.26248032]\n",
      " [0.90532768 0.25661138 0.28491907]\n",
      " [0.92027364 0.07837951 0.67474987]\n",
      " [0.9208885  0.09420739 0.63384216]\n",
      " [0.90617846 0.2533888  0.29062723]\n",
      " [0.92022138 0.08436516 0.65917797]\n",
      " [0.91749486 0.26141657 0.22357221]\n",
      " [0.94410144 0.24103509 0.24429796]\n",
      " [0.92305719 0.25944532 0.2236055 ]\n",
      " [0.89829112 0.27421881 0.26248032]\n",
      " [0.91912403 0.07242695 0.68929485]\n",
      " [0.92635856 0.0917688  0.62778114]\n",
      " [0.92022138 0.08436516 0.65917797]\n",
      " [0.92215135 0.10975045 0.59546213]\n",
      " [0.90967501 0.26715072 0.23280341]\n",
      " [0.91749486 0.26141657 0.22357221]\n",
      " [0.94410144 0.24103509 0.24429796]\n",
      " [0.92022138 0.08436516 0.65917797]\n",
      " [0.94270288 0.16716248 0.38901128]\n",
      " [0.91596121 0.26232545 0.22464583]\n",
      " [0.90967501 0.26715072 0.23280341]\n",
      " [0.92022138 0.08436516 0.65917797]\n",
      " [0.89204789 0.26744514 0.30980669]\n",
      " [0.93220293 0.12341985 0.53759778]\n",
      " [0.89204789 0.26744514 0.30980669]\n",
      " [0.89204789 0.26744514 0.30980669]\n",
      " [0.92200877 0.25669928 0.2220139 ]\n",
      " [0.9312747  0.12699967 0.52898906]\n",
      " [0.92022138 0.08436516 0.65917797]]\n",
      "female_labels are: [0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 1 1 0 1 0 1 1 1 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.119\n",
      "(*) epoch 2, cost 2.338\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.297\n",
      "(*) epoch 2, cost 3.355\n",
      "(*) epoch 3, cost 2.622\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.75483931 0.07825887 0.77863129]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.75632595 0.19229232 0.63893953]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.76246041 0.11384244 0.36682486]\n",
      " [0.88097941 0.04473064 0.59048004]\n",
      " [0.53804747 0.55515384 0.45242589]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.551\n",
      "(*) epoch 2, cost 2.859\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.372\n",
      "(*) epoch 2, cost 1.325\n",
      "(*) epoch 3, cost 1.050\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.0173302  0.58831709 0.27267269]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.0173302  0.58831709 0.27267269]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.0173302  0.58831709 0.27267269]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.0173302  0.58831709 0.27267269]\n",
      " [0.02084801 0.55808928 0.26860545]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.0173302  0.58831709 0.27267269]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.02084801 0.55808928 0.26860545]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.0173302  0.58831709 0.27267269]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.0173302  0.58831709 0.27267269]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.0173302  0.58831709 0.27267269]\n",
      " [0.12338677 0.34994257 0.23034022]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.01827292 0.58302117 0.2711118 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.04598219 0.47209149 0.23986736]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.02084801 0.55808928 0.26860545]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]\n",
      " [0.24102398 0.22025679 0.1682259 ]]\n",
      "female_labels are: [1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.241\n",
      "(*) epoch 2, cost 5.050\n",
      "(*) epoch 3, cost 4.645\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.584\n",
      "(*) epoch 2, cost 3.065\n",
      "(*) epoch 3, cost 2.426\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.8942175  0.29422097 0.49735532]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.86899869 0.26379807 0.42056631]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.87619144 0.29593686 0.61527052]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.66899909 0.28382616 0.67471966]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.66899909 0.28382616 0.67471966]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.66899909 0.28382616 0.67471966]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.78266207 0.27176031 0.34026931]\n",
      " [0.66899909 0.28382616 0.67471966]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.8942175  0.29422097 0.49735532]\n",
      " [0.82810313 0.23608435 0.52481527]\n",
      " [0.72847957 0.27408398 0.65410196]\n",
      " [0.82810313 0.23608435 0.52481527]]\n",
      "female_labels are: [1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "female_pred_labels are: [1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 1 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0\n",
      " 1 0 1 0 1 1 1 0 1 1 1 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.922\n",
      "(*) epoch 2, cost 1.691\n",
      "(*) epoch 3, cost 1.360\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.500\n",
      "(*) epoch 2, cost 2.939\n",
      "(*) epoch 3, cost 2.352\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.82877166 0.87910677 0.58220006]\n",
      " [0.82325596 0.92452195 0.62515812]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.81998027 0.93607187 0.63937519]\n",
      " [0.81998027 0.93607187 0.63937519]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82325596 0.92452195 0.62515812]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82325596 0.92452195 0.62515812]\n",
      " [0.82877166 0.87910677 0.58220006]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.81863452 0.93805061 0.64291091]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.81998027 0.93607187 0.63937519]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82877166 0.87910677 0.58220006]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82877166 0.87910677 0.58220006]\n",
      " [0.82222095 0.92927479 0.63046615]\n",
      " [0.82325596 0.92452195 0.62515812]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.80691639 0.13464544 0.07556959]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82877166 0.87910677 0.58220006]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.80691639 0.13464544 0.07556959]\n",
      " [0.81938528 0.42764679 0.26825972]\n",
      " [0.81998027 0.93607187 0.63937519]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82877166 0.87910677 0.58220006]\n",
      " [0.82325596 0.92452195 0.62515812]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.82590004 0.59122564 0.37609276]\n",
      " [0.82005466 0.9351048  0.63839109]\n",
      " [0.80582927 0.11817442 0.0652994 ]\n",
      " [0.81998027 0.93607187 0.63937519]\n",
      " [0.82877166 0.87910677 0.58220006]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 6.063\n",
      "(*) epoch 2, cost 3.683\n",
      "(*) epoch 3, cost 2.670\n",
      "(*) epoch 4, cost 2.288\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.472\n",
      "(*) epoch 2, cost 2.028\n",
      "(*) epoch 3, cost 1.532\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.29194951 0.62747776 0.66970559]\n",
      " [0.24786132 0.70605245 0.68659146]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.24786132 0.70605245 0.68659146]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.29194951 0.62747776 0.66970559]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.24786132 0.70605245 0.68659146]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.6993924  0.23923739 0.52034741]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.29194951 0.62747776 0.66970559]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.6993924  0.23923739 0.52034741]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.6405217  0.30477042 0.48259192]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.39926327 0.07623812 0.76391507]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.24786132 0.70605245 0.68659146]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.6993924  0.23923739 0.52034741]\n",
      " [0.29194951 0.62747776 0.66970559]\n",
      " [0.29194951 0.62747776 0.66970559]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.29194951 0.62747776 0.66970559]\n",
      " [0.39926327 0.07623812 0.76391507]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.24786132 0.70605245 0.68659146]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.29194951 0.62747776 0.66970559]\n",
      " [0.29194951 0.62747776 0.66970559]\n",
      " [0.44027853 0.33178826 0.67236396]\n",
      " [0.44027853 0.33178826 0.67236396]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1\n",
      " 1 1 1 0 0 1 1 0 1 0 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.059\n",
      "(*) epoch 2, cost 3.118\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.241\n",
      "(*) epoch 2, cost 2.709\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.35248931 0.7004767  0.20488675]\n",
      " [0.56444024 0.80885975 0.17362872]\n",
      " [0.21741744 0.68713698 0.25188511]\n",
      " [0.37504481 0.57440696 0.15560039]\n",
      " [0.40606702 0.48937884 0.12393286]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.37504481 0.57440696 0.15560039]\n",
      " [0.23315291 0.09404675 0.03284757]\n",
      " [0.24830369 0.71879545 0.25112614]\n",
      " [0.24830369 0.71879545 0.25112614]\n",
      " [0.21859735 0.54256492 0.19971627]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.20677576 0.50405585 0.19002918]\n",
      " [0.40606702 0.48937884 0.12393286]\n",
      " [0.57975081 0.84352852 0.17821712]\n",
      " [0.27836156 0.75611333 0.25249498]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.22729293 0.09283783 0.03318741]\n",
      " [0.24830369 0.71879545 0.25112614]\n",
      " [0.23129103 0.09249665 0.03276609]\n",
      " [0.57975081 0.84352852 0.17821712]\n",
      " [0.33645863 0.42495109 0.12087759]\n",
      " [0.40606702 0.48937884 0.12393286]\n",
      " [0.30037969 0.75631082 0.24391756]\n",
      " [0.57975081 0.84352852 0.17821712]\n",
      " [0.40606702 0.48937884 0.12393286]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.59385847 0.62724231 0.14173267]\n",
      " [0.40606702 0.48937884 0.12393286]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.57975081 0.84352852 0.17821712]\n",
      " [0.53349227 0.75230322 0.16653355]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.21859735 0.54256492 0.19971627]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.30037969 0.75631082 0.24391756]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.35248931 0.7004767  0.20488675]\n",
      " [0.30037969 0.75631082 0.24391756]\n",
      " [0.23129103 0.09249665 0.03276609]\n",
      " [0.28521761 0.6348764  0.20756945]\n",
      " [0.20714054 0.48260492 0.18219352]\n",
      " [0.57975081 0.84352852 0.17821712]\n",
      " [0.33645863 0.42495109 0.12087759]\n",
      " [0.59385847 0.62724231 0.14173267]\n",
      " [0.21658199 0.08897662 0.03331608]\n",
      " [0.2183069  0.51969333 0.19168788]\n",
      " [0.25249501 0.28583099 0.09728646]\n",
      " [0.57975081 0.84352852 0.17821712]]\n",
      "female_labels are: [0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.917\n",
      "(*) epoch 2, cost 1.880\n",
      "(*) epoch 3, cost 1.576\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.548\n",
      "(*) epoch 2, cost 1.153\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.36083825 0.98357102 0.49816508]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.1487205  0.98474776 0.70739715]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.1487205  0.98474776 0.70739715]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.89153543 0.90826764 0.53945055]\n",
      " [0.88444465 0.89531841 0.5564897 ]\n",
      " [0.89153543 0.90826764 0.53945055]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.156\n",
      "(*) epoch 2, cost 2.570\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.892\n",
      "(*) epoch 2, cost 1.977\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.13242758 0.25051923 0.07189879]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.1822907  0.78052591 0.04823177]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.201225   0.10914489 0.12207188]\n",
      " [0.201225   0.10914489 0.12207188]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.201225   0.10914489 0.12207188]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.201225   0.10914489 0.12207188]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.1822907  0.78052591 0.04823177]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.201225   0.10914489 0.12207188]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.20631042 0.06240771 0.10064084]\n",
      " [0.11967861 0.26308341 0.10939491]\n",
      " [0.07665855 0.42889519 0.04881049]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.169\n",
      "(*) epoch 2, cost 2.124\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.631\n",
      "(*) epoch 2, cost 3.284\n",
      "(*) epoch 3, cost 2.920\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.32466791 0.52346417 0.20192795]\n",
      " [0.4471219  0.35014361 0.48621103]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.4471219  0.35014361 0.48621103]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.4471219  0.35014361 0.48621103]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.4783091  0.44755826 0.35690367]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.32466791 0.52346417 0.20192795]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.21297522 0.39550523 0.23516041]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.27524658 0.11134112 0.76284249]\n",
      " [0.34460643 0.2601266  0.42394983]\n",
      " [0.49063423 0.10197187 0.61452694]\n",
      " [0.34460643 0.2601266  0.42394983]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.451\n",
      "(*) epoch 2, cost 1.981\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.785\n",
      "(*) epoch 2, cost 3.207\n",
      "(*) epoch 3, cost 2.633\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.91178676 0.16865168 0.91896441]\n",
      " [0.92055564 0.19649332 0.94937659]\n",
      " [0.88900058 0.1903158  0.79667702]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.88626147 0.18905718 0.79043413]\n",
      " [0.89686384 0.21071704 0.82035416]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.88900058 0.1903158  0.79667702]\n",
      " [0.88626147 0.18905718 0.79043413]\n",
      " [0.88900058 0.1903158  0.79667702]\n",
      " [0.92055564 0.19649332 0.94937659]\n",
      " [0.92055564 0.19649332 0.94937659]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.91178676 0.16865168 0.91896441]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8803638  0.08051283 0.75589785]\n",
      " [0.88626147 0.18905718 0.79043413]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.88626147 0.18905718 0.79043413]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.91178676 0.16865168 0.91896441]\n",
      " [0.88900058 0.1903158  0.79667702]\n",
      " [0.91178676 0.16865168 0.91896441]\n",
      " [0.91941762 0.19348267 0.94704874]\n",
      " [0.8803638  0.08051283 0.75589785]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.91178676 0.16865168 0.91896441]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.91178676 0.16865168 0.91896441]\n",
      " [0.91178676 0.16865168 0.91896441]\n",
      " [0.92055564 0.19649332 0.94937659]\n",
      " [0.87304018 0.23142798 0.77643112]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.88900058 0.1903158  0.79667702]\n",
      " [0.92380802 0.20208927 0.96229446]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.88900058 0.1903158  0.79667702]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]\n",
      " [0.8702769  0.1901082  0.77128306]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0\n",
      " 0 1 1 1 0 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.680\n",
      "(*) epoch 2, cost 2.893\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.031\n",
      "(*) epoch 2, cost 2.882\n",
      "(*) epoch 3, cost 2.300\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.34901231 0.83568167 0.22826327]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.16457438 0.85724646 0.38894731]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.37896675 0.78434572 0.3204274 ]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.37896675 0.78434572 0.3204274 ]\n",
      " [0.37896675 0.78434572 0.3204274 ]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.4312489  0.60193541 0.65130071]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.37896675 0.78434572 0.3204274 ]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.17358385 0.8191389  0.42843435]\n",
      " [0.41784558 0.77014719 0.32896638]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.37896675 0.78434572 0.3204274 ]\n",
      " [0.37896675 0.78434572 0.3204274 ]\n",
      " [0.17358385 0.8191389  0.42843435]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.37896675 0.78434572 0.3204274 ]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.4312489  0.60193541 0.65130071]\n",
      " [0.4312489  0.60193541 0.65130071]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.34901231 0.83568167 0.22826327]\n",
      " [0.59281641 0.85999645 0.05672002]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.47534929 0.85276304 0.13644602]\n",
      " [0.4312489  0.60193541 0.65130071]]\n",
      "female_labels are: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.484\n",
      "(*) epoch 2, cost 2.482\n",
      "(*) epoch 3, cost 1.941\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.285\n",
      "(*) epoch 2, cost 1.274\n",
      "(*) epoch 3, cost 0.963\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05113569 0.03710089 0.08147459]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05113569 0.03710089 0.08147459]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.04842683 0.03221475 0.07974515]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.04842683 0.03221475 0.07974515]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.04842683 0.03221475 0.07974515]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.04842683 0.03221475 0.07974515]\n",
      " [0.04842683 0.03221475 0.07974515]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.22748525 0.31961436 0.0636478 ]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05191082 0.03610494 0.08480701]\n",
      " [0.05113569 0.03710089 0.08147459]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.544\n",
      "(*) epoch 2, cost 2.806\n",
      "(*) epoch 3, cost 2.098\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.248\n",
      "(*) epoch 2, cost 2.165\n",
      "(*) epoch 3, cost 1.691\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.08166315 0.02781128 0.65198084]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.06920103 0.01753884 0.81130384]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.29764469 0.25600853 0.53788964]\n",
      " [0.29764469 0.25600853 0.53788964]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.0684952  0.01757428 0.81520778]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.15668356 0.09841611 0.71098126]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.15668356 0.09841611 0.71098126]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.09458664 0.03733216 0.5959552 ]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.06468664 0.02623723 0.19721652]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.3364882  0.25281011 0.50227721]\n",
      " [0.07073838 0.01842796 0.80699001]\n",
      " [0.15668356 0.09841611 0.71098126]\n",
      " [0.07073838 0.01842796 0.80699001]]\n",
      "female_labels are: [1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]\n",
      "female_pred_labels are: [1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.658\n",
      "(*) epoch 2, cost 2.413\n",
      "(*) epoch 3, cost 1.901\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.106\n",
      "(*) epoch 2, cost 1.602\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.11462875 0.64411671 0.03411271]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11454663 0.64286723 0.03473124]\n",
      " [0.10117765 0.68994476 0.0240775 ]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.11405839 0.64493936 0.03366198]\n",
      " [0.33535056 0.59689349 0.17699963]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11454663 0.64286723 0.03473124]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11405839 0.64493936 0.03366198]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.33535056 0.59689349 0.17699963]\n",
      " [0.33535056 0.59689349 0.17699963]\n",
      " [0.10117765 0.68994476 0.0240775 ]\n",
      " [0.11405839 0.64493936 0.03366198]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.10117765 0.68994476 0.0240775 ]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.33535056 0.59689349 0.17699963]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.10117765 0.68994476 0.0240775 ]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.33535056 0.59689349 0.17699963]\n",
      " [0.33535056 0.59689349 0.17699963]\n",
      " [0.10117765 0.68994476 0.0240775 ]\n",
      " [0.10117765 0.68994476 0.0240775 ]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11481026 0.6429992  0.03490943]\n",
      " [0.33535056 0.59689349 0.17699963]\n",
      " [0.11405839 0.64493936 0.03366198]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.11462875 0.64411671 0.03411271]\n",
      " [0.10004639 0.69244281 0.02372407]\n",
      " [0.11405839 0.64493936 0.03366198]\n",
      " [0.10117765 0.68994476 0.0240775 ]]\n",
      "female_labels are: [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.233\n",
      "(*) epoch 2, cost 2.373\n",
      "(*) epoch 3, cost 1.768\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 0.581\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.21292742 0.22851652 0.46517655]\n",
      " [0.23457904 0.26023623 0.51952503]\n",
      " [0.12614744 0.07647436 0.20123563]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.36926185 0.47647803 0.88800742]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.36926185 0.47647803 0.88800742]\n",
      " [0.36926185 0.47647803 0.88800742]\n",
      " [0.12614744 0.07647436 0.20123563]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.36926185 0.47647803 0.88800742]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.12614744 0.07647436 0.20123563]\n",
      " [0.12614744 0.07647436 0.20123563]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.12614744 0.07647436 0.20123563]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.36926185 0.47647803 0.88800742]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.21292742 0.22851652 0.46517655]\n",
      " [0.36926185 0.47647803 0.88800742]\n",
      " [0.21292742 0.22851652 0.46517655]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.555\n",
      "(*) epoch 2, cost 1.277\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.089\n",
      "(*) epoch 2, cost 3.414\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.20108754 0.96274863 0.9236558 ]\n",
      " [0.1864571  0.7596519  0.86819415]\n",
      " [0.20467586 0.89668242 0.88702484]\n",
      " [0.23691977 0.98937868 0.9130928 ]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.16761908 0.65122553 0.86481954]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.18596808 0.9198771  0.92146498]\n",
      " [0.2257271  0.9848524  0.91714039]\n",
      " [0.20467586 0.89668242 0.88702484]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.23374618 0.98823454 0.9142746 ]\n",
      " [0.20108754 0.96274863 0.9236558 ]\n",
      " [0.17358131 0.627454   0.84463889]\n",
      " [0.17560819 0.62968299 0.84342805]\n",
      " [0.20000197 0.72087384 0.83404065]\n",
      " [0.19949732 0.63224364 0.79300726]\n",
      " [0.19949732 0.63224364 0.79300726]\n",
      " [0.17358131 0.627454   0.84463889]\n",
      " [0.18596808 0.9198771  0.92146498]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.20108754 0.96274863 0.9236558 ]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.20467586 0.89668242 0.88702484]\n",
      " [0.23374618 0.98823454 0.9142746 ]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.18596808 0.9198771  0.92146498]\n",
      " [0.20467586 0.89668242 0.88702484]\n",
      " [0.22655708 0.37946132 0.58745012]\n",
      " [0.20640754 0.92518688 0.90047552]\n",
      " [0.2257271  0.9848524  0.91714039]\n",
      " [0.18596808 0.9198771  0.92146498]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.17560819 0.62968299 0.84342805]\n",
      " [0.1864571  0.7596519  0.86819415]\n",
      " [0.20108754 0.96274863 0.9236558 ]\n",
      " [0.23691977 0.98937868 0.9130928 ]\n",
      " [0.23691977 0.98937868 0.9130928 ]\n",
      " [0.19240682 0.66639236 0.81911672]\n",
      " [0.21713354 0.83858822 0.86600589]\n",
      " [0.23374618 0.98823454 0.9142746 ]\n",
      " [0.19273109 0.94321296 0.92342278]\n",
      " [0.18596808 0.9198771  0.92146498]\n",
      " [0.20108754 0.96274863 0.9236558 ]\n",
      " [0.18596808 0.9198771  0.92146498]\n",
      " [0.17560819 0.62968299 0.84342805]\n",
      " [0.19240682 0.66639236 0.81911672]]\n",
      "female_labels are: [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.431\n",
      "(*) epoch 2, cost 1.310\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.878\n",
      "(*) epoch 2, cost 2.761\n",
      "(*) epoch 3, cost 2.391\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.13462619 0.67415795 0.84889609]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.45300813 0.51740707 0.66051648]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.41777235 0.54071357 0.67073817]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.45300813 0.51740707 0.66051648]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.41777235 0.54071357 0.67073817]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.1347842  0.67325089 0.85053663]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.45300813 0.51740707 0.66051648]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.41777235 0.54071357 0.67073817]\n",
      " [0.13462619 0.67415795 0.84889609]\n",
      " [0.1347842  0.67325089 0.85053663]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.1347842  0.67325089 0.85053663]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.57122429 0.43226477 0.635684  ]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.78831569 0.19900975 0.71828897]\n",
      " [0.1347842  0.67325089 0.85053663]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.713\n",
      "(*) epoch 2, cost 1.127\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.077\n",
      "(*) epoch 2, cost 2.202\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.03559316 0.96724621 0.00941058]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03582162 0.96705241 0.00944514]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03559168 0.96724746 0.00941036]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.18425984 0.84113687 0.0318953 ]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.18425984 0.84113687 0.0318953 ]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03559316 0.96724621 0.00941058]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.03620112 0.96673049 0.00950253]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03559168 0.96724746 0.00941036]\n",
      " [0.03559181 0.96724735 0.00941038]\n",
      " [0.36175609 0.69057231 0.05874028]\n",
      " [0.03582162 0.96705241 0.00944514]\n",
      " [0.03559181 0.96724735 0.00941038]]\n",
      "female_labels are: [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
      "female_pred_labels are: [0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.623\n",
      "(*) epoch 2, cost 1.472\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 8.910\n",
      "(*) epoch 2, cost 5.737\n",
      "(*) epoch 3, cost 4.689\n",
      "(*) epoch 4, cost 4.352\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.24884114 0.76679451 0.21509811]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.12241035 0.9312059  0.66256618]\n",
      " [0.12456831 0.92440991 0.64713493]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.10272185 0.40506479 0.16485843]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.12456831 0.92440991 0.64713493]\n",
      " [0.12456831 0.92440991 0.64713493]\n",
      " [0.22534571 0.78586053 0.21947091]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.19784487 0.80390612 0.28481479]\n",
      " [0.22906782 0.78615057 0.23623347]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.10212734 0.3883475  0.14952575]\n",
      " [0.16341227 0.873206   0.47229316]\n",
      " [0.12456831 0.92440991 0.64713493]\n",
      " [0.16838904 0.85767083 0.42774264]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.1573703  0.54670078 0.15562927]\n",
      " [0.1216828  0.93292336 0.6704123 ]\n",
      " [0.70705012 0.19606009 0.04610667]\n",
      " [0.40983611 0.56375026 0.15173495]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.46409448 0.49985509 0.13442914]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.22534571 0.78586053 0.21947091]\n",
      " [0.19389722 0.72486607 0.21649024]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.22534571 0.78586053 0.21947091]\n",
      " [0.18039235 0.82314825 0.35664764]\n",
      " [0.12237749 0.93134859 0.66287648]\n",
      " [0.1573703  0.54670078 0.15562927]\n",
      " [0.12456831 0.92440991 0.64713493]\n",
      " [0.12932085 0.91958562 0.62393776]\n",
      " [0.12237749 0.93134859 0.66287648]\n",
      " [0.12237749 0.93134859 0.66287648]\n",
      " [0.13204725 0.91332362 0.60814746]\n",
      " [0.12456831 0.92440991 0.64713493]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.12176509 0.93276353 0.66954471]\n",
      " [0.10212734 0.3883475  0.14952575]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.12241035 0.9312059  0.66256618]\n",
      " [0.18551464 0.7915142  0.30917704]\n",
      " [0.25786956 0.75709789 0.18459153]\n",
      " [0.12169589 0.93274804 0.66952091]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.773\n",
      "(*) epoch 2, cost 1.259\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.274\n",
      "(*) epoch 2, cost 3.465\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.73697083 0.814873   0.96335954]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.10551122 0.872841   0.02465511]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.62022657 0.81847153 0.79558687]\n",
      " [0.6294918  0.82847346 0.80595593]\n",
      " [0.67014929 0.82407616 0.86677239]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.62022657 0.81847153 0.79558687]\n",
      " [0.10645079 0.88251536 0.01927077]\n",
      " [0.67014929 0.82407616 0.86677239]\n",
      " [0.6294918  0.82847346 0.80595593]\n",
      " [0.6294918  0.82847346 0.80595593]\n",
      " [0.11636535 0.79415216 0.09504021]\n",
      " [0.10645079 0.88251536 0.01927077]\n",
      " [0.62022657 0.81847153 0.79558687]\n",
      " [0.11625224 0.87352936 0.03959502]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.67014929 0.82407616 0.86677239]\n",
      " [0.10645079 0.88251536 0.01927077]\n",
      " [0.7362299  0.81529671 0.96285396]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.10721884 0.8770047  0.02419788]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.67014929 0.82407616 0.86677239]\n",
      " [0.6294918  0.82847346 0.80595593]\n",
      " [0.10592187 0.81713678 0.06407257]\n",
      " [0.10721884 0.8770047  0.02419788]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.67014929 0.82407616 0.86677239]\n",
      " [0.11636535 0.79415216 0.09504021]\n",
      " [0.10539865 0.82084935 0.06073562]\n",
      " [0.6294918  0.82847346 0.80595593]\n",
      " [0.67014929 0.82407616 0.86677239]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.67014929 0.82407616 0.86677239]\n",
      " [0.65325196 0.81714171 0.8434602 ]\n",
      " [0.10721884 0.8770047  0.02419788]\n",
      " [0.10539865 0.82084935 0.06073562]\n",
      " [0.10645079 0.88251536 0.01927077]\n",
      " [0.10539865 0.82084935 0.06073562]\n",
      " [0.10721884 0.8770047  0.02419788]\n",
      " [0.11625224 0.87352936 0.03959502]\n",
      " [0.10539865 0.82084935 0.06073562]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.12088865 0.87489829 0.04519415]\n",
      " [0.10539865 0.82084935 0.06073562]\n",
      " [0.62022657 0.81847153 0.79558687]\n",
      " [0.10551122 0.872841   0.02465511]]\n",
      "female_labels are: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.398\n",
      "(*) epoch 2, cost 2.654\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.369\n",
      "(*) epoch 2, cost 3.646\n",
      "(*) epoch 3, cost 3.218\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.86185147 0.09519873 0.38283959]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.94567379 0.10392652 0.05859186]\n",
      " [0.86185147 0.09519873 0.38283959]\n",
      " [0.93901024 0.11858811 0.06123196]\n",
      " [0.89836351 0.06864798 0.32865383]\n",
      " [0.86185147 0.09519873 0.38283959]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.93785364 0.12105513 0.06237826]\n",
      " [0.93785364 0.12105513 0.06237826]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.84965731 0.14052623 0.37312206]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.79474646 0.21219866 0.42927012]\n",
      " [0.79474646 0.21219866 0.42927012]\n",
      " [0.89299037 0.08129189 0.32432997]\n",
      " [0.93901024 0.11858811 0.06123196]\n",
      " [0.93785364 0.12105513 0.06237826]\n",
      " [0.97326743 0.02366857 0.13379516]\n",
      " [0.64613258 0.21660425 0.78602414]\n",
      " [0.98851296 0.0113798  0.03327134]\n",
      " [0.86185147 0.09519873 0.38283959]\n",
      " [0.93901024 0.11858811 0.06123196]\n",
      " [0.89836351 0.06864798 0.32865383]\n",
      " [0.98851296 0.0113798  0.03327134]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.79253992 0.22087729 0.42676962]\n",
      " [0.98747395 0.01220349 0.03749147]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.79474646 0.21219866 0.42927012]\n",
      " [0.97326743 0.02366857 0.13379516]\n",
      " [0.55595449 0.2710211  0.90132931]\n",
      " [0.64613258 0.21660425 0.78602414]\n",
      " [0.79474646 0.21219866 0.42927012]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.9886352  0.01135402 0.0316207 ]\n",
      " [0.93785364 0.12105513 0.06237826]\n",
      " [0.67847428 0.19757195 0.74387455]\n",
      " [0.97326743 0.02366857 0.13379516]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.92083625 0.05069255 0.40572716]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.86572161 0.10490195 0.3681093 ]\n",
      " [0.93777917 0.12128227 0.0621609 ]\n",
      " [0.79474646 0.21219866 0.42927012]\n",
      " [0.89836351 0.06864798 0.32865383]\n",
      " [0.98851296 0.0113798  0.03327134]\n",
      " [0.86185147 0.09519873 0.38283959]\n",
      " [0.90496588 0.06640298 0.30765171]\n",
      " [0.79474646 0.21219866 0.42927012]]\n",
      "female_labels are: [0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.027\n",
      "(*) epoch 2, cost 3.656\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.259\n",
      "(*) epoch 2, cost 3.808\n",
      "(*) epoch 3, cost 3.221\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.08564819 0.17192448 0.63359592]\n",
      " [0.2130762  0.1010012  0.39862115]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.08564819 0.17192448 0.63359592]\n",
      " [0.08564819 0.17192448 0.63359592]\n",
      " [0.32373172 0.06306821 0.25753378]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.0870062  0.1707385  0.63032931]\n",
      " [0.0857147  0.18946189 0.65818536]\n",
      " [0.34221146 0.05720893 0.23454529]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.07964839 0.17995848 0.65946126]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.08564819 0.17192448 0.63359592]\n",
      " [0.31378006 0.0747816  0.2865279 ]\n",
      " [0.06367974 0.2020951  0.66434769]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.33035687 0.06095972 0.24929431]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.15874719 0.13705781 0.48755287]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.07000398 0.30024342 0.51158787]\n",
      " [0.04440576 0.43363208 0.51206052]\n",
      " [0.04919835 0.36708225 0.55770899]\n",
      " [0.08548753 0.17127357 0.63116225]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.04933933 0.36908655 0.55409626]\n",
      " [0.04933933 0.36908655 0.55409626]\n",
      " [0.08548753 0.17127357 0.63116225]\n",
      " [0.06374539 0.20261544 0.66490111]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.0857147  0.18946189 0.65818536]\n",
      " [0.07000398 0.30024342 0.51158787]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.06374539 0.20261544 0.66490111]\n",
      " [0.31378006 0.0747816  0.2865279 ]\n",
      " [0.08564819 0.17192448 0.63359592]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.08088923 0.17950476 0.65882662]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.07000398 0.30024342 0.51158787]\n",
      " [0.08026524 0.17971438 0.65914132]\n",
      " [0.08639869 0.17168327 0.63319515]\n",
      " [0.31378006 0.0747816  0.2865279 ]\n",
      " [0.08564819 0.17192448 0.63359592]\n",
      " [0.33651164 0.05900927 0.24163924]\n",
      " [0.08026524 0.17971438 0.65914132]]\n",
      "female_labels are: [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 1 0 1 0]\n",
      "trans_female_pred_labels are: [0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 1 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.270\n",
      "(*) epoch 2, cost 1.504\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.220\n",
      "(*) epoch 2, cost 3.398\n",
      "(*) epoch 3, cost 2.891\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.78600336 0.18007288 0.65666076]\n",
      " [0.85445732 0.15676703 0.74783612]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.84908933 0.15859462 0.74068637]\n",
      " [0.8330509  0.16405507 0.71932443]\n",
      " [0.72157303 0.20200885 0.57084458]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.72157303 0.20200885 0.57084458]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.75011341 0.19229199 0.60885814]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.75011341 0.19229199 0.60885814]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.8330509  0.16405507 0.71932443]\n",
      " [0.72157303 0.20200885 0.57084458]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.75011341 0.19229199 0.60885814]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.75011341 0.19229199 0.60885814]\n",
      " [0.75011341 0.19229199 0.60885814]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.8330509  0.16405507 0.71932443]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.78600336 0.18007288 0.65666076]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.87245003 0.15064123 0.771801  ]\n",
      " [0.78600336 0.18007288 0.65666076]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.991\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.304\n",
      "(*) epoch 2, cost 1.595\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.87676592 0.83320442 0.94517533]\n",
      " [0.93843689 0.81526669 0.9416149 ]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.93843689 0.81526669 0.9416149 ]\n",
      " [0.5487734  0.49141297 0.71187093]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.87676592 0.83320442 0.94517533]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.5487734  0.49141297 0.71187093]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.93843689 0.81526669 0.9416149 ]\n",
      " [0.93843689 0.81526669 0.9416149 ]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.93843689 0.81526669 0.9416149 ]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.93843689 0.81526669 0.9416149 ]\n",
      " [0.52110244 0.91412658 0.94766489]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.52110244 0.91412658 0.94766489]\n",
      " [0.6015183  0.91341095 0.96116804]\n",
      " [0.87676592 0.83320442 0.94517533]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.5487734  0.49141297 0.71187093]\n",
      " [0.76349982 0.86624238 0.95177752]\n",
      " [0.76349982 0.86624238 0.95177752]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 1\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 0.159\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.705\n",
      "(*) epoch 2, cost 3.113\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]\n",
      " [0.46032591 0.53761171 0.52924228]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.531\n",
      "(*) epoch 2, cost 2.793\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.792\n",
      "(*) epoch 2, cost 2.725\n",
      "(*) epoch 3, cost 2.068\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.28695286 0.06789721 0.07849655]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.56560121 0.0882473  0.13066201]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.75656029 0.12904875 0.22564119]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.75656029 0.12904875 0.22564119]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.63460148 0.09054603 0.14434957]\n",
      " [0.63460148 0.09054603 0.14434957]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.20980028 0.05545751 0.06895888]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.43076611 0.08263756 0.10513972]\n",
      " [0.47196688 0.07529909 0.09699279]\n",
      " [0.45183154 0.0788444  0.10112822]\n",
      " [0.20980028 0.05545751 0.06895888]\n",
      " [0.47196688 0.07529909 0.09699279]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.669\n",
      "(*) epoch 2, cost 0.928\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.043\n",
      "(*) epoch 2, cost 0.966\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.20672346 0.58716763 0.32090079]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.20672346 0.58716763 0.32090079]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.20672346 0.58716763 0.32090079]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.09727111 0.56770298 0.18093402]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.27123412 0.59857077 0.40325912]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.09727111 0.56770298 0.18093402]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.07772582 0.56419394 0.15587384]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.27123412 0.59857077 0.40325912]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.09727111 0.56770298 0.18093402]\n",
      " [0.20672346 0.58716763 0.32090079]\n",
      " [0.24216612 0.59342925 0.36614245]\n",
      " [0.24216612 0.59342925 0.36614245]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.925\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.366\n",
      "(*) epoch 2, cost 2.148\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.15200683 0.47347403 0.69622487]\n",
      " [0.15168299 0.45794188 0.70354769]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.13244836 0.36443164 0.75611329]\n",
      " [0.11098054 0.33199946 0.7816025 ]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.11710789 0.74570619 0.58785438]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.11991757 0.74989434 0.58454433]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.12353391 0.3563767  0.76420094]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.11991757 0.74989434 0.58454433]\n",
      " [0.13244836 0.36443164 0.75611329]\n",
      " [0.15168299 0.45794188 0.70354769]\n",
      " [0.1249665  0.35402859 0.76458134]\n",
      " [0.11401613 0.33391729 0.77922886]\n",
      " [0.13110866 0.367552   0.75533105]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.15200683 0.47347403 0.69622487]\n",
      " [0.1173439  0.75030154 0.58563437]\n",
      " [0.15064452 0.46836924 0.69924759]\n",
      " [0.05834899 0.15446495 0.88930704]\n",
      " [0.15200683 0.47347403 0.69622487]]\n",
      "female_labels are: [1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 1 1 0 0 0 0 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.704\n",
      "(*) epoch 2, cost 2.467\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.526\n",
      "(*) epoch 2, cost 1.874\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.03814719 0.61095824 0.0475617 ]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03151289 0.6630088  0.05222727]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03814719 0.61095824 0.0475617 ]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.03151289 0.6630088  0.05222727]\n",
      " [0.0343355  0.56606776 0.15589338]\n",
      " [0.03171674 0.65975668 0.05659111]\n",
      " [0.0343355  0.56606776 0.15589338]]\n",
      "female_labels are: [1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.751\n",
      "(*) epoch 2, cost 3.318\n",
      "(*) epoch 3, cost 2.779\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.586\n",
      "(*) epoch 2, cost 3.230\n",
      "(*) epoch 3, cost 2.484\n",
      "(*) training time: 0.01 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.15918061 0.58761279 0.59371487]\n",
      " [0.1005626  0.34994751 0.80110416]\n",
      " [0.10705968 0.49329987 0.68156869]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.08889998 0.38059523 0.76218005]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.1005626  0.34994751 0.80110416]\n",
      " [0.18931651 0.59099392 0.58018137]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.10842403 0.49235877 0.68267916]\n",
      " [0.1005626  0.34994751 0.80110416]\n",
      " [0.12868871 0.56787904 0.61918147]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.10842403 0.49235877 0.68267916]\n",
      " [0.1005626  0.34994751 0.80110416]\n",
      " [0.10705968 0.49329987 0.68156869]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.12868871 0.56787904 0.61918147]\n",
      " [0.1005626  0.34994751 0.80110416]\n",
      " [0.10705968 0.49329987 0.68156869]\n",
      " [0.20186769 0.60798925 0.56249715]\n",
      " [0.10842403 0.49235877 0.68267916]\n",
      " [0.1005626  0.34994751 0.80110416]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.10705968 0.49329987 0.68156869]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.15918061 0.58761279 0.59371487]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.1005626  0.34994751 0.80110416]\n",
      " [0.10705968 0.49329987 0.68156869]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.12868871 0.56787904 0.61918147]\n",
      " [0.10705968 0.49329987 0.68156869]\n",
      " [0.10705968 0.49329987 0.68156869]\n",
      " [0.12868871 0.56787904 0.61918147]\n",
      " [0.18931651 0.59099392 0.58018137]\n",
      " [0.0686685  0.22342919 0.89060108]\n",
      " [0.12868871 0.56787904 0.61918147]\n",
      " [0.09427935 0.42070844 0.73132989]\n",
      " [0.12868871 0.56787904 0.61918147]\n",
      " [0.09427935 0.42070844 0.73132989]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0\n",
      " 1 1 0 1 1 1 1 1 0 1 0 1 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.919\n",
      "(*) epoch 2, cost 4.372\n",
      "(*) epoch 3, cost 3.393\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.299\n",
      "(*) epoch 2, cost 0.991\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.42408445 0.49128715 0.2514464 ]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.42311163 0.46657443 0.27424938]\n",
      " [0.81216503 0.13556378 0.02894998]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.81216503 0.13556378 0.02894998]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.81216503 0.13556378 0.02894998]\n",
      " [0.81216503 0.13556378 0.02894998]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.43594272 0.33209883 0.36420036]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.79344919 0.12472938 0.07998096]\n",
      " [0.81216503 0.13556378 0.02894998]]\n",
      "female_labels are: [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.405\n",
      "(*) epoch 2, cost 1.989\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.512\n",
      "(*) epoch 2, cost 2.940\n",
      "(*) epoch 3, cost 2.319\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.77158073 0.01820706 0.55893966]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.77158073 0.01820706 0.55893966]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.74237198 0.01592877 0.54279233]\n",
      " [0.74237198 0.01592877 0.54279233]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.74237198 0.01592877 0.54279233]\n",
      " [0.74237198 0.01592877 0.54279233]\n",
      " [0.74237198 0.01592877 0.54279233]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.38982334 0.02041344 0.47310579]\n",
      " [0.62484158 0.00879618 0.47799205]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.38982334 0.02041344 0.47310579]\n",
      " [0.77158073 0.01820706 0.55893966]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.77158073 0.01820706 0.55893966]\n",
      " [0.17373902 0.04482788 0.31985083]\n",
      " [0.16814088 0.04583991 0.31262495]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.62484158 0.00879618 0.47799205]\n",
      " [0.77158073 0.01820706 0.55893966]\n",
      " [0.62484158 0.00879618 0.47799205]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.77158073 0.01820706 0.55893966]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.16471305 0.04622278 0.30945342]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.62484158 0.00879618 0.47799205]\n",
      " [0.62484158 0.00879618 0.47799205]\n",
      " [0.23019094 0.03928055 0.3502698 ]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.77158073 0.01820706 0.55893966]\n",
      " [0.74237198 0.01592877 0.54279233]\n",
      " [0.62484158 0.00879618 0.47799205]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.16814088 0.04583991 0.31262495]\n",
      " [0.26100854 0.03347929 0.401631  ]\n",
      " [0.38982334 0.02041344 0.47310579]\n",
      " [0.74237198 0.01592877 0.54279233]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.966\n",
      "(*) epoch 2, cost 2.066\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.707\n",
      "(*) epoch 2, cost 2.101\n",
      "(*) epoch 3, cost 1.714\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.04545586 0.05991757 0.71511846]\n",
      " [0.01711936 0.00136843 0.76778283]\n",
      " [0.04545586 0.05991757 0.71511846]\n",
      " [0.01711936 0.00136843 0.76778283]\n",
      " [0.04545586 0.05991757 0.71511846]\n",
      " [0.04545586 0.05991757 0.71511846]\n",
      " [0.01711936 0.00136843 0.76778283]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.01787974 0.00145549 0.7681655 ]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.05164193 0.0715658  0.70499548]\n",
      " [0.04545586 0.05991757 0.71511846]\n",
      " [0.04545586 0.05991757 0.71511846]\n",
      " [0.04545586 0.05991757 0.71511846]\n",
      " [0.02080475 0.00201627 0.76932158]\n",
      " [0.01711936 0.00136843 0.76778283]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.01711936 0.00136843 0.76778283]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.34100887 0.03512881 0.78017671]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.34100887 0.03512881 0.78017671]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.05164193 0.0715658  0.70499548]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.04545586 0.05991757 0.71511846]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]\n",
      " [0.01711936 0.00136843 0.76778283]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27295223 0.02884952 0.77993322]\n",
      " [0.27183484 0.02460212 0.79662505]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.798\n",
      "(*) epoch 2, cost 3.926\n",
      "(*) epoch 3, cost 3.237\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.950\n",
      "(*) epoch 2, cost 3.244\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.81677212 0.88932405 0.68994096]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.76921561 0.8533381  0.82616013]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.75105956 0.83883747 0.80402832]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.61030705 0.61424768 0.36693953]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.80837128 0.8852135  0.72894707]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.75458004 0.84148623 0.80780367]\n",
      " [0.75458004 0.84148623 0.80780367]\n",
      " [0.78674755 0.84600349 0.81613446]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.81961596 0.88496301 0.68709147]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.81677212 0.88932405 0.68994096]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.81961596 0.88496301 0.68709147]\n",
      " [0.56239446 0.59244791 0.33041488]\n",
      " [0.75458004 0.84148623 0.80780367]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.75458004 0.84148623 0.80780367]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.81677212 0.88932405 0.68994096]\n",
      " [0.72630784 0.92986842 0.51669308]\n",
      " [0.80837128 0.8852135  0.72894707]\n",
      " [0.80401998 0.88399776 0.74709687]\n",
      " [0.79586827 0.85066626 0.8220067 ]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.76430354 0.84740644 0.81599344]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.58926391 0.57919767 0.34403358]\n",
      " [0.58926391 0.57919767 0.34403358]]\n",
      "female_labels are: [0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 1 1 1 0 0 1 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.748\n",
      "(*) epoch 2, cost 3.639\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.982\n",
      "(*) epoch 2, cost 2.732\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.32043722 0.61876544 0.00735886]\n",
      " [0.06997288 0.87237235 0.00212468]\n",
      " [0.22173192 0.66608457 0.00338042]\n",
      " [0.28831293 0.64489474 0.00629313]\n",
      " [0.22124718 0.66417423 0.00332566]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.2227313  0.6518898  0.00318504]\n",
      " [0.06984656 0.87326232 0.00215186]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.22173192 0.66608457 0.00338042]\n",
      " [0.06984656 0.87326232 0.00215186]\n",
      " [0.07221949 0.87191129 0.0022391 ]\n",
      " [0.22051341 0.66079804 0.00323913]\n",
      " [0.06984656 0.87326232 0.00215186]\n",
      " [0.07221949 0.87191129 0.0022391 ]\n",
      " [0.07221949 0.87191129 0.0022391 ]\n",
      " [0.07174023 0.86829309 0.00207705]\n",
      " [0.06997288 0.87237235 0.00212468]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.07221949 0.87191129 0.0022391 ]\n",
      " [0.22051341 0.66079804 0.00323913]\n",
      " [0.07221949 0.87191129 0.0022391 ]\n",
      " [0.21737603 0.65926586 0.00310808]\n",
      " [0.27732423 0.64774796 0.00572989]\n",
      " [0.0894685  0.86008175 0.00283807]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.06997288 0.87237235 0.00212468]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.06997288 0.87237235 0.00212468]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.22124718 0.66417423 0.00332566]\n",
      " [0.22124718 0.66417423 0.00332566]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.07221949 0.87191129 0.0022391 ]\n",
      " [0.06997288 0.87237235 0.00212468]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.07174023 0.86829309 0.00207705]\n",
      " [0.27732423 0.64774796 0.00572989]\n",
      " [0.44916292 0.56937863 0.01408585]\n",
      " [0.25313251 0.65854705 0.00475488]\n",
      " [0.22051341 0.66079804 0.00323913]\n",
      " [0.06984656 0.87326232 0.00215186]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.07221949 0.87191129 0.0022391 ]\n",
      " [0.06997288 0.87237235 0.00212468]\n",
      " [0.32043722 0.61876544 0.00735886]\n",
      " [0.06997288 0.87237235 0.00212468]]\n",
      "female_labels are: [1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0\n",
      " 0 1 0 1 1 1 1 0 1 0 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.976\n",
      "(*) epoch 2, cost 2.322\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.808\n",
      "(*) epoch 2, cost 2.323\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.18189327 0.90953762 0.61716696]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.18167726 0.90928749 0.61775674]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.47567931 0.86475301 0.62182155]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.18192497 0.90988057 0.61609497]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.47567931 0.86475301 0.62182155]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.47567931 0.86475301 0.62182155]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.47567931 0.86475301 0.62182155]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.34529309 0.87947965 0.61853936]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.142058   0.76871597 0.62708806]\n",
      " [0.18189327 0.90953762 0.61716696]\n",
      " [0.18192497 0.90988057 0.61609497]]\n",
      "female_labels are: [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.754\n",
      "(*) epoch 2, cost 3.366\n",
      "(*) epoch 3, cost 2.708\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.29 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.001\n",
      "(*) epoch 2, cost 1.334\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.04427425 0.11358311 0.33021385]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.09562713 0.18733983 0.42655323]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.06357594 0.18289312 0.56543479]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.17810087 0.22445821 0.35137093]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.04427425 0.11358311 0.33021385]\n",
      " [0.09562713 0.18733983 0.42655323]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.354\n",
      "(*) epoch 2, cost 2.860\n",
      "(*) epoch 3, cost 1.925\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.213\n",
      "(*) epoch 2, cost 2.782\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.26 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.51765989 0.10734985 0.83738266]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.18164184 0.53685058 0.53814204]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.45968964 0.1491911  0.86903077]\n",
      " [0.57185998 0.02645969 0.90801235]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.45968964 0.1491911  0.86903077]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.35399697 0.30195973 0.72897947]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.45968964 0.1491911  0.86903077]\n",
      " [0.57183755 0.0267396  0.90735792]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.45968964 0.1491911  0.86903077]\n",
      " [0.4260123  0.18845339 0.85055409]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.4260123  0.18845339 0.85055409]\n",
      " [0.45968964 0.1491911  0.86903077]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.45968964 0.1491911  0.86903077]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.4260123  0.18845339 0.85055409]\n",
      " [0.73109628 0.06996751 0.5606762 ]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]\n",
      " [0.41428505 0.20397446 0.83892384]]\n",
      "female_labels are: [0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1\n",
      " 0 1 1 0 1 1 0 0 1 1 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.843\n",
      "(*) epoch 2, cost 2.287\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.093\n",
      "(*) epoch 2, cost 2.355\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.28504716 0.35295608 0.36066671]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.6776934  0.26182773 0.06473532]\n",
      " [0.54215646 0.24541789 0.33783619]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.6776934  0.26182773 0.06473532]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.37082546 0.27450838 0.32847226]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.6776934  0.26182773 0.06473532]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.27571782 0.27307646 0.48946124]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.61720472 0.2692054  0.13827791]\n",
      " [0.56887634 0.30743818 0.10035372]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.27571782 0.27307646 0.48946124]\n",
      " [0.47650394 0.2807822  0.35363669]\n",
      " [0.52529802 0.3223349  0.11438624]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.51430541 0.32267363 0.12513557]\n",
      " [0.27571782 0.27307646 0.48946124]\n",
      " [0.28504716 0.35295608 0.36066671]\n",
      " [0.61720472 0.2692054  0.13827791]\n",
      " [0.51430541 0.32267363 0.12513557]]\n",
      "female_labels are: [1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.050\n",
      "(*) epoch 2, cost 2.799\n",
      "(*) epoch 3, cost 2.425\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.854\n",
      "(*) epoch 2, cost 1.752\n",
      "(*) epoch 3, cost 1.283\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.79317642 0.07561977 0.07292679]\n",
      " [0.81357548 0.07266161 0.06328179]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.79317642 0.07561977 0.07292679]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81305463 0.07353826 0.06364366]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.28894948 0.18157788 0.31363771]\n",
      " [0.81185146 0.07473238 0.06435474]]\n",
      "female_labels are: [0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "female_pred_labels are: [0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 1 0 1 0 1 0 0 1 0 0 1]\n",
      "trans_female_pred_labels are: [0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 1 0 1 0 1 0 0 1 0 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.330\n",
      "(*) epoch 2, cost 2.562\n",
      "(*) epoch 3, cost 1.860\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.907\n",
      "(*) epoch 2, cost 4.030\n",
      "(*) epoch 3, cost 3.336\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.71572639 0.51980339 0.77395349]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.71572639 0.51980339 0.77395349]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.8477039  0.64262508 0.52158075]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.71572639 0.51980339 0.77395349]\n",
      " [0.71572639 0.51980339 0.77395349]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.8477039  0.64262508 0.52158075]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.8477039  0.64262508 0.52158075]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.58404604 0.92842329 0.36270236]\n",
      " [0.72136616 0.5214804  0.76832272]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.94194412 0.50798824 0.88451545]\n",
      " [0.8477039  0.64262508 0.52158075]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.71572639 0.51980339 0.77395349]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.81184957 0.34780989 0.96846145]\n",
      " [0.55857511 0.92303983 0.3985881 ]\n",
      " [0.8477039  0.64262508 0.52158075]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "female_pred_labels are: [0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.143\n",
      "(*) epoch 2, cost 2.910\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.883\n",
      "(*) epoch 2, cost 2.505\n",
      "(*) epoch 3, cost 1.877\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.45005326 0.55472812 0.1490895 ]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.72176135 0.18091717 0.09559925]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.43177778 0.59067439 0.14724342]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.72176135 0.18091717 0.09559925]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.43177778 0.59067439 0.14724342]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.34879379 0.73327254 0.29675815]\n",
      " [0.43177778 0.59067439 0.14724342]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.72176135 0.18091717 0.09559925]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.72176135 0.18091717 0.09559925]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.43177778 0.59067439 0.14724342]\n",
      " [0.72176135 0.18091717 0.09559925]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.43177778 0.59067439 0.14724342]\n",
      " [0.47710027 0.48876161 0.12831336]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.72176135 0.18091717 0.09559925]\n",
      " [0.45005326 0.55472812 0.1490895 ]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]\n",
      " [0.37025303 0.71413022 0.25184352]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.584\n",
      "(*) epoch 2, cost 1.249\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.922\n",
      "(*) epoch 2, cost 2.965\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.81870398 0.00467376 0.940684  ]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.87880549 0.00132281 0.9460924 ]\n",
      " [0.88085712 0.00141426 0.94246795]\n",
      " [0.80953395 0.00520137 0.93955644]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.80057409 0.00571968 0.93840322]\n",
      " [0.87872478 0.00131692 0.94627747]\n",
      " [0.88159114 0.00144987 0.94111758]\n",
      " [0.80944842 0.00520923 0.93949165]\n",
      " [0.80953395 0.00520137 0.93955644]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.84092475 0.00337843 0.94372751]\n",
      " [0.80944842 0.00520923 0.93949165]\n",
      " [0.80953395 0.00520137 0.93955644]\n",
      " [0.87856416 0.00131066 0.94654463]\n",
      " [0.86217086 0.00232921 0.94313464]\n",
      " [0.86012184 0.00244263 0.94296554]\n",
      " [0.87878256 0.00132031 0.94616022]\n",
      " [0.80944842 0.00520923 0.93949165]\n",
      " [0.84092475 0.00337843 0.94372751]\n",
      " [0.80944842 0.00520923 0.93949165]\n",
      " [0.80057409 0.00571968 0.93840322]\n",
      " [0.86217086 0.00232921 0.94313464]\n",
      " [0.87880549 0.00132281 0.9460924 ]\n",
      " [0.84050199 0.00341301 0.94348578]\n",
      " [0.84519768 0.00317384 0.94348948]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.82402945 0.00436423 0.94139657]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.87856243 0.00130967 0.94656443]\n",
      " [0.81870398 0.00467376 0.940684  ]\n",
      " [0.80953395 0.00520137 0.93955644]\n",
      " [0.86217086 0.00232921 0.94313464]\n",
      " [0.80944842 0.00520923 0.93949165]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.87869891 0.00131457 0.94634528]\n",
      " [0.81870398 0.00467376 0.940684  ]\n",
      " [0.84092475 0.00337843 0.94372751]\n",
      " [0.84050199 0.00341301 0.94348578]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.88085712 0.00141426 0.94246795]\n",
      " [0.86683585 0.00206876 0.94356101]\n",
      " [0.81870398 0.00467376 0.940684  ]\n",
      " [0.85164697 0.00290549 0.9423816 ]\n",
      " [0.88159114 0.00144987 0.94111758]\n",
      " [0.86012184 0.00244263 0.94296554]\n",
      " [0.86217086 0.00232921 0.94313464]\n",
      " [0.87878256 0.00132031 0.94616022]\n",
      " [0.80953395 0.00520137 0.93955644]]\n",
      "female_labels are: [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "female_pred_labels are: [1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.483\n",
      "(*) epoch 2, cost 1.091\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.676\n",
      "(*) epoch 2, cost 2.881\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.99684988 0.01635178 0.9888657 ]\n",
      " [0.96904412 0.10826632 0.27539947]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.9969976  0.01586285 0.99266209]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699465 0.01587266 0.99258593]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99684988 0.01635178 0.9888657 ]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.9969976  0.01586286 0.99266203]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.96904412 0.10826632 0.27539947]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.9969975  0.01586319 0.99265948]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.99699756 0.01586301 0.99266092]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.9969975  0.01586319 0.99265948]\n",
      " [0.98060083 0.07012213 0.57137697]\n",
      " [0.99666161 0.01697455 0.98403083]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1\n",
      " 1 0 1 1 0 0 0 0 1 1 0 1 1]\n",
      "trans_female_pred_labels are: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.537\n",
      "(*) epoch 2, cost 1.670\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.631\n",
      "(*) epoch 2, cost 2.819\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.29533992 0.1406844  0.76838778]\n",
      " [0.13180223 0.71751785 0.11341468]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.06230975 0.42695688 0.19858914]\n",
      " [0.20151634 0.17258824 0.64361441]\n",
      " [0.08325865 0.29915872 0.35705559]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.29603053 0.13765383 0.77333309]\n",
      " [0.31947524 0.11642998 0.82392638]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.05622986 0.35573296 0.25080764]\n",
      " [0.29603053 0.13765383 0.77333309]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.31947524 0.11642998 0.82392638]\n",
      " [0.31947524 0.11642998 0.82392638]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.20151634 0.17258824 0.64361441]\n",
      " [0.08717315 0.30397838 0.35210155]\n",
      " [0.05773788 0.3560839  0.25338894]\n",
      " [0.21386482 0.18109668 0.64011132]\n",
      " [0.23374673 0.18315346 0.65693666]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.04177321 0.43899112 0.13130152]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.29603053 0.13765383 0.77333309]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.21922875 0.16460215 0.66973687]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.26085669 0.14837025 0.72928541]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.26647433 0.14670725 0.73687896]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.23374673 0.18315346 0.65693666]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.26647433 0.14670725 0.73687896]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.26647433 0.14670725 0.73687896]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.29533992 0.1406844  0.76838778]\n",
      " [0.21386482 0.18109668 0.64011132]\n",
      " [0.14762273 0.17547254 0.59873365]\n",
      " [0.24462423 0.15459362 0.70521663]\n",
      " [0.23374673 0.18315346 0.65693666]\n",
      " [0.08047798 0.305671   0.34473812]]\n",
      "female_labels are: [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "female_pred_labels are: [1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.910\n",
      "(*) epoch 2, cost 3.349\n",
      "(*) epoch 3, cost 2.814\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.894\n",
      "(*) epoch 2, cost 2.783\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.75193274 0.82198695 0.7572904 ]\n",
      " [0.64908487 0.77090329 0.54196501]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.1405118  0.24832811 0.91396739]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.42682441 0.51358246 0.89088426]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.16397411 0.25658115 0.84852425]\n",
      " [0.16723269 0.29458414 0.28702799]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.14631657 0.26102233 0.92691145]\n",
      " [0.71530923 0.81075912 0.65222092]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.65995967 0.77894508 0.54951157]\n",
      " [0.64908487 0.77090329 0.54196501]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.1405118  0.24832811 0.91396739]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.16397411 0.25658115 0.84852425]\n",
      " [0.1405118  0.24832811 0.91396739]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.69897875 0.80263348 0.58081565]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.71530923 0.81075912 0.65222092]\n",
      " [0.65995967 0.77894508 0.54951157]\n",
      " [0.1405118  0.24832811 0.91396739]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.16397411 0.25658115 0.84852425]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.71530923 0.81075912 0.65222092]\n",
      " [0.75193274 0.82198695 0.7572904 ]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.1405118  0.24832811 0.91396739]\n",
      " [0.70901893 0.79865746 0.67475977]\n",
      " [0.33312158 0.43098986 0.90245607]\n",
      " [0.1405118  0.24832811 0.91396739]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0\n",
      " 0 0 1 0 1 1 0 0 1 1 0 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0\n",
      " 0 0 1 0 1 1 0 0 1 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.463\n",
      "(*) epoch 2, cost 2.140\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.553\n",
      "(*) epoch 2, cost 2.016\n",
      "(*) epoch 3, cost 1.290\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03338352 0.77247491 0.91915396]\n",
      " [0.03338352 0.77247491 0.91915396]\n",
      " [0.03923645 0.74999936 0.91578518]\n",
      " [0.03338352 0.77247491 0.91915396]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03923645 0.74999936 0.91578518]\n",
      " [0.14531452 0.25144439 0.67397874]\n",
      " [0.03338352 0.77247491 0.91915396]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03338352 0.77247491 0.91915396]\n",
      " [0.14531452 0.25144439 0.67397874]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.14531452 0.25144439 0.67397874]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.08097731 0.44083508 0.89254984]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.14531452 0.25144439 0.67397874]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03338352 0.77247491 0.91915396]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.14531452 0.25144439 0.67397874]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.14531452 0.25144439 0.67397874]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.03593937 0.68254258 0.93580782]\n",
      " [0.14531452 0.25144439 0.67397874]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.389\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.185\n",
      "(*) epoch 2, cost 3.337\n",
      "(*) epoch 3, cost 2.632\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.5642536  0.01356508 0.78928109]\n",
      " [0.56425498 0.01355442 0.78928702]\n",
      " [0.55554635 0.08081431 0.75186214]\n",
      " [0.56422015 0.01382339 0.78913736]\n",
      " [0.5642548  0.0135558  0.78928625]\n",
      " [0.56425929 0.01352111 0.78930556]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56083059 0.0400022  0.7745709 ]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56365465 0.01819097 0.78670714]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56425471 0.01355651 0.78928586]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56109868 0.03793165 0.77572299]\n",
      " [0.55712078 0.06865442 0.75862817]\n",
      " [0.56424776 0.01361019 0.78925599]\n",
      " [0.55554635 0.08081431 0.75186214]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56347339 0.01959087 0.78592821]\n",
      " [0.5642548  0.0135558  0.78928625]\n",
      " [0.56364707 0.01824953 0.78667456]\n",
      " [0.55851495 0.05788673 0.76461955]\n",
      " [0.56424776 0.01361019 0.78925599]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56425085 0.01358627 0.7892693 ]\n",
      " [0.56422015 0.01382339 0.78913736]\n",
      " [0.5642489  0.01360135 0.78926091]\n",
      " [0.56425085 0.01358627 0.7892693 ]\n",
      " [0.55554635 0.08081431 0.75186214]\n",
      " [0.56425929 0.01352111 0.78930556]\n",
      " [0.5642548  0.0135558  0.78928625]\n",
      " [0.56109868 0.03793165 0.77572299]\n",
      " [0.56422015 0.01382339 0.78913736]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56273926 0.02526087 0.78277329]\n",
      " [0.56424776 0.01361019 0.78925599]\n",
      " [0.55554635 0.08081431 0.75186214]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56422015 0.01382339 0.78913736]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56424776 0.01361019 0.78925599]\n",
      " [0.5642548  0.0135558  0.78928625]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.5642536  0.01356508 0.78928109]\n",
      " [0.56359965 0.01861575 0.78647079]\n",
      " [0.56425498 0.01355442 0.78928702]]\n",
      "female_labels are: [0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.720\n",
      "(*) epoch 2, cost 1.094\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.768\n",
      "(*) epoch 2, cost 3.500\n",
      "(*) epoch 3, cost 3.021\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.46003949 0.5942794  0.55820672]\n",
      " [0.44883477 0.64695689 0.53528873]\n",
      " [0.41239353 0.85096715 0.41987541]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.46003949 0.5942794  0.55820672]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.4145571  0.8434322  0.42682125]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.48147295 0.52051948 0.58101151]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.46003949 0.5942794  0.55820672]\n",
      " [0.45647402 0.60793813 0.55346497]\n",
      " [0.4606848  0.5914831  0.55940511]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.44883477 0.64695689 0.53528873]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.45530963 0.60777329 0.55593552]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.45647402 0.60793813 0.55346497]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.4606848  0.5914831  0.55940511]\n",
      " [0.4790364  0.46132668 0.63316393]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.46003949 0.5942794  0.55820672]\n",
      " [0.4790364  0.46132668 0.63316393]\n",
      " [0.41321951 0.84807223 0.42252794]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.47451908 0.50502359 0.60569884]\n",
      " [0.51095792 0.50874714 0.53980727]\n",
      " [0.45722942 0.60823921 0.55184255]\n",
      " [0.47451908 0.50502359 0.60569884]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.913\n",
      "(*) epoch 2, cost 3.248\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.428\n",
      "(*) epoch 2, cost 3.057\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.09575336 0.05417398 0.46597131]\n",
      " [0.02121274 0.08119939 0.1853896 ]\n",
      " [0.0513105  0.07036066 0.31489917]\n",
      " [0.02121274 0.08119939 0.1853896 ]\n",
      " [0.02704155 0.072455   0.1967618 ]\n",
      " [0.02326591 0.06747094 0.16611333]\n",
      " [0.02717973 0.07074367 0.19180103]\n",
      " [0.02346005 0.07454539 0.18004683]\n",
      " [0.01958335 0.08982153 0.19996455]\n",
      " [0.02393419 0.06691892 0.16427655]\n",
      " [0.02438721 0.06470937 0.16106547]\n",
      " [0.03970286 0.07331374 0.26825895]\n",
      " [0.02346005 0.07454539 0.18004683]\n",
      " [0.0246342  0.06504804 0.1626344 ]\n",
      " [0.02704155 0.072455   0.1967618 ]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.0246342  0.06504804 0.1626344 ]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02704155 0.072455   0.1967618 ]\n",
      " [0.02418792 0.06616293 0.16354816]\n",
      " [0.02156525 0.08066802 0.18606422]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02452665 0.06556199 0.16345172]\n",
      " [0.01958335 0.08982153 0.19996455]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.04951927 0.07035061 0.30623953]\n",
      " [0.02438721 0.06470937 0.16106547]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02121274 0.08119939 0.1853896 ]\n",
      " [0.02233418 0.0760541  0.17805622]\n",
      " [0.02426857 0.0661399  0.16597185]\n",
      " [0.02121274 0.08119939 0.1853896 ]\n",
      " [0.09575336 0.05417398 0.46597131]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02426857 0.0661399  0.16597185]\n",
      " [0.02326591 0.06747094 0.16611333]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.01958335 0.08982153 0.19996455]\n",
      " [0.02704155 0.072455   0.1967618 ]\n",
      " [0.02473935 0.06573683 0.16633286]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02302821 0.07022348 0.16788691]\n",
      " [0.02981372 0.07545142 0.22659087]\n",
      " [0.02326591 0.06747094 0.16611333]\n",
      " [0.02279588 0.07145835 0.16961965]\n",
      " [0.09575336 0.05417398 0.46597131]\n",
      " [0.02395922 0.07181253 0.18051765]\n",
      " [0.02279588 0.07145835 0.16961965]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.515\n",
      "(*) epoch 2, cost 2.216\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.815\n",
      "(*) epoch 2, cost 1.433\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.59276353 0.10913686 0.71529164]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15875838 0.0229329  0.25726015]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15875838 0.0229329  0.25726015]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.59276353 0.10913686 0.71529164]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.59276353 0.10913686 0.71529164]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15810274 0.27506867 0.69349719]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.57933916 0.09878829 0.65291829]\n",
      " [0.15810274 0.27506867 0.69349719]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.972\n",
      "(*) epoch 2, cost 2.811\n",
      "(*) epoch 3, cost 2.471\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.486\n",
      "(*) epoch 2, cost 2.249\n",
      "(*) epoch 3, cost 1.644\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.48640248 0.13549616 0.72792011]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.81865638 0.43514404 0.45235313]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.75031521 0.51760756 0.56022557]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.86160368 0.42437583 0.3725334 ]\n",
      " [0.87897745 0.41900772 0.33760654]\n",
      " [0.87897745 0.41900772 0.33760654]]\n",
      "female_labels are: [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.761\n",
      "(*) epoch 2, cost 2.097\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.649\n",
      "(*) epoch 2, cost 1.206\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.79010025 0.16600194 0.42555517]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.92239926 0.19475919 0.59012382]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]\n",
      " [0.85620263 0.41749473 0.18038211]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.641\n",
      "(*) epoch 2, cost 3.394\n",
      "(*) epoch 3, cost 2.922\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.715\n",
      "(*) epoch 2, cost 1.547\n",
      "(*) epoch 3, cost 1.037\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.172103   0.12931869 0.95249008]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.17685957 0.1283983  0.95431153]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.21612267 0.37487894 0.81387976]\n",
      " [0.1668135  0.13465766 0.94924171]\n",
      " [0.1668135  0.13465766 0.94924171]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0\n",
      " 0 1 1 1 1 1 0 1 1 1 0 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.876\n",
      "(*) epoch 2, cost 3.532\n",
      "(*) epoch 3, cost 2.427\n",
      "(*) epoch 4, cost 2.016\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.898\n",
      "(*) epoch 2, cost 1.976\n",
      "(*) epoch 3, cost 1.344\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05477769 0.55408983 0.72372578]\n",
      " [0.05477769 0.55408983 0.72372578]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05477769 0.55408983 0.72372578]\n",
      " [0.05477769 0.55408983 0.72372578]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05477769 0.55408983 0.72372578]\n",
      " [0.05254057 0.54581379 0.70988951]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05477769 0.55408983 0.72372578]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05254057 0.54581379 0.70988951]\n",
      " [0.05254057 0.54581379 0.70988951]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05477769 0.55408983 0.72372578]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05254057 0.54581379 0.70988951]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.31935912 0.80660844 0.92532973]\n",
      " [0.05477769 0.55408983 0.72372578]]\n",
      "female_labels are: [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.506\n",
      "(*) epoch 2, cost 2.111\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.767\n",
      "(*) epoch 2, cost 1.850\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.69643983 0.84068112 0.07282273]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.88705005 0.17841131 0.42423021]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.82804368 0.22511093 0.40760766]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.81647822 0.38771579 0.25104482]\n",
      " [0.82135767 0.13933405 0.53194476]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.82970665 0.24575033 0.38043558]\n",
      " [0.82970665 0.24575033 0.38043558]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.76070532 0.14347439 0.57694068]\n",
      " [0.76070532 0.14347439 0.57694068]\n",
      " [0.82970665 0.24575033 0.38043558]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.82970665 0.24575033 0.38043558]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.80406816 0.44390414 0.22093445]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.82804368 0.22511093 0.40760766]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.83174913 0.25668089 0.3653685 ]\n",
      " [0.69643983 0.84068112 0.07282273]\n",
      " [0.83174913 0.25668089 0.3653685 ]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.116\n",
      "(*) epoch 2, cost 0.756\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.200\n",
      "(*) epoch 2, cost 2.279\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.82117913 0.37450053 0.37688577]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.81364582 0.37373571 0.37648629]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.82117913 0.37450053 0.37688577]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.81364582 0.37373571 0.37648629]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94096495 0.40350156 0.35408207]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.82117913 0.37450053 0.37688577]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.83837278 0.4039304  0.32987092]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.81364582 0.37373571 0.37648629]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.94096495 0.40350156 0.35408207]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94741414 0.39806916 0.3649592 ]\n",
      " [0.95176095 0.39186069 0.37671369]\n",
      " [0.94741414 0.39806916 0.3649592 ]]\n",
      "female_labels are: [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.900\n",
      "(*) epoch 2, cost 2.467\n",
      "(*) epoch 3, cost 1.518\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.807\n",
      "(*) epoch 2, cost 3.367\n",
      "(*) epoch 3, cost 2.898\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.9342016  0.16440214 0.6220272 ]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.66916544 0.64818975 0.6363005 ]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.90472884 0.21636583 0.63601844]\n",
      " [0.90472884 0.21636583 0.63601844]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.66916544 0.64818975 0.6363005 ]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.90472884 0.21636583 0.63601844]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.69693616 0.61111346 0.70746778]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.96803129 0.10497663 0.60596148]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.79003788 0.4839604  0.60344882]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.66916544 0.64818975 0.6363005 ]\n",
      " [0.66916544 0.64818975 0.6363005 ]\n",
      " [0.96803129 0.10497663 0.60596148]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.96893233 0.10339053 0.60553501]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.66916544 0.64818975 0.6363005 ]\n",
      " [0.96803129 0.10497663 0.60596148]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.69507741 0.61017    0.71145934]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.89799743 0.14322875 0.60973829]\n",
      " [0.9342016  0.16440214 0.6220272 ]\n",
      " [0.69507741 0.61017    0.71145934]]\n",
      "female_labels are: [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "female_pred_labels are: [1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 0 0 1 0 0 1 0 1 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.146\n",
      "(*) epoch 2, cost 1.677\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.330\n",
      "(*) epoch 2, cost 1.967\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.70456066 0.14207745 0.46906235]\n",
      " [0.4836355  0.11596132 0.79897084]\n",
      " [0.4836355  0.11596132 0.79897084]\n",
      " [0.4836355  0.11596132 0.79897084]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.70456066 0.14207745 0.46906235]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.74616527 0.10790238 0.44875906]\n",
      " [0.74616527 0.10790238 0.44875906]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.70456066 0.14207745 0.46906235]\n",
      " [0.72876206 0.1239912  0.45529906]\n",
      " [0.70456066 0.14207745 0.46906235]\n",
      " [0.72876206 0.1239912  0.45529906]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.70456066 0.14207745 0.46906235]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.70456066 0.14207745 0.46906235]\n",
      " [0.72876206 0.1239912  0.45529906]\n",
      " [0.4836355  0.11596132 0.79897084]\n",
      " [0.74616527 0.10790238 0.44875906]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.4836355  0.11596132 0.79897084]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.70456066 0.14207745 0.46906235]\n",
      " [0.42800203 0.18756322 0.79862856]\n",
      " [0.6868773  0.09928251 0.53961354]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.4836355  0.11596132 0.79897084]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.46981822 0.12579176 0.80734842]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.4836355  0.11596132 0.79897084]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.82313859 0.01332224 0.44516456]\n",
      " [0.37479994 0.29616145 0.75640926]\n",
      " [0.82313859 0.01332224 0.44516456]]\n",
      "female_labels are: [1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 1 0 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.357\n",
      "(*) epoch 2, cost 0.948\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.818\n",
      "(*) epoch 2, cost 1.325\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.89736344 0.94278326 0.23118917]\n",
      " [0.02238503 0.39427785 0.08964328]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.58930642 0.74523797 0.18188637]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.57759414 0.74010621 0.17972636]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.57759414 0.74010621 0.17972636]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.89736344 0.94278326 0.23118917]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.57759414 0.74010621 0.17972636]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.70188766 0.81488556 0.20021   ]\n",
      " [0.89736344 0.94278326 0.23118917]\n",
      " [0.53006117 0.76462356 0.16551799]\n",
      " [0.70188766 0.81488556 0.20021   ]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.936\n",
      "(*) epoch 2, cost 3.582\n",
      "(*) epoch 3, cost 3.056\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.650\n",
      "(*) epoch 2, cost 1.443\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.09403639 0.44788423 0.10840939]\n",
      " [0.09403639 0.44788423 0.10840939]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.10098854 0.66396931 0.04694483]\n",
      " [0.10098854 0.66396931 0.04694483]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.10098854 0.66396931 0.04694483]\n",
      " [0.06813724 0.35382233 0.08937441]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.09403639 0.44788423 0.10840939]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.10098854 0.66396931 0.04694483]\n",
      " [0.06813724 0.35382233 0.08937441]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.09872353 0.5780027  0.07150047]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.09872353 0.5780027  0.07150047]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.10098854 0.66396931 0.04694483]\n",
      " [0.10098854 0.66396931 0.04694483]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.09403639 0.44788423 0.10840939]\n",
      " [0.09403639 0.44788423 0.10840939]\n",
      " [0.3962715  0.44582518 0.43490691]\n",
      " [0.10098854 0.66396931 0.04694483]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.086\n",
      "(*) epoch 2, cost 2.633\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.010\n",
      "(*) epoch 2, cost 2.786\n",
      "(*) epoch 3, cost 2.317\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.27037166 0.08343717 0.31720591]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.23377187 0.08564515 0.29410561]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.06672346 0.65237468 0.14398144]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.06672346 0.65237468 0.14398144]\n",
      " [0.14181962 0.09021294 0.25841065]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.14181962 0.09021294 0.25841065]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.16871154 0.09267256 0.25182371]\n",
      " [0.14181962 0.09021294 0.25841065]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.14181962 0.09021294 0.25841065]\n",
      " [0.14181962 0.09021294 0.25841065]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.20025458 0.0934378  0.25732452]\n",
      " [0.27771619 0.24924274 0.47101075]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.22135828 0.15479646 0.37898702]\n",
      " [0.06672346 0.65237468 0.14398144]\n",
      " [0.27037166 0.08343717 0.31720591]\n",
      " [0.14181962 0.09021294 0.25841065]\n",
      " [0.27037166 0.08343717 0.31720591]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.825\n",
      "(*) epoch 2, cost 3.379\n",
      "(*) epoch 3, cost 2.894\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.599\n",
      "(*) epoch 2, cost 3.625\n",
      "(*) epoch 3, cost 3.083\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.98528284 0.06707467 0.17082915]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.87249531 0.73397242 0.29516495]\n",
      " [0.81699447 0.77543822 0.31824603]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.87249531 0.73397242 0.29516495]\n",
      " [0.82270871 0.77951328 0.30034707]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.81699447 0.77543822 0.31824603]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.98528284 0.06707467 0.17082915]\n",
      " [0.98528284 0.06707467 0.17082915]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.82270871 0.77951328 0.30034707]\n",
      " [0.98565772 0.07118305 0.163763  ]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.98528284 0.06707467 0.17082915]\n",
      " [0.98528284 0.06707467 0.17082915]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.98565772 0.07118305 0.163763  ]\n",
      " [0.98392977 0.07380912 0.17518166]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.98675722 0.10883334 0.12400951]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.9885589  0.08295393 0.12546815]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.85139983 0.78758183 0.24947864]\n",
      " [0.98528284 0.06707467 0.17082915]\n",
      " [0.98528284 0.06707467 0.17082915]\n",
      " [0.98675722 0.10883334 0.12400951]\n",
      " [0.82067063 0.77905805 0.30374465]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.91438646 0.49925615 0.22773931]\n",
      " [0.87249531 0.73397242 0.29516495]\n",
      " [0.98528284 0.06707467 0.17082915]\n",
      " [0.97595833 0.19445656 0.12428591]\n",
      " [0.91438646 0.49925615 0.22773931]]\n",
      "female_labels are: [1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1\n",
      " 0 0 1 1 1 0 0 0 0 0 1 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.212\n",
      "(*) epoch 2, cost 2.238\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.706\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.29613008 0.54499024 0.72746198]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29914978 0.54196932 0.73359084]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.29613008 0.54499024 0.72746198]\n",
      " [0.6636791  0.50583146 0.74209043]\n",
      " [0.6636791  0.50583146 0.74209043]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.022\n",
      "(*) epoch 2, cost 2.435\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.534\n",
      "(*) epoch 2, cost 2.034\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.25601848e-02 5.97161153e-01 3.47527411e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.12422511e-02 5.49415820e-01 4.24834404e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.25601848e-02 5.97161153e-01 3.47527411e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [1.12422511e-02 5.49415820e-01 4.24834404e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [1.25601848e-02 5.97161153e-01 3.47527411e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [5.37553792e-02 4.16308072e-01 6.30945906e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.51312497e-01 5.65695906e-01 1.33489284e-01]\n",
      " [1.12422511e-02 5.49415820e-01 4.24834404e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.25601848e-02 5.97161153e-01 3.47527411e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.25601848e-02 5.97161153e-01 3.47527411e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.68159697e-04 2.50155208e-01 9.38230809e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [8.06547469e-02 5.44441985e-01 3.99885808e-01]\n",
      " [6.82182460e-02 4.71019055e-01 5.30771344e-01]\n",
      " [1.12422511e-02 5.49415820e-01 4.24834404e-01]\n",
      " [1.12422511e-02 5.49415820e-01 4.24834404e-01]]\n",
      "female_labels are: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.989\n",
      "(*) epoch 2, cost 3.037\n",
      "(*) epoch 3, cost 2.454\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.540\n",
      "(*) epoch 2, cost 2.055\n",
      "(*) epoch 3, cost 1.697\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.2871617  0.17255661 0.29883952]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.2871617  0.17255661 0.29883952]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.2871617  0.17255661 0.29883952]\n",
      " [0.21466578 0.13546625 0.42998012]\n",
      " [0.41756452 0.34201272 0.70718804]\n",
      " [0.13543867 0.08376196 0.60738608]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.13543867 0.08376196 0.60738608]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.2871617  0.17255661 0.29883952]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.21466578 0.13546625 0.42998012]\n",
      " [0.21466578 0.13546625 0.42998012]\n",
      " [0.21351408 0.11418    0.68136474]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.13543867 0.08376196 0.60738608]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.2871617  0.17255661 0.29883952]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.2871617  0.17255661 0.29883952]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.2871617  0.17255661 0.29883952]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]\n",
      " [0.31844971 0.24877327 0.67957674]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.070\n",
      "(*) epoch 2, cost 3.212\n",
      "(*) epoch 3, cost 2.458\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.647\n",
      "(*) epoch 2, cost 2.337\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.92970979 0.07187312 0.16206418]\n",
      " [0.94675354 0.08269238 0.19293434]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.26959675 0.42403258 0.86349513]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.94391325 0.08221257 0.18596359]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.87859732 0.1187196  0.27972707]\n",
      " [0.93831013 0.08471879 0.18944188]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.94626508 0.08143207 0.18673021]\n",
      " [0.94626508 0.08143207 0.18673021]\n",
      " [0.92970979 0.07187312 0.16206418]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.94675354 0.08269238 0.19293434]\n",
      " [0.92970979 0.07187312 0.16206418]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.94626508 0.08143207 0.18673021]\n",
      " [0.94675354 0.08269238 0.19293434]\n",
      " [0.93831013 0.08471879 0.18944188]\n",
      " [0.94626508 0.08143207 0.18673021]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.93831013 0.08471879 0.18944188]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.94675354 0.08269238 0.19293434]\n",
      " [0.94675354 0.08269238 0.19293434]\n",
      " [0.69572172 0.27912273 0.53645894]\n",
      " [0.60708862 0.2819152  0.63136379]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.77446391 0.24028586 0.48189664]\n",
      " [0.94673476 0.08177971 0.18907947]\n",
      " [0.93831013 0.08471879 0.18944188]\n",
      " [0.94391325 0.08221257 0.18596359]\n",
      " [0.82459161 0.16811568 0.39396687]\n",
      " [0.92970979 0.07187312 0.16206418]\n",
      " [0.74015852 0.21699469 0.49928854]\n",
      " [0.59107769 0.30521792 0.62164909]\n",
      " [0.94675354 0.08269238 0.19293434]\n",
      " [0.82459161 0.16811568 0.39396687]]\n",
      "female_labels are: [0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.280\n",
      "(*) epoch 2, cost 0.769\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.573\n",
      "(*) epoch 2, cost 2.519\n",
      "(*) epoch 3, cost 2.135\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]\n",
      " [0.50395077 0.63537433 0.48685134]]\n",
      "exception 1\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.461\n",
      "(*) epoch 2, cost 3.142\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.991\n",
      "(*) epoch 2, cost 2.270\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.28732838 0.08031113 0.06510433]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.53867145 0.18091486 0.05915293]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.75693782 0.31509425 0.07783908]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.75693782 0.31509425 0.07783908]\n",
      " [0.21140484 0.08126778 0.05718817]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.75693782 0.31509425 0.07783908]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.69657635 0.23813134 0.06269591]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.75693782 0.31509425 0.07783908]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.39849834 0.14068438 0.05860299]\n",
      " [0.75693782 0.31509425 0.07783908]\n",
      " [0.16319792 0.09625538 0.07950085]\n",
      " [0.75693782 0.31509425 0.07783908]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.75693782 0.31509425 0.07783908]\n",
      " [0.1304199  0.14557652 0.10909563]\n",
      " [0.16319792 0.09625538 0.07950085]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 0 1]\n",
      "trans_female_pred_labels are: [0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.405\n",
      "(*) epoch 2, cost 2.472\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.474\n",
      "(*) epoch 2, cost 1.324\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.84750364 0.14643702 0.24117823]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.40264849 0.80140885 0.1941541 ]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.89183581 0.2946102  0.10813351]\n",
      " [0.84750364 0.14643702 0.24117823]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.7196769  0.20458045 0.23753987]\n",
      " [0.84750364 0.14643702 0.24117823]]\n",
      "female_labels are: [0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.013\n",
      "(*) epoch 2, cost 3.861\n",
      "(*) epoch 3, cost 3.580\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.640\n",
      "(*) epoch 2, cost 2.368\n",
      "(*) epoch 3, cost 1.891\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.43265035 0.28656169 0.94324194]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.54493164 0.21508539 0.96039816]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.40203632 0.2924111  0.9306956 ]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.40203632 0.2924111  0.9306956 ]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.63868368 0.19769266 0.96878542]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.63868368 0.19769266 0.96878542]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.54493164 0.21508539 0.96039816]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.54493164 0.21508539 0.96039816]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.54493164 0.21508539 0.96039816]\n",
      " [0.54493164 0.21508539 0.96039816]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.08756216 0.57827655 0.96489625]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.37554828 0.31435142 0.92649967]\n",
      " [0.43265035 0.28656169 0.94324194]\n",
      " [0.37554828 0.31435142 0.92649967]]\n",
      "female_labels are: [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.795\n",
      "(*) epoch 2, cost 3.522\n",
      "(*) epoch 3, cost 3.074\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.232\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.06896774 0.27063874 0.83723471]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.06896774 0.27063874 0.83723471]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.06896774 0.27063874 0.83723471]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.06896774 0.27063874 0.83723471]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]\n",
      " [0.53481291 0.83887051 0.24224268]]\n",
      "female_labels are: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.597\n",
      "(*) epoch 2, cost 4.109\n",
      "(*) epoch 3, cost 3.474\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.988\n",
      "(*) epoch 2, cost 1.360\n",
      "(*) epoch 3, cost 0.770\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]\n",
      " [0.13502345 0.49584235 0.29676003]]\n",
      "female_labels are: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "exception 2\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.021\n",
      "(*) epoch 2, cost 1.067\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.576\n",
      "(*) epoch 2, cost 3.107\n",
      "(*) epoch 3, cost 2.398\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.59045473 0.36413355 0.33227383]\n",
      " [0.28438967 0.56646481 0.11265199]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.55632577 0.37731373 0.30349067]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.28509994 0.55086469 0.10947944]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.62052004 0.35511804 0.36485781]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.62052004 0.35511804 0.36485781]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.62052004 0.35511804 0.36485781]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.62052004 0.35511804 0.36485781]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.53083821 0.3899332  0.28308713]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.57087278 0.37907903 0.31995505]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.58898957 0.37478156 0.33764647]\n",
      " [0.59045473 0.36413355 0.33227383]\n",
      " [0.55334021 0.38366946 0.30350115]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.59986654 0.36118838 0.342069  ]\n",
      " [0.58898957 0.37478156 0.33764647]]\n",
      "female_labels are: [0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.345\n",
      "(*) epoch 2, cost 3.004\n",
      "(*) epoch 3, cost 2.024\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.530\n",
      "(*) epoch 2, cost 3.112\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.67961448 0.2639274  0.65612808]\n",
      " [0.69566226 0.49600228 0.41189028]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.69566226 0.49600228 0.41189028]\n",
      " [0.71814005 0.60270655 0.2732362 ]\n",
      " [0.68835209 0.43128384 0.47072171]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.65594952 0.11859503 0.80978143]\n",
      " [0.65594952 0.11859503 0.80978143]\n",
      " [0.70939254 0.71540585 0.14734817]\n",
      " [0.71814005 0.60270655 0.2732362 ]\n",
      " [0.70939254 0.71540585 0.14734817]\n",
      " [0.73217564 0.65312698 0.20935288]\n",
      " [0.65594952 0.11859503 0.80978143]\n",
      " [0.63190278 0.16369533 0.77362259]\n",
      " [0.65594952 0.11859503 0.80978143]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.65594952 0.11859503 0.80978143]\n",
      " [0.68417043 0.79844083 0.04965954]\n",
      " [0.68835209 0.43128384 0.47072171]\n",
      " [0.72388079 0.66150402 0.20935277]\n",
      " [0.65594952 0.11859503 0.80978143]\n",
      " [0.73217564 0.65312698 0.20935288]\n",
      " [0.67961448 0.2639274  0.65612808]\n",
      " [0.68835209 0.43128384 0.47072171]\n",
      " [0.69566226 0.49600228 0.41189028]\n",
      " [0.71814005 0.60270655 0.2732362 ]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.67961448 0.2639274  0.65612808]\n",
      " [0.69566226 0.49600228 0.41189028]\n",
      " [0.67961448 0.2639274  0.65612808]\n",
      " [0.73217564 0.65312698 0.20935288]\n",
      " [0.68417043 0.79844083 0.04965954]\n",
      " [0.71814005 0.60270655 0.2732362 ]\n",
      " [0.71098965 0.73567072 0.12744696]\n",
      " [0.67961448 0.2639274  0.65612808]\n",
      " [0.68417043 0.79844083 0.04965954]\n",
      " [0.70939254 0.71540585 0.14734817]\n",
      " [0.72388079 0.66150402 0.20935277]\n",
      " [0.71814005 0.60270655 0.2732362 ]\n",
      " [0.69566226 0.49600228 0.41189028]\n",
      " [0.68417043 0.79844083 0.04965954]\n",
      " [0.71098965 0.73567072 0.12744696]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.72388079 0.66150402 0.20935277]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.72888512 0.62463114 0.2431104 ]\n",
      " [0.65594952 0.11859503 0.80978143]]\n",
      "female_labels are: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.161\n",
      "(*) epoch 2, cost 1.874\n",
      "(*) epoch 3, cost 1.335\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.691\n",
      "(*) epoch 2, cost 2.189\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.4731574  0.30349392 0.57297159]\n",
      " [0.49197349 0.28527155 0.58790126]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.49197349 0.28527155 0.58790126]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.50035756 0.28223741 0.58834925]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.9076448  0.08260216 0.57578511]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.50035756 0.28223741 0.58834925]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.50035756 0.28223741 0.58834925]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.44243503 0.33859298 0.60491835]\n",
      " [0.44243503 0.33859298 0.60491835]\n",
      " [0.79125885 0.10633514 0.56087008]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.49197349 0.28527155 0.58790126]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.49197349 0.28527155 0.58790126]\n",
      " [0.44243503 0.33859298 0.60491835]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.50035756 0.28223741 0.58834925]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.49197349 0.28527155 0.58790126]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.44243503 0.33859298 0.60491835]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.49197349 0.28527155 0.58790126]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.4731574  0.30349392 0.57297159]\n",
      " [0.50035756 0.28223741 0.58834925]\n",
      " [0.4731574  0.30349392 0.57297159]]\n",
      "female_labels are: [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.398\n",
      "(*) epoch 2, cost 3.099\n",
      "(*) epoch 3, cost 2.356\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.310\n",
      "(*) epoch 2, cost 1.918\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.32116775 0.76642232 0.25775349]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.32116775 0.76642232 0.25775349]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.32116775 0.76642232 0.25775349]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.32116775 0.76642232 0.25775349]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.32757009 0.69061467 0.34977862]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.34248801 0.62646772 0.4024355 ]\n",
      " [0.21171697 0.85895849 0.16660061]\n",
      " [0.16494375 0.89776306 0.12481645]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.33102415 0.64292996 0.38544261]\n",
      " [0.34248801 0.62646772 0.4024355 ]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.32116775 0.76642232 0.25775349]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.32116775 0.76642232 0.25775349]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.32116775 0.76642232 0.25775349]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.30692866 0.77904529 0.24551292]\n",
      " [0.24175838 0.83242018 0.18988585]\n",
      " [0.39874287 0.54557101 0.48628554]\n",
      " [0.32116775 0.76642232 0.25775349]\n",
      " [0.32116775 0.76642232 0.25775349]]\n",
      "female_labels are: [0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0]\n",
      "female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "trans_female_pred_labels are: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "enter try\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 8.354\n",
      "(*) epoch 2, cost 5.439\n",
      "(*) epoch 3, cost 4.574\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.478\n",
      "(*) epoch 2, cost 2.428\n",
      "(*) epoch 3, cost 1.587\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "enter balanced\n",
      "before return is: [[0.97616524 0.14167769 0.19055209]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.98366019 0.09552532 0.10393672]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97355101 0.10060296 0.26337979]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96365728 0.18192276 0.41598511]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97138976 0.15879272 0.26474943]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.98366019 0.09552532 0.10393672]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97616524 0.14167769 0.19055209]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97355101 0.10060296 0.26337979]\n",
      " [0.96365728 0.18192276 0.41598511]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.97138976 0.15879272 0.26474943]\n",
      " [0.98563147 0.09857112 0.14341104]\n",
      " [0.96149485 0.1881929  0.41886994]\n",
      " [0.95050499 0.22402279 0.46767201]\n",
      " [0.96149485 0.1881929  0.41886994]]\n",
      "female_labels are: [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1]\n",
      "female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trans_female_pred_labels are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "    female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "    trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s = \\\n",
    "    run_proc_multi(simulate_1, custom_train_reps, svm.SVC , n_times = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = \"../outputs/sim1_logit_scores.csv\"\n",
    "save_scores(male_accuracies, male_precisions, male_recalls, male_f1s, \\\n",
    "        female_accuracies, female_precisions, female_recalls, female_f1s, \\\n",
    "        trans_female_accuracies, trans_female_precisions, trans_female_recalls, trans_female_f1s, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans female to female accuracy is: 16.511295628558738\n",
      "average trans female to female f1 is: 24.679122426223397\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_plot(score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
