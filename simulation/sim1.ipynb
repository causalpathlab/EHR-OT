{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation goals\n",
    "\n",
    "* Categorical response variable\n",
    "\n",
    "* Different feature distribution for different domains\n",
    "\n",
    "Simulation\n",
    "\n",
    "* $D$: total number of features\n",
    "\n",
    "* $d_{1}$: number of features with higher frequency in a domain 1\n",
    "\n",
    "* $d_{2}$: number of features with higher frequency in a domain 2\n",
    "\n",
    "\n",
    "* $d_{1} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$\n",
    "\n",
    "* $d_{2} \\sim \\operatorname{Unif}(0, \\lfloor D/4 \\rfloor)$ ($d_{1} + d_{2} \\le D$)\n",
    "\n",
    "* $k \\in [D]$ for indexing feature\n",
    "\n",
    "* Let $\\Delta_{r} = \\{j \\in [D]: \\textrm{feature } j \\textrm{ is more frequent in a domain } r \\}$\n",
    "\n",
    "* Sample $\\Delta_{1} \\subseteq [D]$ such that $|\\Delta_{1}| = d_{1}$ \n",
    "\n",
    "* Sample $\\Delta_{2} \\subseteq [D]\\backslash \\Delta_{1}$ such that $|\\Delta_{2}| = d_{2}$\n",
    "\n",
    "* Let $\\alpha_{1} \\overset{\\Delta}{=} \\left( \\alpha_{11}, \\ldots, \\alpha_{1D} \\right)$ be a feature frequency vector for a domain 1\n",
    "\n",
    "* Let $\\alpha_{2} \\overset{\\Delta}{=} \\left( \\alpha_{21}, \\ldots, \\alpha_{2D} \\right)$ be a feature frequency vector for a domain 2\n",
    "\n",
    "\n",
    "* For each $k \\in [D]$: \n",
    "\n",
    "    * If $k \\in \\Delta_{1}$, $\\alpha_{1k} > \\alpha_{2k}$\n",
    "\n",
    "    * If $k \\in \\Delta_{2}$, $\\alpha_{2k} > \\alpha_{1k}$\n",
    "\n",
    "    * Otherwise $\\alpha_{1k} = \\alpha_{2k}$\n",
    "\n",
    "\n",
    "* Sample $\\rho_{1} \\sim \\operatorname{Dir}(\\alpha_{1})$\n",
    "\n",
    "* Sample $\\rho_{2} \\sim \\operatorname{Dir}(\\alpha_{2})$\n",
    "\n",
    "* Sample a code-specific contribution to mortality: $W_{i} \\sim   \\mathcal{N}\\!\\left(0,1\\right)$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "    * $\\tilde{X}_{i} \\sim \\operatorname{Multi}(n_{i}; \\rho_{r})$ where $\\tilde{X}_{i}$ is a vector of counts for each diagnosis code/feature, $n_i = 3k$.\n",
    "\n",
    "\t* We set $X_{ik} = \\min \\left\\{ \\tilde{X}_{ik}, 1 \\right\\}$ where $\\tilde{X}_{ik}$ is a count for a diagnosis code/feature $k$, $k \\in [D]$\n",
    "\n",
    "* For all patient $i$ in a domain $r$\n",
    "\n",
    "    * $b = -\\operatorname{Mean}(\\sum_{k} W_{k} X_{ik})$\n",
    "\n",
    "* For each patient $i$ in a domain $r$\n",
    "\n",
    "\t* pathogenic score $\\bar{p}_{i} = \\operatorname{sigmoid}(\\sum_{k} W_{k} X_{ik} + b)$ (aka a liability model)\n",
    "\n",
    "    <!-- * If $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; else $Y_{i} = 0$. -->\n",
    "\n",
    "\t* Sample $Y_{i} \\sim \\operatorname{Bern}(\\bar{p}_{i})$\n",
    "\n",
    "    * Alternatively, if $\\bar{p}_{i} \\ge 0.5, Y_{i} = 1$; otherwise, $Y_{i} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/deep_patient/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from deep_patient.sda import SDA\n",
    "from math import floor, exp, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "base_dir = \"/home/wanxinli/deep_patient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    unit_1 = 1/(2*d_1-2*d_2+3*D)\n",
    "    alpha_1 = [5*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([3*unit_1]*(D-d_1-d_2))\n",
    "  \n",
    "    unit_2 = 1/(-2*d_1+2*d_2+3*D)\n",
    "    alpha_2 = [unit_2]*d_1\n",
    "    alpha_2.extend([5*unit_2]*d_2)\n",
    "    alpha_2.extend([3*unit_2]*(D-d_1-d_2))  \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [abs(W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            cur_sum = np.sum(np.multiply(W, X_i))\n",
    "            all_sum.append(cur_sum)\n",
    "        \n",
    "        print(\"all_sum before preprocessing is:\", all_sum)\n",
    "        # standardize\n",
    "        all_sum = preprocessing.scale(all_sum)\n",
    "        print(\"all_sum after preprocessing is:\", all_sum)\n",
    "\n",
    "        all_sum = np.array(all_sum)\n",
    "        \n",
    "        P = []\n",
    "        for cur_sum in all_sum:\n",
    "            p_i = sigmoid(cur_sum)\n",
    "            P.append(p_i)\n",
    "            Y_i = 0\n",
    "            if p_i >= 0.5: # TODO: mimic exact logistic regression, change to np.random.binomial later\n",
    "                Y_i = 1\n",
    "            # Y_i = np.random.binomial(1, p_i) # too much noise, domain 1 data cannot learn well\n",
    "            Y.append(int(Y_i))\n",
    "        print(\"P is:\", P)\n",
    "\n",
    "            \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), label_1, np.array(feature_2), label_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Wrapper function with different set ups for simulate()\n",
    "\"\"\"\n",
    "def simulate_wrapper(num_patient):\n",
    "    D = 20\n",
    "    d_1 = 8\n",
    "    d_2 = 8\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train deep patient model and generate representations for targets and sources\n",
    "\"\"\"\n",
    "\n",
    "def custom_train_reps(target_seqs, source_seqs):\n",
    "    \"\"\" \n",
    "    Customized training algorithm for generating target representations and source representations\n",
    "    \n",
    "    :returns: target representations, source representations\n",
    "    \"\"\"\n",
    "\n",
    "    # customized parameters\n",
    "    nhidden = 3\n",
    "    nlayer = 1\n",
    "\n",
    "    # for targets\n",
    "    # initiate the model\n",
    "    target_sda = SDA(target_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    target_sda.train(target_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    target_reps = target_sda.apply(target_seqs)\n",
    "\n",
    "    # for sources\n",
    "    # initiate the model\n",
    "    source_sda = SDA(source_seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    source_sda.train(source_seqs)\n",
    "\n",
    "    # apply the mode\n",
    "    source_reps = source_sda.apply(source_seqs)\n",
    "    return target_reps, source_reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(target_reps, target_labels, source_reps, source_labels, trans_source_reps, title):\n",
    "    target_1 = [i for i, x in enumerate(target_labels) if x == 1]\n",
    "    target_0 = [i for i, x in enumerate(target_labels) if x == 0]\n",
    "    source_1 = [i for i, x in enumerate(source_labels) if x == 1]\n",
    "    source_0 = [i for i, x in enumerate(source_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(target_reps[target_0,0], target_reps[target_0,1], target_reps[target_0,2], color='red', label=\"target 0\", alpha=0.5, facecolors='none', s=130)\n",
    "    ax.scatter(target_reps[target_1,0], target_reps[target_1,1], target_reps[target_1,2], color='red', label=\"target 1\", alpha=0.5, marker=\"x\", s=130)\n",
    "\n",
    "    ax.scatter(source_reps[source_0,0], source_reps[source_0,1], source_reps[source_0,2], color='blue', label=\"source 0\", alpha=0.5, facecolors='none', s=100)\n",
    "    ax.scatter(source_reps[source_1,0], source_reps[source_1,1], source_reps[source_1,2], color='blue', label=\"source 1\", alpha=0.5, marker=\"x\", s=100)\n",
    "\n",
    "    ax.scatter(trans_source_reps[source_0,0], trans_source_reps[source_0,1], trans_source_reps[source_0,2], color='green', label=\"trans source 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_source_reps[source_1,0], trans_source_reps[source_1,1], trans_source_reps[source_1,2], color='green', label=\"trans source 1\",  alpha=0.5, marker=\"x\", s=70)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_opp(target_reps, target_labels, source_reps, source_labels, trans_target_reps, title):\n",
    "    target_1 = [i for i, x in enumerate(target_labels) if x == 1]\n",
    "    target_0 = [i for i, x in enumerate(target_labels) if x == 0]\n",
    "    source_1 = [i for i, x in enumerate(source_labels) if x == 1]\n",
    "    source_0 = [i for i, x in enumerate(source_labels) if x == 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(target_reps[target_0,0], target_reps[target_0,1], target_reps[target_0,2], color='red', label=\"target 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(target_reps[target_1,0], target_reps[target_1,1], target_reps[target_1,2], color='red', label=\"target 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(source_reps[source_0,0], source_reps[source_0,1], source_reps[source_0,2], color='blue', label=\"source 0\", alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(source_reps[source_1,0], source_reps[source_1,1], source_reps[source_1,2], color='blue', label=\"source 1\", alpha=0.5, marker=\"x\")\n",
    "\n",
    "    ax.scatter(trans_target_reps[target_0,0], trans_target_reps[target_0,1], trans_target_reps[target_0,2], color='green', label=\"trans target 0\",  alpha=0.5, facecolors='none', s=70)\n",
    "    ax.scatter(trans_target_reps[target_1,0], trans_target_reps[target_1,1], trans_target_reps[target_1,2], color='green', label=\"trans target 1\",  alpha=0.5, marker=\"x\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_sum before preprocessing is: [2.047864394143187, 2.047864394143187, 1.0772811680115835, 1.0772811680115835, 2.047864394143187, 2.226982743680851, 3.5321716051017376, 2.226982743680851, 2.047864394143187, 3.1268771366842483, 3.790535317010329, 2.047864394143187, 2.047864394143187, 1.0772811680115835, 1.0772811680115835, 2.047864394143187, 2.226982743680851, 1.0772811680115835, 2.047864394143187, 2.047864394143187, 2.047864394143187, 2.640833741341061, 1.0772811680115835, 2.047864394143187, 2.226982743680851, 3.611416967472665, 2.047864394143187, 0.8543409599776696, 1.0772811680115835, 1.0772811680115835, 2.047864394143187, 3.197565969812455, 2.226982743680851, 2.047864394143187, 1.0772811680115835, 3.790535317010329, 1.0772811680115835, 1.0772811680115835, 2.047864394143187, 0.8543409599776696, 1.0772811680115835, 1.0772811680115835, 2.047864394143187, 1.0772811680115835, 2.047864394143187, 2.226982743680851, 1.0772811680115835, 3.197565969812455, 1.0772811680115835, 2.047864394143187]\n",
      "all_sum after preprocessing is: [ 0.15795386  0.15795386 -1.05165159 -1.05165159  0.15795386  0.38118307\n",
      "  2.00779634  0.38118307  0.15795386  1.50269139  2.32978641  0.15795386\n",
      "  0.15795386 -1.05165159 -1.05165159  0.15795386  0.38118307 -1.05165159\n",
      "  0.15795386  0.15795386  0.15795386  0.89695175 -1.05165159  0.15795386\n",
      "  0.38118307  2.10655719  0.15795386 -1.32949452 -1.05165159 -1.05165159\n",
      "  0.15795386  1.59078852  0.38118307  0.15795386 -1.05165159  2.32978641\n",
      " -1.05165159 -1.05165159  0.15795386 -1.32949452 -1.05165159 -1.05165159\n",
      "  0.15795386 -1.05165159  0.15795386  0.38118307 -1.05165159  1.59078852\n",
      " -1.05165159  0.15795386]\n",
      "P is: [0.5394065679749431, 0.5394065679749431, 0.2589080768240843, 0.2589080768240843, 0.5394065679749431, 0.5941584142697558, 0.8816132170568562, 0.5941584142697558, 0.5394065679749431, 0.8179755444072931, 0.9113140755023914, 0.5394065679749431, 0.5394065679749431, 0.2589080768240843, 0.2589080768240843, 0.5394065679749431, 0.5941584142697558, 0.2589080768240843, 0.5394065679749431, 0.5394065679749431, 0.5394065679749431, 0.7103226827736276, 0.2589080768240843, 0.5394065679749431, 0.5941584142697558, 0.8915388714643292, 0.5394065679749431, 0.20924298979096664, 0.2589080768240843, 0.2589080768240843, 0.5394065679749431, 0.8307270135072359, 0.5941584142697558, 0.5394065679749431, 0.2589080768240843, 0.9113140755023914, 0.2589080768240843, 0.2589080768240843, 0.5394065679749431, 0.20924298979096664, 0.2589080768240843, 0.2589080768240843, 0.5394065679749431, 0.2589080768240843, 0.5394065679749431, 0.5941584142697558, 0.2589080768240843, 0.8307270135072359, 0.2589080768240843, 0.5394065679749431]\n",
      "all_sum before preprocessing is: [1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.0355307695004696, 1.0355307695004696, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.0355307695004696, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.0355307695004696, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.1326660343366026, 1.0355307695004696, 1.1326660343366026]\n",
      "all_sum after preprocessing is: [ 0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333\n",
      "  0.33333333 -3.         -3.          0.33333333  0.33333333  0.33333333\n",
      "  0.33333333  0.33333333  0.33333333  0.33333333 -3.          0.33333333\n",
      "  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333\n",
      "  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333\n",
      "  0.33333333  0.33333333  0.33333333  0.33333333 -3.          0.33333333\n",
      "  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333\n",
      "  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333\n",
      " -3.          0.33333333]\n",
      "P is: [0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.04742587317756668, 0.04742587317756668, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.04742587317756668, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.04742587317756668, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.582570206462314, 0.04742587317756668, 0.582570206462314]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.695\n",
      "(*) epoch 2, cost 1.750\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 1.41 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.561\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0997672853488352, 2.7991156530461074, 1.0997672853488352, 2.7991156530461074, 1.8305925516116588, 1.7730980746294112, 1.8305925516116588, 3.415422811012229, 1.8305925516116588, 1.0422728083665875, 1.0997672853488352, 2.7991156530461074, 1.3314736453937912, 1.8305925516116588, 1.0997672853488352, 1.8305925516116588, 2.29999674682824, 1.0997672853488352, 1.0422728083665875, 2.7991156530461074, 1.0997672853488352, 2.0682903867832843, 1.0997672853488352, 2.4468997095777802, 2.0682903867832843, 2.0682903867832843, 2.0682903867832843, 1.0997672853488352, 1.8305925516116588, 2.7991156530461074, 1.8305925516116588, 1.0997672853488352, 1.8305925516116588, 1.0997672853488352, 1.0997672853488352, 2.7991156530461074, 1.8305925516116588, 2.0682903867832843, 1.8305925516116588, 1.0997672853488352, 2.0682903867832843, 2.0682903867832843, 2.0682903867832843, 1.7730980746294112, 1.0997672853488352, 2.29999674682824, 0.6006483791309678, 2.0682903867832843, 1.8305925516116588, 1.8305925516116588]\n",
      "all_sum after preprocessing is: [-1.11572537  1.61546839 -1.11572537  1.61546839  0.05885746 -0.0335477\n",
      "  0.05885746  2.60599764  0.05885746 -1.20813053 -1.11572537  1.61546839\n",
      " -0.74332676  0.05885746 -1.11572537  0.05885746  0.81328417 -1.11572537\n",
      " -1.20813053  1.61546839 -1.11572537  0.44088557 -1.11572537  1.04938671\n",
      "  0.44088557  0.44088557  0.44088557 -1.11572537  0.05885746  1.61546839\n",
      "  0.05885746 -1.11572537  0.05885746 -1.11572537 -1.11572537  1.61546839\n",
      "  0.05885746  0.44088557  0.05885746 -1.11572537  0.44088557  0.44088557\n",
      "  0.44088557 -0.0335477  -1.11572537  0.81328417 -1.91790959  0.44088557\n",
      "  0.05885746  0.05885746]\n",
      "P is: [0.2468050445606058, 0.8341692167490395, 0.2468050445606058, 0.8341692167490395, 0.5147101177532464, 0.49161386075492114, 0.5147101177532464, 0.9312465813732902, 0.5147101177532464, 0.23003199982790878, 0.2468050445606058, 0.8341692167490395, 0.322277101464206, 0.5147101177532464, 0.2468050445606058, 0.5147101177532464, 0.6928088994884118, 0.2468050445606058, 0.23003199982790878, 0.8341692167490395, 0.2468050445606058, 0.6084700229816724, 0.2468050445606058, 0.7406571123301647, 0.6084700229816724, 0.6084700229816724, 0.6084700229816724, 0.2468050445606058, 0.5147101177532464, 0.8341692167490395, 0.5147101177532464, 0.2468050445606058, 0.5147101177532464, 0.2468050445606058, 0.2468050445606058, 0.8341692167490395, 0.5147101177532464, 0.6084700229816724, 0.5147101177532464, 0.2468050445606058, 0.6084700229816724, 0.6084700229816724, 0.6084700229816724, 0.49161386075492114, 0.2468050445606058, 0.6928088994884118, 0.12809485613422564, 0.6084700229816724, 0.5147101177532464, 0.5147101177532464]\n",
      "all_sum before preprocessing is: [1.245997720277643, 5.829337925021644, 6.88997770647773, 1.245997720277643, 6.88997770647773, 5.829337925021644, 5.829337925021644, 1.245997720277643, 6.88997770647773, 5.829337925021644, 1.245997720277643, 1.245997720277643, 1.245997720277643, 5.829337925021644, 6.88997770647773, 5.829337925021644, 5.829337925021644, 1.245997720277643, 1.245997720277643, 5.829337925021644, 1.245997720277643, 5.829337925021644, 1.245997720277643, 1.245997720277643, 1.245997720277643, 2.3066375017337286, 5.829337925021644, 1.245997720277643, 5.829337925021644, 6.88997770647773, 5.829337925021644, 2.3066375017337286, 5.829337925021644, 1.245997720277643, 2.3066375017337286, 5.829337925021644, 6.88997770647773, 6.88997770647773, 1.245997720277643, 5.829337925021644, 1.245997720277643, 1.245997720277643, 6.88997770647773, 6.88997770647773, 1.245997720277643, 5.829337925021644, 1.245997720277643, 5.829337925021644, 2.3066375017337286, 5.829337925021644]\n",
      "all_sum after preprocessing is: [-1.14027053  0.75965119  1.19931582 -1.14027053  1.19931582  0.75965119\n",
      "  0.75965119 -1.14027053  1.19931582  0.75965119 -1.14027053 -1.14027053\n",
      " -1.14027053  0.75965119  1.19931582  0.75965119  0.75965119 -1.14027053\n",
      " -1.14027053  0.75965119 -1.14027053  0.75965119 -1.14027053 -1.14027053\n",
      " -1.14027053 -0.70060591  0.75965119 -1.14027053  0.75965119  1.19931582\n",
      "  0.75965119 -0.70060591  0.75965119 -1.14027053 -0.70060591  0.75965119\n",
      "  1.19931582  1.19931582 -1.14027053  0.75965119 -1.14027053 -1.14027053\n",
      "  1.19931582  1.19931582 -1.14027053  0.75965119 -1.14027053  0.75965119\n",
      " -0.70060591  0.75965119]\n",
      "P is: [0.24227069425965744, 0.6812779984347465, 0.7684030486325748, 0.24227069425965744, 0.7684030486325748, 0.6812779984347465, 0.6812779984347465, 0.24227069425965744, 0.7684030486325748, 0.6812779984347465, 0.24227069425965744, 0.24227069425965744, 0.24227069425965744, 0.6812779984347465, 0.7684030486325748, 0.6812779984347465, 0.6812779984347465, 0.24227069425965744, 0.24227069425965744, 0.6812779984347465, 0.24227069425965744, 0.6812779984347465, 0.24227069425965744, 0.24227069425965744, 0.24227069425965744, 0.3316779042951976, 0.6812779984347465, 0.24227069425965744, 0.6812779984347465, 0.7684030486325748, 0.6812779984347465, 0.3316779042951976, 0.6812779984347465, 0.24227069425965744, 0.3316779042951976, 0.6812779984347465, 0.7684030486325748, 0.7684030486325748, 0.24227069425965744, 0.6812779984347465, 0.24227069425965744, 0.24227069425965744, 0.7684030486325748, 0.7684030486325748, 0.24227069425965744, 0.6812779984347465, 0.24227069425965744, 0.6812779984347465, 0.3316779042951976, 0.6812779984347465]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.167\n",
      "(*) epoch 2, cost 1.920\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.068\n",
      "(*) epoch 2, cost 1.623\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.1983920420687015, 2.1983920420687015, 4.050178310153801, 2.1983920420687015, 1.9442747480353468, 2.9807516705928823, 4.050178310153801, 2.1983920420687015, 4.050178310153801, 4.050178310153801, 2.1983920420687015, 2.9807516705928823, 2.1983920420687015, 1.9620795801118815, 2.1983920420687015, 4.725430881783565, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.9807516705928823, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.9807516705928823, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.9807516705928823, 3.2678186816296204, 2.1983920420687015, 3.2678186816296204, 2.8736446136984646, 3.8978117999492743, 3.2678186816296204, 2.1983920420687015, 2.1983920420687015, 4.050178310153801, 2.9807516705928823, 2.1983920420687015, 2.1983920420687015, 2.1983920420687015, 2.9807516705928823, 2.1983920420687015]\n",
      "all_sum after preprocessing is: [-0.63590982 -0.63590982  1.9978825  -0.63590982 -0.9973404   0.47683889\n",
      "  1.9978825  -0.63590982  1.9978825   1.9978825  -0.63590982  0.47683889\n",
      " -0.63590982 -0.97201662 -0.63590982  2.95829303 -0.63590982 -0.63590982\n",
      " -0.63590982 -0.63590982  0.47683889 -0.63590982 -0.63590982 -0.63590982\n",
      " -0.63590982 -0.63590982 -0.63590982  0.47683889 -0.63590982 -0.63590982\n",
      " -0.63590982 -0.63590982 -0.63590982 -0.63590982  0.47683889  0.88513379\n",
      " -0.63590982  0.88513379  0.32450071  1.78117188  0.88513379 -0.63590982\n",
      " -0.63590982  1.9978825   0.47683889 -0.63590982 -0.63590982 -0.63590982\n",
      "  0.47683889 -0.63590982]\n",
      "P is: [0.34617171393341295, 0.34617171393341295, 0.880574574506162, 0.34617171393341295, 0.26946465200223596, 0.6170011468153505, 0.880574574506162, 0.34617171393341295, 0.880574574506162, 0.880574574506162, 0.34617171393341295, 0.6170011468153505, 0.34617171393341295, 0.2744787301178825, 0.34617171393341295, 0.9506539798911597, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.6170011468153505, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.6170011468153505, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.6170011468153505, 0.7078849373267901, 0.34617171393341295, 0.7078849373267901, 0.5804207165835362, 0.855841509161379, 0.7078849373267901, 0.34617171393341295, 0.34617171393341295, 0.880574574506162, 0.6170011468153505, 0.34617171393341295, 0.34617171393341295, 0.34617171393341295, 0.6170011468153505, 0.34617171393341295]\n",
      "all_sum before preprocessing is: [8.25522413608005, 8.25522413608005, 7.628065641142738, 6.48096201536234, 8.737625439005539, 6.48096201536234, 8.885268337059447, 7.194114038260863, 5.7453076668355445, 8.885268337059447, 7.037168484627766, 7.111006216341735, 3.3785451730560347, 8.25522413608005, 5.853803520425027, 9.364783933942853, 5.779965788711058, 7.628065641142738, 9.994828134922248, 7.037168484627766, 8.737625439005539, 7.628065641142738, 8.220566014204536, 6.410009989690454, 7.111006216341735, 7.7381647112790475, 7.628065641142738, 7.628065641142738, 8.25522413608005, 6.262367091636547, 7.628065641142738, 7.628065641142738, 9.512426831996759, 8.737625439005539, 3.3785451730560347, 8.737625439005539, 7.111006216341735, 8.25522413608005, 10.62198662985956, 7.111006216341735, 8.885268337059447, 8.25522413608005, 6.48096201536234, 5.853803520425027, 5.853803520425027, 7.628065641142738, 8.885268337059447, 8.885268337059447, 7.111006216341735, 8.885268337059447]\n",
      "all_sum after preprocessing is: [ 0.47624183  0.47624183  0.03320226 -0.77713884  0.81702151 -0.77713884\n",
      "  0.92131994 -0.27335141 -1.29682246  0.92131994 -0.38422145 -0.33206074\n",
      " -2.9687594   0.47624183 -1.22017842  1.26006109 -1.27233914  0.03320226\n",
      "  1.7051392  -0.38422145  0.81702151  0.03320226  0.45175852 -0.82726103\n",
      " -0.33206074  0.11097884  0.03320226  0.03320226  0.47624183 -0.93155946\n",
      "  0.03320226  0.03320226  1.36435952  0.81702151 -2.9687594   0.81702151\n",
      " -0.33206074  0.47624183  2.14817877 -0.33206074  0.92131994  0.47624183\n",
      " -0.77713884 -1.22017842 -1.22017842  0.03320226  0.92131994  0.92131994\n",
      " -0.33206074  0.92131994]\n",
      "P is: [0.6168600467183715, 0.6168600467183715, 0.5082998016652966, 0.3149368578424625, 0.6936037240126465, 0.3149368578424625, 0.7153109766414489, 0.4320845150292261, 0.21470027804094632, 0.7153109766414489, 0.40510913834492096, 0.417739298830942, 0.04885734196687529, 0.6168600467183715, 0.22790505309611786, 0.7790366235930066, 0.21885709280204654, 0.5082998016652966, 0.846204752236512, 0.40510913834492096, 0.6936037240126465, 0.5082998016652966, 0.6110572558576017, 0.3042245218143385, 0.417739298830942, 0.527716269180186, 0.5082998016652966, 0.5082998016652966, 0.6168600467183715, 0.2826084403422341, 0.5082998016652966, 0.5082998016652966, 0.796467320337889, 0.6936037240126465, 0.04885734196687529, 0.6936037240126465, 0.417739298830942, 0.6168600467183715, 0.8954984674999981, 0.417739298830942, 0.7153109766414489, 0.6168600467183715, 0.3149368578424625, 0.22790505309611786, 0.22790505309611786, 0.5082998016652966, 0.7153109766414489, 0.7153109766414489, 0.417739298830942, 0.7153109766414489]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.023\n",
      "(*) epoch 2, cost 3.327\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.001\n",
      "(*) epoch 2, cost 4.405\n",
      "(*) epoch 3, cost 3.785\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.3362428071713306, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 5.042971821976451, 3.298375411172214, 3.4811632183948746, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.4811632183948746, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 5.042971821976451, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214, 1.351011413794601, 3.298375411172214, 5.042971821976451, 3.298375411172214, 3.298375411172214, 1.351011413794601, 3.298375411172214, 3.298375411172214, 3.298375411172214, 3.298375411172214]\n",
      "all_sum after preprocessing is: [ 0.00521735 -0.06026066 -0.06026066 -0.06026066 -0.06026066 -0.06026066\n",
      " -0.06026066 -0.06026066  2.95639018 -0.06026066  0.25580498 -0.06026066\n",
      " -0.06026066 -0.06026066 -0.06026066 -0.06026066 -0.06026066 -0.06026066\n",
      " -0.06026066 -0.06026066 -0.06026066  0.25580498 -0.06026066 -0.06026066\n",
      " -0.06026066 -0.06026066 -0.06026066  2.95639018 -0.06026066 -0.06026066\n",
      " -0.06026066 -0.06026066 -0.06026066 -0.06026066 -0.06026066 -0.06026066\n",
      " -0.06026066 -0.06026066 -0.06026066 -0.06026066 -3.42752499 -0.06026066\n",
      "  2.95639018 -0.06026066 -0.06026066 -3.42752499 -0.06026066 -0.06026066\n",
      " -0.06026066 -0.06026066]\n",
      "P is: [0.5013043350872793, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.950564638784358, 0.4849393912244923, 0.5636047855091098, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.5636047855091098, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.950564638784358, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.03144622727171593, 0.4849393912244923, 0.950564638784358, 0.4849393912244923, 0.4849393912244923, 0.03144622727171593, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923, 0.4849393912244923]\n",
      "all_sum before preprocessing is: [1.3999284430308678, 1.3999284430308678, 2.6677848145435226, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 3.9792103625638124, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.2102611506594445, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.2102611506594445, 2.5216866986797344, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.2102611506594445, 1.3999284430308678, 2.6677848145435226, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 2.066067887629561, 1.3999284430308678, 2.6677848145435226, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678, 1.3999284430308678]\n",
      "all_sum after preprocessing is: [-0.30868084 -0.30868084  2.26548388 -0.30868084 -0.30868084 -0.30868084\n",
      " -0.30868084  4.92810834 -0.30868084 -0.30868084 -0.30868084 -0.30868084\n",
      " -0.30868084 -0.30868084 -0.30868084 -0.30868084 -0.30868084 -0.30868084\n",
      " -0.69376772 -0.30868084 -0.30868084 -0.30868084 -0.30868084 -0.30868084\n",
      " -0.30868084 -0.30868084 -0.30868084 -0.69376772  1.96885674 -0.30868084\n",
      " -0.30868084 -0.30868084 -0.30868084 -0.30868084 -0.30868084 -0.30868084\n",
      " -0.69376772 -0.30868084  2.26548388 -0.30868084 -0.30868084 -0.30868084\n",
      "  1.04380095 -0.30868084  2.26548388 -0.30868084 -0.30868084 -0.30868084\n",
      " -0.30868084 -0.30868084]\n",
      "P is: [0.4234367630771784, 0.4234367630771784, 0.9059778002800186, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.9928118571704573, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.3331954498131286, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.3331954498131286, 0.8774882623418709, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.3331954498131286, 0.4234367630771784, 0.9059778002800186, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.7395827361354075, 0.4234367630771784, 0.9059778002800186, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784, 0.4234367630771784]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.676\n",
      "(*) epoch 2, cost 2.264\n",
      "(*) epoch 3, cost 1.986\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.325\n",
      "(*) epoch 2, cost 0.849\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 2.1898296324156354, 1.4308343396610352, 2.1898296324156354, 1.4308343396610352, 3.1306583398046066, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 2.1898296324156354, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 0.9186023667847452, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 3.1306583398046066, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 2.6184263669283165, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352, 1.4308343396610352]\n",
      "all_sum after preprocessing is: [-0.31044815 -0.31044815 -0.31044815 -0.31044815 -0.31044815 -0.31044815\n",
      " -0.31044815 -0.31044815 -0.31044815  1.54431341 -0.31044815  1.54431341\n",
      " -0.31044815  3.84342242 -0.31044815 -0.31044815 -0.31044815 -0.31044815\n",
      " -0.31044815 -0.31044815 -0.31044815 -0.31044815 -0.31044815 -0.31044815\n",
      " -0.31044815  1.54431341 -0.31044815 -0.31044815 -0.31044815 -1.56219263\n",
      " -0.31044815 -0.31044815 -0.31044815 -0.31044815 -0.31044815 -0.31044815\n",
      " -0.31044815 -0.31044815 -0.31044815  3.84342242 -0.31044815 -0.31044815\n",
      " -0.31044815 -0.31044815 -0.31044815  2.59167793 -0.31044815 -0.31044815\n",
      " -0.31044815 -0.31044815]\n",
      "P is: [0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.8240908929575597, 0.4230053548572404, 0.8240908929575597, 0.4230053548572404, 0.9790290345428538, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.8240908929575597, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.17333224392792232, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.9790290345428538, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.9303240613202691, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404, 0.4230053548572404]\n",
      "all_sum before preprocessing is: [2.4673873897036627, 3.7162493731078463, 3.7162493731078463, 6.299791390775028, 2.2875954793917685, 2.2875954793917685, 3.8960412834197404, 3.7162493731078463, 3.7162493731078463, 4.060623709289279, 6.2366764923219815, 2.2875954793917685, 3.8960412834197404, 3.845508156478063, 3.7162493731078463, 3.034994368708392, 5.280919386725464, 4.526763160877517, 4.210462033155848, 3.7162493731078463, 3.7162493731078463, 3.7162493731078463, 2.2875954793917685, 3.7162493731078463, 3.7162493731078463, 4.463648262424471, 3.0981092671614396, 3.8960412834197404, 3.034994368708392, 3.7162493731078463, 4.463648262424471, 3.0981092671614396, 2.2875954793917685, 2.2875954793917685, 4.463648262424471, 4.828602139102255, 2.2875954793917685, 3.8960412834197404, 3.7162493731078463, 3.034994368708392, 2.2875954793917685, 4.463648262424471, 2.9901663557196643, 5.5971860949382775, 3.0981092671614396, 3.7162493731078463, 3.2147862790202866, 3.7162493731078463, 4.060623709289279, 3.277901177473334]\n",
      "all_sum after preprocessing is: [-1.25824561  0.05793846  0.05793846  2.78075084 -1.44772952 -1.44772952\n",
      "  0.24742237  0.05793846  0.05793846  0.4208769   2.71423362 -1.44772952\n",
      "  0.24742237  0.19416517  0.05793846 -0.66004079  1.70695475  0.91214441\n",
      "  0.57879252  0.05793846  0.05793846  0.05793846 -1.44772952  0.05793846\n",
      "  0.05793846  0.8456272  -0.59352357  0.24742237 -0.66004079  0.05793846\n",
      "  0.8456272  -0.59352357 -1.44772952 -1.44772952  0.8456272   1.23025455\n",
      " -1.44772952  0.24742237  0.05793846 -0.66004079 -1.44772952  0.8456272\n",
      " -0.70728533  2.04027037 -0.59352357  0.05793846 -0.47055688  0.05793846\n",
      "  0.4208769  -0.40403966]\n",
      "P is: [0.22127604769512454, 0.5144805647199878, 0.5144805647199878, 0.9416267284724481, 0.190351240607117, 0.190351240607117, 0.5615419567474764, 0.5144805647199878, 0.5144805647199878, 0.6036930650374106, 0.9378613309691372, 0.190351240607117, 0.5615419567474764, 0.5483893631241323, 0.5144805647199878, 0.34073044926465174, 0.8464408842875765, 0.7134387756982822, 0.6407895179315601, 0.5144805647199878, 0.5144805647199878, 0.5144805647199878, 0.190351240607117, 0.5144805647199878, 0.5144805647199878, 0.6996490434027366, 0.3558267927888771, 0.5615419567474764, 0.34073044926465174, 0.5144805647199878, 0.6996490434027366, 0.3558267927888771, 0.190351240607117, 0.190351240607117, 0.6996490434027366, 0.7738631235597919, 0.190351240607117, 0.5615419567474764, 0.5144805647199878, 0.34073044926465174, 0.190351240607117, 0.6996490434027366, 0.3301989595924531, 0.8849607960069411, 0.3558267927888771, 0.5144805647199878, 0.384484446204051, 0.5144805647199878, 0.6036930650374106, 0.4003421558358718]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.036\n",
      "(*) epoch 2, cost 1.798\n",
      "(*) epoch 3, cost 1.361\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.878\n",
      "(*) epoch 2, cost 3.569\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.4909057630702147, 2.4909057630702147, 2.3358260234112582, 2.7875783438051034, 2.4909057630702147, 2.4909057630702147, 2.4909057630702147, 2.4909057630702147, 2.7875783438051034, 2.7875783438051034, 2.4909057630702147, 2.4909057630702147, 5.540313830992975, 2.3358260234112582, 2.7875783438051034, 2.4909057630702147, 2.7875783438051034, 2.4909057630702147, 2.6324986041461473, 2.7875783438051034, 2.4909057630702147, 2.4909057630702147, 2.7875783438051034, 2.4909057630702147, 2.4909057630702147, 2.4909057630702147, 2.7875783438051034, 2.7875783438051034, 2.6324986041461473, 2.7875783438051034, 2.4909057630702147, 2.4909057630702147, 2.7875783438051034, 2.4909057630702147, 2.7875783438051034, 2.4909057630702147, 2.4909057630702147, 2.4909057630702147, 2.4909057630702147, 2.4909057630702147, 2.4909057630702147, 2.3358260234112582, 2.4909057630702147, 2.7875783438051034, 2.4909057630702147, 2.7875783438051034, 2.7875783438051034, 2.4909057630702147, 2.4909057630702147, 2.7875783438051034]\n",
      "all_sum after preprocessing is: [-0.34645652 -0.34645652 -0.69927743  0.32850136 -0.34645652 -0.34645652\n",
      " -0.34645652 -0.34645652  0.32850136  0.32850136 -0.34645652 -0.34645652\n",
      "  6.59123211 -0.69927743  0.32850136 -0.34645652  0.32850136 -0.34645652\n",
      " -0.02431956  0.32850136 -0.34645652 -0.34645652  0.32850136 -0.34645652\n",
      " -0.34645652 -0.34645652  0.32850136  0.32850136 -0.02431956  0.32850136\n",
      " -0.34645652 -0.34645652  0.32850136 -0.34645652  0.32850136 -0.34645652\n",
      " -0.34645652 -0.34645652 -0.34645652 -0.34645652 -0.34645652 -0.69927743\n",
      " -0.34645652  0.32850136 -0.34645652  0.32850136  0.32850136 -0.34645652\n",
      " -0.34645652  0.32850136]\n",
      "P is: [0.41424196962932774, 0.41424196962932774, 0.33197245001447573, 0.5813946897941349, 0.41424196962932774, 0.41424196962932774, 0.41424196962932774, 0.41424196962932774, 0.5813946897941349, 0.5813946897941349, 0.41424196962932774, 0.41424196962932774, 0.9986295327239187, 0.33197245001447573, 0.5813946897941349, 0.41424196962932774, 0.5813946897941349, 0.41424196962932774, 0.493920410515221, 0.5813946897941349, 0.41424196962932774, 0.41424196962932774, 0.5813946897941349, 0.41424196962932774, 0.41424196962932774, 0.41424196962932774, 0.5813946897941349, 0.5813946897941349, 0.493920410515221, 0.5813946897941349, 0.41424196962932774, 0.41424196962932774, 0.5813946897941349, 0.41424196962932774, 0.5813946897941349, 0.41424196962932774, 0.41424196962932774, 0.41424196962932774, 0.41424196962932774, 0.41424196962932774, 0.41424196962932774, 0.33197245001447573, 0.41424196962932774, 0.5813946897941349, 0.41424196962932774, 0.5813946897941349, 0.5813946897941349, 0.41424196962932774, 0.41424196962932774, 0.5813946897941349]\n",
      "all_sum before preprocessing is: [2.2616167167423535, 2.05672139717173, 2.785284469081783, 1.9901297747044098, 1.9901297747044098, 2.5803891495111597, 2.5803891495111597, 2.5803891495111597, 1.9901297747044098, 2.05672139717173, 2.05672139717173, 1.9901297747044098, 2.5803891495111597, 2.05672139717173, 2.822505487120209, 2.5803891495111597, 2.5803891495111597, 1.9901297747044098, 2.8890971095875297, 1.9901297747044098, 1.46646202236498, 2.5803891495111597, 1.46646202236498, 2.05672139717173, 2.1950250942750333, 2.05672139717173, 1.7274379192968112, 2.05672139717173, 1.46646202236498, 2.05672139717173, 2.05672139717173, 1.9901297747044098, 1.9901297747044098, 2.05672139717173, 1.46646202236498, 1.9592524576994381, 1.46646202236498, 2.5803891495111597, 2.5803891495111597, 2.785284469081783, 2.05672139717173, 2.05672139717173, 2.5803891495111597, 1.46646202236498, 2.05672139717173, 2.5803891495111597, 2.5803891495111597, 1.46646202236498, 1.46646202236498, 2.8890971095875297]\n",
      "all_sum after preprocessing is: [ 0.25712022 -0.22965046  1.50119993 -0.38785246 -0.38785246  1.01442925\n",
      "  1.01442925  1.01442925 -0.38785246 -0.22965046 -0.22965046 -0.38785246\n",
      "  1.01442925 -0.22965046  1.58962606  1.01442925  1.01442925 -0.38785246\n",
      "  1.74782806 -0.38785246 -1.63193217  1.01442925 -1.63193217 -0.22965046\n",
      "  0.09891822 -0.22965046 -1.01193062 -0.22965046 -1.63193217 -0.22965046\n",
      " -0.22965046 -0.38785246 -0.38785246 -0.22965046 -1.63193217 -0.46120783\n",
      " -1.63193217  1.01442925  1.01442925  1.50119993 -0.22965046 -0.22965046\n",
      "  1.01442925 -1.63193217 -0.22965046  1.01442925  1.01442925 -1.63193217\n",
      " -1.63193217  1.74782806]\n",
      "P is: [0.5639282474605481, 0.44283838661126496, 0.8177533733470407, 0.40423438378789756, 0.40423438378789756, 0.7338860650175815, 0.7338860650175815, 0.7338860650175815, 0.40423438378789756, 0.44283838661126496, 0.44283838661126496, 0.40423438378789756, 0.7338860650175815, 0.44283838661126496, 0.830563485997887, 0.7338860650175815, 0.7338860650175815, 0.40423438378789756, 0.8516786476620057, 0.40423438378789756, 0.16356584543797317, 0.7338860650175815, 0.16356584543797317, 0.44283838661126496, 0.5247094106709633, 0.44283838661126496, 0.26660219544846053, 0.44283838661126496, 0.16356584543797317, 0.44283838661126496, 0.44283838661126496, 0.40423438378789756, 0.40423438378789756, 0.44283838661126496, 0.16356584543797317, 0.386699331180443, 0.16356584543797317, 0.7338860650175815, 0.7338860650175815, 0.8177533733470407, 0.44283838661126496, 0.44283838661126496, 0.7338860650175815, 0.16356584543797317, 0.44283838661126496, 0.7338860650175815, 0.7338860650175815, 0.16356584543797317, 0.16356584543797317, 0.8516786476620057]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.996\n",
      "(*) epoch 2, cost 2.311\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.828\n",
      "(*) epoch 2, cost 2.552\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7085233744846668, 0.8962889378243979, 1.8981813987827039, 2.626623751671448, 1.7085233744846668, 2.626623751671448, 1.7085233744846668, 0.8962889378243979, 1.8143893150111792, 2.626623751671448, 1.5700245988405932, 1.8143893150111792, 1.7085233744846668, 2.954780551613559, 1.8143893150111792, 2.0366801744267775, 1.7085233744846668, 2.954780551613559, 3.628516212629754, 2.0366801744267775, 1.7085233744846668, 0.8962889378243979, 2.710415835442973, 2.626623751671448, 0.8962889378243979, 2.954780551613559, 0.5681321378822872, 3.9566730125718648, 2.816281775969485, 2.0366801744267775, 2.0366801744267775, 0.8962889378243979, 2.626623751671448, 1.7085233744846668, 2.626623751671448, 1.4862325150690685, 1.7085233744846668, 1.8981813987827039, 2.816281775969485, 1.7085233744846668, 0.8962889378243979, 1.7085233744846668, 2.626623751671448, 1.8143893150111792, 2.626623751671448, 0.8962889378243979, 1.7085233744846668, 1.8143893150111792, 1.8981813987827039, 2.626623751671448]\n",
      "all_sum after preprocessing is: [-0.39947729 -1.50981113 -0.14021258  0.85557651 -0.39947729  0.85557651\n",
      " -0.39947729 -1.50981113 -0.25475733  0.85557651 -0.58880671 -0.25475733\n",
      " -0.39947729  1.30417064 -0.25475733  0.04911684 -0.39947729  1.30417064\n",
      "  2.22517506  0.04911684 -0.39947729 -1.50981113  0.97012126  0.85557651\n",
      " -1.50981113  1.30417064 -1.95840526  2.67376919  1.11484122  0.04911684\n",
      "  0.04911684 -1.50981113  0.85557651 -0.39947729  0.85557651 -0.70335146\n",
      " -0.39947729 -0.14021258  1.11484122 -0.39947729 -1.50981113 -0.39947729\n",
      "  0.85557651 -0.25475733  0.85557651 -1.50981113 -0.39947729 -0.25475733\n",
      " -0.14021258  0.85557651]\n",
      "P is: [0.40143793361607116, 0.18096678575048172, 0.46500416935731936, 0.7017356334636674, 0.40143793361607116, 0.7017356334636674, 0.40143793361607116, 0.18096678575048172, 0.4366529074115337, 0.7017356334636674, 0.35690869706772516, 0.4366529074115337, 0.40143793361607116, 0.7865360585478722, 0.4366529074115337, 0.5122767423449188, 0.40143793361607116, 0.7865360585478722, 0.9024875698895185, 0.5122767423449188, 0.40143793361607116, 0.18096678575048172, 0.7251436664095696, 0.7017356334636674, 0.18096678575048172, 0.7865360585478722, 0.12363973905469512, 0.9354609652448694, 0.7530305622707834, 0.5122767423449188, 0.5122767423449188, 0.18096678575048172, 0.7017356334636674, 0.40143793361607116, 0.7017356334636674, 0.33106958631978417, 0.40143793361607116, 0.46500416935731936, 0.7530305622707834, 0.40143793361607116, 0.18096678575048172, 0.40143793361607116, 0.7017356334636674, 0.4366529074115337, 0.7017356334636674, 0.18096678575048172, 0.40143793361607116, 0.4366529074115337, 0.46500416935731936, 0.7017356334636674]\n",
      "all_sum before preprocessing is: [1.9088034480951335, 1.452857969688525, 2.3105948166402905, 2.4774173174398326, 1.9088034480951335, 1.9088034480951335, 2.4774173174398326, 1.9088034480951335, 0.923870771602776, 2.0670901606799443, 1.171068742982559, 2.4774173174398326, 1.9088034480951335, 2.592384043346257, 2.15788530732696, 1.9088034480951335, 2.764241960078566, 0.8842441003438258, 2.023770174001558, 1.9088034480951335, 1.171068742982559, 1.9088034480951335, 1.171068742982559, 0.8842441003438258, 1.9088034480951335, 1.9088034480951335, 0.8842441003438258, 2.063396845260508, 0.8842441003438258, 2.517043988698783, 3.0483295217528648, 3.0483295217528648, 2.592384043346257, 0.8842441003438258, 3.616943391097564, 1.9088034480951335, 1.9088034480951335, 0.8842441003438258, 1.9088034480951335, 0.8842441003438258, 3.455698093569502, 2.023770174001558, 1.9088034480951335, 2.4774173174398326, 1.9088034480951335, 2.592384043346257, 1.452857969688525, 0.8842441003438258, 2.023770174001558, 2.4774173174398326]\n",
      "all_sum after preprocessing is: [-0.0259404  -0.68762996  0.55715816  0.79925883 -0.0259404  -0.0259404\n",
      "  0.79925883 -0.0259404  -1.4553211   0.20377273 -1.09657576  0.79925883\n",
      " -0.0259404   0.96610396  0.33553893 -0.0259404   1.21551227 -1.51282919\n",
      "  0.14090473 -0.0259404  -1.09657576 -0.0259404  -1.09657576 -1.51282919\n",
      " -0.0259404  -0.0259404  -1.51282919  0.19841282 -1.51282919  0.85676693\n",
      "  1.62779352  1.62779352  0.96610396 -1.51282919  2.45299276 -0.0259404\n",
      " -0.0259404  -1.51282919 -0.0259404  -1.51282919  2.21898598  0.14090473\n",
      " -0.0259404   0.79925883 -0.0259404   0.96610396 -0.68762996 -1.51282919\n",
      "  0.14090473  0.79925883]\n",
      "P is: [0.4935152634244034, 0.33456050782497393, 0.63579473919875, 0.6898159163273055, 0.4935152634244034, 0.4935152634244034, 0.6898159163273055, 0.4935152634244034, 0.18918399372560632, 0.5507676347567348, 0.2503820434014081, 0.6898159163273055, 0.4935152634244034, 0.7243422543368554, 0.5831064698291155, 0.4935152634244034, 0.7712728279596623, 0.18051988508131397, 0.5351680153583053, 0.4935152634244034, 0.2503820434014081, 0.4935152634244034, 0.2503820434014081, 0.18051988508131397, 0.4935152634244034, 0.4935152634244034, 0.18051988508131397, 0.5494411130263966, 0.18051988508131397, 0.7019847303922236, 0.8358671491445947, 0.8358671491445947, 0.7243422543368554, 0.18051988508131397, 0.9207800300877329, 0.4935152634244034, 0.4935152634244034, 0.18051988508131397, 0.4935152634244034, 0.18051988508131397, 0.9019415497246838, 0.5351680153583053, 0.4935152634244034, 0.6898159163273055, 0.4935152634244034, 0.7243422543368554, 0.33456050782497393, 0.18051988508131397, 0.5351680153583053, 0.6898159163273055]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.360\n",
      "(*) epoch 2, cost 3.094\n",
      "(*) epoch 3, cost 2.415\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.761\n",
      "(*) epoch 2, cost 3.054\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.7645832673174002, 4.276056330069257, 2.1434438720702045, 3.027205021777615, 4.194002175591105, 3.301010472092225, 2.8808221176099895, 5.159817479776668, 2.6890708217735315, 2.3351951679066625, 3.3102410258836947, 2.571809280817678, 3.5728319714809422, 4.931380421130891, 4.276056330069257, 2.1434438720702045, 3.027205021777615, 3.301010472092225, 2.6890708217735315, 5.013434575609043, 2.1434438720702045, 4.7396291252944325, 4.276056330069257, 3.301010472092225, 4.467807625905715, 3.8558679755870218, 5.013434575609043, 4.276056330069257, 3.027205021777615, 4.467807625905715, 3.556509740409683, 2.3351951679066625, 3.760083251695076, 3.5728319714809422, 3.218956317614073, 3.027205021777615, 2.6890708217735315, 3.218956317614073, 3.8558679755870218, 5.7054444294799955, 3.8558679755870218, 3.109259176255767, 2.1434438720702045, 3.027205021777615, 3.760083251695076, 3.5728319714809422, 3.301010472092225, 4.276056330069257, 3.3102410258836947, 3.3102410258836947]\n",
      "all_sum after preprocessing is: [ 0.26729264  0.86445986 -1.62545865 -0.59362877  0.76865804 -0.27394891\n",
      " -0.76453723  1.89628973 -0.98841527 -1.4015806  -0.26317183 -1.12532326\n",
      "  0.0434146   1.62957945  0.86445986 -1.62545865 -0.59362877 -0.27394891\n",
      " -0.98841527  1.72538128 -1.62545865  1.40570141  0.86445986 -0.27394891\n",
      "  1.0883379   0.37387154  1.72538128  0.86445986 -0.59362877  1.0883379\n",
      "  0.02435768 -1.4015806   0.26203868  0.0434146  -0.36975073 -0.59362877\n",
      " -0.98841527 -0.36975073  0.37387154  2.53333311  0.37387154 -0.49782695\n",
      " -1.62545865 -0.59362877  0.26203868  0.0434146  -0.27394891  0.86445986\n",
      " -0.26317183 -0.26317183]\n",
      "P is: [0.5664281326086348, 0.7035916038243862, 0.16445343142576177, 0.3558026791353403, 0.6832305289649504, 0.4319379013335807, 0.31766199634778153, 0.8694710199079382, 0.2712252051288558, 0.1975654132320702, 0.4345841615405788, 0.2450252094231782, 0.5108519461786364, 0.8361120201568681, 0.7035916038243862, 0.16445343142576177, 0.3558026791353403, 0.4319379013335807, 0.2712252051288558, 0.8488206809258456, 0.16445343142576177, 0.8030870582909168, 0.7035916038243862, 0.4319379013335807, 0.7480686082731111, 0.5923941469657242, 0.8488206809258456, 0.7035916038243862, 0.3558026791353403, 0.7480686082731111, 0.506089119556419, 0.1975654132320702, 0.5651373778844211, 0.5108519461786364, 0.40860125495005545, 0.3558026791353403, 0.2712252051288558, 0.40860125495005545, 0.5923941469657242, 0.9264458076628719, 0.5923941469657242, 0.3780514789638399, 0.16445343142576177, 0.3558026791353403, 0.5651373778844211, 0.5108519461786364, 0.4319379013335807, 0.7035916038243862, 0.4345841615405788, 0.4345841615405788]\n",
      "all_sum before preprocessing is: [2.6402842508904545, 2.4252748466117815, 3.252201405970916, 3.252201405970916, 2.4252748466117815, 2.735165467936305, 2.15320883426288, 2.15320883426288, 4.174009182375901, 3.252201405970916, 3.252201405970916, 1.8133576915313199, 3.3470826230167665, 3.252201405970916, 3.252201405970916, 1.8133576915313199, 2.4252748466117815, 3.252201405970916, 2.4252748466117815, 3.252201405970916, 2.6402842508904545, 1.8133576915313199, 3.252201405970916, 1.8133576915313199, 3.252201405970916, 3.252201405970916, 3.252201405970916, 1.8133576915313199, 2.6402842508904545, 2.6402842508904545, 2.771657658400885, 3.252201405970916, 2.4252748466117815, 3.252201405970916, 3.252201405970916, 3.252201405970916, 2.6402842508904545, 3.3673956030631205, 3.252201405970916, 4.174009182375901, 1.5412916791824183, 3.252201405970916, 3.252201405970916, 2.15320883426288, 2.4252748466117815, 3.252201405970916, 2.4252748466117815, 3.252201405970916, 3.252201405970916, 3.252201405970916]\n",
      "all_sum after preprocessing is: [-0.35551755 -0.71602085  0.67047551  0.67047551 -0.71602085 -0.19643152\n",
      " -1.17219018 -1.17219018  2.21605789  0.67047551  0.67047551 -1.7420139\n",
      "  0.82956154  0.67047551  0.67047551 -1.7420139  -0.71602085  0.67047551\n",
      " -0.71602085  0.67047551 -0.35551755 -1.7420139   0.67047551 -1.7420139\n",
      "  0.67047551  0.67047551  0.67047551 -1.7420139  -0.35551755 -0.35551755\n",
      " -0.13524557  0.67047551 -0.71602085  0.67047551  0.67047551  0.67047551\n",
      " -0.35551755  0.86362003  0.67047551  2.21605789 -2.19818324  0.67047551\n",
      "  0.67047551 -1.17219018 -0.71602085  0.67047551 -0.71602085  0.67047551\n",
      "  0.67047551  0.67047551]\n",
      "P is: [0.412045073010761, 0.3282698201298044, 0.6616096253825251, 0.6616096253825251, 0.3282698201298044, 0.4510494172387471, 0.23645932710568732, 0.23645932710568732, 0.9016822757185468, 0.6616096253825251, 0.6616096253825251, 0.1490573118815178, 0.6962622111138791, 0.6616096253825251, 0.6616096253825251, 0.1490573118815178, 0.3282698201298044, 0.6616096253825251, 0.3282698201298044, 0.6616096253825251, 0.412045073010761, 0.1490573118815178, 0.6616096253825251, 0.1490573118815178, 0.6616096253825251, 0.6616096253825251, 0.6616096253825251, 0.1490573118815178, 0.412045073010761, 0.412045073010761, 0.46624005251782463, 0.6616096253825251, 0.3282698201298044, 0.6616096253825251, 0.6616096253825251, 0.6616096253825251, 0.412045073010761, 0.7034164271436358, 0.6616096253825251, 0.9016822757185468, 0.09991375387377846, 0.6616096253825251, 0.6616096253825251, 0.23645932710568732, 0.3282698201298044, 0.6616096253825251, 0.3282698201298044, 0.6616096253825251, 0.6616096253825251, 0.6616096253825251]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 8.101\n",
      "(*) epoch 2, cost 4.445\n",
      "(*) epoch 3, cost 3.553\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.049\n",
      "(*) epoch 2, cost 2.881\n",
      "(*) epoch 3, cost 2.430\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.9279325911926906, 4.280651980665371, 5.688276531913946, 3.9279325911926906, 3.2270031569222257, 3.9279325911926906, 3.538230146407963, 3.9279325911926906, 3.9279325911926906, 3.789293214000488, 3.2270031569222257, 3.538230146407963, 4.490222648270953, 4.490222648270953, 4.100520203486225, 4.100520203486225, 4.965485224403595, 5.688276531913946, 4.490222648270953, 3.538230146407963, 3.9279325911926906, 5.5277752814818575, 3.9279325911926906, 3.9279325911926906, 3.538230146407963, 3.2270031569222257, 4.490222648270953, 3.789293214000488, 3.789293214000488, 3.9279325911926906, 3.789293214000488, 3.538230146407963, 4.826845847211393, 3.789293214000488, 4.531715048257896, 3.789293214000488, 3.472300541807105, 3.9279325911926906, 3.789293214000488, 4.490222648270953, 4.100520203486225, 4.5757827796188675, 3.8089237407475456, 3.472300541807105, 3.0825980970223776, 3.9279325911926906, 4.490222648270953, 4.490222648270953, 4.100520203486225, 3.538230146407963]\n",
      "all_sum after preprocessing is: [-0.20688092  0.40114481  2.82764012 -0.20688092 -1.41515906 -0.20688092\n",
      " -0.87865888 -0.20688092 -0.20688092 -0.44587064 -1.41515906 -0.87865888\n",
      "  0.76240751  0.76240751  0.09062955  0.09062955  1.58167598  2.82764012\n",
      "  0.76240751 -0.87865888 -0.20688092  2.55096441 -0.20688092 -0.20688092\n",
      " -0.87865888 -1.41515906  0.76240751 -0.44587064 -0.44587064 -0.20688092\n",
      " -0.44587064 -0.87865888  1.34268626 -0.44587064  0.83393306 -0.44587064\n",
      " -0.99230984 -0.20688092 -0.44587064  0.76240751  0.09062955  0.90989802\n",
      " -0.41203109 -0.99230984 -1.6640878  -0.20688092  0.76240751  0.76240751\n",
      "  0.09062955 -0.87865888]\n",
      "P is: [0.44846345258536174, 0.5989626827690795, 0.9441512969809469, 0.44846345258536174, 0.19542161179831657, 0.44846345258536174, 0.2934557692028427, 0.44846345258536174, 0.44846345258536174, 0.3903430066300309, 0.19542161179831657, 0.2934557692028427, 0.6818762020453291, 0.6818762020453291, 0.5226418910983638, 0.5226418910983638, 0.8294417466894566, 0.9441512969809469, 0.6818762020453291, 0.2934557692028427, 0.44846345258536174, 0.9276382776038798, 0.44846345258536174, 0.44846345258536174, 0.2934557692028427, 0.19542161179831657, 0.6818762020453291, 0.3903430066300309, 0.3903430066300309, 0.44846345258536174, 0.3903430066300309, 0.2934557692028427, 0.7929313487299523, 0.3903430066300309, 0.697185911060407, 0.3903430066300309, 0.27045608344125777, 0.44846345258536174, 0.3903430066300309, 0.6818762020453291, 0.5226418910983638, 0.7129792933641298, 0.39842520484622584, 0.27045608344125777, 0.15921402151742287, 0.44846345258536174, 0.6818762020453291, 0.6818762020453291, 0.5226418910983638, 0.2934557692028427]\n",
      "all_sum before preprocessing is: [1.5220361521315493, 1.6188689454911762, 2.7075886656596944, 3.5145427903182895, 2.0882024039394285, 3.5145427903182895, 2.1850351972990554, 2.465696453461145, 2.3300946161379783, 3.5145427903182895, 1.5225883218054663, 2.3295424464640613, 2.7075886656596944, 1.6188689454911762, 2.466248623135062, 2.466248623135062, 1.5220361521315493, 1.6188689454911762, 3.5145427903182895, 2.7070364959857773, 2.7075886656596944, 1.2812482792808337, 3.5150949599922066, 1.5220361521315493, 1.5225883218054663, 1.5220361521315493, 2.426375239823688, 2.466248623135062, 1.6188689454911762, 1.24137489596946, 2.425823070149771, 2.466248623135062, 1.5225883218054663, 2.426375239823688, 3.423089892690376, 2.7070364959857773, 3.5145427903182895, 3.5145427903182895, 1.5225883218054663, 2.7075886656596944, 1.6183167758172592, 0.1925285591123153, 3.5150949599922066, 2.7075886656596944, 1.6188689454911762, 1.9861837435517449, 1.5220361521315493, 2.0887545736133455, 2.0887545736133455, 1.5220361521315493]\n",
      "all_sum after preprocessing is: [-0.94878746 -0.82377884  0.58173008  1.62348692 -0.21788152  1.62348692\n",
      " -0.09287289  0.26945351  0.09439505  1.62348692 -0.94807463  0.09368222\n",
      "  0.58173008 -0.82377884  0.27016635  0.27016635 -0.94878746 -0.82377884\n",
      "  1.62348692  0.58101724  0.58173008 -1.25963836  1.62419976 -0.94878746\n",
      " -0.94807463 -0.94878746  0.21869084  0.27016635 -0.82377884 -1.31111387\n",
      "  0.217978    0.27016635 -0.94807463  0.21869084  1.50542361  0.58101724\n",
      "  1.62348692  1.62348692 -0.94807463  0.58173008 -0.82449168 -2.66514728\n",
      "  1.62419976  0.58173008 -0.82377884 -0.34958496 -0.94878746 -0.21716868\n",
      " -0.21716868 -0.94878746]\n",
      "P is: [0.27912873808277056, 0.3049621064138658, 0.6414654005891182, 0.8352754581541989, 0.44574408883965977, 0.8352754581541989, 0.4767984510732485, 0.5669587372024827, 0.5235812561224756, 0.8352754581541989, 0.2792721947366263, 0.523403440350357, 0.6414654005891182, 0.3049621064138658, 0.5671337420399021, 0.5671337420399021, 0.27912873808277056, 0.3049621064138658, 0.8352754581541989, 0.6413014404964398, 0.6414654005891182, 0.22103615236047924, 0.8353735141819919, 0.27912873808277056, 0.2792721947366263, 0.27912873808277056, 0.5544558508551357, 0.5671337420399021, 0.3049621064138658, 0.21230051368142108, 0.5542797487191835, 0.5671337420399021, 0.2792721947366263, 0.5544558508551357, 0.8183819949683526, 0.6413014404964398, 0.8352754581541989, 0.8352754581541989, 0.2792721947366263, 0.6414654005891182, 0.3048110343942824, 0.06506152996564254, 0.8353735141819919, 0.6414654005891182, 0.3049621064138658, 0.4134830702021183, 0.27912873808277056, 0.4459202064451848, 0.4459202064451848, 0.27912873808277056]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.008\n",
      "(*) epoch 2, cost 3.750\n",
      "(*) epoch 3, cost 3.236\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.965\n",
      "(*) epoch 2, cost 4.287\n",
      "(*) epoch 3, cost 3.303\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.3369456844034482, 2.0534376531544734, 3.0423251230913246, 2.2086449102170618, 2.0534376531544734, 2.0534376531544734, 2.16707541503302, 3.0423251230913246, 1.3369456844034482, 2.0534376531544734, 2.0534376531544734, 2.0534376531544734, 2.0534376531544734, 1.3369456844034482, 2.16707541503302, 2.16707541503302, 1.3369456844034482, 2.0534376531544734, 1.3369456844034482, 2.0534376531544734, 2.0534376531544734, 2.0534376531544734, 2.16707541503302, 2.0534376531544734, 2.2086449102170618, 2.0534376531544734, 2.0534376531544734, 2.0534376531544734, 2.16707541503302, 2.0534376531544734, 2.0534376531544734, 2.0534376531544734, 3.0423251230913246, 1.3369456844034482, 2.3258331543402995, 1.4505834462819946, 2.0534376531544734, 1.3369456844034482, 2.0534376531544734, 3.0423251230913246, 2.0534376531544734, 2.0534376531544734, 2.0534376531544734, 2.0534376531544734, 1.3369456844034482, 2.0534376531544734, 2.0534376531544734, 2.16707541503302, 2.0534376531544734, 2.3258331543402995]\n",
      "all_sum after preprocessing is: [-1.68291721  0.04051657  2.4191644   0.41384863  0.04051657  0.04051657\n",
      "  0.3138583   2.4191644  -1.68291721  0.04051657  0.04051657  0.04051657\n",
      "  0.04051657 -1.68291721  0.3138583   0.3138583  -1.68291721  0.04051657\n",
      " -1.68291721  0.04051657  0.04051657  0.04051657  0.3138583   0.04051657\n",
      "  0.41384863  0.04051657  0.04051657  0.04051657  0.3138583   0.04051657\n",
      "  0.04051657  0.04051657  2.4191644  -1.68291721  0.69573062 -1.40957548\n",
      "  0.04051657 -1.68291721  0.04051657  2.4191644   0.04051657  0.04051657\n",
      "  0.04051657  0.04051657 -1.68291721  0.04051657  0.04051657  0.3138583\n",
      "  0.04051657  0.69573062]\n",
      "P is: [0.15670956835689756, 0.5101277559901453, 0.9182770591532388, 0.6020103492582327, 0.5101277559901453, 0.5101277559901453, 0.5778267478640482, 0.9182770591532388, 0.15670956835689756, 0.5101277559901453, 0.5101277559901453, 0.5101277559901453, 0.5101277559901453, 0.15670956835689756, 0.5778267478640482, 0.5778267478640482, 0.15670956835689756, 0.5101277559901453, 0.15670956835689756, 0.5101277559901453, 0.5101277559901453, 0.5101277559901453, 0.5778267478640482, 0.5101277559901453, 0.6020103492582327, 0.5101277559901453, 0.5101277559901453, 0.5101277559901453, 0.5778267478640482, 0.5101277559901453, 0.5101277559901453, 0.5101277559901453, 0.9182770591532388, 0.15670956835689756, 0.6672405168091747, 0.1963010234118794, 0.5101277559901453, 0.15670956835689756, 0.5101277559901453, 0.9182770591532388, 0.5101277559901453, 0.5101277559901453, 0.5101277559901453, 0.5101277559901453, 0.15670956835689756, 0.5101277559901453, 0.5101277559901453, 0.5778267478640482, 0.5101277559901453, 0.6672405168091747]\n",
      "all_sum before preprocessing is: [3.1646565176674826, 2.7326661336010605, 5.125703827072178, 5.1585003760228005, 5.125703827072178, 5.1585003760228005, 2.7326661336010605, 3.1646565176674826, 2.7326661336010605, 2.7326661336010605, 2.7326661336010605, 4.7075209844025885, 4.693713443005756, 4.693713443005756, 5.125703827072178, 3.1646565176674826, 2.7326661336010605, 4.693713443005756, 2.7326661336010605, 5.172307917419632, 2.746473674997892, 5.125703827072178, 4.693713443005756, 2.7326661336010605, 2.7326661336010605, 3.1646565176674826, 3.1974530666181042, 3.1646565176674826, 4.693713443005756, 3.1646565176674826, 5.125703827072178, 2.7326661336010605, 4.693713443005756, 3.1646565176674826, 4.7075209844025885, 2.7326661336010605, 2.7326661336010605, 3.1646565176674826, 4.693713443005756, 4.693713443005756, 5.125703827072178, 5.1585003760228005, 3.1646565176674826, 2.7326661336010605, 4.7075209844025885, 2.7326661336010605, 2.7326661336010605, 4.693713443005756, 5.1585003760228005, 4.693713443005756]\n",
      "all_sum after preprocessing is: [-0.68073102 -1.10320509  1.23711639  1.26919046  1.23711639  1.26919046\n",
      " -1.10320509 -0.68073102 -1.10320509 -1.10320509 -1.10320509  0.82814569\n",
      "  0.81464232  0.81464232  1.23711639 -0.68073102 -1.10320509  0.81464232\n",
      " -1.10320509  1.28269383 -1.08970172  1.23711639  0.81464232 -1.10320509\n",
      " -1.10320509 -0.68073102 -0.64865695 -0.68073102  0.81464232 -0.68073102\n",
      "  1.23711639 -1.10320509  0.81464232 -0.68073102  0.82814569 -1.10320509\n",
      " -1.10320509 -0.68073102  0.81464232  0.81464232  1.23711639  1.26919046\n",
      " -0.68073102 -1.10320509  0.82814569 -1.10320509 -1.10320509  0.81464232\n",
      "  1.26919046  0.81464232]\n",
      "P is: [0.3360981658111475, 0.2491398387651239, 0.7750616805871738, 0.7806041363941519, 0.7750616805871738, 0.7806041363941519, 0.2491398387651239, 0.3360981658111475, 0.2491398387651239, 0.2491398387651239, 0.2491398387651239, 0.6959627031944003, 0.6930978703980868, 0.6930978703980868, 0.7750616805871738, 0.3360981658111475, 0.2491398387651239, 0.6930978703980868, 0.2491398387651239, 0.78290797772522, 0.2516744514529276, 0.7750616805871738, 0.6930978703980868, 0.2491398387651239, 0.2491398387651239, 0.3360981658111475, 0.34329225501438465, 0.3360981658111475, 0.6930978703980868, 0.3360981658111475, 0.7750616805871738, 0.2491398387651239, 0.6930978703980868, 0.3360981658111475, 0.6959627031944003, 0.2491398387651239, 0.2491398387651239, 0.3360981658111475, 0.6930978703980868, 0.6930978703980868, 0.7750616805871738, 0.7806041363941519, 0.3360981658111475, 0.2491398387651239, 0.6959627031944003, 0.2491398387651239, 0.2491398387651239, 0.6930978703980868, 0.7806041363941519, 0.6930978703980868]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.633\n",
      "(*) epoch 2, cost 1.983\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 5.539\n",
      "(*) epoch 2, cost 3.405\n",
      "(*) epoch 3, cost 2.775\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.2037757766564279, 1.8621696820562894, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.8621696820562894, 1.8621696820562894, 1.2037757766564279, 1.2037757766564279, 1.8621696820562894, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.8621696820562894, 1.8621696820562894, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 2.471590401436516, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.8621696820562894, 1.8621696820562894, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.2037757766564279, 1.8621696820562894, 2.5007718686526386, 1.2037757766564279, 1.842377963252777, 1.8621696820562894, 1.8621696820562894, 2.5007718686526386, 1.8621696820562894, 1.8621696820562894, 1.2037757766564279, 2.5007718686526386, 1.842377963252777, 1.2037757766564279, 1.2037757766564279]\n",
      "all_sum after preprocessing is: [-0.72280277  0.86400908 -0.72280277 -0.72280277 -0.72280277 -0.72280277\n",
      "  0.86400908  0.86400908 -0.72280277 -0.72280277  0.86400908 -0.72280277\n",
      " -0.72280277 -0.72280277 -0.72280277 -0.72280277 -0.72280277  0.86400908\n",
      "  0.86400908 -0.72280277 -0.72280277 -0.72280277 -0.72280277 -0.72280277\n",
      " -0.72280277 -0.72280277  2.33278941 -0.72280277 -0.72280277 -0.72280277\n",
      "  0.86400908  0.86400908 -0.72280277 -0.72280277 -0.72280277 -0.72280277\n",
      "  0.86400908  2.40312041 -0.72280277  0.81630856  0.86400908  0.86400908\n",
      "  2.40312041  0.86400908  0.86400908 -0.72280277  2.40312041  0.81630856\n",
      " -0.72280277 -0.72280277]\n",
      "P is: [0.32677609304443, 0.7034975853422116, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.7034975853422116, 0.7034975853422116, 0.32677609304443, 0.32677609304443, 0.7034975853422116, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.7034975853422116, 0.7034975853422116, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.911556481192065, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.7034975853422116, 0.7034975853422116, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.32677609304443, 0.7034975853422116, 0.9170649409998044, 0.32677609304443, 0.6934521881705857, 0.7034975853422116, 0.7034975853422116, 0.9170649409998044, 0.7034975853422116, 0.7034975853422116, 0.32677609304443, 0.9170649409998044, 0.6934521881705857, 0.32677609304443, 0.32677609304443]\n",
      "all_sum before preprocessing is: [4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.52798522576843, 5.425356595020351, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.877327583412132, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.877327583412132, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.877327583412132, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.4511754518760815, 4.52798522576843, 4.4511754518760815]\n",
      "all_sum after preprocessing is: [-0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163\n",
      " -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163\n",
      " -0.28865163 -0.28865163 -0.28865163 -0.28865163  0.17204866  5.55442683\n",
      " -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163  2.26738259\n",
      " -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163\n",
      " -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163\n",
      "  2.26738259 -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163\n",
      "  2.26738259 -0.28865163 -0.28865163 -0.28865163 -0.28865163 -0.28865163\n",
      "  0.17204866 -0.28865163]\n",
      "P is: [0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.542906377837862, 0.9961446351951004, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.9061394114635444, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.9061394114635444, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.9061394114635444, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.4283340013155994, 0.542906377837862, 0.4283340013155994]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.654\n",
      "(*) epoch 2, cost 2.314\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.611\n",
      "(*) epoch 2, cost 1.725\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [1.8047249191177765, 0.8268480439530435, 1.6575420246920385, 0.8268480439530435, 0.9518616890744912, 0.9121526947102719, 1.6575420246920385, 0.8268480439530435, 0.8268480439530435, 0.9121526947102719, 2.017794394961513, 1.210526821311237, 0.9121526947102719, 1.210526821311237, 1.1252221705540086, 0.8268480439530435, 0.8268480439530435, 1.719420268360548, 0.8268480439530435, 1.8047249191177765, 0.9518616890744912, 1.7428466754492669, 3.104191035763357, 0.8268480439530435, 0.8268480439530435, 1.210526821311237, 1.1252221705540086, 0.8268480439530435, 1.0371663398317197, 0.9518616890744912, 0.9121526947102719, 0.8268480439530435, 1.7428466754492669, 1.6575420246920385, 1.6575420246920385, 0.8268480439530435, 0.8268480439530435, 0.9121526947102719, 0.9121526947102719, 1.719420268360548, 0.9121526947102719, 0.9121526947102719, 0.9121526947102719, 1.210526821311237, 0.8268480439530435, 0.8268480439530435, 0.8268480439530435, 0.9121526947102719, 1.1252221705540086, 0.8268480439530435]\n",
      "all_sum after preprocessing is: [ 1.43931816 -0.71531332  1.11501875 -0.71531332 -0.43986112 -0.52735501\n",
      "  1.11501875 -0.71531332 -0.71531332 -0.52735501  1.90879056  0.1300757\n",
      " -0.52735501  0.1300757  -0.05788261 -0.71531332 -0.71531332  1.25135985\n",
      " -0.71531332  1.43931816 -0.43986112  1.30297706  4.302532   -0.71531332\n",
      " -0.71531332  0.1300757  -0.05788261 -0.71531332 -0.25190281 -0.43986112\n",
      " -0.52735501 -0.71531332  1.30297706  1.11501875  1.11501875 -0.71531332\n",
      " -0.71531332 -0.52735501 -0.52735501  1.25135985 -0.52735501 -0.52735501\n",
      " -0.52735501  0.1300757  -0.71531332 -0.71531332 -0.71531332 -0.52735501\n",
      " -0.05788261 -0.71531332]\n",
      "P is: [0.8083490425837797, 0.3284258558399799, 0.7530635766411141, 0.3284258558399799, 0.39177406211611787, 0.37113400157779136, 0.7530635766411141, 0.3284258558399799, 0.3284258558399799, 0.37113400157779136, 0.8708832123162227, 0.5324731516480511, 0.37113400157779136, 0.5324731516480511, 0.48553338612702085, 0.3284258558399799, 0.3284258558399799, 0.7775351689732725, 0.3284258558399799, 0.8083490425837797, 0.39177406211611787, 0.7863355907069149, 0.9866464829167513, 0.3284258558399799, 0.3284258558399799, 0.5324731516480511, 0.48553338612702085, 0.3284258558399799, 0.4373552085661273, 0.39177406211611787, 0.37113400157779136, 0.3284258558399799, 0.7863355907069149, 0.7530635766411141, 0.7530635766411141, 0.3284258558399799, 0.3284258558399799, 0.37113400157779136, 0.37113400157779136, 0.7775351689732725, 0.37113400157779136, 0.37113400157779136, 0.37113400157779136, 0.5324731516480511, 0.3284258558399799, 0.3284258558399799, 0.3284258558399799, 0.37113400157779136, 0.48553338612702085, 0.3284258558399799]\n",
      "all_sum before preprocessing is: [2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 3.951791435862033, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.0137552145610567, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 3.951791435862033, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 2.199182344399105, 1.906931122218858]\n",
      "all_sum after preprocessing is: [-0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487\n",
      " -0.17364487 -0.17364487  4.85240919 -0.17364487 -0.17364487 -0.17364487\n",
      " -0.70540451 -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487\n",
      " -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487\n",
      " -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487  4.85240919\n",
      " -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487\n",
      " -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487\n",
      " -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487 -0.17364487\n",
      " -0.17364487 -1.01174987]\n",
      "P is: [0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.9922509760801207, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.3306150698208214, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.9922509760801207, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.456697534608581, 0.2666375384067582]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.283\n",
      "(*) epoch 2, cost 1.859\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.598\n",
      "(*) epoch 2, cost 2.511\n",
      "(*) epoch 3, cost 2.004\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 3.5774149520617384, 2.510806939214217, 2.510806939214217, 2.0305836789710057, 2.510806939214217, 2.510806939214217, 3.551518090592173, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 3.5774149520617384, 3.145027445167239, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 3.145027445167239, 2.510806939214217, 2.510806939214217, 2.510806939214217, 3.551518090592173, 2.510806939214217, 3.551518090592173, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217, 2.510806939214217]\n",
      "all_sum after preprocessing is: [-0.35400245 -0.35400245 -0.35400245 -0.35400245 -0.35400245 -0.35400245\n",
      "  2.76983014 -0.35400245 -0.35400245 -1.76045828 -0.35400245 -0.35400245\n",
      "  2.6939846  -0.35400245 -0.35400245 -0.35400245 -0.35400245 -0.35400245\n",
      " -0.35400245 -0.35400245 -0.35400245 -0.35400245 -0.35400245  2.76983014\n",
      "  1.50347346 -0.35400245 -0.35400245 -0.35400245 -0.35400245 -0.35400245\n",
      " -0.35400245 -0.35400245 -0.35400245 -0.35400245  1.50347346 -0.35400245\n",
      " -0.35400245 -0.35400245  2.6939846  -0.35400245  2.6939846  -0.35400245\n",
      " -0.35400245 -0.35400245 -0.35400245 -0.35400245 -0.35400245 -0.35400245\n",
      " -0.35400245 -0.35400245]\n",
      "P is: [0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.9410235601958116, 0.4124121761849813, 0.4124121761849813, 0.14673295222578114, 0.4124121761849813, 0.4124121761849813, 0.9366707543598651, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.9410235601958116, 0.8180919586845907, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.8180919586845907, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.9366707543598651, 0.4124121761849813, 0.9366707543598651, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813, 0.4124121761849813]\n",
      "all_sum before preprocessing is: [0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 1.5504593235977444, 0.9881175458112184, 1.5504593235977444, 1.5504593235977444, 0.9881175458112184, 0.9881175458112184, 1.1407029836685325, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.26774567371060815, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 2.273474844025264, 0.9881175458112184, 1.5504593235977444, 1.5504593235977444, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 1.5504593235977444, 0.9881175458112184, 0.26774567371060815, 0.9881175458112184, 1.5504593235977444, 0.9881175458112184, 0.9881175458112184, 0.9881175458112184, 0.8300874514971341, 0.9881175458112184]\n",
      "all_sum after preprocessing is: [-0.24716574 -0.24716574 -0.24716574  1.5935092  -0.24716574  1.5935092\n",
      "  1.5935092  -0.24716574 -0.24716574  0.25228175 -0.24716574 -0.24716574\n",
      " -0.24716574 -0.24716574 -0.24716574 -0.24716574 -0.24716574 -0.24716574\n",
      " -0.24716574 -2.6051098  -0.24716574 -0.24716574 -0.24716574 -0.24716574\n",
      " -0.24716574 -0.24716574 -0.24716574  3.96010653 -0.24716574  1.5935092\n",
      "  1.5935092  -0.24716574 -0.24716574 -0.24716574 -0.24716574 -0.24716574\n",
      " -0.24716574 -0.24716574 -0.24716574 -0.24716574  1.5935092  -0.24716574\n",
      " -2.6051098  -0.24716574  1.5935092  -0.24716574 -0.24716574 -0.24716574\n",
      " -0.76443486 -0.24716574]\n",
      "P is: [0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.8311092502329301, 0.43852122894169543, 0.8311092502329301, 0.8311092502329301, 0.43852122894169543, 0.43852122894169543, 0.5627380379127984, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.06881028532557218, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.981295445519641, 0.43852122894169543, 0.8311092502329301, 0.8311092502329301, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.8311092502329301, 0.43852122894169543, 0.06881028532557218, 0.43852122894169543, 0.8311092502329301, 0.43852122894169543, 0.43852122894169543, 0.43852122894169543, 0.3176841855788848, 0.43852122894169543]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.273\n",
      "(*) epoch 2, cost 1.586\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.986\n",
      "(*) epoch 2, cost 1.750\n",
      "(*) epoch 3, cost 1.303\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.425460458206951, 3.425460458206951, 1.3404458809280213, 2.312395002257325, 2.6257533533273274, 2.312395002257325, 1.9795273229262718, 2.6257533533273274, 4.202667966762858, 1.9795273229262718, 3.758328137538004, 1.3404458809280213, 2.7863790162087008, 1.653804231998024, 2.312395002257325, 3.1121021071369483, 1.666168971856269, 2.312395002257325, 1.784785710152875, 2.6257533533273274, 4.071686488608007, 2.443376480412176, 3.425460458206951, 2.312395002257325, 3.1121021071369483, 3.425460458206951, 1.9795273229262718, 1.653804231998024, 1.1385596797518194, 3.5564419363618023, 3.1121021071369483, 4.071686488608007, 2.312395002257325, 1.3404458809280213, 3.0997373672787036, 2.312395002257325, 1.0075782015969683, 3.1121021071369483, 1.784785710152875, 2.4535113368776478, 2.756734831482179, 2.312395002257325, 2.7026067982079636, 0.6942198505269656, 4.071686488608007, 2.6257533533273274, 3.758328137538004, 3.1121021071369483, 3.758328137538004, 4.071686488608007]\n",
      "all_sum after preprocessing is: [ 0.90326221  0.90326221 -1.44491204 -0.35028857  0.00262024 -0.35028857\n",
      " -0.72516907  0.00262024  1.77856479 -0.72516907  1.27814271 -1.44491204\n",
      "  0.18351924 -1.09200323 -0.35028857  0.5503534  -1.07807788 -0.35028857\n",
      " -0.94448995  0.00262024  1.63105152 -0.20277529  0.90326221 -0.35028857\n",
      "  0.5503534   0.90326221 -0.72516907 -1.09200323 -1.67227926  1.05077548\n",
      "  0.5503534   1.63105152 -0.35028857 -1.44491204  0.53642805 -0.35028857\n",
      " -1.81979254  0.5503534  -0.94448995 -0.19136126  0.15013352 -0.35028857\n",
      "  0.08917373 -2.17270135  1.63105152  0.00262024  1.27814271  0.5503534\n",
      "  1.27814271  1.63105152]\n",
      "P is: [0.7116194254399228, 0.7116194254399228, 0.19078584383362507, 0.4133124462534794, 0.5006550600122168, 0.4133124462534794, 0.3262557361003175, 0.5006550600122168, 0.8555195564718245, 0.3262557361003175, 0.7821334584237617, 0.19078584383362507, 0.5457514749765865, 0.25124124507467316, 0.4133124462534794, 0.6342175782927137, 0.2538699331019739, 0.4133124462534794, 0.27999428613912675, 0.5006550600122168, 0.8363136350217768, 0.4494791680734448, 0.7116194254399228, 0.4133124462534794, 0.6342175782927137, 0.7116194254399228, 0.3262557361003175, 0.25124124507467316, 0.15812053069154594, 0.7409237855189453, 0.6342175782927137, 0.8363136350217768, 0.4133124462534794, 0.19078584383362507, 0.6309810996130237, 0.4133124462534794, 0.13945876856616407, 0.6342175782927137, 0.27999428613912675, 0.45230514063855304, 0.5374630378082508, 0.4133124462534794, 0.5222786705652824, 0.10222884246238022, 0.8363136350217768, 0.5006550600122168, 0.7821334584237617, 0.6342175782927137, 0.7821334584237617, 0.8363136350217768]\n",
      "all_sum before preprocessing is: [2.6147744284471948, 4.160985713696482, 3.4483529104089143, 4.160985713696482, 2.393171808564028, 2.942096855086519, 2.942096855086519, 2.942096855086519, 3.4483529104089143, 2.942096855086519, 2.7204942352033523, 3.12103048376959, 6.306940237094258, 2.7204942352033523, 2.6147744284471948, 2.942096855086519, 2.942096855086519, 2.7204942352033523, 3.2267502905257475, 2.7204942352033523, 2.942096855086519, 2.7204942352033523, 3.9393830938133143, 2.942096855086519, 3.12103048376959, 2.942096855086519, 3.833663287057157, 2.942096855086519, 3.4483529104089143, 3.4483529104089143, 2.942096855086519, 2.942096855086519, 2.942096855086519, 3.12103048376959, 2.6147744284471948, 5.309653998367462, 2.7204942352033523, 2.7204942352033523, 2.7204942352033523, 2.942096855086519, 2.942096855086519, 2.899427863886423, 2.942096855086519, 2.942096855086519, 2.942096855086519, 5.636976425006787, 2.942096855086519, 6.143232480329182, 2.7204942352033523, 3.4483529104089143]\n",
      "all_sum after preprocessing is: [-0.7487961   1.05429361  0.2232682   1.05429361 -1.00721447 -0.36709425\n",
      " -0.36709425 -0.36709425  0.2232682  -0.36709425 -0.62551263 -0.15843365\n",
      "  3.55676437 -0.62551263 -0.7487961  -0.36709425 -0.36709425 -0.62551263\n",
      " -0.03515017 -0.62551263 -0.36709425 -0.62551263  0.79587524 -0.36709425\n",
      " -0.15843365 -0.36709425  0.67259177 -0.36709425  0.2232682   0.2232682\n",
      " -0.36709425 -0.36709425 -0.36709425 -0.15843365 -0.7487961   2.39379488\n",
      " -0.62551263 -0.62551263 -0.62551263 -0.36709425 -0.36709425 -0.41685202\n",
      " -0.36709425 -0.36709425 -0.36709425  2.77549672 -0.36709425  3.36585917\n",
      " -0.62551263  0.2232682 ]\n",
      "P is: [0.3210836813058593, 0.7415985383275634, 0.5555863323245569, 0.7415985383275634, 0.26752533672455747, 0.40924333835262994, 0.40924333835262994, 0.40924333835262994, 0.5555863323245569, 0.40924333835262994, 0.34852873100476034, 0.46047423239939855, 0.9722604458185944, 0.34852873100476034, 0.3210836813058593, 0.40924333835262994, 0.40924333835262994, 0.34852873100476034, 0.49121336095479523, 0.34852873100476034, 0.40924333835262994, 0.34852873100476034, 0.6890914646800733, 0.40924333835262994, 0.46047423239939855, 0.40924333835262994, 0.6620832566195651, 0.40924333835262994, 0.5555863323245569, 0.5555863323245569, 0.40924333835262994, 0.40924333835262994, 0.40924333835262994, 0.46047423239939855, 0.3210836813058593, 0.9163529064072864, 0.34852873100476034, 0.34852873100476034, 0.34852873100476034, 0.40924333835262994, 0.40924333835262994, 0.3972702789350443, 0.40924333835262994, 0.40924333835262994, 0.40924333835262994, 0.941337260757652, 0.40924333835262994, 0.9666203434014571, 0.34852873100476034, 0.5555863323245569]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.504\n",
      "(*) epoch 2, cost 3.409\n",
      "(*) epoch 3, cost 2.957\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.671\n",
      "(*) epoch 2, cost 3.543\n",
      "(*) epoch 3, cost 3.073\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.0194985806214696, 2.0194985806214696, 1.1823956516072616, 2.314838178218615, 1.3380202173126468, 2.9963165415274373, 1.3380202173126468, 1.3380202173126468, 2.271812741539085, 2.0194985806214696, 1.3380202173126468, 2.0194985806214696, 2.0194985806214696, 1.3380202173126468, 2.0194985806214696, 2.0194985806214696, 2.0194985806214696, 2.935945902548946, 1.3380202173126468, 1.3380202173126468, 2.0194985806214696, 1.3380202173126468, 2.0194985806214696, 1.3380202173126468, 2.0194985806214696, 1.3380202173126468, 2.9963165415274373, 2.935945902548946, 1.3380202173126468, 2.0194985806214696, 2.0194985806214696, 1.3380202173126468, 2.0194985806214696, 2.9963165415274373, 2.0194985806214696, 1.3380202173126468, 1.3380202173126468, 2.0194985806214696, 2.9963165415274373, 2.9963165415274373, 1.3380202173126468, 1.3380202173126468, 1.3380202173126468, 1.3380202173126468, 1.3380202173126468, 1.3380202173126468, 1.3380202173126468, 2.0194985806214696, 2.0194985806214696, 1.3380202173126468]\n",
      "all_sum after preprocessing is: [ 0.30232581  0.30232581 -1.17507147  0.82356866 -0.90041073  2.0263052\n",
      " -0.90041073 -0.90041073  0.74763336  0.30232581 -0.90041073  0.30232581\n",
      "  0.30232581 -0.90041073  0.30232581  0.30232581  0.30232581  1.91975747\n",
      " -0.90041073 -0.90041073  0.30232581 -0.90041073  0.30232581 -0.90041073\n",
      "  0.30232581 -0.90041073  2.0263052   1.91975747 -0.90041073  0.30232581\n",
      "  0.30232581 -0.90041073  0.30232581  2.0263052   0.30232581 -0.90041073\n",
      " -0.90041073  0.30232581  2.0263052   2.0263052  -0.90041073 -0.90041073\n",
      " -0.90041073 -0.90041073 -0.90041073 -0.90041073 -0.90041073  0.30232581\n",
      "  0.30232581 -0.90041073]\n",
      "P is: [0.5750109815691851, 0.5750109815691851, 0.2359395158626004, 0.6949933423243216, 0.2889660995085816, 0.8835314080351125, 0.2889660995085816, 0.2889660995085816, 0.6786628016512459, 0.5750109815691851, 0.2889660995085816, 0.5750109815691851, 0.5750109815691851, 0.2889660995085816, 0.5750109815691851, 0.5750109815691851, 0.5750109815691851, 0.8721113859705099, 0.2889660995085816, 0.2889660995085816, 0.5750109815691851, 0.2889660995085816, 0.5750109815691851, 0.2889660995085816, 0.5750109815691851, 0.2889660995085816, 0.8835314080351125, 0.8721113859705099, 0.2889660995085816, 0.5750109815691851, 0.5750109815691851, 0.2889660995085816, 0.5750109815691851, 0.8835314080351125, 0.5750109815691851, 0.2889660995085816, 0.2889660995085816, 0.5750109815691851, 0.8835314080351125, 0.8835314080351125, 0.2889660995085816, 0.2889660995085816, 0.2889660995085816, 0.2889660995085816, 0.2889660995085816, 0.2889660995085816, 0.2889660995085816, 0.5750109815691851, 0.5750109815691851, 0.2889660995085816]\n",
      "all_sum before preprocessing is: [1.270879767623507, 1.270879767623507, 0.7741147680473257, 0.7741147680473257, 1.7041165930501745, 1.7041165930501745, 1.270879767623507, 1.270879767623507, 0.34087794262065824, 1.7041165930501745, 1.7041165930501745, 1.7041165930501745, 1.7041165930501745, 1.270879767623507, 1.270879767623507, 1.270879767623507, 1.7041165930501745, 1.7041165930501745, 1.7041165930501745, 0.34087794262065824, 1.270879767623507, 0.34087794262065824, 1.7041165930501745, 1.270879767623507, 0.7741147680473257, 0.34087794262065824, 1.7041165930501745, 1.270879767623507, 1.7041165930501745, 1.7041165930501745, 0.7741147680473257, 0.34087794262065824, 1.7041165930501745, 1.270879767623507, 1.7041165930501745, 1.270879767623507, 0.7741147680473257, 1.7041165930501745, 1.270879767623507, 1.270879767623507, 1.7041165930501745, 0.7741147680473257, 0.34087794262065824, 1.7041165930501745, 0.7741147680473257, 1.7041165930501745, 1.270879767623507, 1.270879767623507, 1.270879767623507, 1.7041165930501745]\n",
      "all_sum after preprocessing is: [ 0.01700057  0.01700057 -1.05847771 -1.05847771  0.95494265  0.95494265\n",
      "  0.01700057  0.01700057 -1.99641979  0.95494265  0.95494265  0.95494265\n",
      "  0.95494265  0.01700057  0.01700057  0.01700057  0.95494265  0.95494265\n",
      "  0.95494265 -1.99641979  0.01700057 -1.99641979  0.95494265  0.01700057\n",
      " -1.05847771 -1.99641979  0.95494265  0.01700057  0.95494265  0.95494265\n",
      " -1.05847771 -1.99641979  0.95494265  0.01700057  0.95494265  0.01700057\n",
      " -1.05847771  0.95494265  0.01700057  0.01700057  0.95494265 -1.05847771\n",
      " -1.99641979  0.95494265 -1.05847771  0.95494265  0.01700057  0.01700057\n",
      "  0.01700057  0.95494265]\n",
      "P is: [0.5042500404068319, 0.5042500404068319, 0.2576004735250798, 0.2576004735250798, 0.7221080978419604, 0.7221080978419604, 0.5042500404068319, 0.5042500404068319, 0.1195793337850453, 0.7221080978419604, 0.7221080978419604, 0.7221080978419604, 0.7221080978419604, 0.5042500404068319, 0.5042500404068319, 0.5042500404068319, 0.7221080978419604, 0.7221080978419604, 0.7221080978419604, 0.1195793337850453, 0.5042500404068319, 0.1195793337850453, 0.7221080978419604, 0.5042500404068319, 0.2576004735250798, 0.1195793337850453, 0.7221080978419604, 0.5042500404068319, 0.7221080978419604, 0.7221080978419604, 0.2576004735250798, 0.1195793337850453, 0.7221080978419604, 0.5042500404068319, 0.7221080978419604, 0.5042500404068319, 0.2576004735250798, 0.7221080978419604, 0.5042500404068319, 0.5042500404068319, 0.7221080978419604, 0.2576004735250798, 0.1195793337850453, 0.7221080978419604, 0.2576004735250798, 0.7221080978419604, 0.5042500404068319, 0.5042500404068319, 0.5042500404068319, 0.7221080978419604]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.396\n",
      "(*) epoch 2, cost 1.990\n",
      "(*) epoch 3, cost 1.569\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.893\n",
      "(*) epoch 2, cost 1.728\n",
      "(*) epoch 3, cost 1.334\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.375177636135006, 2.375177636135006, 2.375177636135006, 2.375177636135006, 1.7276183001682257, 2.375177636135006, 2.375177636135006, 2.375177636135006, 1.7276183001682257, 1.7276183001682257, 1.7276183001682257, 2.375177636135006, 2.6063241143502225, 2.375177636135006, 1.7276183001682257, 2.375177636135006, 2.375177636135006, 1.7276183001682257, 3.2538834503170024, 2.375177636135006, 1.7276183001682257, 2.375177636135006, 2.375177636135006, 3.2538834503170024, 1.7276183001682257, 2.375177636135006, 2.375177636135006, 2.375177636135006, 2.375177636135006, 2.375177636135006, 2.375177636135006, 2.375177636135006, 3.2538834503170024, 2.375177636135006, 2.375177636135006, 1.7276183001682257, 1.7276183001682257, 2.375177636135006, 2.375177636135006, 1.7276183001682257, 1.7276183001682257, 2.375177636135006, 1.7276183001682257, 2.375177636135006, 2.375177636135006, 2.375177636135006, 1.7276183001682257, 2.6063241143502225, 2.375177636135006, 1.7276183001682257]\n",
      "all_sum after preprocessing is: [ 0.33414813  0.33414813  0.33414813  0.33414813 -1.30138784  0.33414813\n",
      "  0.33414813  0.33414813 -1.30138784 -1.30138784 -1.30138784  0.33414813\n",
      "  0.91795314  0.33414813 -1.30138784  0.33414813  0.33414813 -1.30138784\n",
      "  2.55348912  0.33414813 -1.30138784  0.33414813  0.33414813  2.55348912\n",
      " -1.30138784  0.33414813  0.33414813  0.33414813  0.33414813  0.33414813\n",
      "  0.33414813  0.33414813  2.55348912  0.33414813  0.33414813 -1.30138784\n",
      " -1.30138784  0.33414813  0.33414813 -1.30138784 -1.30138784  0.33414813\n",
      " -1.30138784  0.33414813  0.33414813  0.33414813 -1.30138784  0.91795314\n",
      "  0.33414813 -1.30138784]\n",
      "P is: [0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.21393153780757784, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.21393153780757784, 0.21393153780757784, 0.21393153780757784, 0.5827683381542493, 0.7146248601582132, 0.5827683381542493, 0.21393153780757784, 0.5827683381542493, 0.5827683381542493, 0.21393153780757784, 0.9278075672006812, 0.5827683381542493, 0.21393153780757784, 0.5827683381542493, 0.5827683381542493, 0.9278075672006812, 0.21393153780757784, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.9278075672006812, 0.5827683381542493, 0.5827683381542493, 0.21393153780757784, 0.21393153780757784, 0.5827683381542493, 0.5827683381542493, 0.21393153780757784, 0.21393153780757784, 0.5827683381542493, 0.21393153780757784, 0.5827683381542493, 0.5827683381542493, 0.5827683381542493, 0.21393153780757784, 0.7146248601582132, 0.5827683381542493, 0.21393153780757784]\n",
      "all_sum before preprocessing is: [4.091890569177696, 2.011338581105026, 2.899758289035615, 3.3060306013410807, 3.0985521370774065, 2.011338581105026, 1.8038601168413522, 2.6922798247719406, 3.8844121049140217, 1.8038601168413522, 3.8844121049140217, 2.6922798247719406, 1.8038601168413522, 1.8038601168413522, 1.8038601168413522, 2.011338581105026, 1.8038601168413522, 2.6922798247719406, 3.0985521370774065, 1.8038601168413522, 1.8038601168413522, 1.8038601168413522, 2.011338581105026, 1.8038601168413522, 3.0985521370774065, 1.8038601168413522, 1.8038601168413522, 1.8038601168413522, 1.8038601168413522, 3.8844121049140217, 1.8038601168413522, 1.8038601168413522, 1.8038601168413522, 1.8038601168413522, 2.011338581105026, 1.8038601168413522, 3.9869718450079947, 1.8038601168413522, 1.8038601168413522, 2.011338581105026, 1.8038601168413522, 1.8038601168413522, 3.8844121049140217, 3.8844121049140217, 1.8038601168413522, 1.8038601168413522, 4.77283181284461, 1.8038601168413522, 3.8844121049140217, 1.8038601168413522]\n",
      "all_sum after preprocessing is: [ 1.94137309 -0.46041566  0.56517585  1.03417652  0.79466342 -0.46041566\n",
      " -0.69992876  0.32566276  1.70186    -0.69992876  1.70186     0.32566276\n",
      " -0.69992876 -0.69992876 -0.69992876 -0.46041566 -0.69992876  0.32566276\n",
      "  0.79466342 -0.69992876 -0.69992876 -0.69992876 -0.46041566 -0.69992876\n",
      "  0.79466342 -0.69992876 -0.69992876 -0.69992876 -0.69992876  1.70186\n",
      " -0.69992876 -0.69992876 -0.69992876 -0.69992876 -0.46041566 -0.69992876\n",
      "  1.82025494 -0.69992876 -0.69992876 -0.46041566 -0.69992876 -0.69992876\n",
      "  1.70186     1.70186    -0.69992876 -0.69992876  2.72745151 -0.69992876\n",
      "  1.70186    -0.69992876]\n",
      "P is: [0.8745029143005588, 0.38688722141532883, 0.6376492842176579, 0.7377247992657356, 0.6888317800346943, 0.38688722141532883, 0.33182802344422524, 0.5807036860544281, 0.8457775051173984, 0.33182802344422524, 0.8457775051173984, 0.5807036860544281, 0.33182802344422524, 0.33182802344422524, 0.33182802344422524, 0.38688722141532883, 0.33182802344422524, 0.5807036860544281, 0.6888317800346943, 0.33182802344422524, 0.33182802344422524, 0.33182802344422524, 0.38688722141532883, 0.33182802344422524, 0.6888317800346943, 0.33182802344422524, 0.33182802344422524, 0.33182802344422524, 0.33182802344422524, 0.8457775051173984, 0.33182802344422524, 0.33182802344422524, 0.33182802344422524, 0.33182802344422524, 0.38688722141532883, 0.33182802344422524, 0.8605967147949275, 0.33182802344422524, 0.33182802344422524, 0.38688722141532883, 0.33182802344422524, 0.33182802344422524, 0.8457775051173984, 0.8457775051173984, 0.33182802344422524, 0.33182802344422524, 0.9386271924586748, 0.33182802344422524, 0.8457775051173984, 0.33182802344422524]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.267\n",
      "(*) epoch 2, cost 1.007\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.610\n",
      "(*) epoch 2, cost 2.150\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.057645742249898, 4.670690706889608, 4.670690706889608, 4.670690706889608, 4.057645742249898, 4.670690706889608, 4.057645742249898, 4.057645742249898, 4.207924643244581, 4.057645742249898, 4.057645742249898, 4.670690706889608, 2.733805383300627, 3.438180024853947, 2.733805383300627, 2.825535835615064, 4.670690706889608, 3.8904480550000713, 4.670690706889608, 4.670690706889608, 4.057645742249898, 4.057645742249898, 4.594822696553391, 3.2774030903603615, 3.3468503479403373, 4.670690706889608, 4.670690706889608, 3.8904480550000713, 4.670690706889608, 4.057645742249898, 4.057645742249898, 3.3468503479403373, 4.057645742249898, 4.670690706889608, 4.057645742249898, 4.802346082158343, 4.670690706889608, 3.2774030903603615, 4.670690706889608, 4.057645742249898, 3.8904480550000713, 4.057645742249898, 4.057645742249898, 3.438580800254774, 3.8904480550000713, 4.057645742249898, 3.8904480550000713, 4.057645742249898, 4.057645742249898, 3.3468503479403373]\n",
      "all_sum after preprocessing is: [-0.013519    1.11374629  1.11374629  1.11374629 -0.013519    1.11374629\n",
      " -0.013519   -0.013519    0.2628134  -0.013519   -0.013519    1.11374629\n",
      " -2.44779279 -1.15259076 -2.44779279 -2.2791191   1.11374629 -0.32096162\n",
      "  1.11374629  1.11374629 -0.013519   -0.013519    0.97424041 -1.44822691\n",
      " -1.3205275   1.11374629  1.11374629 -0.32096162  1.11374629 -0.013519\n",
      " -0.013519   -1.3205275  -0.013519    1.11374629 -0.013519    1.35583381\n",
      "  1.11374629 -1.44822691  1.11374629 -0.013519   -0.32096162 -0.013519\n",
      " -0.013519   -1.15185381 -0.32096162 -0.013519   -0.32096162 -0.013519\n",
      " -0.013519   -1.3205275 ]\n",
      "P is: [0.49662030112476985, 0.7528268760029663, 0.7528268760029663, 0.7528268760029663, 0.49662030112476985, 0.7528268760029663, 0.49662030112476985, 0.49662030112476985, 0.565327762456447, 0.49662030112476985, 0.49662030112476985, 0.7528268760029663, 0.07960010800192752, 0.24001618922548373, 0.07960010800192752, 0.092867135758694, 0.7528268760029663, 0.42044141135845203, 0.7528268760029663, 0.7528268760029663, 0.49662030112476985, 0.49662030112476985, 0.725963895114384, 0.19027459577235512, 0.21073054482374162, 0.7528268760029663, 0.7528268760029663, 0.42044141135845203, 0.7528268760029663, 0.49662030112476985, 0.49662030112476985, 0.21073054482374162, 0.49662030112476985, 0.7528268760029663, 0.49662030112476985, 0.7950817484594378, 0.7528268760029663, 0.19027459577235512, 0.7528268760029663, 0.49662030112476985, 0.42044141135845203, 0.49662030112476985, 0.49662030112476985, 0.2401506398849271, 0.42044141135845203, 0.49662030112476985, 0.42044141135845203, 0.49662030112476985, 0.49662030112476985, 0.21073054482374162]\n",
      "all_sum before preprocessing is: [2.7779701102028795, 2.3468171960719038, 2.432819510768896, 1.8310999342972805, 1.8310999342972805, 2.432819510768896, 2.176250533731264, 2.432819510768896, 2.432819510768896, 2.7779701102028795, 1.8310999342972805, 2.6452843998253406, 2.0435648233537256, 3.2936873719775024, 2.432819510768896, 2.176250533731264, 2.9485367725435188, 1.8310999342972805, 2.432819510768896, 2.432819510768896, 2.7779701102028795, 2.7779701102028795, 3.928460132552289, 2.432819510768896, 2.432819510768896, 2.0435648233537256, 1.8310999342972805, 1.8310999342972805, 2.0435648233537256, 2.7779701102028795, 2.432819510768896, 2.432819510768896, 2.432819510768896, 2.432819510768896, 2.432819510768896, 1.8310999342972805, 1.8310999342972805, 2.432819510768896, 1.8310999342972805, 2.432819510768896, 2.432819510768896, 2.7779701102028795, 1.8310999342972805, 2.432819510768896, 2.432819510768896, 1.8310999342972805, 2.432819510768896, 1.8310999342972805, 2.432819510768896, 1.8310999342972805]\n",
      "all_sum after preprocessing is: [ 1.0276126   0.00632683  0.21004328 -1.21526923 -1.21526923  0.21004328\n",
      " -0.39769991  0.21004328  0.21004328  1.0276126  -1.21526923  0.71331569\n",
      " -0.71199681  2.24920865  0.21004328 -0.39769991  1.43163933 -1.21526923\n",
      "  0.21004328  0.21004328  1.0276126   1.0276126   3.7528153   0.21004328\n",
      "  0.21004328 -0.71199681 -1.21526923 -1.21526923 -0.71199681  1.0276126\n",
      "  0.21004328  0.21004328  0.21004328  0.21004328  0.21004328 -1.21526923\n",
      " -1.21526923  0.21004328 -1.21526923  0.21004328  0.21004328  1.0276126\n",
      " -1.21526923  0.21004328  0.21004328 -1.21526923  0.21004328 -1.21526923\n",
      "  0.21004328 -1.21526923]\n",
      "P is: [0.7364527863139032, 0.5015817021114912, 0.5523186104032937, 0.22877005009739984, 0.22877005009739984, 0.5523186104032937, 0.40186508724927367, 0.5523186104032937, 0.5523186104032937, 0.7364527863139032, 0.22877005009739984, 0.6711333916674724, 0.32915776746241165, 0.9045822533511275, 0.5523186104032937, 0.40186508724927367, 0.807156614426239, 0.22877005009739984, 0.5523186104032937, 0.5523186104032937, 0.7364527863139032, 0.7364527863139032, 0.9770857470574292, 0.5523186104032937, 0.5523186104032937, 0.32915776746241165, 0.22877005009739984, 0.22877005009739984, 0.32915776746241165, 0.7364527863139032, 0.5523186104032937, 0.5523186104032937, 0.5523186104032937, 0.5523186104032937, 0.5523186104032937, 0.22877005009739984, 0.22877005009739984, 0.5523186104032937, 0.22877005009739984, 0.5523186104032937, 0.5523186104032937, 0.7364527863139032, 0.22877005009739984, 0.5523186104032937, 0.5523186104032937, 0.22877005009739984, 0.5523186104032937, 0.22877005009739984, 0.5523186104032937, 0.22877005009739984]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.688\n",
      "(*) epoch 2, cost 3.257\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.375\n",
      "(*) epoch 2, cost 3.217\n",
      "(*) epoch 3, cost 2.580\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.383638768464683, 6.569782525155624, 6.716766413245965, 7.499664393934001, 6.804838993721992, 4.878920263297598, 3.303207077899626, 4.878920263297598, 4.878920263297598, 6.716766413245965, 7.61473209867707, 3.3912796583756535, 7.499664393934001, 4.878920263297598, 5.906873308290887, 7.61473209867707, 5.326602812380497, 7.61473209867707, 3.980954577866492, 6.601698708502895, 4.878920263297598, 6.804838993721992, 3.980954577866492, 3.188139373156556, 7.499664393934001, 7.61473209867707, 6.804838993721992, 5.573745663509605, 4.878920263297598, 3.980954577866492, 6.804838993721992, 4.878920263297598, 5.688813368252676, 6.383638768464683, 4.201172763330732, 5.688813368252676, 4.201172763330732, 5.573745663509605, 6.804838993721992, 7.61473209867707, 5.906873308290887, 4.878920263297598, 6.804838993721992, 5.688813368252676, 5.688813368252676, 7.61473209867707, 4.878920263297598, 4.878920263297598, 3.3912796583756535, 5.906873308290887]\n",
      "all_sum after preprocessing is: [ 0.47778856  0.61925113  0.73095361  1.32592799  0.79788561 -0.66574351\n",
      " -1.86322899 -0.66574351 -0.66574351  0.73095361  1.41337531 -1.79629699\n",
      "  1.32592799 -0.66574351  0.11546392  1.41337531 -0.32552084  1.41337531\n",
      " -1.34816521  0.64350629 -0.66574351  0.79788561 -1.34816521 -1.95067632\n",
      "  1.32592799  1.41337531  0.79788561 -0.13770114 -0.66574351 -1.34816521\n",
      "  0.79788561 -0.66574351 -0.05025381  0.47778856 -1.18080729 -0.05025381\n",
      " -1.18080729 -0.13770114  0.79788561  1.41337531  0.11546392 -0.66574351\n",
      "  0.79788561 -0.05025381 -0.05025381  1.41337531 -0.66574351 -0.66574351\n",
      " -1.79629699  0.11546392]\n",
      "P is: [0.6172255390222849, 0.6500482113735199, 0.6750145017326967, 0.7901662783915385, 0.6895220120890282, 0.3394505935554022, 0.1343271301794508, 0.3394505935554022, 0.3394505935554022, 0.6750145017326967, 0.804297773429657, 0.14230242760174175, 0.7901662783915385, 0.3394505935554022, 0.5288339516167341, 0.804297773429657, 0.4193308692059954, 0.804297773429657, 0.2061704988857957, 0.6555456310087041, 0.3394505935554022, 0.6895220120890282, 0.2061704988857957, 0.1244796310434645, 0.7901662783915385, 0.804297773429657, 0.6895220120890282, 0.4656290082775987, 0.3394505935554022, 0.2061704988857957, 0.6895220120890282, 0.3394505935554022, 0.4874391897033892, 0.6172255390222849, 0.23490707365010907, 0.4874391897033892, 0.23490707365010907, 0.4656290082775987, 0.6895220120890282, 0.804297773429657, 0.5288339516167341, 0.3394505935554022, 0.6895220120890282, 0.4874391897033892, 0.4874391897033892, 0.804297773429657, 0.3394505935554022, 0.3394505935554022, 0.14230242760174175, 0.5288339516167341]\n",
      "all_sum before preprocessing is: [3.441891683447574, 2.62964489102526, 2.960180737610561, 3.133824841504381, 2.62964489102526, 3.133824841504381, 2.8032889949190802, 3.441891683447574, 3.8589460709628534, 2.298447656027316, 2.9947860403709634, 2.1825392479486494, 3.527748835964909, 2.8211419364771433, 1.659844967498822, 2.1825392479486494, 2.457616225717991, 3.69255981943782, 2.3561833518424695, 2.3561833518424695, 1.659844967498822, 2.8211419364771433, 2.3561833518424695, 4.134023048732195, 2.8211419364771433, 3.0616136114860826, 2.62964489102526, 4.470862697512374, 2.51307509453395, 2.8211419364771433, 2.321578049082067, 5.253058234373357, 2.8211419364771433, 3.441891683447574, 2.283972121824171, 2.1825392479486494, 2.62964489102526, 2.8211419364771433, 2.62964489102526, 4.6445068014061945, 3.5508792290196602, 4.023757054435764, 3.268247579553754, 2.62964489102526, 2.8211419364771433, 2.62964489102526, 2.62964489102526, 4.497548759491347, 2.8032889949190802, 3.441891683447574]\n",
      "all_sum after preprocessing is: [ 0.61878033 -0.47772501 -0.03151294  0.20290065 -0.47772501  0.20290065\n",
      " -0.24331142  0.61878033  1.18178946 -0.92482993  0.01520303 -1.08130231\n",
      "  0.73468454 -0.21921056 -1.78692168 -1.08130231 -0.70995781  0.95717373\n",
      " -0.84688872 -0.84688872 -1.78692168 -0.21921056 -0.84688872  1.55313396\n",
      " -0.21921056  0.10541796 -0.47772501  2.00785594 -0.63509024 -0.21921056\n",
      " -0.89360469  3.06379312 -0.21921056  0.61878033 -0.9443714  -1.08130231\n",
      " -0.47772501 -0.21921056 -0.47772501  2.24226954  0.76590978  1.40427865\n",
      "  0.38436674 -0.47772501 -0.21921056 -0.47772501 -0.47772501  2.04388121\n",
      " -0.24331142  0.61878033]\n",
      "P is: [0.6499411030387233, 0.38278947476397823, 0.4921224164738787, 0.5505518517723392, 0.38278947476397823, 0.5505518517723392, 0.43947046567643305, 0.6499411030387233, 0.7652694017159636, 0.28397478588593705, 0.5038006846355352, 0.2532596458798956, 0.6758324207367281, 0.44541576452124954, 0.14345054944536756, 0.2532596458798956, 0.32960816185959685, 0.7225555812727674, 0.30008592687803615, 0.30008592687803615, 0.14345054944536756, 0.44541576452124954, 0.30008592687803615, 0.825365912203989, 0.44541576452124954, 0.5263301114319456, 0.38278947476397823, 0.8816194374698058, 0.34635723878969493, 0.44541576452124954, 0.29036650619775906, 0.9553742934086911, 0.44541576452124954, 0.6499411030387233, 0.2800181855223221, 0.2532596458798956, 0.38278947476397823, 0.44541576452124954, 0.38278947476397823, 0.9039816320593173, 0.6826354342539054, 0.8028619672480758, 0.5949258742714403, 0.38278947476397823, 0.44541576452124954, 0.38278947476397823, 0.38278947476397823, 0.8853278878925416, 0.43947046567643305, 0.6499411030387233]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.692\n",
      "(*) epoch 2, cost 5.036\n",
      "(*) epoch 3, cost 4.031\n",
      "(*) epoch 4, cost 3.792\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.643\n",
      "(*) epoch 2, cost 3.002\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.29680989010651, 4.2871147765112765, 3.1065295626465543, 3.359614105441082, 3.2362332475262394, 2.595844304286501, 1.2530950269733907, 2.8815612838635944, 2.38436121355594, 2.8815612838635944, 2.5140648984356253, 1.9540606127933997, 1.9540606127933997, 1.9540606127933997, 2.576869113770197, 1.9540606127933997, 3.29680989010651, 2.5352676617062304, 3.359614105441082, 2.5140648984356253, 2.38436121355594, 3.727110490869051, 3.727110490869051, 3.29680989010651, 0.8855986415454218, 1.4456029271876474, 3.1558485899287265, 2.533040088951929, 2.0168648281279715, 2.0168648281279715, 4.224310561176704, 1.7502950972810445, 1.9540606127933997, 2.676228961884014, 2.8815612838635944, 3.359614105441082, 4.946478910267318, 3.727110490869051, 2.321556998221369, 3.29680989010651, 2.0168648281279715, 2.576869113770197, 2.321556998221369, 3.727110490869051, 2.321556998221369, 3.6643062755344786, 1.9540606127933997, 3.29680989010651, 1.607766990636036, 4.224310561176704]\n",
      "all_sum after preprocessing is: [ 0.63753431  1.81077506  0.41210411  0.71194015  0.56576754 -0.1929184\n",
      " -1.78370946  0.14557816 -0.44346809  0.14557816 -0.28980466 -0.95325675\n",
      " -0.95325675 -0.95325675 -0.21539882 -0.95325675  0.63753431 -0.26468518\n",
      "  0.71194015 -0.28980466 -0.44346809  1.14732297  1.14732297  0.63753431\n",
      " -2.21909228 -1.5556402   0.47053368 -0.26732424 -0.87885091 -0.87885091\n",
      "  1.73636922 -1.19466321 -0.95325675 -0.09768455  0.14557816  0.71194015\n",
      "  2.59194142  1.14732297 -0.51787393  0.63753431 -0.87885091 -0.21539882\n",
      " -0.51787393  1.14732297 -0.51787393  1.07291713 -0.95325675  0.63753431\n",
      " -1.36352008  1.73636922]\n",
      "P is: [0.654195876233988, 0.8594555206833406, 0.6015922972238318, 0.6708297203019029, 0.6377859848564963, 0.45191942630282883, 0.14384569449201212, 0.5363303999082236, 0.3909149035685925, 0.5363303999082236, 0.42805169045587377, 0.2782303358612355, 0.2782303358612355, 0.2782303358612355, 0.44635753693321, 0.2782303358612355, 0.654195876233988, 0.4342123386867036, 0.6708297203019029, 0.42805169045587377, 0.3909149035685925, 0.7590216065624463, 0.7590216065624463, 0.654195876233988, 0.09804904941338873, 0.17427314105250488, 0.6155100640979584, 0.4335641072374366, 0.2934159553581502, 0.2934159553581502, 0.8502253013126702, 0.232425961234234, 0.2782303358612355, 0.47559826430581686, 0.5363303999082236, 0.6708297203019029, 0.9303411388317658, 0.7590216065624463, 0.3733495146012693, 0.654195876233988, 0.2934159553581502, 0.44635753693321, 0.3733495146012693, 0.7590216065624463, 0.3733495146012693, 0.7451512775695692, 0.2782303358612355, 0.654195876233988, 0.2036687922412281, 0.8502253013126702]\n",
      "all_sum before preprocessing is: [2.094017671130958, 3.1791622294312214, 1.78632526265938, 3.1791622294312214, 2.6953361277931958, 1.1833419506151277, 3.1791622294312214, 1.1833419506151277, 3.1791622294312214, 1.7846604072773657, 3.1791622294312214, 1.78632526265938, 2.387643719321618, 3.1791622294312214, 2.387643719321618, 2.387643719321618, 2.6953361277931958, 2.387643719321618, 3.780480686093459, 3.1791622294312214, 1.7846604072773657, 2.387643719321618, 1.7846604072773657, 2.387643719321618, 1.78632526265938, 2.6953361277931958, 3.1791622294312214, 2.387643719321618, 3.780480686093459, 2.387643719321618, 1.1833419506151277, 1.7846604072773657, 1.78632526265938, 1.78632526265938, 4.088173094565037, 3.2993555955817437, 2.387643719321618, 1.7846604072773657, 1.78632526265938, 1.78632526265938, 1.78632526265938, 2.387643719321618, 3.1433361126948176, 2.387643719321618, 3.1791622294312214, 3.780480686093459, 1.1833419506151277, 3.486854637902799, 1.7846604072773657, 2.5761789173869696]\n",
      "all_sum after preprocessing is: [-0.48152145  0.96807531 -0.89255416  0.96807531  0.32175336 -1.69805298\n",
      "  0.96807531 -1.69805298  0.96807531 -0.89477817  0.96807531 -0.89255416\n",
      " -0.08927936  0.96807531 -0.08927936 -0.08927936  0.32175336 -0.08927936\n",
      "  1.77135011  0.96807531 -0.89477817 -0.08927936 -0.89477817 -0.08927936\n",
      " -0.89255416  0.32175336  0.96807531 -0.08927936  1.77135011 -0.08927936\n",
      " -1.69805298 -0.89477817 -0.89255416 -0.89255416  2.18238283  1.12863632\n",
      " -0.08927936 -0.89477817 -0.89255416 -0.89255416 -0.89255416 -0.08927936\n",
      "  0.92021678 -0.08927936  0.96807531  1.77135011 -1.69805298  1.37910803\n",
      " -0.89477817  0.1625765 ]\n",
      "P is: [0.38189292223358784, 0.7247356996167488, 0.2905830190384571, 0.7247356996167488, 0.5797514994296831, 0.15471972881644605, 0.7247356996167488, 0.15471972881644605, 0.7247356996167488, 0.29012476580872654, 0.7247356996167488, 0.2905830190384571, 0.47769497395964894, 0.7247356996167488, 0.47769497395964894, 0.47769497395964894, 0.5797514994296831, 0.47769497395964894, 0.8546254903641001, 0.7247356996167488, 0.29012476580872654, 0.47769497395964894, 0.29012476580872654, 0.47769497395964894, 0.2905830190384571, 0.5797514994296831, 0.7247356996167488, 0.47769497395964894, 0.8546254903641001, 0.47769497395964894, 0.15471972881644605, 0.29012476580872654, 0.2905830190384571, 0.2905830190384571, 0.8986562901773437, 0.7555871497875212, 0.47769497395964894, 0.29012476580872654, 0.2905830190384571, 0.2905830190384571, 0.2905830190384571, 0.47769497395964894, 0.7150862737587511, 0.47769497395964894, 0.7247356996167488, 0.8546254903641001, 0.15471972881644605, 0.7988477069732572, 0.29012476580872654, 0.5405548375924829]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.113\n",
      "(*) epoch 2, cost 2.870\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.117\n",
      "(*) epoch 2, cost 2.471\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [3.4627630617735523, 5.382863560557716, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 2.257349491064307, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 5.382863560557716, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 2.492673398844918, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 2.492673398844918, 3.4627630617735523, 3.4627630617735523, 5.382863560557716, 5.382863560557716, 2.492673398844918, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 5.382863560557716, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 2.492673398844918, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 3.4627630617735523, 5.382863560557716, 3.4627630617735523, 3.4627630617735523, 5.382863560557716, 2.492673398844918, 3.4627630617735523]\n",
      "all_sum after preprocessing is: [-0.18795395  2.25550049 -0.18795395 -0.18795395 -0.18795395 -0.18795395\n",
      " -1.72192217 -0.18795395 -0.18795395 -0.18795395 -0.18795395 -0.18795395\n",
      "  2.25550049 -0.18795395 -0.18795395 -0.18795395 -0.18795395 -0.18795395\n",
      " -1.42245699 -0.18795395 -0.18795395 -0.18795395 -0.18795395 -0.18795395\n",
      " -1.42245699 -0.18795395 -0.18795395  2.25550049  2.25550049 -1.42245699\n",
      " -0.18795395 -0.18795395 -0.18795395 -0.18795395  2.25550049 -0.18795395\n",
      " -0.18795395 -0.18795395 -0.18795395 -1.42245699 -0.18795395 -0.18795395\n",
      " -0.18795395 -0.18795395  2.25550049 -0.18795395 -0.18795395  2.25550049\n",
      " -1.42245699 -0.18795395]\n",
      "P is: [0.45314935361645026, 0.905123940884845, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.15162374135721207, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.905123940884845, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.194276694121195, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.194276694121195, 0.45314935361645026, 0.45314935361645026, 0.905123940884845, 0.905123940884845, 0.194276694121195, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.905123940884845, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.194276694121195, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.45314935361645026, 0.905123940884845, 0.45314935361645026, 0.45314935361645026, 0.905123940884845, 0.194276694121195, 0.45314935361645026]\n",
      "all_sum before preprocessing is: [2.5009695975091346, 2.2203522302465015, 2.0890890492702026, 2.0890890492702026, 2.388093277273975, 2.519356458250274, 2.0890890492702026, 2.0890890492702026, 0.5011964961892972, 2.2952886708542706, 0.5011964961892972, 2.0890890492702026, 2.2203522302465015, 2.519356458250274, 2.0890890492702026, 2.0890890492702026, 2.2203522302465015, 2.4265518518305695, 2.0890890492702026, 0.20219226818552496, 0.20219226818552496, 2.519356458250274, 2.0890890492702026, 0.5396550707458919, 2.388093277273975, 0.20219226818552496, 2.519356458250274, 2.388093277273975, 2.2203522302465015, 2.0890890492702026, 2.0890890492702026, 2.0890890492702026, 2.5009695975091346, 0.20219226818552496, 2.519356458250274, 2.388093277273975, 2.594292898858043, 2.388093277273975, 2.388093277273975, 2.0890890492702026, 2.0890890492702026, 2.0890890492702026, 2.0890890492702026, 0.20219226818552496, 2.0890890492702026, 2.388093277273975, 2.2203522302465015, 2.2203522302465015, 2.388093277273975, 2.388093277273975]\n",
      "all_sum after preprocessing is: [ 0.74245699  0.36018627  0.18137314  0.18137314  0.58869134  0.76750448\n",
      "  0.18137314  0.18137314 -1.98173187  0.46226836 -1.98173187  0.18137314\n",
      "  0.36018627  0.76750448  0.18137314  0.18137314  0.36018627  0.6410815\n",
      "  0.18137314 -2.38905008 -2.38905008  0.76750448  0.18137314 -1.92934172\n",
      "  0.58869134 -2.38905008  0.76750448  0.58869134  0.36018627  0.18137314\n",
      "  0.18137314  0.18137314  0.74245699 -2.38905008  0.76750448  0.58869134\n",
      "  0.86958657  0.58869134  0.58869134  0.18137314  0.18137314  0.18137314\n",
      "  0.18137314 -2.38905008  0.18137314  0.58869134  0.36018627  0.36018627\n",
      "  0.58869134  0.58869134]\n",
      "P is: [0.6775328994521121, 0.5890855245391601, 0.5452193901141215, 0.5452193901141215, 0.6430648225542505, 0.6829808148699877, 0.5452193901141215, 0.5452193901141215, 0.12113434028343477, 0.6135521564877409, 0.12113434028343477, 0.5452193901141215, 0.5890855245391601, 0.6829808148699877, 0.5452193901141215, 0.5452193901141215, 0.5890855245391601, 0.6549978933862233, 0.5452193901141215, 0.0840115029449377, 0.0840115029449377, 0.6829808148699877, 0.5452193901141215, 0.1268234597781671, 0.6430648225542505, 0.0840115029449377, 0.6829808148699877, 0.6430648225542505, 0.5890855245391601, 0.5452193901141215, 0.5452193901141215, 0.5452193901141215, 0.6775328994521121, 0.0840115029449377, 0.6829808148699877, 0.6430648225542505, 0.7046596638029466, 0.6430648225542505, 0.6430648225542505, 0.5452193901141215, 0.5452193901141215, 0.5452193901141215, 0.5452193901141215, 0.0840115029449377, 0.5452193901141215, 0.6430648225542505, 0.5890855245391601, 0.5890855245391601, 0.6430648225542505, 0.6430648225542505]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.581\n",
      "(*) epoch 2, cost 1.827\n",
      "(*) epoch 3, cost 1.168\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.418\n",
      "(*) epoch 2, cost 2.203\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.3634232162602236, 1.1791029799097537, 1.0934801154848093, 2.5811577979954903, 1.0111466054791218, 0.9777139899108918, 1.0111466054791218, 1.0111466054791218, 1.115849223720824, 1.0934801154848093, 1.2280038743472113, 2.443022564185558, 0.4948954909964977, 1.149281839289054, 1.3172382137196859, 2.228899457397822, 0.9777139899108918, 1.0934801154848093, 1.0111466054791218, 2.36068905417987, 2.61097893861619, 0.7648203215884787, 2.4988242879898026, 1.0111466054791218, 1.0934801154848093, 2.206849185072056, 1.0111466054791218, 2.443022564185558, 1.2280038743472113, 1.0111466054791218, 1.0111466054791218, 1.0934801154848093, 2.3272564386116406, 0.9777139899108918, 1.0934801154848093, 0.4810978215839292, 1.1791029799097537, 2.3272564386116406, 1.1791029799097537, 1.0111466054791218, 2.5286454286105022, 1.0111466054791218, 1.1456703643415236, 1.0934801154848093, 1.0600474999165792, 1.1456703643415236, 2.57754632304796, 2.0907642235878896, 0.9777139899108918, 1.2316153492947417]\n",
      "all_sum after preprocessing is: [ 1.49233109 -0.3876139  -0.52352839  1.83795471 -0.65422148 -0.70729115\n",
      " -0.65422148 -0.65422148 -0.48802052 -0.52352839 -0.30999048  1.61868408\n",
      " -1.47369891 -0.43495085 -0.16834328  1.27879318 -0.70729115 -0.52352839\n",
      " -0.65422148  1.48799099  1.88529165 -1.04523047  1.70726162 -0.65422148\n",
      " -0.52352839  1.24379142 -0.65422148  1.61868408 -0.30999048 -0.65422148\n",
      " -0.65422148 -0.52352839  1.43492132 -0.70729115 -0.52352839 -1.4956008\n",
      " -0.3876139   1.43492132 -0.3876139  -0.65422148  1.75459856 -0.65422148\n",
      " -0.44068357 -0.52352839 -0.57659806 -0.44068357  1.83222199  1.05952256\n",
      " -0.70729115 -0.30425776]\n",
      "P is: [0.8164278993177428, 0.40429183625611514, 0.3720275488064918, 0.8627066345636696, 0.3420388680297125, 0.33019767416850965, 0.3420388680297125, 0.3420388680297125, 0.38035999400757076, 0.3720275488064918, 0.4231170624072354, 0.8346135681943002, 0.1863810491466186, 0.3929447356423947, 0.4580132907125605, 0.782244279723708, 0.33019767416850965, 0.3720275488064918, 0.3420388680297125, 0.8157765395634293, 0.8682177552058514, 0.26014203178351325, 0.8464807659823378, 0.3420388680297125, 0.3720275488064918, 0.7762232760708184, 0.3420388680297125, 0.8346135681943002, 0.4231170624072354, 0.3420388680297125, 0.3420388680297125, 0.3720275488064918, 0.8076669571111397, 0.33019767416850965, 0.3720275488064918, 0.1830825650881115, 0.40429183625611514, 0.8076669571111397, 0.40429183625611514, 0.3420388680297125, 0.8525318770683457, 0.3420388680297125, 0.3915781002511338, 0.3720275488064918, 0.35971575608403616, 0.3915781002511338, 0.8620262161417278, 0.7425992946738189, 0.33019767416850965, 0.42451696913153847]\n",
      "all_sum before preprocessing is: [3.17109991550948, 3.17109991550948, 3.17109991550948, 3.17109991550948, 3.17109991550948, 3.17109991550948, 2.8048218573547694, 3.17109991550948, 3.17109991550948, 2.8048218573547694, 3.17109991550948, 2.8048218573547694, 3.17109991550948, 3.17109991550948, 3.17109991550948, 2.8048218573547694, 3.583594398626864, 3.7435506032307133, 4.690640635025696, 3.17109991550948, 3.17109991550948, 3.17109991550948, 3.17109991550948, 3.17109991550948, 3.3310561201133284, 4.690640635025696, 2.8048218573547694, 3.17109991550948, 3.17109991550948, 3.17109991550948, 2.8048218573547694, 3.17109991550948, 3.17109991550948, 3.697334178268039, 3.17109991550948, 3.17109991550948, 3.697334178268039, 2.8048218573547694, 3.17109991550948, 2.8048218573547694, 3.697334178268039, 4.850596839629545, 3.17109991550948, 3.17109991550948, 3.17109991550948, 3.17109991550948, 2.8048218573547694, 4.3243625768709855, 3.217316340472154, 3.17109991550948]\n",
      "all_sum after preprocessing is: [-0.23043444 -0.23043444 -0.23043444 -0.23043444 -0.23043444 -0.23043444\n",
      " -1.01996266 -0.23043444 -0.23043444 -1.01996266 -0.23043444 -1.01996266\n",
      " -0.23043444 -0.23043444 -0.23043444 -1.01996266  0.65871529  1.00350782\n",
      "  3.04500142 -0.23043444 -0.23043444 -0.23043444 -0.23043444 -0.23043444\n",
      "  0.11435809  3.04500142 -1.01996266 -0.23043444 -0.23043444 -0.23043444\n",
      " -1.01996266 -0.23043444 -0.23043444  0.90388631 -0.23043444 -0.23043444\n",
      "  0.90388631 -1.01996266 -0.23043444 -1.01996266  0.90388631  3.38979395\n",
      " -0.23043444 -0.23043444 -0.23043444 -0.23043444 -1.01996266  2.25547319\n",
      " -0.13081293 -0.23043444]\n",
      "P is: [0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.2650346732399991, 0.44264496185342955, 0.44264496185342955, 0.2650346732399991, 0.44264496185342955, 0.2650346732399991, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.2650346732399991, 0.6589717371642434, 0.7317476985274981, 0.9545662321602201, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.5285584057302152, 0.9545662321602201, 0.2650346732399991, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.2650346732399991, 0.44264496185342955, 0.44264496185342955, 0.7117474859308027, 0.44264496185342955, 0.44264496185342955, 0.7117474859308027, 0.2650346732399991, 0.44264496185342955, 0.2650346732399991, 0.7117474859308027, 0.9673840438662294, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.44264496185342955, 0.2650346732399991, 0.9051215970113996, 0.46734332179369686, 0.44264496185342955]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.436\n",
      "(*) epoch 2, cost 4.647\n",
      "(*) epoch 3, cost 4.106\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.995\n",
      "(*) epoch 2, cost 1.729\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.8426967564593703, 0.8426967564593703, 0.8426967564593703, 0.8426967564593703, 4.316427580180559, 0.8426967564593703, 0.8426967564593703, 0.09993608471965851, 2.0664945144536935, 2.0664945144536935, 0.8426967564593703, 0.8426967564593703, 2.0664945144536935, 0.8426967564593703, 1.0700338161062102, 2.0664945144536935, 0.8426967564593703, 1.218967533780686, 2.0664945144536935, 0.8426967564593703, 1.218967533780686, 2.7163590448649204, 1.0700338161062102, 0.8426967564593703, 0.8426967564593703, 0.8426967564593703, 0.8426967564593703, 0.8426967564593703, 2.0664945144536935, 2.0664945144536935, 0.8426967564593703, 0.8426967564593703, 2.0664945144536935, 0.09993608471965851, 0.8426967564593703, 2.0664945144536935, 0.8426967564593703, 0.8426967564593703, 2.5473824233713263, 0.8426967564593703, 2.7163590448649204, 0.8426967564593703, 1.7000046200352976, 0.8426967564593703, 2.7163590448649204, 0.8426967564593703, 2.0664945144536935, 0.8426967564593703, 0.8426967564593703, 0.8426967564593703]\n",
      "all_sum after preprocessing is: [-0.59458997 -0.59458997 -0.59458997 -0.59458997  3.77831824 -0.59458997\n",
      " -0.59458997 -1.52961471  0.9459886   0.9459886  -0.59458997 -0.59458997\n",
      "  0.9459886  -0.59458997 -0.30840657  0.9459886  -0.59458997 -0.12092127\n",
      "  0.9459886  -0.59458997 -0.12092127  1.76407097 -0.30840657 -0.59458997\n",
      " -0.59458997 -0.59458997 -0.59458997 -0.59458997  0.9459886   0.9459886\n",
      " -0.59458997 -0.59458997  0.9459886  -1.52961471 -0.59458997  0.9459886\n",
      " -0.59458997 -0.59458997  1.55135464 -0.59458997  1.76407097 -0.59458997\n",
      "  0.48463257 -0.59458997  1.76407097 -0.59458997  0.9459886  -0.59458997\n",
      " -0.59458997 -0.59458997]\n",
      "P is: [0.35558239604573033, 0.35558239604573033, 0.35558239604573033, 0.35558239604573033, 0.9776498432075499, 0.35558239604573033, 0.35558239604573033, 0.17805006598185366, 0.7203077373628819, 0.7203077373628819, 0.35558239604573033, 0.35558239604573033, 0.7203077373628819, 0.35558239604573033, 0.42350372392339747, 0.7203077373628819, 0.35558239604573033, 0.46980646430117196, 0.7203077373628819, 0.35558239604573033, 0.46980646430117196, 0.8537187870571915, 0.42350372392339747, 0.35558239604573033, 0.35558239604573033, 0.35558239604573033, 0.35558239604573033, 0.35558239604573033, 0.7203077373628819, 0.7203077373628819, 0.35558239604573033, 0.35558239604573033, 0.7203077373628819, 0.17805006598185366, 0.35558239604573033, 0.7203077373628819, 0.35558239604573033, 0.35558239604573033, 0.8251092978544164, 0.35558239604573033, 0.8537187870571915, 0.35558239604573033, 0.6188411893060184, 0.35558239604573033, 0.8537187870571915, 0.35558239604573033, 0.7203077373628819, 0.35558239604573033, 0.35558239604573033, 0.35558239604573033]\n",
      "all_sum before preprocessing is: [0.40322335542554494, 1.5076677780290932, 0.7124616623688926, 0.7124616623688926, 1.5076677780290932, 1.9487935823598665, 0.7124616623688926, 0.7124616623688926, 0.40322335542554494, 1.5076677780290932, 0.40322335542554494, 1.816906084972441, 1.9487935823598665, 1.9487935823598665, 1.9487935823598665, 1.9487935823598665, 1.5076677780290932, 1.5076677780290932, 1.153587466699666, 1.9487935823598665, 1.5076677780290932, 1.5076677780290932, 1.5076677780290932, 1.5076677780290932, 2.2580318893032145, 0.40322335542554494, 1.5076677780290932, 0.6849616778392936, 0.6849616778392936, 0.8443491597563182, 0.40322335542554494, 1.816906084972441, 1.5076677780290932, 0.40322335542554494, 0.40322335542554494, 0.8443491597563182, 2.2580318893032145, 1.816906084972441, 0.7124616623688926, 1.5076677780290932, 1.9487935823598665, 2.2580318893032145, 0.40322335542554494, 0.7124616623688926, 1.5076677780290932, 1.153587466699666, 0.40322335542554494, 0.7124616623688926, 1.816906084972441, 0.8443491597563182]\n",
      "all_sum after preprocessing is: [-1.38908676  0.43956143 -0.87707542 -0.87707542  0.43956143  1.16994124\n",
      " -0.87707542 -0.87707542 -1.38908676  0.43956143 -1.38908676  0.95157277\n",
      "  1.16994124  1.16994124  1.16994124  1.16994124  0.43956143  0.43956143\n",
      " -0.14669561  1.16994124  0.43956143  0.43956143  0.43956143  0.43956143\n",
      "  1.68195258 -1.38908676  0.43956143 -0.92260763 -0.92260763 -0.65870695\n",
      " -1.38908676  0.95157277  0.43956143 -1.38908676 -1.38908676 -0.65870695\n",
      "  1.68195258  0.95157277 -0.87707542  0.43956143  1.16994124  1.68195258\n",
      " -1.38908676 -0.87707542  0.43956143 -0.14669561 -1.38908676 -0.87707542\n",
      "  0.95157277 -0.65870695]\n",
      "P is: [0.199553590205579, 0.6081545237639091, 0.2937841902738216, 0.2937841902738216, 0.6081545237639091, 0.7631343943402942, 0.2937841902738216, 0.2937841902738216, 0.199553590205579, 0.6081545237639091, 0.199553590205579, 0.7214313655685293, 0.7631343943402942, 0.7631343943402942, 0.7631343943402942, 0.7631343943402942, 0.6081545237639091, 0.6081545237639091, 0.4633917232466688, 0.7631343943402942, 0.6081545237639091, 0.6081545237639091, 0.6081545237639091, 0.6081545237639091, 0.8431629120531613, 0.199553590205579, 0.6081545237639091, 0.2844268696512981, 0.2844268696512981, 0.34103013625984263, 0.199553590205579, 0.7214313655685293, 0.6081545237639091, 0.199553590205579, 0.199553590205579, 0.34103013625984263, 0.8431629120531613, 0.7214313655685293, 0.2937841902738216, 0.6081545237639091, 0.7631343943402942, 0.8431629120531613, 0.199553590205579, 0.2937841902738216, 0.6081545237639091, 0.4633917232466688, 0.199553590205579, 0.2937841902738216, 0.7214313655685293, 0.34103013625984263]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.903\n",
      "(*) epoch 2, cost 2.010\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.404\n",
      "(*) epoch 2, cost 1.812\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8321009543924656, 2.7327718819929565, 2.7327718819929565, 1.8321009543924656, 3.4012930657502283, 1.8321009543924656, 1.8321009543924656, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.5006221381497378, 2.7327718819929565, 1.0348664164007897, 2.7327718819929565, 1.8321009543924656, 3.4012930657502283, 1.8321009543924656, 2.7327718819929565, 2.7327718819929565, 1.8321009543924656, 2.6040585277585526, 1.9355373440012809, 2.7327718819929565, 1.8321009543924656, 1.8321009543924656, 2.7327718819929565, 1.8321009543924656, 1.8321009543924656, 3.4012930657502283, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 2.7327718819929565, 1.8321009543924656, 3.4012930657502283, 2.5006221381497378, 1.8321009543924656, 1.8321009543924656, 1.8321009543924656, 1.8321009543924656, 1.8321009543924656]\n",
      "all_sum after preprocessing is: [-1.09701029  0.58860939  0.58860939 -1.09701029  1.83975721 -1.09701029\n",
      " -1.09701029  0.58860939  0.58860939  0.58860939  0.58860939  0.58860939\n",
      "  0.58860939  0.15413753  0.58860939 -2.58904715  0.58860939 -1.09701029\n",
      "  1.83975721 -1.09701029  0.58860939  0.58860939 -1.09701029  0.34772034\n",
      " -0.90342747  0.58860939 -1.09701029 -1.09701029  0.58860939 -1.09701029\n",
      " -1.09701029  1.83975721  0.58860939  0.58860939  0.58860939  0.58860939\n",
      "  0.58860939  0.58860939  0.58860939  0.58860939  0.58860939  0.58860939\n",
      " -1.09701029  1.83975721  0.15413753 -1.09701029 -1.09701029 -1.09701029\n",
      " -1.09701029 -1.09701029]\n",
      "P is: [0.2503004949687669, 0.6430460115372989, 0.6430460115372989, 0.2503004949687669, 0.8629199900156123, 0.2503004949687669, 0.2503004949687669, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.5384582693316547, 0.6430460115372989, 0.06984666204983142, 0.6430460115372989, 0.2503004949687669, 0.8629199900156123, 0.2503004949687669, 0.6430460115372989, 0.6430460115372989, 0.2503004949687669, 0.5860646585901007, 0.2883466598093931, 0.6430460115372989, 0.2503004949687669, 0.2503004949687669, 0.6430460115372989, 0.2503004949687669, 0.2503004949687669, 0.8629199900156123, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.6430460115372989, 0.2503004949687669, 0.8629199900156123, 0.5384582693316547, 0.2503004949687669, 0.2503004949687669, 0.2503004949687669, 0.2503004949687669, 0.2503004949687669]\n",
      "all_sum before preprocessing is: [3.069626131401009, 0.933216207090657, 0.8772211500033568, 3.0136310743137087, 0.980425878258018, 3.0136310743137087, 0.8772211500033568, 0.8772211500033568, 0.8772211500033568, 3.0136310743137087, 0.980425878258018, 0.8300114788359958, 2.966421403146348, 3.0136310743137087, 0.8772211500033568, 0.8300114788359958, 3.0136310743137087, 0.8772211500033568, 2.1879475408713107, 2.966421403146348, 0.8300114788359958, 0.8300114788359958, 3.069626131401009, 0.980425878258018, 2.966421403146348, 2.338361940293333, 3.069626131401009, 0.8300114788359958, 0.8772211500033568, 3.11683580256837, 0.933216207090657, 0.980425878258018, 0.8300114788359958, 0.980425878258018, 3.0136310743137087, 0.8772211500033568, 0.980425878258018, 0.933216207090657, 2.966421403146348, 0.8772211500033568, 0.980425878258018, 3.0136310743137087, 3.0136310743137087, 0.8300114788359958, 0.8300114788359958, 0.8772211500033568, 0.980425878258018, 0.933216207090657, 0.980425878258018, 0.8772211500033568]\n",
      "all_sum after preprocessing is: [ 1.45381925 -0.70885047 -0.7655338   1.39713592 -0.66106052  1.39713592\n",
      " -0.7655338  -0.7655338  -0.7655338   1.39713592 -0.66106052 -0.81332375\n",
      "  1.34934597  1.39713592 -0.7655338  -0.81332375  1.39713592 -0.7655338\n",
      "  0.56130346  1.34934597 -0.81332375 -0.81332375  1.45381925 -0.66106052\n",
      "  1.34934597  0.71356668  1.45381925 -0.81332375 -0.7655338   1.5016092\n",
      " -0.70885047 -0.66106052 -0.81332375 -0.66106052  1.39713592 -0.7655338\n",
      " -0.66106052 -0.70885047  1.34934597 -0.7655338  -0.66106052  1.39713592\n",
      "  1.39713592 -0.81332375 -0.81332375 -0.7655338  -0.66106052 -0.70885047\n",
      " -0.66106052 -0.7655338 ]\n",
      "P is: [0.8105855237491749, 0.3298528933399754, 0.31744602671037236, 0.801729009273795, 0.34050142028015223, 0.801729009273795, 0.31744602671037236, 0.31744602671037236, 0.31744602671037236, 0.801729009273795, 0.34050142028015223, 0.30718267781788144, 0.7940226818588271, 0.801729009273795, 0.31744602671037236, 0.30718267781788144, 0.801729009273795, 0.31744602671037236, 0.6367540812601071, 0.7940226818588271, 0.30718267781788144, 0.30718267781788144, 0.8105855237491749, 0.34050142028015223, 0.7940226818588271, 0.6711887866750544, 0.8105855237491749, 0.30718267781788144, 0.31744602671037236, 0.8178143595253681, 0.3298528933399754, 0.34050142028015223, 0.30718267781788144, 0.34050142028015223, 0.801729009273795, 0.31744602671037236, 0.34050142028015223, 0.3298528933399754, 0.7940226818588271, 0.31744602671037236, 0.34050142028015223, 0.801729009273795, 0.801729009273795, 0.30718267781788144, 0.30718267781788144, 0.31744602671037236, 0.34050142028015223, 0.3298528933399754, 0.34050142028015223, 0.31744602671037236]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.588\n",
      "(*) epoch 2, cost 2.209\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.960\n",
      "(*) epoch 2, cost 2.256\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 1.0646249763043074, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 1.4902142499645408, 2.1763331241088464, 2.1763331241088464, 1.4902142499645408, 2.1763331241088464, 2.3870169306814435, 0.3785061021600018, 1.4902142499645408, 1.4902142499645408, 1.4902142499645408, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464, 2.1763331241088464]\n",
      "all_sum after preprocessing is: [ 0.35054438  0.35054438  0.35054438  0.35054438  0.35054438  0.35054438\n",
      "  0.35054438  0.35054438  0.35054438  0.35054438 -2.82839758  0.35054438\n",
      "  0.35054438  0.35054438  0.35054438  0.35054438  0.35054438  0.35054438\n",
      "  0.35054438  0.35054438  0.35054438  0.35054438  0.35054438  0.35054438\n",
      "  0.35054438  0.35054438  0.35054438  0.35054438 -1.61142026  0.35054438\n",
      "  0.35054438 -1.61142026  0.35054438  0.9529971  -4.79036222 -1.61142026\n",
      " -1.61142026 -1.61142026  0.35054438  0.35054438  0.35054438  0.35054438\n",
      "  0.35054438  0.35054438  0.35054438  0.35054438  0.35054438  0.35054438\n",
      "  0.35054438  0.35054438]\n",
      "P is: [0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.05580877620862509, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.16639152254406536, 0.5867495836309682, 0.5867495836309682, 0.16639152254406536, 0.5867495836309682, 0.7217175186798895, 0.00824096911652482, 0.16639152254406536, 0.16639152254406536, 0.16639152254406536, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682, 0.5867495836309682]\n",
      "all_sum before preprocessing is: [5.077817521595289, 3.3500547575288704, 3.3500547575288704, 3.3500547575288704, 3.3500547575288704, 3.3500547575288704, 5.845914115985563, 3.3500547575288704, 6.907786127483448, 5.845914115985563, 3.3500547575288704, 3.3500547575288704, 3.3500547575288704, 5.845914115985563, 3.3500547575288704, 3.3500547575288704, 5.131906798309067, 4.411926769026756, 5.077817521595289, 4.411926769026756, 3.3500547575288704, 3.3500547575288704, 5.845914115985563, 3.3500547575288704, 4.411926769026756, 3.3500547575288704, 3.3500547575288704, 4.411926769026756, 3.3500547575288704, 4.411926769026756, 4.411926769026756, 5.845914115985563, 5.845914115985563, 4.55014748518731, 5.845914115985563, 5.077817521595289, 5.845914115985563, 4.843922902294922, 3.3500547575288704, 4.411926769026756, 5.845914115985563, 3.3500547575288704, 5.077817521595289, 6.907786127483448, 3.3500547575288704, 5.845914115985563, 6.907786127483448, 4.411926769026756, 3.3500547575288704, 5.845914115985563]\n",
      "all_sum after preprocessing is: [ 0.49030514 -1.0022446  -1.0022446  -1.0022446  -1.0022446  -1.0022446\n",
      "  1.15383511 -1.0022446   2.07114669  1.15383511 -1.0022446  -1.0022446\n",
      " -1.0022446   1.15383511 -1.0022446  -1.0022446   0.53703085 -0.08493302\n",
      "  0.49030514 -0.08493302 -1.0022446  -1.0022446   1.15383511 -1.0022446\n",
      " -0.08493302 -1.0022446  -1.0022446  -0.08493302 -1.0022446  -0.08493302\n",
      " -0.08493302  1.15383511  1.15383511  0.0344707   1.15383511  0.49030514\n",
      "  1.15383511  0.28825231 -1.0022446  -0.08493302  1.15383511 -1.0022446\n",
      "  0.49030514  2.07114669 -1.0022446   1.15383511  2.07114669 -0.08493302\n",
      " -1.0022446   1.15383511]\n",
      "P is: [0.6201783130843151, 0.26850033559774583, 0.26850033559774583, 0.26850033559774583, 0.26850033559774583, 0.26850033559774583, 0.7602107178623274, 0.26850033559774583, 0.8880669977461197, 0.7602107178623274, 0.26850033559774583, 0.26850033559774583, 0.26850033559774583, 0.7602107178623274, 0.26850033559774583, 0.26850033559774583, 0.63112144722886, 0.4787795007152702, 0.6201783130843151, 0.4787795007152702, 0.26850033559774583, 0.26850033559774583, 0.7602107178623274, 0.26850033559774583, 0.4787795007152702, 0.26850033559774583, 0.26850033559774583, 0.4787795007152702, 0.26850033559774583, 0.4787795007152702, 0.4787795007152702, 0.7602107178623274, 0.7602107178623274, 0.5086168215665469, 0.7602107178623274, 0.6201783130843151, 0.7602107178623274, 0.5715682163916074, 0.26850033559774583, 0.4787795007152702, 0.7602107178623274, 0.26850033559774583, 0.6201783130843151, 0.8880669977461197, 0.26850033559774583, 0.7602107178623274, 0.8880669977461197, 0.4787795007152702, 0.26850033559774583, 0.7602107178623274]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.374\n",
      "(*) epoch 2, cost 1.835\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.248\n",
      "(*) epoch 2, cost 2.133\n",
      "(*) epoch 3, cost 1.779\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.6701782582002043, 3.6701782582002043, 2.903787821023176, 3.9320745797714576, 3.6701782582002043, 3.638621316761804, 3.6701782582002043, 2.903787821023176, 3.6701782582002043, 3.6701782582002043, 3.6701782582002043, 3.638621316761804, 3.638621316761804, 3.6701782582002043, 3.6701782582002043, 3.638621316761804, 3.197241084032829, 3.6701782582002043, 3.963631521209858, 3.638621316761804, 3.638621316761804, 3.638621316761804, 3.6701782582002043, 2.903787821023176, 3.6701782582002043, 3.963631521209858, 3.6701782582002043, 3.9320745797714576, 3.638621316761804, 2.903787821023176, 3.963631521209858, 3.6701782582002043, 3.9320745797714576, 2.903787821023176, 3.6701782582002043, 3.6701782582002043, 3.6701782582002043, 3.6701782582002043, 2.8722308795847757, 3.6701782582002043, 3.6701782582002043, 3.638621316761804, 3.6701782582002043, 3.963631521209858, 3.6701782582002043, 3.638621316761804, 2.903787821023176, 3.638621316761804, 3.638621316761804, 3.638621316761804]\n",
      "all_sum after preprocessing is: [ 0.28564455  0.28564455 -2.24811705  1.15149935  0.28564455  0.18131422\n",
      "  0.28564455 -2.24811705  0.28564455  0.28564455  0.28564455  0.18131422\n",
      "  0.18131422  0.28564455  0.28564455  0.18131422 -1.27793192  0.28564455\n",
      "  1.25582968  0.18131422  0.18131422  0.18131422  0.28564455 -2.24811705\n",
      "  0.28564455  1.25582968  0.28564455  1.15149935  0.18131422 -2.24811705\n",
      "  1.25582968  0.28564455  1.15149935 -2.24811705  0.28564455  0.28564455\n",
      "  0.28564455  0.28564455 -2.35244738  0.28564455  0.28564455  0.18131422\n",
      "  0.28564455  1.25582968  0.28564455  0.18131422 -2.24811705  0.18131422\n",
      "  0.18131422  0.18131422]\n",
      "P is: [0.5709295128773989, 0.5709295128773989, 0.0955120080901855, 0.7597846727531314, 0.5709295128773989, 0.5452047803976006, 0.5709295128773989, 0.0955120080901855, 0.5709295128773989, 0.5709295128773989, 0.5709295128773989, 0.5452047803976006, 0.5452047803976006, 0.5709295128773989, 0.5709295128773989, 0.5452047803976006, 0.21790246263129573, 0.5709295128773989, 0.778307374887054, 0.5452047803976006, 0.5452047803976006, 0.5452047803976006, 0.5709295128773989, 0.0955120080901855, 0.5709295128773989, 0.778307374887054, 0.5709295128773989, 0.7597846727531314, 0.5452047803976006, 0.0955120080901855, 0.778307374887054, 0.5709295128773989, 0.7597846727531314, 0.0955120080901855, 0.5709295128773989, 0.5709295128773989, 0.5709295128773989, 0.5709295128773989, 0.08687143823160391, 0.5709295128773989, 0.5709295128773989, 0.5452047803976006, 0.5709295128773989, 0.778307374887054, 0.5709295128773989, 0.5452047803976006, 0.0955120080901855, 0.5452047803976006, 0.5452047803976006, 0.5452047803976006]\n",
      "all_sum before preprocessing is: [1.171017688064355, 2.6454241926306787, 2.549950432810202, 3.1828279797096544, 1.5714445276661126, 1.5714445276661126, 2.2449973530289213, 1.4759707678456357, 2.549950432810202, 1.171017688064355, 1.171017688064355, 1.171017688064355, 1.171017688064355, 4.256807644674221, 2.549950432810202, 3.340851340009851, 2.549950432810202, 1.171017688064355, 1.4759707678456357, 1.4759707678456357, 1.8763976074473934, 1.4759707678456357, 1.171017688064355, 2.6454241926306787, 1.8763976074473934, 2.9503772724119592, 1.9431454676228275, 2.9503772724119592, 2.2449973530289213, 1.171017688064355, 1.4759707678456357, 2.549950432810202, 2.549950432810202, 2.2449973530289213, 2.549950432810202, 1.4759707678456357, 1.5614917556622467, 1.4759707678456357, 1.8763976074473934, 1.4759707678456357, 1.8763976074473934, 1.4759707678456357, 1.4759707678456357, 2.2449973530289213, 1.4759707678456357, 2.2449973530289213, 1.8763976074473934, 2.9503772724119592, 1.8763976074473934, 1.4759707678456357]\n",
      "all_sum after preprocessing is: [-1.17510429  0.9674865   0.82874512  1.74843558 -0.59320856 -0.59320856\n",
      "  0.38559076 -0.73194994  0.82874512 -1.17510429 -1.17510429 -1.17510429\n",
      " -1.17510429  3.30913064  0.82874512  1.97807333  0.82874512 -1.17510429\n",
      " -0.73194994 -0.73194994 -0.1500542  -0.73194994 -1.17510429  0.9674865\n",
      " -0.1500542   1.41064085 -0.05305697  1.41064085  0.38559076 -1.17510429\n",
      " -0.73194994  0.82874512  0.82874512  0.38559076  0.82874512 -0.73194994\n",
      " -0.60767181 -0.73194994 -0.1500542  -0.73194994 -0.1500542  -0.73194994\n",
      " -0.73194994  0.38559076 -0.73194994  0.38559076 -0.1500542   1.41064085\n",
      " -0.1500542  -0.73194994]\n",
      "P is: [0.23593359894419663, 0.7246182204014043, 0.696089525736159, 0.8517553743442553, 0.3558990017179121, 0.3558990017179121, 0.5952208160276645, 0.3247669725260603, 0.696089525736159, 0.23593359894419663, 0.23593359894419663, 0.23593359894419663, 0.23593359894419663, 0.9647407204028077, 0.696089525736159, 0.8784756285034447, 0.696089525736159, 0.23593359894419663, 0.3247669725260603, 0.3247669725260603, 0.46255667992644267, 0.3247669725260603, 0.23593359894419663, 0.7246182204014043, 0.46255667992644267, 0.803867003199809, 0.48673886818395695, 0.803867003199809, 0.5952208160276645, 0.23593359894419663, 0.3247669725260603, 0.696089525736159, 0.696089525736159, 0.5952208160276645, 0.696089525736159, 0.3247669725260603, 0.35259047202008215, 0.3247669725260603, 0.46255667992644267, 0.3247669725260603, 0.46255667992644267, 0.3247669725260603, 0.3247669725260603, 0.5952208160276645, 0.3247669725260603, 0.5952208160276645, 0.46255667992644267, 0.803867003199809, 0.46255667992644267, 0.3247669725260603]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.213\n",
      "(*) epoch 2, cost 2.917\n",
      "(*) epoch 3, cost 2.393\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.593\n",
      "(*) epoch 2, cost 2.109\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.655509268157578, 2.135629003039461, 1.655509268157578, 2.115847216633493, 1.655509268157578, 1.8398087623817736, 1.655509268157578, 1.8398087623817736, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 2.135629003039461, 2.135629003039461, 1.655509268157578, 1.63572748175161, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 2.135629003039461, 1.655509268157578, 1.961676429681596, 1.655509268157578, 1.63572748175161, 1.63572748175161, 1.655509268157578, 1.655509268157578, 2.135629003039461, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.63572748175161, 1.655509268157578, 1.655509268157578, 1.655509268157578, 1.63572748175161]\n",
      "all_sum after preprocessing is: [-0.42761901  2.55929749 -0.42761901  2.43623123 -0.42761901  0.71894332\n",
      " -0.42761901  0.71894332 -0.42761901 -0.42761901 -0.42761901 -0.42761901\n",
      "  2.55929749  2.55929749 -0.42761901 -0.55068528 -0.42761901 -0.42761901\n",
      " -0.42761901 -0.42761901 -0.42761901 -0.42761901 -0.42761901  2.55929749\n",
      " -0.42761901  1.47710534 -0.42761901 -0.55068528 -0.55068528 -0.42761901\n",
      " -0.42761901  2.55929749 -0.42761901 -0.42761901 -0.42761901 -0.42761901\n",
      " -0.42761901 -0.42761901 -0.42761901 -0.42761901 -0.42761901 -0.42761901\n",
      " -0.42761901 -0.42761901 -0.42761901 -0.55068528 -0.42761901 -0.42761901\n",
      " -0.42761901 -0.55068528]\n",
      "P is: [0.39469503357901575, 0.9281956508423713, 0.39469503357901575, 0.9195487185968014, 0.39469503357901575, 0.6723742863356391, 0.39469503357901575, 0.6723742863356391, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.9281956508423713, 0.9281956508423713, 0.39469503357901575, 0.36570543421517493, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.9281956508423713, 0.39469503357901575, 0.8141349606301678, 0.39469503357901575, 0.36570543421517493, 0.36570543421517493, 0.39469503357901575, 0.39469503357901575, 0.9281956508423713, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.36570543421517493, 0.39469503357901575, 0.39469503357901575, 0.39469503357901575, 0.36570543421517493]\n",
      "all_sum before preprocessing is: [2.017031469965909, 2.017031469965909, 2.017031469965909, 2.3939383770467466, 2.017031469965909, 1.5771393648673424, 2.017031469965909, 2.3939383770467466, 0.9067122295751978, 2.3939383770467466, 1.2836191366560354, 0.9067122295751978, 2.017031469965909, 2.3939383770467466, 1.2836191366560354, 0.9067122295751978, 1.2836191366560354, 1.2836191366560354, 3.701948107145, 1.2836191366560354, 1.2836191366560354, 2.017031469965909, 2.3939383770467466, 2.017031469965909, 2.017031469965909, 1.2836191366560354, 2.017031469965909, 0.9067122295751978, 2.3939383770467466, 0.9067122295751978, 1.2836191366560354, 1.2836191366560354, 2.017031469965909, 2.3939383770467466, 2.3939383770467466, 2.017031469965909, 2.3939383770467466, 1.2836191366560354, 2.3939383770467466, 2.3939383770467466, 1.2836191366560354, 2.017031469965909, 2.017031469965909, 2.017031469965909, 0.9067122295751978, 2.017031469965909, 2.3939383770467466, 2.017031469965909, 2.017031469965909, 2.017031469965909]\n",
      "all_sum after preprocessing is: [ 0.31252551  0.31252551  0.31252551  0.96973942  0.31252551 -0.45451591\n",
      "  0.31252551  0.96973942 -1.62354208  0.96973942 -0.96632817 -1.62354208\n",
      "  0.31252551  0.96973942 -0.96632817 -1.62354208 -0.96632817 -0.96632817\n",
      "  3.25052062 -0.96632817 -0.96632817  0.31252551  0.96973942  0.31252551\n",
      "  0.31252551 -0.96632817  0.31252551 -1.62354208  0.96973942 -1.62354208\n",
      " -0.96632817 -0.96632817  0.31252551  0.96973942  0.96973942  0.31252551\n",
      "  0.96973942 -0.96632817  0.96973942  0.96973942 -0.96632817  0.31252551\n",
      "  0.31252551  0.31252551 -1.62354208  0.31252551  0.96973942  0.31252551\n",
      "  0.31252551  0.31252551]\n",
      "P is: [0.5775015893110583, 0.5775015893110583, 0.5775015893110583, 0.7250675551824664, 0.5775015893110583, 0.38828760554293784, 0.5775015893110583, 0.7250675551824664, 0.16471695296272792, 0.7250675551824664, 0.2756129798248519, 0.16471695296272792, 0.5775015893110583, 0.7250675551824664, 0.2756129798248519, 0.16471695296272792, 0.2756129798248519, 0.2756129798248519, 0.9626918157407801, 0.2756129798248519, 0.2756129798248519, 0.5775015893110583, 0.7250675551824664, 0.5775015893110583, 0.5775015893110583, 0.2756129798248519, 0.5775015893110583, 0.16471695296272792, 0.7250675551824664, 0.16471695296272792, 0.2756129798248519, 0.2756129798248519, 0.5775015893110583, 0.7250675551824664, 0.7250675551824664, 0.5775015893110583, 0.7250675551824664, 0.2756129798248519, 0.7250675551824664, 0.7250675551824664, 0.2756129798248519, 0.5775015893110583, 0.5775015893110583, 0.5775015893110583, 0.16471695296272792, 0.5775015893110583, 0.7250675551824664, 0.5775015893110583, 0.5775015893110583, 0.5775015893110583]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.024\n",
      "(*) epoch 2, cost 2.445\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.641\n",
      "(*) epoch 2, cost 2.956\n",
      "(*) epoch 3, cost 2.051\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.048071878297493, 2.048071878297493, 2.048071878297493, 2.048071878297493, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 2.048071878297493, 2.048071878297493, 4.023845203419913, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 1.4447921497287426, 2.5278686190842583, 1.4447921497287426, 2.048071878297493, 1.4447921497287426, 1.4447921497287426, 1.4447921497287426, 1.4447921497287426, 1.7771548629251464, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 2.048071878297493, 2.048071878297493, 2.048071878297493, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 2.048071878297493, 2.048071878297493, 1.4447921497287426, 1.4447921497287426, 1.4447921497287426, 2.048071878297493, 2.048071878297493, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 2.048071878297493, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 1.4447921497287426, 2.048071878297493, 1.4447921497287426]\n",
      "all_sum after preprocessing is: [ 0.40327605  0.40327605  0.40327605  0.40327605  0.40327605 -0.99906169\n",
      "  0.40327605  0.40327605  0.40327605  4.99600706  0.40327605 -0.99906169\n",
      "  0.40327605 -0.99906169  1.51857473 -0.99906169  0.40327605 -0.99906169\n",
      " -0.99906169 -0.99906169 -0.99906169 -0.22647684  0.40327605 -0.99906169\n",
      "  0.40327605 -0.99906169  0.40327605  0.40327605  0.40327605  0.40327605\n",
      "  0.40327605 -0.99906169  0.40327605  0.40327605  0.40327605 -0.99906169\n",
      " -0.99906169 -0.99906169  0.40327605  0.40327605  0.40327605 -0.99906169\n",
      "  0.40327605  0.40327605  0.40327605 -0.99906169  0.40327605 -0.99906169\n",
      "  0.40327605 -0.99906169]\n",
      "P is: [0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.993280551418401, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.2691259435332618, 0.8203285059128216, 0.2691259435332618, 0.5994745120584191, 0.2691259435332618, 0.2691259435332618, 0.2691259435332618, 0.2691259435332618, 0.4436215623487404, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.2691259435332618, 0.2691259435332618, 0.2691259435332618, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.5994745120584191, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.2691259435332618, 0.5994745120584191, 0.2691259435332618]\n",
      "all_sum before preprocessing is: [1.8941875094007556, 2.6825776544174165, 1.7072924698608885, 2.7424648091923656, 1.8941875094007556, 2.1391424978323172, 2.979542290427269, 2.4378791205453734, 1.2854036095288914, 1.8941875094007556, 1.8924155226975519, 1.5954508866876995, 2.4977662753203225, 1.8941875094007556, 1.6553380414626488, 2.3838410317043603, 1.7093761303036614, 1.5954508866876995, 1.6553380414626488, 1.8325283679226028, 2.4378791205453734, 1.8941875094007556, 2.6825776544174165, 2.9196551356523193, 1.5301021434009348, 2.0197556657045395, 1.5301021434009348, 1.9540746641757047, 2.321736496120831, 2.6825776544174165, 2.4437281864793094, 2.4378791205453734, 1.9540746641757047, 2.7424648091923656, 2.6825776544174165, 2.4378791205453734, 1.8941875094007556, 2.4437281864793094, 2.7348437565552257, 2.9196551356523193, 2.7424648091923656, 1.9540746641757047, 2.4977662753203225, 1.9540746641757047, 2.6825776544174165, 2.4977662753203225, 2.6825776544174165, 2.6825776544174165, 2.6825776544174165, 1.9540746641757047]\n",
      "all_sum after preprocessing is: [-0.74591349  1.01970655 -1.16446975  1.15382537 -0.74591349 -0.19733049\n",
      "  1.6847665   0.47169788 -2.10930072 -0.74591349 -0.7498819  -1.41494186\n",
      "  0.6058167  -0.74591349 -1.28082303  0.35067818 -1.15980334 -1.41494186\n",
      " -1.28082303 -0.88400073  0.47169788 -0.74591349  1.01970655  1.55064767\n",
      " -1.56129205 -0.46470037 -1.56129205 -0.61179467  0.21159348  1.01970655\n",
      "  0.48479701  0.47169788 -0.61179467  1.15382537  1.01970655  0.47169788\n",
      " -0.74591349  0.48479701  1.13675783  1.55064767  1.15382537 -0.61179467\n",
      "  0.6058167  -0.61179467  1.01970655  0.6058167   1.01970655  1.01970655\n",
      "  1.01970655 -0.61179467]\n",
      "P is: [0.3217123814697501, 0.7349154343570876, 0.23785605746984007, 0.760208943052054, 0.3217123814697501, 0.45082683914557786, 0.8435346630396768, 0.6157855421254875, 0.10819612164087497, 0.3217123814697501, 0.32084703414777715, 0.19545576597810585, 0.6469859457377669, 0.3217123814697501, 0.2174101583245286, 0.5867820271611949, 0.23870302161173854, 0.19545576597810585, 0.2174101583245286, 0.2923494161466905, 0.6157855421254875, 0.3217123814697501, 0.7349154343570876, 0.8250072562807096, 0.17346132451659937, 0.3858713589980977, 0.17346132451659937, 0.3516499188672301, 0.5527018859411943, 0.7349154343570876, 0.6188799772279754, 0.6157855421254875, 0.3516499188672301, 0.760208943052054, 0.7349154343570876, 0.6157855421254875, 0.3217123814697501, 0.6188799772279754, 0.7570838752565211, 0.8250072562807096, 0.760208943052054, 0.3516499188672301, 0.6469859457377669, 0.3516499188672301, 0.7349154343570876, 0.6469859457377669, 0.7349154343570876, 0.7349154343570876, 0.7349154343570876, 0.3516499188672301]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.523\n",
      "(*) epoch 2, cost 2.586\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.551\n",
      "(*) epoch 2, cost 3.536\n",
      "(*) epoch 3, cost 3.222\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.9327603004762757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.6911860211172987, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 1.9327603004762757, 2.6911860211172987, 2.6911860211172987, 2.5252278456018757, 2.5252278456018757, 2.6911860211172987, 2.5252278456018757, 1.9327603004762757, 2.6038200830939138, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 1.9327603004762757, 2.5252278456018757, 2.5252278456018757, 2.5252278456018757, 1.9327603004762757, 2.5252278456018757, 2.5252278456018757]\n",
      "all_sum after preprocessing is: [-2.91059343  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273\n",
      "  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273\n",
      "  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273  1.11712526\n",
      "  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273\n",
      " -2.91059343  1.11712526  1.11712526  0.23578273  0.23578273  1.11712526\n",
      "  0.23578273 -2.91059343  0.65315705  0.23578273  0.23578273  0.23578273\n",
      "  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273  0.23578273\n",
      "  0.23578273 -2.91059343  0.23578273  0.23578273  0.23578273 -2.91059343\n",
      "  0.23578273  0.23578273]\n",
      "P is: [0.05163236934735955, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.7534550925111688, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.05163236934735955, 0.7534550925111688, 0.7534550925111688, 0.5586741083681509, 0.5586741083681509, 0.7534550925111688, 0.5586741083681509, 0.05163236934735955, 0.65772154433936, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.05163236934735955, 0.5586741083681509, 0.5586741083681509, 0.5586741083681509, 0.05163236934735955, 0.5586741083681509, 0.5586741083681509]\n",
      "all_sum before preprocessing is: [2.0432992373126053, 2.934985069143686, 2.0432992373126053, 5.211306135687731, 3.798064234113718, 2.4661939565773623, 1.5745081247462815, 2.934985069143686, 2.934985069143686, 2.4661939565773623, 2.0432992373126053, 2.934985069143686, 2.4661939565773623, 5.668431214617968, 2.4661939565773623, 1.8293859043925713, 2.0432992373126053, 4.093349191071409, 1.5745081247462815, 1.5745081247462815, 4.516243910336166, 1.1221008473048504, 1.5745081247462815, 3.798064234113718, 3.798064234113718, 2.934985069143686, 2.4661939565773623, 2.4661939565773623, 3.588176956453369, 1.8293859043925713, 0.468908959995167, 1.5745081247462815, 2.2277000120559647, 4.516243910336166, 1.5745081247462815, 2.4661939565773623, 1.5745081247462815, 2.4661939565773623, 2.934985069143686, 2.0432992373126053, 2.4661939565773623, 2.4661939565773623, 3.624558078505086, 2.9063784022826376, 3.3751695148489613, 3.1193858438870454, 3.5595702895923207, 2.8384132289001247, 3.624558078505086, 3.798064234113718]\n",
      "all_sum after preprocessing is: [-0.67037103  0.19203712 -0.67037103  2.39361728  1.02677787 -0.26136167\n",
      " -1.12376981  0.19203712  0.19203712 -0.26136167 -0.67037103  0.19203712\n",
      " -0.26136167  2.83573307 -0.26136167 -0.87726071 -0.67037103  1.31236742\n",
      " -1.12376981 -1.12376981  1.72137678 -1.56132271 -1.12376981  1.02677787\n",
      "  1.02677787  0.19203712 -0.26136167 -0.26136167  0.82378205 -0.87726071\n",
      " -2.19306764 -1.12376981 -0.49202488  1.72137678 -1.12376981 -0.26136167\n",
      " -1.12376981 -0.26136167  0.19203712 -0.67037103 -0.26136167 -0.26136167\n",
      "  0.85896863  0.16436973  0.61776851  0.37038326  0.79611466  0.09863613\n",
      "  0.85896863  1.02677787]\n",
      "P is: [0.3384137667936397, 0.5478622806047125, 0.3384137667936397, 0.9163392921376239, 0.7362907427204395, 0.43502900987433524, 0.24531269163817612, 0.5478622806047125, 0.5478622806047125, 0.43502900987433524, 0.3384137667936397, 0.5478622806047125, 0.43502900987433524, 0.944576504430659, 0.43502900987433524, 0.29374574824413335, 0.3384137667936397, 0.7879090412755532, 0.24531269163817612, 0.24531269163817612, 0.8483060892698816, 0.17345692821645042, 0.24531269163817612, 0.7362907427204395, 0.7362907427204395, 0.5478622806047125, 0.43502900987433524, 0.43502900987433524, 0.6950385744531802, 0.29374574824413335, 0.1003747465108396, 0.24531269163817612, 0.3794166734474426, 0.8483060892698816, 0.24531269163817612, 0.43502900987433524, 0.24531269163817612, 0.43502900987433524, 0.5478622806047125, 0.3384137667936397, 0.43502900987433524, 0.43502900987433524, 0.7024451272250094, 0.5410001634518367, 0.649710861939827, 0.5915515854997101, 0.6891427560680908, 0.5246390588665307, 0.7024451272250094, 0.7362907427204395]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.661\n",
      "(*) epoch 2, cost 1.157\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.719\n",
      "(*) epoch 2, cost 4.333\n",
      "(*) epoch 3, cost 3.764\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.1138404861249454, 3.8713319210227213, 3.539727564577732, 2.298392508997141, 3.539727564577732, 3.539727564577732, 3.401628740132109, 2.298392508997141, 2.298392508997141, 2.1138404861249454, 2.298392508997141, 4.134003321079118, 5.283692750640659, 2.1138404861249454, 3.9959044966334947, 5.283692750640659, 5.421791575086282, 2.1138404861249454, 5.283692750640659, 5.270610627975145, 5.283692750640659, 2.298392508997141, 5.468244773512855, 2.1138404861249454, 3.5861807630043048, 2.1138404861249454, 2.298392508997141, 2.1138404861249454, 2.1138404861249454, 3.9959044966334947, 2.1138404861249454, 3.9959044966334947, 2.100758363459431, 4.18045651950569, 5.283692750640659, 2.1138404861249454, 2.1138404861249454, 2.1138404861249454, 3.3687435808375215, 3.9959044966334947, 5.283692750640659, 2.1138404861249454, 2.9590198472083316, 3.9959044966334947, 5.283692750640659, 5.468244773512855, 5.421791575086282, 4.18045651950569, 5.468244773512855, 3.401628740132109]\n",
      "all_sum after preprocessing is: [-1.10003562  0.26402091  0.00665005 -0.95679772  0.00665005  0.00665005\n",
      " -0.10053375 -0.95679772 -0.95679772 -1.10003562 -0.95679772  0.46789026\n",
      "  1.36020834 -1.10003562  0.36070647  1.36020834  1.46739214 -1.10003562\n",
      "  1.36020834  1.3500548   1.36020834 -0.95679772  1.50344625 -1.10003562\n",
      "  0.04270416 -1.10003562 -0.95679772 -1.10003562 -1.10003562  0.36070647\n",
      " -1.10003562  0.36070647 -1.11018916  0.50394437  1.36020834 -1.10003562\n",
      " -1.10003562 -1.10003562 -0.12605718  0.36070647  1.36020834 -1.10003562\n",
      " -0.44405949  0.36070647  1.36020834  1.50344625  1.46739214  0.50394437\n",
      "  1.50344625 -0.10053375]\n",
      "P is: [0.24973321960180464, 0.5656244626450799, 0.5016625055790037, 0.2775198029534734, 0.5016625055790037, 0.5016625055790037, 0.47488770996670737, 0.2775198029534734, 0.2775198029534734, 0.24973321960180464, 0.2775198029534734, 0.614884288524592, 0.7957935565248897, 0.24973321960180464, 0.5892114389467834, 0.7957935565248897, 0.8126606801235398, 0.24973321960180464, 0.7957935565248897, 0.7941385878061805, 0.7957935565248897, 0.2775198029534734, 0.8180879092907395, 0.24973321960180464, 0.5106744169697189, 0.24973321960180464, 0.2775198029534734, 0.24973321960180464, 0.24973321960180464, 0.5892114389467834, 0.24973321960180464, 0.5892114389467834, 0.2478356247228672, 0.6233858246809563, 0.7957935565248897, 0.24973321960180464, 0.24973321960180464, 0.24973321960180464, 0.46852736921822247, 0.5892114389467834, 0.7957935565248897, 0.24973321960180464, 0.39077409944882413, 0.5892114389467834, 0.7957935565248897, 0.8180879092907395, 0.8126606801235398, 0.6233858246809563, 0.8180879092907395, 0.47488770996670737]\n",
      "all_sum before preprocessing is: [1.6269975321473515, 1.5197257033038938, 3.1749071830202564, 1.5197257033038938, 1.5197257033038938, 3.1749071830202564, 3.1749071830202564, 1.5197257033038938, 1.5197257033038938, 3.622793838037035, 1.3757954915670556, 1.5197257033038938, 3.622793838037035, 1.5197257033038938, 1.5197257033038938, 3.282179011863714, 1.5197257033038938, 1.9676123583206722, 3.1749071830202564, 1.6269975321473515, 1.5197257033038938, 3.1749071830202564, 1.5197257033038938, 1.5197257033038938, 1.5197257033038938, 1.5197257033038938, 1.5197257033038938, 1.5197257033038938, 1.5197257033038938, 1.5197257033038938, 3.1749071830202564, 1.5197257033038938, 1.6269975321473515, 1.5197257033038938, 3.1749071830202564, 1.9363323414517253, 1.5197257033038938, 1.5197257033038938, 1.6269975321473515, 1.6269975321473515, 1.9676123583206722, 3.1749071830202564, 1.5197257033038938, 3.1749071830202564, 3.1749071830202564, 3.1749071830202564, 3.030976971283418, 1.5197257033038938, 3.1749071830202564, 3.1749071830202564]\n",
      "all_sum after preprocessing is: [-0.63693525 -0.77176058  1.30856554 -0.77176058 -0.77176058  1.30856554\n",
      "  1.30856554 -0.77176058 -0.77176058  1.87149493 -0.95266025 -0.77176058\n",
      "  1.87149493 -0.77176058 -0.77176058  1.44339087 -0.77176058 -0.20883119\n",
      "  1.30856554 -0.63693525 -0.77176058  1.30856554 -0.77176058 -0.77176058\n",
      " -0.77176058 -0.77176058 -0.77176058 -0.77176058 -0.77176058 -0.77176058\n",
      "  1.30856554 -0.77176058 -0.63693525 -0.77176058  1.30856554 -0.24814569\n",
      " -0.77176058 -0.77176058 -0.63693525 -0.63693525 -0.20883119  1.30856554\n",
      " -0.77176058  1.30856554  1.30856554  1.30856554  1.12766587 -0.77176058\n",
      "  1.30856554  1.30856554]\n",
      "P is: [0.34593965745847016, 0.31609837975770433, 0.7872730195550975, 0.31609837975770433, 0.31609837975770433, 0.7872730195550975, 0.7872730195550975, 0.31609837975770433, 0.31609837975770433, 0.8666311589234299, 0.27835013880090403, 0.31609837975770433, 0.8666311589234299, 0.31609837975770433, 0.31609837975770433, 0.8089791975592587, 0.31609837975770433, 0.4479811127558471, 0.7872730195550975, 0.34593965745847016, 0.31609837975770433, 0.7872730195550975, 0.31609837975770433, 0.31609837975770433, 0.31609837975770433, 0.31609837975770433, 0.31609837975770433, 0.31609837975770433, 0.31609837975770433, 0.31609837975770433, 0.7872730195550975, 0.31609837975770433, 0.34593965745847016, 0.31609837975770433, 0.7872730195550975, 0.43827996011356957, 0.31609837975770433, 0.31609837975770433, 0.34593965745847016, 0.34593965745847016, 0.4479811127558471, 0.7872730195550975, 0.31609837975770433, 0.7872730195550975, 0.7872730195550975, 0.7872730195550975, 0.7554078866666791, 0.31609837975770433, 0.7872730195550975, 0.7872730195550975]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.542\n",
      "(*) epoch 2, cost 3.236\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.860\n",
      "(*) epoch 2, cost 1.463\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.079493271109573, 3.6559892453953307, 3.0300592035074976, 2.5647026106769215, 3.45356322922174, 3.6559892453953307, 3.9436673028424707, 2.2264506262362285, 3.1658851717746006, 4.814081106881342, 4.079493271109573, 3.3177372609546376, 3.9436673028424707, 3.6559892453953307, 3.6559892453953307, 3.0300592035074976, 3.6559892453953307, 3.3177372609546376, 2.5647026106769215, 3.6559892453953307, 3.6559892453953307, 3.9436673028424707, 2.988206636391164, 3.9436673028424707, 3.6559892453953307, 3.6559892453953307, 2.8523806681240615, 4.079493271109573, 3.6559892453953307, 2.700528578944024, 3.9436673028424707, 3.6559892453953307, 3.1658851717746006, 3.9436673028424707, 3.9436673028424707, 2.362276594503331, 4.052325096726406, 3.3177372609546376, 3.9436673028424707, 3.1658851717746006, 4.390577081167099, 3.3177372609546376, 3.6559892453953307, 3.9436673028424707, 2.2264506262362285, 3.3177372609546376, 3.764647039279266, 2.5647026106769215, 3.0300592035074976, 3.6559892453953307]\n",
      "all_sum after preprocessing is: [ 1.07403963  0.31627295 -0.80369026 -1.63634284 -0.04592358  0.31627295\n",
      "  0.83100913 -2.24156986 -0.56065976  2.3884219   1.07403963 -0.28895408\n",
      "  0.83100913  0.31627295  0.31627295 -0.80369026  0.31627295 -0.28895408\n",
      " -1.63634284  0.31627295  0.31627295  0.83100913 -0.87857616  0.83100913\n",
      "  0.31627295  0.31627295 -1.12160665  1.07403963  0.31627295 -1.39331234\n",
      "  0.83100913  0.31627295 -0.56065976  0.83100913  0.83100913 -1.99853937\n",
      "  1.0254282  -0.28895408  0.83100913 -0.56065976  1.63065522 -0.28895408\n",
      "  0.31627295  0.83100913 -2.24156986 -0.28895408  0.51069201 -1.63634284\n",
      " -0.80369026  0.31627295]\n",
      "P is: [0.7453643821729906, 0.5784156742753511, 0.30923669063560344, 0.162963307746627, 0.4885211219821038, 0.5784156742753511, 0.6965682637389901, 0.0960791157470926, 0.36339481667660173, 0.9159401440046108, 0.7453643821729906, 0.4282599459388373, 0.6965682637389901, 0.5784156742753511, 0.5784156742753511, 0.30923669063560344, 0.5784156742753511, 0.4282599459388373, 0.162963307746627, 0.5784156742753511, 0.5784156742753511, 0.6965682637389901, 0.29347292034765216, 0.6965682637389901, 0.5784156742753511, 0.5784156742753511, 0.24571338726395164, 0.7453643821729906, 0.5784156742753511, 0.19887948654551255, 0.6965682637389901, 0.5784156742753511, 0.36339481667660173, 0.6965682637389901, 0.6965682637389901, 0.1193563640725346, 0.7360285968768132, 0.4282599459388373, 0.6965682637389901, 0.36339481667660173, 0.8362593780753972, 0.4282599459388373, 0.5784156742753511, 0.6965682637389901, 0.0960791157470926, 0.4282599459388373, 0.6249686845549391, 0.162963307746627, 0.30923669063560344, 0.5784156742753511]\n",
      "all_sum before preprocessing is: [3.4807455684321797, 2.443603208474052, 3.4807455684321797, 2.443603208474052, 3.4807455684321797, 2.443603208474052, 4.661773197100564, 2.443603208474052, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 4.315195221301625, 2.443603208474052, 3.4807455684321797, 2.443603208474052, 3.4807455684321797, 3.2780528613434976, 3.4807455684321797, 4.227661658155372, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 2.8732931485316895, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 4.315195221301625, 2.8732931485316895, 3.4807455684321797, 4.123426296572741, 4.227661658155372, 3.4807455684321797, 3.4807455684321797, 5.4962228499700085, 1.836150788573562, 2.443603208474052, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 3.4807455684321797, 2.8732931485316895, 3.4807455684321797, 3.4807455684321797]\n",
      "all_sum after preprocessing is: [ 0.12594206 -1.53685092  0.12594206 -1.53685092  0.12594206 -1.53685092\n",
      "  2.01941832 -1.53685092  0.12594206  0.12594206  0.12594206  0.12594206\n",
      "  1.46376903 -1.53685092  0.12594206 -1.53685092  0.12594206 -0.19902395\n",
      "  0.12594206  1.32343131  0.12594206  0.12594206  0.12594206  0.12594206\n",
      " -0.84795281  0.12594206  0.12594206  0.12594206  0.12594206  0.12594206\n",
      "  1.46376903 -0.84795281  0.12594206  1.15631652  1.32343131  0.12594206\n",
      "  0.12594206  3.35724529 -2.51074578 -1.53685092  0.12594206  0.12594206\n",
      "  0.12594206  0.12594206  0.12594206  0.12594206  0.12594206 -0.84795281\n",
      "  0.12594206  0.12594206]\n",
      "P is: [0.5314439631135854, 0.17699352515556135, 0.5314439631135854, 0.17699352515556135, 0.5314439631135854, 0.17699352515556135, 0.8828208490959163, 0.17699352515556135, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.8121084607548104, 0.17699352515556135, 0.5314439631135854, 0.17699352515556135, 0.5314439631135854, 0.45040760347630676, 0.5314439631135854, 0.7897520200346042, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.2998624795625674, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.8121084607548104, 0.2998624795625674, 0.5314439631135854, 0.7606627626753972, 0.7897520200346042, 0.5314439631135854, 0.5314439631135854, 0.9663412926610605, 0.07510828597269363, 0.17699352515556135, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.5314439631135854, 0.2998624795625674, 0.5314439631135854, 0.5314439631135854]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.089\n",
      "(*) epoch 2, cost 3.182\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.950\n",
      "(*) epoch 2, cost 3.438\n",
      "(*) epoch 3, cost 2.914\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.8009488077272677, 1.8009488077272677, 0.9183176065757032, 0.9183176065757032, 1.4377896042008562, 0.9183176065757032, 0.9183176065757032, 1.4377896042008562, 0.9183176065757032, 1.8009488077272677, 0.9183176065757032, 1.8009488077272677, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 1.4377896042008562, 0.9183176065757032, 0.9183176065757032, 1.8009488077272677, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 1.4377896042008562, 0.9183176065757032, 0.9183176065757032, 1.4377896042008562, 1.8009488077272677, 1.8009488077272677, 0.9183176065757032, 0.9183176065757032, 1.8009488077272677, 0.9183176065757032, 1.8009488077272677, 0.9183176065757032, 1.4377896042008562, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 1.8009488077272677, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 0.9183176065757032, 1.8009488077272677, 0.9183176065757032, 1.8009488077272677, 1.8009488077272677]\n",
      "all_sum after preprocessing is: [ 1.52662351  1.52662351 -0.75404966 -0.75404966  0.58823899 -0.75404966\n",
      " -0.75404966  0.58823899 -0.75404966  1.52662351 -0.75404966  1.52662351\n",
      " -0.75404966 -0.75404966 -0.75404966 -0.75404966  0.58823899 -0.75404966\n",
      " -0.75404966  1.52662351 -0.75404966 -0.75404966 -0.75404966  0.58823899\n",
      " -0.75404966 -0.75404966  0.58823899  1.52662351  1.52662351 -0.75404966\n",
      " -0.75404966  1.52662351 -0.75404966  1.52662351 -0.75404966  0.58823899\n",
      " -0.75404966 -0.75404966 -0.75404966 -0.75404966 -0.75404966  1.52662351\n",
      " -0.75404966 -0.75404966 -0.75404966 -0.75404966  1.52662351 -0.75404966\n",
      "  1.52662351  1.52662351]\n",
      "P is: [0.8215117564437002, 0.8215117564437002, 0.3199395401257386, 0.3199395401257386, 0.6429609871250794, 0.3199395401257386, 0.3199395401257386, 0.6429609871250794, 0.3199395401257386, 0.8215117564437002, 0.3199395401257386, 0.8215117564437002, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.6429609871250794, 0.3199395401257386, 0.3199395401257386, 0.8215117564437002, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.6429609871250794, 0.3199395401257386, 0.3199395401257386, 0.6429609871250794, 0.8215117564437002, 0.8215117564437002, 0.3199395401257386, 0.3199395401257386, 0.8215117564437002, 0.3199395401257386, 0.8215117564437002, 0.3199395401257386, 0.6429609871250794, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.8215117564437002, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.3199395401257386, 0.8215117564437002, 0.3199395401257386, 0.8215117564437002, 0.8215117564437002]\n",
      "all_sum before preprocessing is: [3.577327691154812, 2.9284493992050376, 2.9284493992050376, 2.6909295583159936, 3.577327691154812, 2.9284493992050376, 3.577327691154812, 3.577327691154812, 2.9284493992050376, 4.667015578533806, 1.9049165377911188, 3.577327691154812, 2.9284493992050376, 3.577327691154812, 3.374894570497177, 1.9049165377911188, 3.577327691154812, 2.9284493992050376, 1.9049165377911188, 3.577327691154812, 3.577327691154812, 2.9284493992050376, 2.9284493992050376, 3.577327691154812, 1.9049165377911188, 3.6124144113862213, 2.9284493992050376, 2.9284493992050376, 3.6124144113862213, 3.237759841922077, 3.577327691154812, 2.9284493992050376, 2.9284493992050376, 2.9284493992050376, 3.237759841922077, 2.9284493992050376, 2.9284493992050376, 3.577327691154812, 3.339807850265768, 2.9284493992050376, 2.9284493992050376, 3.577327691154812, 2.9284493992050376, 3.6124144113862213, 2.5537948297408937, 2.9284493992050376, 2.5537948297408937, 2.9284493992050376, 2.9284493992050376, 2.9284493992050376]\n",
      "all_sum after preprocessing is: [ 0.91691267 -0.33182894 -0.33182894 -0.78892685  0.91691267 -0.33182894\n",
      "  0.91691267  0.91691267 -0.33182894  3.01397558 -2.30157902  0.91691267\n",
      " -0.33182894  0.91691267  0.52733782 -2.30157902  0.91691267 -0.33182894\n",
      " -2.30157902  0.91691267  0.91691267 -0.33182894 -0.33182894  0.91691267\n",
      " -2.30157902  0.98443572 -0.33182894 -0.33182894  0.98443572  0.26342725\n",
      "  0.91691267 -0.33182894 -0.33182894 -0.33182894  0.26342725 -0.33182894\n",
      " -0.33182894  0.91691267  0.45981476 -0.33182894 -0.33182894  0.91691267\n",
      " -0.33182894  0.98443572 -1.05283742 -0.33182894 -1.05283742 -0.33182894\n",
      " -0.33182894 -0.33182894]\n",
      "P is: [0.7144126224993087, 0.41779568031895, 0.41779568031895, 0.3123991429440554, 0.7144126224993087, 0.41779568031895, 0.7144126224993087, 0.7144126224993087, 0.41779568031895, 0.9532015183940751, 0.0909922713862974, 0.7144126224993087, 0.41779568031895, 0.7144126224993087, 0.6288619869500914, 0.0909922713862974, 0.7144126224993087, 0.41779568031895, 0.0909922713862974, 0.7144126224993087, 0.7144126224993087, 0.41779568031895, 0.41779568031895, 0.7144126224993087, 0.0909922713862974, 0.727987473800081, 0.41779568031895, 0.41779568031895, 0.727987473800081, 0.5654785977960014, 0.7144126224993087, 0.41779568031895, 0.41779568031895, 0.41779568031895, 0.5654785977960014, 0.41779568031895, 0.41779568031895, 0.7144126224993087, 0.6129702312556862, 0.41779568031895, 0.41779568031895, 0.7144126224993087, 0.41779568031895, 0.727987473800081, 0.2586806111350189, 0.41779568031895, 0.2586806111350189, 0.41779568031895, 0.41779568031895, 0.41779568031895]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.178\n",
      "(*) epoch 2, cost 0.732\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.876\n",
      "(*) epoch 2, cost 3.022\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 1.039793709523515, 0.17574493655515486, 1.039793709523515, 0.17574493655515486, 0.17574493655515486, 1.6618181292846437, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 2.525866902253004, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.42227145080182865, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 1.9083446435313174, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486, 0.17574493655515486]\n",
      "all_sum after preprocessing is: [-0.31949214 -0.31949214 -0.31949214  1.51029351 -0.31949214  1.51029351\n",
      " -0.31949214 -0.31949214  2.82754711 -0.31949214 -0.31949214 -0.31949214\n",
      " -0.31949214 -0.31949214 -0.31949214 -0.31949214  4.65733277 -0.31949214\n",
      " -0.31949214 -0.31949214 -0.31949214 -0.31949214 -0.31949214 -0.31949214\n",
      " -0.31949214 -0.31949214 -0.31949214  0.20257408 -0.31949214 -0.31949214\n",
      " -0.31949214 -0.31949214 -0.31949214 -0.31949214 -0.31949214 -0.31949214\n",
      "  3.34961334 -0.31949214 -0.31949214 -0.31949214 -0.31949214 -0.31949214\n",
      " -0.31949214 -0.31949214 -0.31949214 -0.31949214 -0.31949214 -0.31949214\n",
      " -0.31949214 -0.31949214]\n",
      "P is: [0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.8191047009125079, 0.42079952136425375, 0.8191047009125079, 0.42079952136425375, 0.42079952136425375, 0.9441463923874138, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.9905975007535944, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.5504710424522873, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.9660921717225143, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375, 0.42079952136425375]\n",
      "all_sum before preprocessing is: [3.6403096811386684, 4.135447142872297, 4.135447142872297, 2.1453611796662355, 2.8412517740267735, 3.1618473799765234, 2.6238234808283805, 3.6569848417101523, 3.6569848417101523, 2.8412517740267735, 2.9444190867781304, 3.3197140751889185, 3.6569848417101523, 1.3296281119828568, 1.8080904131450017, 2.6238234808283805, 2.8412517740267735, 1.3296281119828568, 2.1453611796662355, 2.8412517740267735, 1.8080904131450017, 1.8080904131450017, 1.8080904131450017, 3.6569848417101523, 2.6238234808283805, 3.6569848417101523, 2.8412517740267735, 2.1453611796662355, 1.3296281119828568, 1.8080904131450017, 4.135447142872297, 2.1453611796662355, 3.6569848417101523, 2.6238234808283805, 2.8412517740267735, 2.8412517740267735, 1.8080904131450017, 2.8412517740267735, 1.8080904131450017, 3.6569848417101523, 2.1453611796662355, 2.8412517740267735, 2.6238234808283805, 2.8412517740267735, 3.6569848417101523, 2.8412517740267735, 2.8412517740267735, 3.6569848417101523, 2.6238234808283805, 2.8412517740267735]\n",
      "all_sum after preprocessing is: [ 1.14912135  1.801936    1.801936   -0.82189549  0.09560239  0.5182921\n",
      " -0.19106623  1.17110674  1.17110674  0.09560239  0.23162347  0.72643165\n",
      "  1.17110674 -1.89739984 -1.26657058 -0.19106623  0.09560239 -1.89739984\n",
      " -0.82189549  0.09560239 -1.26657058 -1.26657058 -1.26657058  1.17110674\n",
      " -0.19106623  1.17110674  0.09560239 -0.82189549 -1.89739984 -1.26657058\n",
      "  1.801936   -0.82189549  1.17110674 -0.19106623  0.09560239  0.09560239\n",
      " -1.26657058  0.09560239 -1.26657058  1.17110674 -0.82189549  0.09560239\n",
      " -0.19106623  0.09560239  1.17110674  0.09560239  0.09560239  1.17110674\n",
      " -0.19106623  0.09560239]\n",
      "P is: [0.7593503920551458, 0.8583844396173929, 0.8583844396173929, 0.3053614488710064, 0.5238824109959879, 0.6267483146779671, 0.4523782291906048, 0.7633450061951917, 0.7633450061951917, 0.5238824109959879, 0.557648365134805, 0.6740217349781769, 0.7633450061951917, 0.13040304484988233, 0.21984487783808557, 0.4523782291906048, 0.5238824109959879, 0.13040304484988233, 0.3053614488710064, 0.5238824109959879, 0.21984487783808557, 0.21984487783808557, 0.21984487783808557, 0.7633450061951917, 0.4523782291906048, 0.7633450061951917, 0.5238824109959879, 0.3053614488710064, 0.13040304484988233, 0.21984487783808557, 0.8583844396173929, 0.3053614488710064, 0.7633450061951917, 0.4523782291906048, 0.5238824109959879, 0.5238824109959879, 0.21984487783808557, 0.5238824109959879, 0.21984487783808557, 0.7633450061951917, 0.3053614488710064, 0.5238824109959879, 0.4523782291906048, 0.5238824109959879, 0.7633450061951917, 0.5238824109959879, 0.5238824109959879, 0.7633450061951917, 0.4523782291906048, 0.5238824109959879]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.454\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.174\n",
      "(*) epoch 2, cost 2.606\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [5.658861453506201, 5.658861453506201, 3.5108700717706776, 3.3293475001881623, 3.255635200856292, 4.384826642576295, 5.477338881923686, 5.658861453506201, 3.5108700717706776, 5.658861453506201, 4.348147440203683, 5.658861453506201, 4.56634921415881, 4.56634921415881, 4.166624868621168, 4.348147440203683, 4.166624868621168, 5.477338881923686, 5.658861453506201, 4.421859739535553, 5.658861453506201, 3.0741126292737766, 3.255635200856292, 3.255635200856292, 4.56634921415881, 4.348147440203683, 5.658861453506201, 4.384826642576295, 4.348147440203683, 5.477338881923686, 5.658861453506201, 4.56634921415881, 4.348147440203683, 6.280184830856533, 5.477338881923686, 5.658861453506201, 3.5108700717706776, 4.384826642576295, 4.603382311118069, 5.477338881923686, 5.658861453506201, 4.348147440203683, 4.56634921415881, 4.56634921415881, 3.5108700717706776, 4.603382311118069, 3.255635200856292, 4.348147440203683, 4.56634921415881, 5.658861453506201]\n",
      "all_sum after preprocessing is: [ 1.17279833  1.17279833 -1.32723491 -1.53850785 -1.62430112 -0.31004252\n",
      "  0.96152538  1.17279833 -1.32723491  1.17279833 -0.35273321  1.17279833\n",
      " -0.09876958 -0.09876958 -0.56400615 -0.35273321 -0.56400615  0.96152538\n",
      "  1.17279833 -0.26693994  1.17279833 -1.83557406 -1.62430112 -1.62430112\n",
      " -0.09876958 -0.35273321  1.17279833 -0.31004252 -0.35273321  0.96152538\n",
      "  1.17279833 -0.09876958 -0.35273321  1.89595257  0.96152538  1.17279833\n",
      " -1.32723491 -0.31004252 -0.055667    0.96152538  1.17279833 -0.35273321\n",
      " -0.09876958 -0.09876958 -1.32723491 -0.055667   -1.62430112 -0.35273321\n",
      " -0.09876958  1.17279833]\n",
      "P is: [0.7636504536415254, 0.7636504536415254, 0.2096171117965336, 0.17675229409691545, 0.16461254737415923, 0.42310435903446686, 0.7234271080232118, 0.7636504536415254, 0.2096171117965336, 0.7636504536415254, 0.4127197819093165, 0.7636504536415254, 0.47532765875932065, 0.47532765875932065, 0.36262102067393437, 0.4127197819093165, 0.36262102067393437, 0.7234271080232118, 0.7636504536415254, 0.4336584880711614, 0.7636504536415254, 0.13757558195057448, 0.16461254737415923, 0.16461254737415923, 0.47532765875932065, 0.4127197819093165, 0.7636504536415254, 0.42310435903446686, 0.4127197819093165, 0.7234271080232118, 0.7636504536415254, 0.47532765875932065, 0.4127197819093165, 0.8694327505646317, 0.7234271080232118, 0.7636504536415254, 0.2096171117965336, 0.42310435903446686, 0.4860868425681126, 0.7234271080232118, 0.7636504536415254, 0.4127197819093165, 0.47532765875932065, 0.47532765875932065, 0.2096171117965336, 0.4860868425681126, 0.16461254737415923, 0.4127197819093165, 0.47532765875932065, 0.7636504536415254]\n",
      "all_sum before preprocessing is: [1.7059867340834283, 1.7042614361267086, 0.8687268235699213, 1.7059867340834283, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 1.7042614361267086, 1.7059867340834283, 0.8687268235699213, 0.8687268235699213, 1.7059867340834283, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 1.7059867340834283, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 4.26008411717885, 1.7059867340834283, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 1.7042614361267086, 4.26008411717885, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213, 0.8687268235699213]\n",
      "all_sum after preprocessing is: [ 0.77604705  0.7736171  -0.40317311  0.77604705 -0.40317311 -0.40317311\n",
      " -0.40317311 -0.40317311 -0.40317311 -0.40317311  0.7736171   0.77604705\n",
      " -0.40317311 -0.40317311  0.77604705 -0.40317311 -0.40317311 -0.40317311\n",
      " -0.40317311 -0.40317311 -0.40317311 -0.40317311  0.77604705 -0.40317311\n",
      " -0.40317311 -0.40317311 -0.40317311 -0.40317311 -0.40317311  4.37330892\n",
      "  0.77604705 -0.40317311 -0.40317311 -0.40317311 -0.40317311 -0.40317311\n",
      " -0.40317311 -0.40317311  0.7736171   4.37330892 -0.40317311 -0.40317311\n",
      " -0.40317311 -0.40317311 -0.40317311 -0.40317311 -0.40317311 -0.40317311\n",
      " -0.40317311 -0.40317311]\n",
      "P is: [0.6848275388884709, 0.684302824382955, 0.40055020446014983, 0.6848275388884709, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.684302824382955, 0.6848275388884709, 0.40055020446014983, 0.40055020446014983, 0.6848275388884709, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.6848275388884709, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.9875475704058244, 0.6848275388884709, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.684302824382955, 0.9875475704058244, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983, 0.40055020446014983]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.118\n",
      "(*) epoch 2, cost 3.414\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.391\n",
      "(*) epoch 2, cost 1.968\n",
      "(*) epoch 3, cost 1.444\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 4.662385195564651, 3.908940199650286, 3.908940199650286, 3.908940199650286, 4.622229133339042, 3.908940199650286, 4.248031696844898, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 4.961320630533654, 4.662385195564651, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 4.622229133339042, 3.908940199650286, 3.908940199650286, 3.908940199650286, 4.662385195564651, 4.248031696844898, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 3.908940199650286, 4.622229133339042, 3.908940199650286, 3.908940199650286, 4.662385195564651, 3.908940199650286, 5.0014766927592635, 4.662385195564651, 3.908940199650286]\n",
      "all_sum after preprocessing is: [-0.53270909 -0.53270909 -0.53270909 -0.53270909 -0.53270909 -0.53270909\n",
      " -0.53270909  1.76602048 -0.53270909 -0.53270909 -0.53270909  1.643506\n",
      " -0.53270909  0.50184507 -0.53270909 -0.53270909 -0.53270909 -0.53270909\n",
      " -0.53270909 -0.53270909  2.67806015  1.76602048 -0.53270909 -0.53270909\n",
      " -0.53270909 -0.53270909 -0.53270909 -0.53270909 -0.53270909 -0.53270909\n",
      " -0.53270909  1.643506   -0.53270909 -0.53270909 -0.53270909  1.76602048\n",
      "  0.50184507 -0.53270909 -0.53270909 -0.53270909 -0.53270909 -0.53270909\n",
      "  1.643506   -0.53270909 -0.53270909  1.76602048 -0.53270909  2.80057464\n",
      "  1.76602048 -0.53270909]\n",
      "P is: [0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.8539620809570172, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.8380114344933643, 0.3698852582721085, 0.6228928310713421, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.9357195432699593, 0.8539620809570172, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.8380114344933643, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.8539620809570172, 0.6228928310713421, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.3698852582721085, 0.8380114344933643, 0.3698852582721085, 0.3698852582721085, 0.8539620809570172, 0.3698852582721085, 0.9427068686594051, 0.8539620809570172, 0.3698852582721085]\n",
      "all_sum before preprocessing is: [2.745268967907057, 2.745268967907057, 3.51179321885396, 3.938288813507672, 3.51179321885396, 3.938288813507672, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.51179321885396, 4.297191039697554, 4.520809309268897, 3.124912138585911, 3.51179321885396, 3.938288813507672, 3.51179321885396, 3.51179321885396, 3.51179321885396, 3.938288813507672, 4.094313714615184, 3.51179321885396, 3.51179321885396, 2.968887237478399, 4.094313714615184, 3.938288813507672, 3.171764562560769, 3.708277797259999, 3.124912138585911, 3.51179321885396, 3.51179321885396, 4.821418439094153, 3.51179321885396, 3.938288813507672, 3.938288813507672, 3.51179321885396, 3.51179321885396, 4.520809309268897, 3.51179321885396, 3.51179321885396, 2.5423916428246867, 3.51179321885396, 3.938288813507672]\n",
      "all_sum after preprocessing is: [-2.03884622 -2.03884622 -0.22387063  0.78598535 -0.22387063  0.78598535\n",
      " -0.22387063 -0.22387063 -0.22387063 -0.22387063 -0.22387063 -0.22387063\n",
      " -0.22387063 -0.22387063 -0.22387063 -0.22387063 -0.22387063 -0.22387063\n",
      "  1.6357938   2.16527698 -1.13992738 -0.22387063  0.78598535 -0.22387063\n",
      " -0.22387063 -0.22387063  0.78598535  1.155421   -0.22387063 -0.22387063\n",
      " -1.50936304  1.155421    0.78598535 -1.02899025  0.24136542 -1.13992738\n",
      " -0.22387063 -0.22387063  2.87705907 -0.22387063  0.78598535  0.78598535\n",
      " -0.22387063 -0.22387063  2.16527698 -0.22387063 -0.22387063 -2.51921902\n",
      " -0.22387063  0.78598535]\n",
      "P is: [0.11518426908332215, 0.11518426908332215, 0.4442649268751218, 0.6869686580929495, 0.4442649268751218, 0.6869686580929495, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.8369617856584818, 0.8970877483100531, 0.24233369362373716, 0.4442649268751218, 0.6869686580929495, 0.4442649268751218, 0.4442649268751218, 0.4442649268751218, 0.6869686580929495, 0.760499692111922, 0.4442649268751218, 0.4442649268751218, 0.1810332100515947, 0.760499692111922, 0.6869686580929495, 0.2632799127498619, 0.5600501089274266, 0.24233369362373716, 0.4442649268751218, 0.4442649268751218, 0.9467006636168525, 0.4442649268751218, 0.6869686580929495, 0.6869686580929495, 0.4442649268751218, 0.4442649268751218, 0.8970877483100531, 0.4442649268751218, 0.4442649268751218, 0.07452179044841273, 0.4442649268751218, 0.6869686580929495]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.279\n",
      "(*) epoch 2, cost 2.865\n",
      "(*) epoch 3, cost 2.348\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.081\n",
      "(*) epoch 2, cost 2.419\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 4.604273674561461, 1.857491001217263, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.4495914923759123, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 1.857491001217263, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 3.143192398618375, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 3.143192398618375, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 3.143192398618375, 2.5510919074597256, 2.5510919074597256, 1.857491001217263, 2.5510919074597256, 1.857491001217263, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 4.604273674561461, 2.5510919074597256, 2.5510919074597256, 2.5510919074597256, 3.455687904898088, 2.5510919074597256, 2.5510919074597256]\n",
      "all_sum after preprocessing is: [-0.16014953 -0.16014953 -0.16014953 -0.16014953  4.04320118 -1.58011532\n",
      " -0.16014953 -0.16014953 -0.16014953 -0.16014953 -0.16014953 -0.36794499\n",
      " -0.16014953 -0.16014953 -0.16014953 -0.16014953 -1.58011532 -0.16014953\n",
      " -0.16014953 -0.16014953 -0.16014953 -0.16014953 -0.16014953  1.0520208\n",
      " -0.16014953 -0.16014953 -0.16014953  1.0520208  -0.16014953 -0.16014953\n",
      " -0.16014953 -0.16014953 -0.16014953  1.0520208  -0.16014953 -0.16014953\n",
      " -1.58011532 -0.16014953 -1.58011532 -0.16014953 -0.16014953 -0.16014953\n",
      " -0.16014953  4.04320118 -0.16014953 -0.16014953 -0.16014953  1.69177332\n",
      " -0.16014953 -0.16014953]\n",
      "P is: [0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.9827611605917461, 0.1707791506006404, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.40903767775907457, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.1707791506006404, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.7411627587978152, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.7411627587978152, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.7411627587978152, 0.4600479706022877, 0.4600479706022877, 0.1707791506006404, 0.4600479706022877, 0.1707791506006404, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.9827611605917461, 0.4600479706022877, 0.4600479706022877, 0.4600479706022877, 0.8444572258929258, 0.4600479706022877, 0.4600479706022877]\n",
      "all_sum before preprocessing is: [4.257649841304214, 3.796993236940365, 4.83657755115439, 3.796993236940365, 3.796993236940365, 3.796993236940365, 3.796993236940365, 4.375920946790541, 3.796993236940365, 2.7885339884211557, 4.375920946790541, 4.375920946790541, 3.796993236940365, 3.796993236940365, 5.195918934126098, 4.375920946790541, 4.375920946790541, 4.375920946790541, 4.616991224275922, 4.257649841304214, 3.796993236940365, 4.375920946790541, 3.796993236940365, 3.796993236940365, 3.796993236940365, 4.375920946790541, 4.257649841304214, 3.796993236940365, 4.257649841304214, 4.375920946790541, 4.375920946790541, 2.7885339884211557, 3.796993236940365, 3.796993236940365, 4.257649841304214, 3.796993236940365, 4.375920946790541, 4.126441887747053, 3.796993236940365, 4.375920946790541, 4.375920946790541, 3.796993236940365, 4.375920946790541, 3.796993236940365, 2.3278773840573073, 3.796993236940365, 3.796993236940365, 3.796993236940365, 3.796993236940365, 3.796993236940365]\n",
      "all_sum after preprocessing is: [ 0.52098831 -0.43726316  1.7252657  -0.43726316 -0.43726316 -0.43726316\n",
      " -0.43726316  0.76701422 -0.43726316 -2.5350461   0.76701422  0.76701422\n",
      " -0.43726316 -0.43726316  2.47276266  0.76701422  0.76701422  0.76701422\n",
      "  1.26848527  0.52098831 -0.43726316  0.76701422 -0.43726316 -0.43726316\n",
      " -0.43726316  0.76701422  0.52098831 -0.43726316  0.52098831  0.76701422\n",
      "  0.76701422 -2.5350461  -0.43726316 -0.43726316  0.52098831 -0.43726316\n",
      "  0.76701422  0.24805135 -0.43726316  0.76701422  0.76701422 -0.43726316\n",
      "  0.76701422 -0.43726316 -3.49329757 -0.43726316 -0.43726316 -0.43726316\n",
      " -0.43726316 -0.43726316]\n",
      "P is: [0.6273788377572038, 0.3923932955233114, 0.8488058491859838, 0.3923932955233114, 0.3923932955233114, 0.3923932955233114, 0.3923932955233114, 0.6828746569689409, 0.3923932955233114, 0.0734375476259654, 0.6828746569689409, 0.6828746569689409, 0.3923932955233114, 0.3923932955233114, 0.9222101853389745, 0.6828746569689409, 0.6828746569689409, 0.6828746569689409, 0.7804833409528668, 0.6273788377572038, 0.3923932955233114, 0.6828746569689409, 0.3923932955233114, 0.3923932955233114, 0.3923932955233114, 0.6828746569689409, 0.6273788377572038, 0.3923932955233114, 0.6273788377572038, 0.6828746569689409, 0.6828746569689409, 0.0734375476259654, 0.3923932955233114, 0.3923932955233114, 0.6273788377572038, 0.3923932955233114, 0.6828746569689409, 0.56169681330725, 0.3923932955233114, 0.6828746569689409, 0.6828746569689409, 0.3923932955233114, 0.6828746569689409, 0.3923932955233114, 0.0295035378744513, 0.3923932955233114, 0.3923932955233114, 0.3923932955233114, 0.3923932955233114, 0.3923932955233114]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.493\n",
      "(*) epoch 2, cost 2.628\n",
      "(*) epoch 3, cost 1.973\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.540\n",
      "(*) epoch 2, cost 2.752\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.789377051871471, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.176742259068745, 5.527586227697305, 4.789377051871471, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.789377051871471, 4.176742259068745, 4.176742259068745, 4.441930878208607, 4.914951434894579, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.789377051871471, 4.176742259068745, 4.441930878208607, 4.176742259068745, 5.436598310425515, 4.176742259068745, 4.441930878208607, 2.40108330433803, 4.176742259068745, 4.914951434894579, 4.176742259068745, 4.789377051871471, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.176742259068745, 4.176742259068745, 6.914869518020028, 4.176742259068745, 4.789377051871471, 6.174807486251349, 4.176742259068745, 4.176742259068745, 4.914951434894579, 4.914951434894579, 4.176742259068745, 4.176742259068745, 4.176742259068745]\n",
      "all_sum after preprocessing is: [ 0.56744333 -0.41812516 -0.41812516 -0.41812516 -0.41812516  1.75502803\n",
      "  0.56744333 -0.41812516 -0.41812516 -0.41812516  0.56744333 -0.41812516\n",
      " -0.41812516  0.00849369  0.76945954 -0.41812516 -0.41812516 -0.41812516\n",
      " -0.41812516 -0.41812516 -0.41812516  0.56744333 -0.41812516  0.00849369\n",
      " -0.41812516  1.60865237 -0.41812516  0.00849369 -3.2746941  -0.41812516\n",
      "  0.76945954 -0.41812516  0.56744333 -0.41812516 -0.41812516 -0.41812516\n",
      " -0.41812516 -0.41812516 -0.41812516  3.98680252 -0.41812516  0.56744333\n",
      "  2.79623706 -0.41812516 -0.41812516  0.76945954  0.76945954 -0.41812516\n",
      " -0.41812516 -0.41812516]\n",
      "P is: [0.6381730286349495, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.8525858618847327, 0.6381730286349495, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.6381730286349495, 0.3969654700405787, 0.3969654700405787, 0.5021234086747884, 0.6834039692652512, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.6381730286349495, 0.3969654700405787, 0.5021234086747884, 0.3969654700405787, 0.8332242011243122, 0.3969654700405787, 0.5021234086747884, 0.036449607545084854, 0.3969654700405787, 0.6834039692652512, 0.3969654700405787, 0.6381730286349495, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787, 0.9817791978692267, 0.3969654700405787, 0.6381730286349495, 0.9424721430269998, 0.3969654700405787, 0.3969654700405787, 0.6834039692652512, 0.6834039692652512, 0.3969654700405787, 0.3969654700405787, 0.3969654700405787]\n",
      "all_sum before preprocessing is: [2.9710698626515764, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 3.6610721532534463, 3.2904304764176193, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 1.5961970408311443, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 3.2904304764176193, 3.2904304764176193, 2.0196834912370303, 1.5961970408311443, 2.0196834912370303, 2.0196834912370303, 3.2904304764176193, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.1248516012287824, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 3.2904304764176193, 2.0196834912370303, 3.2904304764176193, 2.0196834912370303, 3.2904304764176193, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303, 3.2904304764176193, 2.0196834912370303, 2.0196834912370303, 2.0196834912370303]\n",
      "all_sum after preprocessing is: [ 1.34378802 -0.45420958 -0.45420958 -0.45420958 -0.45420958 -0.45420958\n",
      "  2.64780341  1.94733842 -0.45420958 -0.45420958 -0.45420958 -0.45420958\n",
      " -0.45420958 -0.45420958 -0.45420958 -0.45420958 -0.45420958 -1.25454439\n",
      " -0.45420958 -0.45420958 -0.45420958  1.94733842  1.94733842 -0.45420958\n",
      " -1.25454439 -0.45420958 -0.45420958  1.94733842 -0.45420958 -0.45420958\n",
      " -0.45420958 -0.45420958 -0.25545541 -0.45420958 -0.45420958 -0.45420958\n",
      "  1.94733842 -0.45420958  1.94733842 -0.45420958  1.94733842 -0.45420958\n",
      " -0.45420958 -0.45420958 -0.45420958 -0.45420958  1.94733842 -0.45420958\n",
      " -0.45420958 -0.45420958]\n",
      "P is: [0.7931121904662548, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.9338754758503595, 0.8751561333227582, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.22191447501989645, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.8751561333227582, 0.8751561333227582, 0.38836036721281436, 0.22191447501989645, 0.38836036721281436, 0.38836036721281436, 0.8751561333227582, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.4364811949125695, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.8751561333227582, 0.38836036721281436, 0.8751561333227582, 0.38836036721281436, 0.8751561333227582, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436, 0.8751561333227582, 0.38836036721281436, 0.38836036721281436, 0.38836036721281436]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.733\n",
      "(*) epoch 2, cost 2.320\n",
      "(*) epoch 3, cost 1.783\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.096\n",
      "(*) epoch 2, cost 1.565\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.11925246110296871, 1.974110324115062, 1.974110324115062, 0.11925246110296871, 0.11925246110296871, 2.9311737590727653, 1.974110324115062, 0.11925246110296871, 1.3637669322827506, 1.974110324115062, 1.3637669322827506, 0.11925246110296871, 1.2615970244338532, 1.3637669322827506, 1.3637669322827506, 0.7295958529352801, 1.076315896060672, 1.974110324115062, 0.11925246110296871, 1.6866592878929834, 1.3637669322827506, 0.7295958529352801, 1.974110324115062, 2.9311737590727653, 2.159391452488243, 0.11925246110296871, 0.11925246110296871, 1.974110324115062, 1.974110324115062, 1.974110324115062, 1.974110324115062, 2.159391452488243, 2.320830367240454, 1.3637669322827506, 1.974110324115062, 1.3637669322827506, 1.3637669322827506, 1.3637669322827506, 0.11925246110296871, 0.11925246110296871, 2.9311737590727653, 1.974110324115062, 1.3637669322827506, 1.6866592878929834, 1.974110324115062, 1.974110324115062, 0.11925246110296871, 1.076315896060672, 0.7295958529352801, 1.076315896060672]\n",
      "all_sum after preprocessing is: [-1.51809933  0.74872689  0.74872689 -1.51809933 -1.51809933  1.91835639\n",
      "  0.74872689 -1.51809933  0.00282477  0.74872689  0.00282477 -1.51809933\n",
      " -0.12203731  0.00282477  0.00282477 -0.77219721 -0.34846982  0.74872689\n",
      " -1.51809933  0.39743229  0.00282477 -0.77219721  0.74872689  1.91835639\n",
      "  0.9751594  -1.51809933 -1.51809933  0.74872689  0.74872689  0.74872689\n",
      "  0.74872689  0.9751594   1.17245428  0.00282477  0.74872689  0.00282477\n",
      "  0.00282477  0.00282477 -1.51809933 -1.51809933  1.91835639  0.74872689\n",
      "  0.00282477  0.39743229  0.74872689  0.74872689 -1.51809933 -0.34846982\n",
      " -0.77219721 -0.34846982]\n",
      "P is: [0.179741573878868, 0.6789012311167602, 0.6789012311167602, 0.179741573878868, 0.179741573878868, 0.8719550378772297, 0.6789012311167602, 0.179741573878868, 0.5007061931331435, 0.6789012311167602, 0.5007061931331435, 0.179741573878868, 0.4695284802340381, 0.5007061931331435, 0.5007061931331435, 0.3160039968402998, 0.4137535344271609, 0.6789012311167602, 0.179741573878868, 0.5980705845187003, 0.5007061931331435, 0.3160039968402998, 0.6789012311167602, 0.8719550378772297, 0.7261466795386867, 0.179741573878868, 0.179741573878868, 0.6789012311167602, 0.6789012311167602, 0.6789012311167602, 0.6789012311167602, 0.7261466795386867, 0.7635883515457744, 0.5007061931331435, 0.6789012311167602, 0.5007061931331435, 0.5007061931331435, 0.5007061931331435, 0.179741573878868, 0.179741573878868, 0.8719550378772297, 0.6789012311167602, 0.5007061931331435, 0.5980705845187003, 0.6789012311167602, 0.6789012311167602, 0.179741573878868, 0.4137535344271609, 0.3160039968402998, 0.4137535344271609]\n",
      "all_sum before preprocessing is: [1.3059794042248087, 1.3059794042248087, 1.114887941642969, 1.114887941642969, 2.0661589164456924, 1.114887941642969, 1.114887941642969, 1.114887941642969, 1.3059794042248087, 1.114887941642969, 1.3059794042248087, 1.8750674538638525, 1.114887941642969, 1.114887941642969, 1.114887941642969, 1.3059794042248087, 1.3059794042248087, 1.114887941642969, 1.114887941642969, 1.3059794042248087, 1.4228514224479865, 1.3059794042248087, 1.114887941642969, 1.114887941642969, 1.114887941642969, 1.3059794042248087, 1.3059794042248087, 1.3059794042248087, 1.8750674538638525, 1.3059794042248087, 1.3059794042248087, 1.3059794042248087, 1.3059794042248087, 1.8750674538638525, 1.3059794042248087, 1.4228514224479865, 1.114887941642969, 1.114887941642969, 1.3059794042248087, 1.3059794042248087, 1.114887941642969, 1.114887941642969, 0.5740874651073556, 1.114887941642969, 1.114887941642969, 1.114887941642969, 1.114887941642969, 1.8750674538638525, 1.3059794042248087, 1.114887941642969]\n",
      "all_sum after preprocessing is: [ 0.14662127  0.14662127 -0.60788333 -0.60788333  3.14811035 -0.60788333\n",
      " -0.60788333 -0.60788333  0.14662127 -0.60788333  0.14662127  2.39360575\n",
      " -0.60788333 -0.60788333 -0.60788333  0.14662127  0.14662127 -0.60788333\n",
      " -0.60788333  0.14662127  0.60807818  0.14662127 -0.60788333 -0.60788333\n",
      " -0.60788333  0.14662127  0.14662127  0.14662127  2.39360575  0.14662127\n",
      "  0.14662127  0.14662127  0.14662127  2.39360575  0.14662127  0.60807818\n",
      " -0.60788333 -0.60788333  0.14662127  0.14662127 -0.60788333 -0.60788333\n",
      " -2.7431773  -0.60788333 -0.60788333 -0.60788333 -0.60788333  2.39360575\n",
      "  0.14662127 -0.60788333]\n",
      "P is: [0.5365897911510826, 0.5365897911510826, 0.35254219026256717, 0.35254219026256717, 0.958834199814217, 0.35254219026256717, 0.35254219026256717, 0.35254219026256717, 0.5365897911510826, 0.35254219026256717, 0.5365897911510826, 0.9163384087941595, 0.35254219026256717, 0.35254219026256717, 0.35254219026256717, 0.5365897911510826, 0.5365897911510826, 0.35254219026256717, 0.35254219026256717, 0.5365897911510826, 0.647502283933835, 0.5365897911510826, 0.35254219026256717, 0.35254219026256717, 0.35254219026256717, 0.5365897911510826, 0.5365897911510826, 0.5365897911510826, 0.9163384087941595, 0.5365897911510826, 0.5365897911510826, 0.5365897911510826, 0.5365897911510826, 0.9163384087941595, 0.5365897911510826, 0.647502283933835, 0.35254219026256717, 0.35254219026256717, 0.5365897911510826, 0.5365897911510826, 0.35254219026256717, 0.35254219026256717, 0.060473129403327185, 0.35254219026256717, 0.35254219026256717, 0.35254219026256717, 0.35254219026256717, 0.9163384087941595, 0.5365897911510826, 0.35254219026256717]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.520\n",
      "(*) epoch 2, cost 1.962\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.824\n",
      "(*) epoch 2, cost 3.019\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.008984414397459, 6.008984414397459, 6.6032973941675905, 3.395942644029118, 5.912680677646806, 6.008984414397459, 5.422048094927279, 4.520695029979863, 6.008984414397459, 5.041062286389773, 6.880602805654492, 4.267561035286151, 5.041062286389773, 6.880602805654492, 6.008984414397459, 4.520695029979863, 7.261588614191997, 3.395942644029118, 6.506993657416938, 5.635375266159905, 3.395942644029118, 6.008984414397459, 4.363864772036804, 6.008984414397459, 3.395942644029118, 4.363864772036804, 5.041062286389773, 5.0479142863013315, 5.041062286389773, 4.958177751806935, 7.938786128544967, 4.363864772036804, 5.235483163293837, 6.6032973941675905, 5.041062286389773, 8.906708256552653, 5.041062286389773, 8.191920123238681, 6.008984414397459, 7.491680920879055, 6.389970222934965, 6.008984414397459, 5.041062286389773, 4.363864772036804, 6.008984414397459, 6.880602805654492, 7.1337368003482045, 6.880602805654492, 5.912680677646806, 5.041062286389773]\n",
      "all_sum after preprocessing is: [ 0.27501006  0.27501006  0.75549737 -1.83756939  0.19715088  0.27501006\n",
      " -0.19951339 -0.92823499  0.27501006 -0.50753097  0.97969191 -1.13288754\n",
      " -0.50753097  0.97969191  0.27501006 -0.92823499  1.28770949 -1.83756939\n",
      "  0.67763818 -0.02704367 -1.83756939  0.27501006 -1.05502836  0.27501006\n",
      " -1.83756939 -1.05502836 -0.50753097 -0.5019913  -0.50753097 -0.57454106\n",
      "  1.83520688 -1.05502836 -0.35034651  0.75549737 -0.50753097  2.61774791\n",
      " -0.50753097  2.03985944  0.27501006  1.47373341  0.58302764  0.27501006\n",
      " -0.50753097 -1.05502836  0.27501006  0.97969191  1.18434447  0.97969191\n",
      "  0.19715088 -0.50753097]\n",
      "P is: [0.5683224523406978, 0.5683224523406978, 0.6803753658878714, 0.1373390099796099, 0.549128693472998, 0.5683224523406978, 0.45028644912692634, 0.2832829344952582, 0.5683224523406978, 0.37577250238505644, 0.7270470807367189, 0.24362860882592483, 0.37577250238505644, 0.7270470807367189, 0.5683224523406978, 0.2832829344952582, 0.783759243978292, 0.1373390099796099, 0.6632113606992469, 0.4932394956010353, 0.1373390099796099, 0.5683224523406978, 0.2582606872153152, 0.5683224523406978, 0.1373390099796099, 0.2582606872153152, 0.37577250238505644, 0.37707282107608114, 0.37577250238505644, 0.3601896610013716, 0.8623808468822561, 0.2582606872153152, 0.4132983954427695, 0.6803753658878714, 0.37577250238505644, 0.9319951073796604, 0.37577250238505644, 0.8849189541182025, 0.5683224523406978, 0.8136241829655467, 0.6417637681399058, 0.5683224523406978, 0.37577250238505644, 0.2582606872153152, 0.5683224523406978, 0.7270470807367189, 0.7657280513528415, 0.7270470807367189, 0.549128693472998, 0.37577250238505644]\n",
      "all_sum before preprocessing is: [1.4246440025888478, 1.7552052634256796, 2.420094833054235, 2.536599422788517, 2.1466931369460545, 2.8100011188966976, 1.7552052634256796, 1.7552052634256796, 1.4246440025888478, 1.4246440025888478, 2.145111549268142, 2.8100011188966976, 2.8728867517881937, 1.7552052634256796, 2.1466931369460545, 1.7552052634256796, 2.420094833054235, 2.145111549268142, 1.7552052634256796, 2.4829804659457313, 1.7552052634256796, 1.3684860913919739, 1.7552052634256796, 2.1466931369460545, 2.4829804659457313, 2.536599422788517, 2.0369162689063947, 2.1466931369460545, 2.145111549268142, 2.145111549268142, 3.5393579090946616, 1.4246440025888478, 2.145111549268142, 2.4829804659457313, 2.8100011188966976, 2.145111549268142, 2.8100011188966976, 1.7552052634256796, 1.7552052634256796, 1.7552052634256796, 1.7552052634256796, 2.1466931369460545, 2.145111549268142, 2.4829804659457313, 2.145111549268142, 1.7552052634256796, 2.145111549268142, 2.1466931369460545, 1.7552052634256796, 2.145111549268142]\n",
      "all_sum after preprocessing is: [-1.53934649 -0.79701126  0.69611878  0.95775095  0.08214572  1.57172402\n",
      " -0.79701126 -0.79701126 -1.53934649 -1.53934649  0.07859397  1.57172402\n",
      "  1.7129451  -0.79701126  0.08214572 -0.79701126  0.69611878  0.07859397\n",
      " -0.79701126  0.83733987 -0.79701126 -1.66545926 -0.79701126  0.08214572\n",
      "  0.83733987  0.95775095 -0.16437814  0.08214572  0.07859397  0.07859397\n",
      "  3.20962689 -1.53934649  0.07859397  0.83733987  1.57172402  0.07859397\n",
      "  1.57172402 -0.79701126 -0.79701126 -0.79701126 -0.79701126  0.08214572\n",
      "  0.07859397  0.83733987  0.07859397 -0.79701126  0.07859397  0.08214572\n",
      " -0.79701126  0.07859397]\n",
      "P is: [0.1766302962370548, 0.3106652016249389, 0.6673266945738944, 0.7226712824196224, 0.5205248886144462, 0.8280292414530797, 0.3106652016249389, 0.3106652016249389, 0.1766302962370548, 0.1766302962370548, 0.5196383857178094, 0.8280292414530797, 0.8472178874735651, 0.3106652016249389, 0.5205248886144462, 0.3106652016249389, 0.6673266945738944, 0.5196383857178094, 0.3106652016249389, 0.6979046654605269, 0.3106652016249389, 0.15903051720369235, 0.3106652016249389, 0.5205248886144462, 0.6979046654605269, 0.7226712824196224, 0.458997747825921, 0.5205248886144462, 0.5196383857178094, 0.5196383857178094, 0.9611949510601038, 0.1766302962370548, 0.5196383857178094, 0.6979046654605269, 0.8280292414530797, 0.5196383857178094, 0.8280292414530797, 0.3106652016249389, 0.3106652016249389, 0.3106652016249389, 0.3106652016249389, 0.5205248886144462, 0.5196383857178094, 0.6979046654605269, 0.5196383857178094, 0.3106652016249389, 0.5196383857178094, 0.5205248886144462, 0.3106652016249389, 0.5196383857178094]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.775\n",
      "(*) epoch 2, cost 4.056\n",
      "(*) epoch 3, cost 2.938\n",
      "(*) epoch 4, cost 2.489\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.643\n",
      "(*) epoch 2, cost 3.937\n",
      "(*) epoch 3, cost 3.157\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.1116684942853903, 1.2344843159230532, 1.1116684942853903, 1.2344843159230532, 1.1116684942853903, 1.7117706139598226, 1.2344843159230532, 1.1116684942853903, 1.1116684942853903, 1.1116684942853903, 1.1116684942853903, 1.2344843159230532, 1.2344843159230532, 1.1116684942853903, 1.2344843159230532, 1.2344843159230532, 1.8345864355974855, 1.8345864355974855, 1.8345864355974855, 1.8345864355974855, 1.2344843159230532, 1.2344843159230532, 1.2344843159230532, 1.1116684942853903, 1.7117706139598226, 1.7117706139598226, 1.1116684942853903, 1.2344843159230532, 1.2344843159230532, 1.2344843159230532, 1.2344843159230532, 1.2344843159230532, 1.2344843159230532, 1.2344843159230532, 1.7117706139598226, 1.2344843159230532, 1.1116684942853903, 1.1116684942853903, 1.1116684942853903, 1.2344843159230532, 1.7117706139598226, 1.8197679885984588, 1.2344843159230532, 1.8345864355974855, 1.2344843159230532, 1.2344843159230532, 1.1116684942853903, 1.2344843159230532, 1.1116684942853903, 1.1116684942853903]\n",
      "all_sum after preprocessing is: [-0.80196983 -0.31667748 -0.80196983 -0.31667748 -0.80196983  1.56926349\n",
      " -0.31667748 -0.80196983 -0.80196983 -0.80196983 -0.80196983 -0.31667748\n",
      " -0.31667748 -0.80196983 -0.31667748 -0.31667748  2.05455584  2.05455584\n",
      "  2.05455584  2.05455584 -0.31667748 -0.31667748 -0.31667748 -0.80196983\n",
      "  1.56926349  1.56926349 -0.80196983 -0.31667748 -0.31667748 -0.31667748\n",
      " -0.31667748 -0.31667748 -0.31667748 -0.31667748  1.56926349 -0.31667748\n",
      " -0.80196983 -0.80196983 -0.80196983 -0.31667748  1.56926349  1.99600248\n",
      " -0.31667748  2.05455584 -0.31667748 -0.31667748 -0.80196983 -0.31667748\n",
      " -0.80196983 -0.80196983]\n",
      "P is: [0.3096043116724826, 0.4214856852214584, 0.3096043116724826, 0.4214856852214584, 0.3096043116724826, 0.8276785879360001, 0.4214856852214584, 0.3096043116724826, 0.3096043116724826, 0.3096043116724826, 0.3096043116724826, 0.4214856852214584, 0.4214856852214584, 0.3096043116724826, 0.4214856852214584, 0.4214856852214584, 0.8864071525176562, 0.8864071525176562, 0.8864071525176562, 0.8864071525176562, 0.4214856852214584, 0.4214856852214584, 0.4214856852214584, 0.3096043116724826, 0.8276785879360001, 0.8276785879360001, 0.3096043116724826, 0.4214856852214584, 0.4214856852214584, 0.4214856852214584, 0.4214856852214584, 0.4214856852214584, 0.4214856852214584, 0.4214856852214584, 0.8276785879360001, 0.4214856852214584, 0.3096043116724826, 0.3096043116724826, 0.3096043116724826, 0.4214856852214584, 0.8276785879360001, 0.8803767250640572, 0.4214856852214584, 0.8864071525176562, 0.4214856852214584, 0.4214856852214584, 0.3096043116724826, 0.4214856852214584, 0.3096043116724826, 0.3096043116724826]\n",
      "all_sum before preprocessing is: [2.0307560859949216, 1.8253030849090353, 1.459014385762843, 1.459014385762843, 2.3970447851411136, 2.0307560859949216, 2.3974263443377826, 2.0307560859949216, 2.0307560859949216, 2.0307560859949216, 1.459014385762843, 2.0307560859949216, 2.0307560859949216, 1.459014385762843, 1.8253030849090353, 2.3974263443377826, 2.0307560859949216, 2.7637150434839746, 2.0307560859949216, 2.0307560859949216, 2.0307560859949216, 2.0307560859949216, 2.3970447851411136, 2.0307560859949216, 2.0307560859949216, 1.459014385762843, 2.0307560859949216, 2.0307560859949216, 1.459014385762843, 2.0307560859949216, 1.459014385762843, 1.459014385762843, 2.0307560859949216, 2.0307560859949216, 1.8256846441057035, 2.0307560859949216, 2.0307560859949216, 2.3970447851411136, 2.3974263443377826, 2.1919733432518957, 2.0307560859949216, 1.8256846441057035, 2.0307560859949216, 1.8256846441057035, 2.0307560859949216, 2.0307560859949216, 2.0307560859949216, 1.459014385762843, 2.0307560859949216, 2.0307560859949216]\n",
      "all_sum after preprocessing is: [ 0.20918981 -0.48880091 -1.73320287 -1.73320287  1.45359177  0.20918981\n",
      "  1.45488805  0.20918981  0.20918981  0.20918981 -1.73320287  0.20918981\n",
      "  0.20918981 -1.73320287 -0.48880091  1.45488805  0.20918981  2.69929\n",
      "  0.20918981  0.20918981  0.20918981  0.20918981  1.45359177  0.20918981\n",
      "  0.20918981 -1.73320287  0.20918981  0.20918981 -1.73320287  0.20918981\n",
      " -1.73320287 -1.73320287  0.20918981  0.20918981 -0.48750463  0.20918981\n",
      "  0.20918981  1.45359177  1.45488805  0.75689732  0.20918981 -0.48750463\n",
      "  0.20918981 -0.48750463  0.20918981  0.20918981  0.20918981 -1.73320287\n",
      "  0.20918981  0.20918981]\n",
      "P is: [0.5521075712344032, 0.3801760821911679, 0.15017835619481223, 0.15017835619481223, 0.8105505949457827, 0.5521075712344032, 0.8107495695314532, 0.5521075712344032, 0.5521075712344032, 0.5521075712344032, 0.15017835619481223, 0.5521075712344032, 0.5521075712344032, 0.15017835619481223, 0.3801760821911679, 0.8107495695314532, 0.5521075712344032, 0.9369847354850894, 0.5521075712344032, 0.5521075712344032, 0.5521075712344032, 0.5521075712344032, 0.8105505949457827, 0.5521075712344032, 0.5521075712344032, 0.15017835619481223, 0.5521075712344032, 0.5521075712344032, 0.15017835619481223, 0.5521075712344032, 0.15017835619481223, 0.15017835619481223, 0.5521075712344032, 0.5521075712344032, 0.3804815880989969, 0.5521075712344032, 0.5521075712344032, 0.8105505949457827, 0.8107495695314532, 0.680679729504606, 0.5521075712344032, 0.3804815880989969, 0.5521075712344032, 0.3804815880989969, 0.5521075712344032, 0.5521075712344032, 0.5521075712344032, 0.15017835619481223, 0.5521075712344032, 0.5521075712344032]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.999\n",
      "(*) epoch 2, cost 1.433\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.959\n",
      "(*) epoch 2, cost 2.381\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [3.4898234192307873, 4.18285885785577, 4.937646371012564, 5.405510072480731, 4.730455850629888, 5.405510072480731, 3.9576871206989552, 4.650722559323937, 5.405510072480731, 4.18285885785577, 3.9576871206989552, 5.405510072480731, 1.9044632839991564, 5.405510072480731, 5.405510072480731, 5.405510072480731, 5.405510072480731, 5.405510072480731, 4.244610932387581, 4.937646371012564, 5.405510072480731, 4.244610932387581, 5.405510072480731, 5.42349128925487, 5.405510072480731, 5.405510072480731, 4.937646371012564, 4.937646371012564, 4.244610932387581, 4.712474633855749, 4.262592149161721, 5.405510072480731, 4.18285885785577, 4.650722559323937, 5.405510072480731, 5.405510072480731, 3.4898234192307873, 4.937646371012564, 4.244610932387581, 5.405510072480731, 4.937646371012564, 4.955627587786703, 5.405510072480731, 4.712474633855749, 4.937646371012564, 4.244610932387581, 5.405510072480731, 4.937646371012564, 5.405510072480731, 5.405510072480731]\n",
      "all_sum after preprocessing is: [-1.92058241 -0.9301635   0.14850548  0.81713083 -0.14759108  0.81713083\n",
      " -1.25195707 -0.26153815  0.81713083 -0.9301635  -1.25195707  0.81713083\n",
      " -4.18622509  0.81713083  0.81713083  0.81713083  0.81713083  0.81713083\n",
      " -0.84191343  0.14850548  0.81713083 -0.84191343  0.81713083  0.84282784\n",
      "  0.81713083  0.81713083  0.14850548  0.14850548 -0.84191343 -0.17328809\n",
      " -0.81621642  0.81713083 -0.9301635  -0.26153815  0.81713083  0.81713083\n",
      " -1.92058241  0.14850548 -0.84191343  0.81713083  0.14850548  0.17420249\n",
      "  0.81713083 -0.17328809  0.14850548 -0.84191343  0.81713083  0.14850548\n",
      "  0.81713083  0.81713083]\n",
      "P is: [0.12779663368141658, 0.2828915456591977, 0.5370582896819186, 0.693626956114297, 0.46316906421679677, 0.693626956114297, 0.22236154497912872, 0.4349856344021605, 0.693626956114297, 0.2828915456591977, 0.22236154497912872, 0.693626956114297, 0.014975881894154868, 0.693626956114297, 0.693626956114297, 0.693626956114297, 0.693626956114297, 0.693626956114297, 0.3011319462525377, 0.5370582896819186, 0.693626956114297, 0.3011319462525377, 0.693626956114297, 0.6990604572637732, 0.693626956114297, 0.693626956114297, 0.5370582896819186, 0.5370582896819186, 0.3011319462525377, 0.4567860630546475, 0.3065673978337553, 0.693626956114297, 0.2828915456591977, 0.4349856344021605, 0.693626956114297, 0.693626956114297, 0.12779663368141658, 0.5370582896819186, 0.3011319462525377, 0.693626956114297, 0.5370582896819186, 0.5434408223403674, 0.693626956114297, 0.4567860630546475, 0.5370582896819186, 0.3011319462525377, 0.693626956114297, 0.5370582896819186, 0.693626956114297, 0.693626956114297]\n",
      "all_sum before preprocessing is: [3.900143797248462, 3.377239765955065, 1.9855868651774964, 1.9855868651774964, 1.9855868651774964, 2.4366119172929546, 2.584388301291682, 1.9855868651774964, 1.9855868651774964, 3.377239765955065, 3.900143797248462, 1.9855868651774964, 5.2917966980260305, 5.742821750141489, 3.377239765955065, 5.2917966980260305, 3.377239765955065, 4.3775678610095135, 1.9855868651774964, 3.900143797248462, 3.377239765955065, 1.9855868651774964, 3.377239765955065, 3.377239765955065, 3.377239765955065, 1.9855868651774964, 3.377239765955065, 3.377239765955065, 1.9855868651774964, 5.2917966980260305, 5.2917966980260305, 4.498945233362647, 3.828264818070523, 3.377239765955065, 3.377239765955065, 1.1927354005141129, 3.377239765955065, 4.498945233362647, 3.377239765955065, 3.377239765955065, 3.377239765955065, 5.2917966980260305, 2.584388301291682, 2.584388301291682, 1.9855868651774964, 2.584388301291682, 1.9855868651774964, 3.377239765955065, 2.584388301291682, 1.9855868651774964]\n",
      "all_sum after preprocessing is: [ 0.61704296  0.14427889 -1.11393188 -1.11393188 -1.11393188 -0.7061545\n",
      " -0.57254802 -1.11393188 -1.11393188  0.14427889  0.61704296 -1.11393188\n",
      "  1.87525373  2.28303112  0.14427889  1.87525373  0.14427889  1.04868802\n",
      " -1.11393188  0.61704296  0.14427889 -1.11393188  0.14427889  0.14427889\n",
      "  0.14427889 -1.11393188  0.14427889  0.14427889 -1.11393188  1.87525373\n",
      "  1.87525373  1.15842682  0.55205628  0.14427889  0.14427889 -1.83075879\n",
      "  0.14427889  1.15842682  0.14427889  0.14427889  0.14427889  1.87525373\n",
      " -0.57254802 -0.57254802 -1.11393188 -0.57254802 -1.11393188  0.14427889\n",
      " -0.57254802 -1.11393188]\n",
      "P is: [0.6495457179418441, 0.5360072833641822, 0.24713859161663873, 0.24713859161663873, 0.24713859161663873, 0.3304491123270635, 0.36064909063001394, 0.24713859161663873, 0.24713859161663873, 0.5360072833641822, 0.6495457179418441, 0.24713859161663873, 0.8670650088454841, 0.9074618990762604, 0.5360072833641822, 0.8670650088454841, 0.5360072833641822, 0.7405228838118618, 0.24713859161663873, 0.6495457179418441, 0.5360072833641822, 0.24713859161663873, 0.5360072833641822, 0.5360072833641822, 0.5360072833641822, 0.24713859161663873, 0.5360072833641822, 0.5360072833641822, 0.24713859161663873, 0.8670650088454841, 0.8670650088454841, 0.7610467424455605, 0.6346125315993288, 0.5360072833641822, 0.5360072833641822, 0.138147904077754, 0.5360072833641822, 0.7610467424455605, 0.5360072833641822, 0.5360072833641822, 0.5360072833641822, 0.8670650088454841, 0.36064909063001394, 0.36064909063001394, 0.24713859161663873, 0.36064909063001394, 0.24713859161663873, 0.5360072833641822, 0.36064909063001394, 0.24713859161663873]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.246\n",
      "(*) epoch 2, cost 3.426\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.584\n",
      "(*) epoch 2, cost 2.721\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.309749022056672, 2.2446322108333048, 2.2446322108333048, 3.627459501147808, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.309749022056672, 2.2446322108333048, 3.3113972033980446, 2.309749022056672, 2.2446322108333048, 3.245931004531018, 2.309749022056672, 2.309749022056672, 2.309749022056672, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.309749022056672, 2.2446322108333048, 2.309749022056672, 2.309749022056672, 2.309749022056672, 2.309749022056672, 2.2446322108333048, 2.2446322108333048, 3.3113972033980446, 2.2446322108333048, 2.2446322108333048, 3.562342689924441, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.2446322108333048, 2.309749022056672, 2.2446322108333048, 2.309749022056672, 2.2446322108333048, 2.2446322108333048, 2.309749022056672, 2.309749022056672, 2.2446322108333048]\n",
      "all_sum after preprocessing is: [-0.20425818 -0.39126045 -0.39126045  3.57993885 -0.39126045 -0.39126045\n",
      " -0.39126045 -0.20425818 -0.39126045  2.67227209 -0.20425818 -0.39126045\n",
      "  2.48426645 -0.20425818 -0.20425818 -0.20425818 -0.39126045 -0.39126045\n",
      " -0.39126045 -0.39126045 -0.39126045 -0.39126045 -0.39126045 -0.20425818\n",
      " -0.39126045 -0.20425818 -0.20425818 -0.20425818 -0.20425818 -0.39126045\n",
      " -0.39126045  2.67227209 -0.39126045 -0.39126045  3.39293659 -0.39126045\n",
      " -0.39126045 -0.39126045 -0.39126045 -0.39126045 -0.39126045 -0.39126045\n",
      " -0.20425818 -0.39126045 -0.20425818 -0.39126045 -0.39126045 -0.20425818\n",
      " -0.20425818 -0.39126045]\n",
      "P is: [0.4491122576570257, 0.40341391106257213, 0.40341391106257213, 0.9728786693958628, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.4491122576570257, 0.40341391106257213, 0.9353705206119165, 0.4491122576570257, 0.40341391106257213, 0.9230314528239932, 0.4491122576570257, 0.4491122576570257, 0.4491122576570257, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.4491122576570257, 0.40341391106257213, 0.4491122576570257, 0.4491122576570257, 0.4491122576570257, 0.4491122576570257, 0.40341391106257213, 0.40341391106257213, 0.9353705206119165, 0.40341391106257213, 0.40341391106257213, 0.9674830554532092, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.40341391106257213, 0.4491122576570257, 0.40341391106257213, 0.4491122576570257, 0.40341391106257213, 0.40341391106257213, 0.4491122576570257, 0.4491122576570257, 0.40341391106257213]\n",
      "all_sum before preprocessing is: [1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 2.938053665018141, 1.4293623035142333, 1.674106200481682, 1.4293623035142333, 1.5624260446108227, 1.674106200481682, 1.5624260446108227, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 2.0676114054442714, 1.4293623035142333, 1.674106200481682, 1.4293623035142333, 2.938053665018141, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.674106200481682, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.674106200481682, 1.4293623035142333, 1.674106200481682, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.674106200481682, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333, 1.4293623035142333]\n",
      "all_sum after preprocessing is: [-0.36452188 -0.36452188 -0.36452188 -0.36452188 -0.36452188 -0.36452188\n",
      "  4.51528531 -0.36452188  0.42709333 -0.36452188  0.06586794  0.42709333\n",
      "  0.06586794 -0.36452188 -0.36452188 -0.36452188 -0.36452188 -0.36452188\n",
      " -0.36452188  1.69987157 -0.36452188  0.42709333 -0.36452188  4.51528531\n",
      " -0.36452188 -0.36452188 -0.36452188 -0.36452188 -0.36452188  0.42709333\n",
      " -0.36452188 -0.36452188 -0.36452188 -0.36452188 -0.36452188  0.42709333\n",
      " -0.36452188  0.42709333 -0.36452188 -0.36452188 -0.36452188  0.42709333\n",
      " -0.36452188 -0.36452188 -0.36452188 -0.36452188 -0.36452188 -0.36452188\n",
      " -0.36452188 -0.36452188]\n",
      "P is: [0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.9891779156014208, 0.4098653890642635, 0.6051793695282541, 0.4098653890642635, 0.5164610338370245, 0.6051793695282541, 0.5164610338370245, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.8455179599828563, 0.4098653890642635, 0.6051793695282541, 0.4098653890642635, 0.9891779156014208, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.6051793695282541, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.6051793695282541, 0.4098653890642635, 0.6051793695282541, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.6051793695282541, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635, 0.4098653890642635]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.702\n",
      "(*) epoch 2, cost 1.318\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.209\n",
      "(*) epoch 2, cost 1.135\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.176687657467996, 2.176687657467996, 1.286912579763455, 1.286912579763455, 2.093070147275814, 2.176687657467996, 2.093070147275814, 2.093070147275814, 1.286912579763455, 2.176687657467996, 2.176687657467996, 2.5630355184171068, 1.286912579763455, 2.093070147275814, 1.286912579763455, 2.093070147275814, 1.286912579763455, 2.9828452249803545, 2.9828452249803545, 2.176687657467996, 1.286912579763455, 2.176687657467996, 1.286912579763455, 1.286912579763455, 2.176687657467996, 1.286912579763455, 1.286912579763455, 1.286912579763455, 2.9828452249803545, 1.286912579763455, 1.286912579763455, 2.176687657467996, 1.286912579763455, 2.176687657467996, 2.176687657467996, 1.286912579763455, 2.176687657467996, 2.093070147275814, 1.286912579763455, 1.286912579763455, 3.5767596721628374, 1.286912579763455, 1.286912579763455, 2.9828452249803545, 1.286912579763455, 2.093070147275814, 1.286912579763455, 1.286912579763455, 1.286912579763455, 1.286912579763455]\n",
      "all_sum after preprocessing is: [ 0.59067636  0.59067636 -0.88409621 -0.88409621  0.45208312  0.59067636\n",
      "  0.45208312  0.45208312 -0.88409621  0.59067636  0.59067636  1.23103508\n",
      " -0.88409621  0.45208312 -0.88409621  0.45208312 -0.88409621  1.9268557\n",
      "  1.9268557   0.59067636 -0.88409621  0.59067636 -0.88409621 -0.88409621\n",
      "  0.59067636 -0.88409621 -0.88409621 -0.88409621  1.9268557  -0.88409621\n",
      " -0.88409621  0.59067636 -0.88409621  0.59067636  0.59067636 -0.88409621\n",
      "  0.59067636  0.45208312 -0.88409621 -0.88409621  2.91124913 -0.88409621\n",
      " -0.88409621  1.9268557  -0.88409621  0.45208312 -0.88409621 -0.88409621\n",
      " -0.88409621 -0.88409621]\n",
      "P is: [0.6435203200744943, 0.6435203200744943, 0.29232966320486564, 0.29232966320486564, 0.6111344011941175, 0.6435203200744943, 0.6111344011941175, 0.6111344011941175, 0.29232966320486564, 0.6435203200744943, 0.6435203200744943, 0.773999686886801, 0.29232966320486564, 0.6111344011941175, 0.29232966320486564, 0.6111344011941175, 0.29232966320486564, 0.8729009847356527, 0.8729009847356527, 0.6435203200744943, 0.29232966320486564, 0.6435203200744943, 0.29232966320486564, 0.29232966320486564, 0.6435203200744943, 0.29232966320486564, 0.29232966320486564, 0.29232966320486564, 0.8729009847356527, 0.29232966320486564, 0.29232966320486564, 0.6435203200744943, 0.29232966320486564, 0.6435203200744943, 0.6435203200744943, 0.29232966320486564, 0.6435203200744943, 0.6111344011941175, 0.29232966320486564, 0.29232966320486564, 0.9483997281636537, 0.29232966320486564, 0.29232966320486564, 0.8729009847356527, 0.29232966320486564, 0.6111344011941175, 0.29232966320486564, 0.29232966320486564, 0.29232966320486564, 0.29232966320486564]\n",
      "all_sum before preprocessing is: [4.234121801887897, 5.1151822587060165, 4.435794638476471, 4.435794638476471, 5.1151822587060165, 4.435794638476471, 5.1151822587060165, 4.435794638476471, 5.1151822587060165, 5.1151822587060165, 5.1151822587060165, 4.234121801887897, 5.1151822587060165, 5.1151822587060165, 6.2777343158538805, 6.2777343158538805, 5.1151822587060165, 3.772472791457472, 5.1151822587060165, 4.435794638476471, 4.435794638476471, 5.1151822587060165, 5.598346695624335, 5.1151822587060165, 5.1151822587060165, 5.1151822587060165, 5.1151822587060165, 4.947147466103837, 3.093085171227927, 4.947147466103837, 5.1151822587060165, 5.1151822587060165, 6.359241306493585, 5.1151822587060165, 4.435794638476471, 5.1151822587060165, 4.435794638476471, 5.1151822587060165, 5.1151822587060165, 4.435794638476471, 5.1151822587060165, 5.1151822587060165, 4.435794638476471, 4.435794638476471, 6.2777343158538805, 4.947147466103837, 5.1151822587060165, 4.435794638476471, 4.435794638476471, 5.1488203026924095]\n",
      "all_sum after preprocessing is: [-1.17214074  0.31002376 -0.83287648 -0.83287648  0.31002376 -0.83287648\n",
      "  0.31002376 -0.83287648  0.31002376  0.31002376  0.31002376 -1.17214074\n",
      "  0.31002376  0.31002376  2.26572766  2.26572766  0.31002376 -1.94875007\n",
      "  0.31002376 -0.83287648 -0.83287648  0.31002376  1.12282742  0.31002376\n",
      "  0.31002376  0.31002376  0.31002376  0.02734712 -3.0916503   0.02734712\n",
      "  0.31002376  0.31002376  2.40284285  0.31002376 -0.83287648  0.31002376\n",
      " -0.83287648  0.31002376  0.31002376 -0.83287648  0.31002376  0.31002376\n",
      " -0.83287648 -0.83287648  2.26572766  0.02734712  0.31002376 -0.83287648\n",
      " -0.83287648  0.36661138]\n",
      "P is: [0.2364682541774417, 0.5768910594947148, 0.30303719660236217, 0.30303719660236217, 0.5768910594947148, 0.30303719660236217, 0.5768910594947148, 0.30303719660236217, 0.5768910594947148, 0.5768910594947148, 0.5768910594947148, 0.2364682541774417, 0.5768910594947148, 0.5768910594947148, 0.905998564047063, 0.905998564047063, 0.5768910594947148, 0.12468971478439064, 0.5768910594947148, 0.30303719660236217, 0.30303719660236217, 0.5768910594947148, 0.7545127978743871, 0.5768910594947148, 0.5768910594947148, 0.5768910594947148, 0.5768910594947148, 0.5068363546453425, 0.04345298863653394, 0.5068363546453425, 0.5768910594947148, 0.5768910594947148, 0.9170438281250975, 0.5768910594947148, 0.30303719660236217, 0.5768910594947148, 0.30303719660236217, 0.5768910594947148, 0.5768910594947148, 0.30303719660236217, 0.5768910594947148, 0.5768910594947148, 0.30303719660236217, 0.30303719660236217, 0.905998564047063, 0.5068363546453425, 0.5768910594947148, 0.30303719660236217, 0.30303719660236217, 0.5906399141581682]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.607\n",
      "(*) epoch 2, cost 1.681\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.461\n",
      "(*) epoch 2, cost 2.541\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.0950866928055114, 1.0950866928055114, 2.424408334158726, 2.424408334158726, 2.424408334158726, 1.4337527726081754, 1.4337527726081754, 1.2618879356904829, 2.424408334158726, 1.4337527726081754, 1.0950866928055114, 1.0950866928055114, 1.0950866928055114, 2.2064163219246664, 2.591209577043698, 2.424408334158726, 2.591209577043698, 1.4337527726081754, 2.424408334158726, 2.684075987448854, 1.4337527726081754, 2.252543497241034, 2.684075987448854, 1.4337527726081754, 1.0950866928055114, 1.0950866928055114, 2.424408334158726, 2.424408334158726, 1.0950866928055114, 2.424408334158726, 1.4337527726081754, 2.424408334158726, 3.197071883475217, 2.424408334158726, 1.4337527726081754, 2.591209577043698, 1.0950866928055114, 2.591209577043698, 1.0950866928055114, 2.5872229980973334, 2.424408334158726, 2.424408334158726, 2.684075987448854, 1.4337527726081754, 1.0950866928055114, 1.0950866928055114, 2.684075987448854, 2.424408334158726, 2.424408334158726, 1.4337527726081754]\n",
      "all_sum after preprocessing is: [-1.28125643 -1.28125643  0.76111648  0.76111648  0.76111648 -0.76092906\n",
      " -0.76092906 -1.0249826   0.76111648 -0.76092906 -1.28125643 -1.28125643\n",
      " -1.28125643  0.42619304  1.01739031  0.76111648  1.01739031 -0.76092906\n",
      "  0.76111648  1.16007048 -0.76092906  0.49706294  1.16007048 -0.76092906\n",
      " -1.28125643 -1.28125643  0.76111648  0.76111648 -1.28125643  0.76111648\n",
      " -0.76092906  0.76111648  1.94823859  0.76111648 -0.76092906  1.01739031\n",
      " -1.28125643  1.01739031 -1.28125643  1.01126532  0.76111648  0.76111648\n",
      "  1.16007048 -0.76092906 -1.28125643 -1.28125643  1.16007048  0.76111648\n",
      "  0.76111648 -0.76092906]\n",
      "P is: [0.21733642808904774, 0.21733642808904774, 0.681596085541029, 0.681596085541029, 0.681596085541029, 0.31844459114546986, 0.31844459114546986, 0.2640579870828961, 0.681596085541029, 0.31844459114546986, 0.21733642808904774, 0.21733642808904774, 0.21733642808904774, 0.6049642365343674, 0.734463951477625, 0.681596085541029, 0.734463951477625, 0.31844459114546986, 0.681596085541029, 0.7613455212400467, 0.31844459114546986, 0.6217688640615908, 0.7613455212400467, 0.31844459114546986, 0.21733642808904774, 0.21733642808904774, 0.681596085541029, 0.681596085541029, 0.21733642808904774, 0.681596085541029, 0.31844459114546986, 0.681596085541029, 0.8752544505711228, 0.681596085541029, 0.31844459114546986, 0.734463951477625, 0.21733642808904774, 0.734463951477625, 0.21733642808904774, 0.7332677011154287, 0.681596085541029, 0.681596085541029, 0.7613455212400467, 0.31844459114546986, 0.21733642808904774, 0.21733642808904774, 0.7613455212400467, 0.681596085541029, 0.681596085541029, 0.31844459114546986]\n",
      "all_sum before preprocessing is: [2.167834076010564, 1.5061310105907262, 2.0884657872713115, 1.2540695857803839, 1.5061310105907262, 2.167834076010564, 1.2540695857803839, 1.9157726512002216, 1.9157726512002216, 1.9157726512002216, 1.9157726512002216, 1.9157726512002216, 2.167834076010564, 1.6788241466618161, 1.5061310105907262, 1.2540695857803839, 1.2540695857803839, 1.9157726512002216, 2.167834076010564, 1.2540695857803839, 1.5061310105907262, 1.5061310105907262, 1.9157726512002216, 1.2540695857803839, 2.167834076010564, 1.5061310105907262, 2.167834076010564, 1.2540695857803839, 2.167834076010564, 1.5061310105907262, 1.5061310105907262, 1.5061310105907262, 1.2540695857803839, 1.9157726512002216, 1.9157726512002216, 2.167834076010564, 2.167834076010564, 2.167834076010564, 1.5061310105907262, 1.2540695857803839, 1.5061310105907262, 2.167834076010564, 1.2540695857803839, 1.5061310105907262, 2.167834076010564, 2.167834076010564, 2.167834076010564, 2.167834076010564, 1.2540695857803839, 1.2540695857803839]\n",
      "all_sum after preprocessing is: [ 1.19361139 -0.62268112  0.97575532 -1.31455835 -0.62268112  1.19361139\n",
      " -1.31455835  0.50173417  0.50173417  0.50173417  0.50173417  0.50173417\n",
      "  1.19361139 -0.14865997 -0.62268112 -1.31455835 -1.31455835  0.50173417\n",
      "  1.19361139 -1.31455835 -0.62268112 -0.62268112  0.50173417 -1.31455835\n",
      "  1.19361139 -0.62268112  1.19361139 -1.31455835  1.19361139 -0.62268112\n",
      " -0.62268112 -0.62268112 -1.31455835  0.50173417  0.50173417  1.19361139\n",
      "  1.19361139  1.19361139 -0.62268112 -1.31455835 -0.62268112  1.19361139\n",
      " -1.31455835 -0.62268112  1.19361139  1.19361139  1.19361139  1.19361139\n",
      " -1.31455835 -1.31455835]\n",
      "P is: [0.7673863355028956, 0.3491719174829792, 0.7262651671635482, 0.211725067747128, 0.3491719174829792, 0.7673863355028956, 0.211725067747128, 0.6228667798578871, 0.6228667798578871, 0.6228667798578871, 0.6228667798578871, 0.6228667798578871, 0.7673863355028956, 0.46290330104451116, 0.3491719174829792, 0.211725067747128, 0.211725067747128, 0.6228667798578871, 0.7673863355028956, 0.211725067747128, 0.3491719174829792, 0.3491719174829792, 0.6228667798578871, 0.211725067747128, 0.7673863355028956, 0.3491719174829792, 0.7673863355028956, 0.211725067747128, 0.7673863355028956, 0.3491719174829792, 0.3491719174829792, 0.3491719174829792, 0.211725067747128, 0.6228667798578871, 0.6228667798578871, 0.7673863355028956, 0.7673863355028956, 0.7673863355028956, 0.3491719174829792, 0.211725067747128, 0.3491719174829792, 0.7673863355028956, 0.211725067747128, 0.3491719174829792, 0.7673863355028956, 0.7673863355028956, 0.7673863355028956, 0.7673863355028956, 0.211725067747128, 0.211725067747128]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.184\n",
      "(*) epoch 2, cost 3.471\n",
      "(*) epoch 3, cost 2.631\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.688\n",
      "(*) epoch 2, cost 2.228\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.6206700665549554, 3.5510318146453064, 3.5510318146453064, 3.944889263617651, 2.672042546190595, 3.132773020978632, 3.132773020978632, 2.8292993173059333, 3.875251011708002, 3.5510318146453064, 3.5510318146453064, 3.6206700665549554, 3.5510318146453064, 3.5510318146453064, 3.5510318146453064, 3.5510318146453064, 3.5510318146453064, 3.6206700665549554, 3.159939591766918, 3.5510318146453064, 3.5510318146453064, 3.5510318146453064, 3.159939591766918, 2.8292993173059333, 3.5510318146453064, 2.8292993173059333, 3.5510318146453064, 3.090301339857269, 3.4569922180413277, 3.5510318146453064, 3.153518514368629, 3.5510318146453064, 3.5510318146453064, 3.875251011708002, 3.5510318146453064, 3.5510318146453064, 3.132773020978632, 3.5510318146453064, 2.8989375692155823, 3.132773020978632, 3.5510318146453064, 3.5510318146453064, 3.5510318146453064, 2.411040523639259, 3.5510318146453064, 3.132773020978632, 3.5510318146453064, 3.132773020978632, 3.132773020978632, 3.5510318146453064]\n",
      "all_sum after preprocessing is: [ 0.74261964  0.5221677   0.5221677   1.7689916  -2.2604249  -0.80190287\n",
      " -0.80190287 -1.76260139  1.54853966  0.5221677   0.5221677   0.74261964\n",
      "  0.5221677   0.5221677   0.5221677   0.5221677   0.5221677   0.74261964\n",
      " -0.71590239  0.5221677   0.5221677   0.5221677  -0.71590239 -1.76260139\n",
      "  0.5221677  -1.76260139  0.5221677  -0.93635433  0.22446909  0.5221677\n",
      " -0.73622943  0.5221677   0.5221677   1.54853966  0.5221677   0.5221677\n",
      " -0.80190287  0.5221677  -1.54214945 -0.80190287  0.5221677   0.5221677\n",
      "  0.5221677  -3.08667196  0.5221677  -0.80190287  0.5221677  -0.80190287\n",
      " -0.80190287  0.5221677 ]\n",
      "P is: [0.6775684325384119, 0.6276545073776536, 0.6276545073776536, 0.8543322214633948, 0.09445401970372198, 0.30961862294375475, 0.30961862294375475, 0.14646483374956729, 0.8247027136188826, 0.6276545073776536, 0.6276545073776536, 0.6775684325384119, 0.6276545073776536, 0.6276545073776536, 0.6276545073776536, 0.6276545073776536, 0.6276545073776536, 0.6775684325384119, 0.3282959411290113, 0.6276545073776536, 0.6276545073776536, 0.6276545073776536, 0.3282959411290113, 0.14646483374956729, 0.6276545073776536, 0.14646483374956729, 0.6276545073776536, 0.2816373391362461, 0.5558828243794953, 0.6276545073776536, 0.32382921430418915, 0.6276545073776536, 0.6276545073776536, 0.8247027136188826, 0.6276545073776536, 0.6276545073776536, 0.30961862294375475, 0.6276545073776536, 0.17622302489574834, 0.30961862294375475, 0.6276545073776536, 0.6276545073776536, 0.6276545073776536, 0.04366038355052402, 0.6276545073776536, 0.30961862294375475, 0.6276545073776536, 0.30961862294375475, 0.30961862294375475, 0.6276545073776536]\n",
      "all_sum before preprocessing is: [2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 1.952930429594998, 1.952930429594998, 2.5386687403961283, 1.780665055035998, 2.5386687403961283, 3.5765705691177674, 2.990832258316637, 2.5386687403961283, 3.5765705691177674, 1.189878311865337, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 1.952930429594998, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 4.304426285525591, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 1.952930429594998, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.366403365837128, 2.366403365837128, 1.952930429594998, 2.5386687403961283, 2.366403365837128, 2.5386687403961283, 1.189878311865337, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 2.5386687403961283, 1.952930429594998, 2.5386687403961283, 2.5386687403961283]\n",
      "all_sum after preprocessing is: [ 0.13239453  0.13239453  0.13239453  0.13239453 -1.08192528 -1.08192528\n",
      "  0.13239453 -1.43905619  0.13239453  2.28411437  1.06979457  0.13239453\n",
      "  2.28411437 -2.66384212  0.13239453  0.13239453  0.13239453  0.13239453\n",
      "  0.13239453  0.13239453 -1.08192528  0.13239453  0.13239453  0.13239453\n",
      "  0.13239453  3.79306401  0.13239453  0.13239453  0.13239453  0.13239453\n",
      " -1.08192528  0.13239453  0.13239453  0.13239453 -0.22473638 -0.22473638\n",
      " -1.08192528  0.13239453 -0.22473638  0.13239453 -2.66384212  0.13239453\n",
      "  0.13239453  0.13239453  0.13239453  0.13239453  0.13239453 -1.08192528\n",
      "  0.13239453  0.13239453]\n",
      "P is: [0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.25314184869731327, 0.25314184869731327, 0.5330503694850676, 0.19169154586417253, 0.5330503694850676, 0.9075528247149688, 0.7445578458648043, 0.5330503694850676, 0.9075528247149688, 0.06514096622023856, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.25314184869731327, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.9779697882843654, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.25314184869731327, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.44405118759720164, 0.44405118759720164, 0.25314184869731327, 0.5330503694850676, 0.44405118759720164, 0.5330503694850676, 0.06514096622023856, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.5330503694850676, 0.25314184869731327, 0.5330503694850676, 0.5330503694850676]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.905\n",
      "(*) epoch 2, cost 2.964\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.082\n",
      "(*) epoch 2, cost 3.177\n",
      "(*) epoch 3, cost 2.492\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.6651568024196353, 2.5971744913608337, 2.17384662406666, 1.6010593156876465, 3.661271978092822, 2.5971744913608337, 1.388143589173597, 1.6010593156876465, 0.39202841350040996, 2.6651568024196353, 2.5971744913608337, 1.6010593156876465, 1.6010593156876465, 2.5971744913608337, 2.4522410759055857, 1.388143589173597, 3.661271978092822, 2.6651568024196353, 2.6651568024196353, 1.6010593156876465, 1.6010593156876465, 0.39202841350040996, 2.5971744913608337, 0.39202841350040996, 1.6010593156876465, 1.6010593156876465, 1.6010593156876465, 2.5971744913608337, 1.6010593156876465, 1.6010593156876465, 3.661271978092822, 2.0667701931817426, 2.5971744913608337, 0.39202841350040996, 2.5971744913608337, 1.388143589173597, 2.5971744913608337, 2.5971744913608337, 2.17384662406666, 2.5971744913608337, 3.661271978092822, 3.1699617997398466, 2.6651568024196353, 1.6010593156876465, 2.5971744913608337, 2.5971744913608337, 3.1699617997398466, 3.1699617997398466, 3.1699617997398466, 2.6651568024196353]\n",
      "all_sum after preprocessing is: [ 0.53407619  0.45291161 -0.05250264 -0.73635762  1.72334542  0.45291161\n",
      " -0.99055927 -0.73635762 -2.17982851  0.53407619  0.45291161 -0.73635762\n",
      " -0.73635762  0.45291161  0.27987454 -0.99055927  1.72334542  0.53407619\n",
      "  0.53407619 -0.73635762 -0.73635762 -2.17982851  0.45291161 -2.17982851\n",
      " -0.73635762 -0.73635762 -0.73635762  0.45291161 -0.73635762 -0.73635762\n",
      "  1.72334542 -0.18034198  0.45291161 -2.17982851  0.45291161 -0.99055927\n",
      "  0.45291161  0.45291161 -0.05250264  0.45291161  1.72334542  1.13676659\n",
      "  0.53407619 -0.73635762  0.45291161  0.45291161  1.13676659  1.13676659\n",
      "  1.13676659  0.53407619]\n",
      "P is: [0.6304333154366798, 0.6113312713654366, 0.48687735303379387, 0.3238011442346655, 0.8485592458349507, 0.6113312713654366, 0.2708016246819646, 0.3238011442346655, 0.10157657724554439, 0.6304333154366798, 0.6113312713654366, 0.3238011442346655, 0.3238011442346655, 0.6113312713654366, 0.5695154648991021, 0.2708016246819646, 0.8485592458349507, 0.6304333154366798, 0.6304333154366798, 0.3238011442346655, 0.3238011442346655, 0.10157657724554439, 0.6113312713654366, 0.10157657724554439, 0.3238011442346655, 0.3238011442346655, 0.3238011442346655, 0.6113312713654366, 0.3238011442346655, 0.3238011442346655, 0.8485592458349507, 0.4550363019886591, 0.6113312713654366, 0.10157657724554439, 0.6113312713654366, 0.2708016246819646, 0.6113312713654366, 0.6113312713654366, 0.48687735303379387, 0.6113312713654366, 0.8485592458349507, 0.7570854857667326, 0.6304333154366798, 0.3238011442346655, 0.6113312713654366, 0.6113312713654366, 0.7570854857667326, 0.7570854857667326, 0.7570854857667326, 0.6304333154366798]\n",
      "all_sum before preprocessing is: [4.062654455218828, 5.224244031082864, 5.224244031082864, 3.752627267545019, 3.752627267545019, 3.752627267545019, 2.5910376916809827, 2.358411161550737, 4.062654455218828, 5.224244031082864, 5.224244031082864, 2.5910376916809827, 3.752627267545019, 5.186556553839818, 5.224244031082864, 4.024966977975781, 2.5910376916809827, 5.797775410145102, 3.164569070743221, 5.186556553839818, 5.224244031082864, 4.062654455218828, 3.752627267545019, 3.752627267545019, 5.797775410145102, 2.5910376916809827, 3.752627267545019, 4.513424399326078, 4.062654455218828, 3.752627267545019, 1.1968215856867013, 3.752627267545019, 2.5910376916809827, 2.358411161550737, 3.752627267545019, 4.062654455218828, 4.636185834281066, 3.752627267545019, 2.5910376916809827, 4.062654455218828, 4.062654455218828, 5.224244031082864, 3.752627267545019, 5.224244031082864, 5.797775410145102, 2.358411161550737, 5.224244031082864, 1.1968215856867013, 3.752627267545019, 5.224244031082864]\n",
      "all_sum after preprocessing is: [ 0.07953687  1.09550435  1.09550435 -0.19162391 -0.19162391 -0.19162391\n",
      " -1.20759138 -1.4110548   0.07953687  1.09550435  1.09550435 -1.20759138\n",
      " -0.19162391  1.06254154  1.09550435  0.04657407 -1.20759138  1.59713525\n",
      " -0.70596048  1.06254154  1.09550435  0.07953687 -0.19162391 -0.19162391\n",
      "  1.59713525 -1.20759138 -0.19162391  0.47379627  0.07953687 -0.19162391\n",
      " -2.42702227 -0.19162391 -1.20759138 -1.4110548  -0.19162391  0.07953687\n",
      "  0.58116777 -0.19162391 -1.20759138  0.07953687  0.07953687  1.09550435\n",
      " -0.19162391  1.09550435  1.59713525 -1.4110548   1.09550435 -2.42702227\n",
      " -0.19162391  1.09550435]\n",
      "P is: [0.5198737426653378, 0.7494168081089555, 0.7494168081089555, 0.45224007784154185, 0.45224007784154185, 0.45224007784154185, 0.23012750590656053, 0.1960677399852654, 0.5198737426653378, 0.7494168081089555, 0.7494168081089555, 0.23012750590656053, 0.45224007784154185, 0.7431759374070689, 0.7494168081089555, 0.5116414129609969, 0.23012750590656053, 0.8316176154623127, 0.3304920401829425, 0.7431759374070689, 0.7494168081089555, 0.5198737426653378, 0.45224007784154185, 0.45224007784154185, 0.8316176154623127, 0.23012750590656053, 0.45224007784154185, 0.6162818873103365, 0.5198737426653378, 0.45224007784154185, 0.08113518686722886, 0.45224007784154185, 0.23012750590656053, 0.1960677399852654, 0.45224007784154185, 0.5198737426653378, 0.6413360670368565, 0.45224007784154185, 0.23012750590656053, 0.5198737426653378, 0.5198737426653378, 0.7494168081089555, 0.45224007784154185, 0.7494168081089555, 0.8316176154623127, 0.1960677399852654, 0.7494168081089555, 0.08113518686722886, 0.45224007784154185, 0.7494168081089555]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.073\n",
      "(*) epoch 2, cost 2.122\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.150\n",
      "(*) epoch 2, cost 2.971\n",
      "(*) epoch 3, cost 2.569\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7888376503143402, 1.7888376503143402, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.6236523202107382, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.6236523202107382, 1.7888376503143402, 2.8061298021293037, 1.6236523202107382, 1.7888376503143402, 1.6236523202107382, 1.6236523202107382, 1.6236523202107382, 2.9713151322329057, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.6236523202107382, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.6236523202107382, 1.7888376503143402, 1.7888376503143402, 1.7888376503143402, 1.6236523202107382, 1.6236523202107382]\n",
      "all_sum after preprocessing is: [ 0.09082769  0.09082769  0.09082769  0.09082769 -0.58871299  0.09082769\n",
      "  0.09082769  0.09082769 -0.58871299 -0.58871299  0.09082769 -0.58871299\n",
      "  0.09082769  0.09082769  0.09082769 -0.58871299  0.09082769  0.09082769\n",
      " -0.58871299  0.09082769  0.09082769 -0.58871299 -0.58871299  0.09082769\n",
      "  4.27577197 -0.58871299  0.09082769 -0.58871299 -0.58871299 -0.58871299\n",
      "  4.95531266  0.09082769 -0.58871299  0.09082769  0.09082769  0.09082769\n",
      " -0.58871299  0.09082769 -0.58871299  0.09082769 -0.58871299  0.09082769\n",
      "  0.09082769 -0.58871299 -0.58871299  0.09082769  0.09082769  0.09082769\n",
      " -0.58871299 -0.58871299]\n",
      "P is: [0.522691324474223, 0.522691324474223, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.3569302075780708, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.3569302075780708, 0.522691324474223, 0.9862892838169287, 0.3569302075780708, 0.522691324474223, 0.3569302075780708, 0.3569302075780708, 0.3569302075780708, 0.9930034200363045, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.3569302075780708, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.3569302075780708, 0.522691324474223, 0.522691324474223, 0.522691324474223, 0.3569302075780708, 0.3569302075780708]\n",
      "all_sum before preprocessing is: [3.011454148435663, 1.2441126250413292, 3.2980695901776387, 3.2630448062200554, 3.125714047695243, 2.5806230151460023, 1.2441126250413292, 2.011664228871112, 3.011454148435663, 3.011454148435663, 2.8942726264208933, 3.011454148435663, 2.44329225662119, 1.9265344161153823, 2.6948829144055826, 2.44329225662119, 1.812274516855802, 2.5575521558807703, 3.148784906960475, 1.9265344161153823, 2.0638651746401946, 2.0638651746401946, 3.148784906960475, 3.011454148435663, 3.125714047695243, 3.148784906960475, 2.5806230151460023, 1.812274516855802, 3.2630448062200554, 2.412193077460402, 2.5806230151460023, 1.812274516855802, 2.0638651746401946, 1.3814433835661417, 2.5806230151460023, 1.2441126250413292, 1.812274516855802, 1.2441126250413292, 1.9846300593381976, 1.9496052753806143, 1.2441126250413292, 1.812274516855802, 1.2441126250413292, 1.2441126250413292, 2.44329225662119, 1.695092994841032, 3.148784906960475, 2.44329225662119, 1.3814433835661417, 1.812274516855802]\n",
      "all_sum after preprocessing is: [ 1.07467098 -1.55164859  1.50058965  1.44854183  1.24446443  0.43444371\n",
      " -1.55164859 -0.41104516  1.07467098  1.07467098  0.90053592  1.07467098\n",
      "  0.23036632 -0.53755048  0.60423716  0.23036632 -0.70734392  0.40015976\n",
      "  1.27874838 -0.53755048 -0.33347308 -0.33347308  1.27874838  1.07467098\n",
      "  1.24446443  1.27874838  0.43444371 -0.70734392  1.44854183  0.18415205\n",
      "  0.43444371 -0.70734392 -0.33347308 -1.34757119  0.43444371 -1.55164859\n",
      " -0.70734392 -1.55164859 -0.4512187  -0.50326652 -1.55164859 -0.70734392\n",
      " -1.55164859 -1.55164859  0.23036632 -0.88147898  1.27874838  0.23036632\n",
      " -1.34757119 -0.70734392]\n",
      "P is: [0.7454841921231798, 0.1748482881892478, 0.8176624036479535, 0.8097739182820781, 0.7763401566725632, 0.6069342852923193, 0.1748482881892478, 0.39866153746713967, 0.7454841921231798, 0.7454841921231798, 0.711059622036469, 0.7454841921231798, 0.5573382309708462, 0.36875758792484536, 0.6466251023092552, 0.5573382309708462, 0.330186001655225, 0.598726044140505, 0.7822366476415299, 0.36875758792484536, 0.4173958106351451, 0.4173958106351451, 0.7822366476415299, 0.7454841921231798, 0.7763401566725632, 0.7822366476415299, 0.6069342852923193, 0.330186001655225, 0.8097739182820781, 0.5459083498387809, 0.6069342852923193, 0.330186001655225, 0.4173958106351451, 0.20626773592765407, 0.6069342852923193, 0.1748482881892478, 0.330186001655225, 0.1748482881892478, 0.3890710474653322, 0.3767733309912262, 0.1748482881892478, 0.330186001655225, 0.1748482881892478, 0.1748482881892478, 0.5573382309708462, 0.2928713909099173, 0.7822366476415299, 0.5573382309708462, 0.20626773592765407, 0.330186001655225]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.324\n",
      "(*) epoch 2, cost 1.627\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.778\n",
      "(*) epoch 2, cost 3.080\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.830683679517632, 0.5424955135224123, 1.9671016905371173, 2.9802687288178316, 2.368713225725235, 2.830683679517632, 0.8862591802501092, 2.518298275025434, 2.368713225725235, 1.256492453202728, 2.518298275025434, 2.368713225725235, 1.9671016905371173, 2.368713225725235, 2.368713225725235, 2.830683679517632, 2.518298275025434, 2.368713225725235, 1.9671016905371173, 2.518298275025434, 2.830683679517632, 2.1166867398373164, 2.368713225725235, 0.9441070487105302, 0.9441070487105302, 2.4604504065650135, 2.518298275025434, 0.794521999410331, 2.368713225725235, 3.8444267765482127, 0.9441070487105302, 2.368713225725235, 2.368713225725235, 2.368713225725235, 2.4290721443295142, 2.6100354558652126, 2.830683679517632, 0.794521999410331, 2.368713225725235, 2.830683679517632, 2.4290721443295142, 2.368713225725235, 2.368713225725235, 2.368713225725235, 2.368713225725235, 2.4290721443295142, 2.368713225725235, 1.9671016905371173, 2.01820906434539, 3.7469330514398225]\n",
      "all_sum after preprocessing is: [ 0.86120476 -2.46175891 -0.39291045  1.07843588  0.19031979  0.86120476\n",
      " -1.96253678  0.40755092  0.19031979 -1.42487483  0.40755092  0.19031979\n",
      " -0.39291045  0.19031979  0.19031979  0.86120476  0.40755092  0.19031979\n",
      " -0.39291045  0.40755092  0.86120476 -0.17567933  0.19031979 -1.87852867\n",
      " -1.87852867  0.32354281  0.40755092 -2.09575979  0.19031979  2.33338765\n",
      " -1.87852867  0.19031979  0.19031979  0.19031979  0.27797451  0.54077393\n",
      "  0.86120476 -2.09575979  0.19031979  0.86120476  0.27797451  0.19031979\n",
      "  0.19031979  0.19031979  0.19031979  0.27797451  0.19031979 -0.39291045\n",
      " -0.31869105  2.19180485]\n",
      "P is: [0.7029123012088189, 0.07858288415521696, 0.40301686609216636, 0.7461978740494075, 0.5474368482151776, 0.7029123012088189, 0.123192772009773, 0.6005004894726679, 0.5474368482151776, 0.19389850176543336, 0.6005004894726679, 0.5474368482151776, 0.40301686609216636, 0.5474368482151776, 0.5474368482151776, 0.7029123012088189, 0.6005004894726679, 0.5474368482151776, 0.40301686609216636, 0.6005004894726679, 0.7029123012088189, 0.4561927798094275, 0.5474368482151776, 0.13255796516632548, 0.13255796516632548, 0.5801874175769529, 0.6005004894726679, 0.10950963068348249, 0.5474368482151776, 0.9116047000830061, 0.13255796516632548, 0.5474368482151776, 0.5474368482151776, 0.5474368482151776, 0.5690495793251543, 0.6319924348378668, 0.7029123012088189, 0.10950963068348249, 0.5474368482151776, 0.7029123012088189, 0.5690495793251543, 0.5474368482151776, 0.5474368482151776, 0.5474368482151776, 0.5474368482151776, 0.5690495793251543, 0.5474368482151776, 0.40301686609216636, 0.4209947815983953, 0.8995111655499451]\n",
      "all_sum before preprocessing is: [2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.0788260893566193, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.0788260893566193, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.0788260893566193, 2.0788260893566193, 2.0788260893566193, 2.7446939654789295, 2.7446939654789295, 2.0788260893566193, 3.6530362415650015, 2.0788260893566193, 3.1304297101761893, 2.464561834053879, 3.1304297101761893, 2.0788260893566193, 2.0788260893566193, 2.0788260893566193, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 3.6530362415650015, 2.7446939654789295, 2.464561834053879, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.0788260893566193, 3.1304297101761893, 2.0788260893566193, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.7446939654789295, 2.0788260893566193, 2.0788260893566193, 2.0788260893566193, 2.7446939654789295]\n",
      "all_sum after preprocessing is: [-0.72615207  0.81069173 -0.72615207 -0.72615207 -0.72615207  0.81069173\n",
      " -0.72615207 -0.72615207 -0.72615207  0.81069173 -0.72615207 -0.72615207\n",
      " -0.72615207 -0.72615207  0.81069173  0.81069173 -0.72615207  2.90717398\n",
      " -0.72615207  1.70098184  0.16413804  1.70098184 -0.72615207 -0.72615207\n",
      " -0.72615207 -0.72615207  0.81069173 -0.72615207  0.81069173 -0.72615207\n",
      " -0.72615207  0.81069173 -0.72615207  2.90717398  0.81069173  0.16413804\n",
      " -0.72615207  0.81069173 -0.72615207 -0.72615207  1.70098184 -0.72615207\n",
      " -0.72615207  0.81069173 -0.72615207  0.81069173 -0.72615207 -0.72615207\n",
      " -0.72615207  0.81069173]\n",
      "P is: [0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.3260396972927083, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.3260396972927083, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.3260396972927083, 0.3260396972927083, 0.3260396972927083, 0.692256887225834, 0.692256887225834, 0.3260396972927083, 0.9481999352363022, 0.3260396972927083, 0.8456629247493155, 0.5409426314769052, 0.8456629247493155, 0.3260396972927083, 0.3260396972927083, 0.3260396972927083, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.9481999352363022, 0.692256887225834, 0.5409426314769052, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.3260396972927083, 0.8456629247493155, 0.3260396972927083, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.692256887225834, 0.3260396972927083, 0.3260396972927083, 0.3260396972927083, 0.692256887225834]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.736\n",
      "(*) epoch 2, cost 3.726\n",
      "(*) epoch 3, cost 3.072\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.867\n",
      "(*) epoch 2, cost 2.994\n",
      "(*) epoch 3, cost 1.911\n",
      "(*) epoch 4, cost 1.371\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.6242101642037605, 3.9325044392261628, 2.596856172639468, 1.39531501407036, 3.6242101642037605, 2.596856172639468, 3.6242101642037605, 2.596856172639468, 3.6242101642037605, 2.596856172639468, 2.596856172639468, 4.585303643655543, 1.39531501407036, 2.596856172639468, 2.596856172639468, 3.6242101642037605, 2.596856172639468, 3.6242101642037605, 2.4226690056346527, 2.596856172639468, 2.596856172639468, 2.596856172639468, 2.596856172639468, 2.596856172639468, 3.6242101642037605, 2.596856172639468, 2.4226690056346527, 3.6242101642037605, 3.383762485086435, 2.596856172639468, 2.596856172639468, 3.6242101642037605, 2.4226690056346527, 2.596856172639468, 3.6242101642037605, 2.596856172639468, 3.6242101642037605, 2.596856172639468, 2.596856172639468, 2.596856172639468, 3.6242101642037605, 1.39531501407036, 2.596856172639468, 2.596856172639468, 2.596856172639468, 3.6242101642037605, 3.6242101642037605, 2.596856172639468, 2.596856172639468, 2.596856172639468]\n",
      "all_sum after preprocessing is: [ 1.1304244   1.6013631  -0.43892281 -2.27435176  1.1304244  -0.43892281\n",
      "  1.1304244  -0.43892281  1.1304244  -0.43892281 -0.43892281  2.59855455\n",
      " -2.27435176 -0.43892281 -0.43892281  1.1304244  -0.43892281  1.1304244\n",
      " -0.70500456 -0.43892281 -0.43892281 -0.43892281 -0.43892281 -0.43892281\n",
      "  1.1304244  -0.43892281 -0.70500456  1.1304244   0.76312559 -0.43892281\n",
      " -0.43892281  1.1304244  -0.70500456 -0.43892281  1.1304244  -0.43892281\n",
      "  1.1304244  -0.43892281 -0.43892281 -0.43892281  1.1304244  -2.27435176\n",
      " -0.43892281 -0.43892281 -0.43892281  1.1304244   1.1304244  -0.43892281\n",
      " -0.43892281 -0.43892281]\n",
      "P is: [0.7559172116279931, 0.832208811417329, 0.39199767214208286, 0.09326953031322129, 0.7559172116279931, 0.39199767214208286, 0.7559172116279931, 0.39199767214208286, 0.7559172116279931, 0.39199767214208286, 0.39199767214208286, 0.9307684946813207, 0.09326953031322129, 0.39199767214208286, 0.39199767214208286, 0.7559172116279931, 0.39199767214208286, 0.7559172116279931, 0.3307035889225178, 0.39199767214208286, 0.39199767214208286, 0.39199767214208286, 0.39199767214208286, 0.39199767214208286, 0.7559172116279931, 0.39199767214208286, 0.3307035889225178, 0.7559172116279931, 0.6820319487026743, 0.39199767214208286, 0.39199767214208286, 0.7559172116279931, 0.3307035889225178, 0.39199767214208286, 0.7559172116279931, 0.39199767214208286, 0.7559172116279931, 0.39199767214208286, 0.39199767214208286, 0.39199767214208286, 0.7559172116279931, 0.09326953031322129, 0.39199767214208286, 0.39199767214208286, 0.39199767214208286, 0.7559172116279931, 0.7559172116279931, 0.39199767214208286, 0.39199767214208286, 0.39199767214208286]\n",
      "all_sum before preprocessing is: [3.524587370346487, 3.118031407240016, 3.397801386851379, 3.118031407240016, 2.6938004950709153, 4.232861597540416, 3.397801386851379, 2.9912454237449086, 3.524587370346487, 3.118031407240016, 3.6605824707053323, 3.118031407240016, 3.948818282515588, 3.948818282515588, 4.106075614045308, 3.397801386851379, 4.106075614045308, 2.6938004950709153, 2.9912454237449086, 3.8220322990204805, 4.9368624893208795, 3.397801386851379, 4.232861597540416, 3.118031407240016, 4.806866930173002, 3.817839802235052, 2.9912454237449086, 3.948818282515588, 3.118031407240016, 3.5337964872102248, 3.948818282515588, 3.118031407240016, 4.806866930173002, 5.063648472815987, 3.118031407240016, 4.806866930173002, 3.118031407240016, 3.118031407240016, 2.9912454237449086, 2.6938004950709153, 3.118031407240016, 3.118031407240016, 3.397801386851379, 5.340208876774581, 3.948818282515588, 2.567014511575807, 2.9912454237449086, 3.948818282515588, 3.118031407240016, 4.518631118362746]\n",
      "all_sum after preprocessing is: [-0.10136983 -0.70163624 -0.28856513 -0.70163624 -1.32799913  0.9443736\n",
      " -0.28856513 -0.88883154 -0.10136983 -0.70163624  0.09942243 -0.70163624\n",
      "  0.52499306  0.52499306  0.7571783  -0.28856513  0.7571783  -1.32799913\n",
      " -0.88883154  0.33779775  1.98380759 -0.28856513  0.9443736  -0.70163624\n",
      "  1.79187346  0.33160767 -0.88883154  0.52499306 -0.70163624 -0.08777287\n",
      "  0.52499306 -0.70163624  1.79187346  2.1710029  -0.70163624  1.79187346\n",
      " -0.70163624 -0.70163624 -0.88883154 -1.32799913 -0.70163624 -0.70163624\n",
      " -0.28856513  2.57933517  0.52499306 -1.51519443 -0.88883154  0.52499306\n",
      " -0.70163624  1.36630283]\n",
      "P is: [0.4746792215131551, 0.33144955232399387, 0.42835518227538333, 0.33144955232399387, 0.20949052581472236, 0.7199822571754342, 0.42835518227538333, 0.29135101463855956, 0.4746792215131551, 0.33144955232399387, 0.5248351533118291, 0.33144955232399387, 0.6283145667683573, 0.6283145667683573, 0.6807407981621668, 0.42835518227538333, 0.6807407981621668, 0.20949052581472236, 0.29135101463855956, 0.5836554717166892, 0.8790864688044836, 0.42835518227538333, 0.7199822571754342, 0.33144955232399387, 0.8571568142080158, 0.5821504962151066, 0.29135101463855956, 0.6283145667683573, 0.33144955232399387, 0.4780708583593114, 0.6283145667683573, 0.33144955232399387, 0.8571568142080158, 0.8976151717105318, 0.33144955232399387, 0.8571568142080158, 0.33144955232399387, 0.33144955232399387, 0.29135101463855956, 0.20949052581472236, 0.33144955232399387, 0.33144955232399387, 0.42835518227538333, 0.9295197266904461, 0.6283145667683573, 0.18017025433839956, 0.29135101463855956, 0.6283145667683573, 0.33144955232399387, 0.796782163357147]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.145\n",
      "(*) epoch 2, cost 2.158\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.746\n",
      "(*) epoch 2, cost 3.255\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.7424012133686402, 1.7424012133686402, 1.7424012133686402, 1.965440770673486, 3.6810395135777307, 1.7424012133686402, 1.0970563822313124, 1.7424012133686402, 1.7424012133686402, 2.742485781785137, 1.7424012133686402, 1.7424012133686402, 1.0970563822313124, 1.7424012133686402, 1.610701033394317, 2.097140950647809, 1.7424012133686402, 1.7424012133686402, 3.0756783364148697, 1.7424012133686402, 1.7424012133686402, 2.1886925810093407, 1.0970563822313124, 2.097140950647809, 1.7424012133686402, 2.1886925810093407, 1.7424012133686402, 0.9653562022569891, 1.610701033394317, 3.23474814593703, 1.7424012133686402, 1.7424012133686402, 1.7424012133686402, 1.7424012133686402, 1.7424012133686402, 1.0970563822313124, 1.7424012133686402, 1.0970563822313124, 1.7424012133686402, 1.0970563822313124, 3.23474814593703, 1.7424012133686402, 1.7424012133686402, 1.610701033394317, 1.7424012133686402, 1.7424012133686402, 1.0970563822313124, 1.7424012133686402, 1.7424012133686402, 1.7424012133686402]\n",
      "all_sum after preprocessing is: [-0.12373886 -0.12373886 -0.12373886  0.28305269  3.41205405 -0.12373886\n",
      " -1.30075351 -0.12373886 -0.12373886  1.70026922 -0.12373886 -0.12373886\n",
      " -1.30075351 -0.12373886 -0.36394074  0.52325457 -0.12373886 -0.12373886\n",
      "  2.30796374 -0.12373886 -0.12373886  0.69023136 -1.30075351  0.52325457\n",
      " -0.12373886  0.69023136 -0.12373886 -1.54095539 -0.36394074  2.59808382\n",
      " -0.12373886 -0.12373886 -0.12373886 -0.12373886 -0.12373886 -1.30075351\n",
      " -0.12373886 -1.30075351 -0.12373886 -1.30075351  2.59808382 -0.12373886\n",
      " -0.12373886 -0.36394074 -0.12373886 -0.12373886 -1.30075351 -0.12373886\n",
      " -0.12373886 -0.12373886]\n",
      "P is: [0.469104694954613, 0.469104694954613, 0.469104694954613, 0.5702944723191156, 0.9680791375802364, 0.469104694954613, 0.21403822954634136, 0.469104694954613, 0.469104694954613, 0.8455698931621475, 0.469104694954613, 0.469104694954613, 0.21403822954634136, 0.469104694954613, 0.41000595938345347, 0.6279084781352409, 0.469104694954613, 0.469104694954613, 0.9095344482957797, 0.469104694954613, 0.469104694954613, 0.6660183925213586, 0.21403822954634136, 0.6279084781352409, 0.469104694954613, 0.6660183925213586, 0.469104694954613, 0.17639643204613847, 0.41000595938345347, 0.9307381558558079, 0.469104694954613, 0.469104694954613, 0.469104694954613, 0.469104694954613, 0.469104694954613, 0.21403822954634136, 0.469104694954613, 0.21403822954634136, 0.469104694954613, 0.21403822954634136, 0.9307381558558079, 0.469104694954613, 0.469104694954613, 0.41000595938345347, 0.469104694954613, 0.469104694954613, 0.21403822954634136, 0.469104694954613, 0.469104694954613, 0.469104694954613]\n",
      "all_sum before preprocessing is: [2.1960145435152665, 2.1960145435152665, 2.652374088694874, 2.652374088694874, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.652374088694874, 2.1960145435152665, 2.652374088694874, 2.652374088694874, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.652374088694874, 2.652374088694874, 2.1960145435152665, 2.1960145435152665, 2.652374088694874, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.1960145435152665, 2.652374088694874, 2.1960145435152665, 2.1960145435152665]\n",
      "all_sum after preprocessing is: [-0.46852129 -0.46852129  2.13437475  2.13437475 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129\n",
      "  2.13437475 -0.46852129  2.13437475  2.13437475 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129  2.13437475  2.13437475 -0.46852129\n",
      " -0.46852129  2.13437475 -0.46852129 -0.46852129 -0.46852129 -0.46852129\n",
      " -0.46852129 -0.46852129 -0.46852129 -0.46852129 -0.46852129  2.13437475\n",
      " -0.46852129 -0.46852129]\n",
      "P is: [0.38496629512219693, 0.38496629512219693, 0.8941996027884163, 0.8941996027884163, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.8941996027884163, 0.38496629512219693, 0.8941996027884163, 0.8941996027884163, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.8941996027884163, 0.8941996027884163, 0.38496629512219693, 0.38496629512219693, 0.8941996027884163, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.38496629512219693, 0.8941996027884163, 0.38496629512219693, 0.38496629512219693]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.107\n",
      "(*) epoch 2, cost 1.891\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.891\n",
      "(*) epoch 2, cost 2.136\n",
      "(*) epoch 3, cost 1.234\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.014917977370469, 2.612583883887874, 2.46539228259277, 2.46539228259277, 2.46539228259277, 3.6875514577474346, 1.390424708733209, 3.8442174357224874, 1.390424708733209, 2.622058260567823, 2.792758802215804, 2.46539228259277, 5.246551529205083, 2.622058260567823, 1.558597457931203, 3.8442174357224874, 5.089885551230029, 2.46539228259277, 2.622058260567823, 2.622058260567823, 1.390424708733209, 3.8442174357224874, 2.612583883887874, 4.074048203070089, 3.6875514577474346, 1.390424708733209, 3.6875514577474346, 2.46539228259277, 1.390424708733209, 2.612583883887874, 5.089885551230029, 1.390424708733209, 2.46539228259277, 4.024392354050418, 5.089885551230029, 2.46539228259277, 2.612583883887874, 2.7692498618629267, 3.8557242069454283, 2.612583883887874, 2.46539228259277, 2.46539228259277, 4.02642474859341, 2.622058260567823, 5.089885551230029, 4.0835225797500385, 3.6875514577474346, 2.612583883887874, 2.476899053815711, 2.9345213033875774]\n",
      "all_sum after preprocessing is: [ 0.96050031 -0.37406725 -0.51414595 -0.51414595 -0.51414595  0.64895348\n",
      " -1.53716668  0.79804872 -1.53716668 -0.36505071 -0.20259912 -0.51414595\n",
      "  2.13261628 -0.36505071 -1.37712073  0.79804872  1.98352104 -0.51414595\n",
      " -0.36505071 -0.36505071 -1.53716668  0.79804872 -0.37406725  1.01677312\n",
      "  0.64895348 -1.53716668  0.64895348 -0.51414595 -1.53716668 -0.37406725\n",
      "  1.98352104 -1.53716668 -0.51414595  0.96951684  1.98352104 -0.51414595\n",
      " -0.37406725 -0.22497201  0.80899943 -0.37406725 -0.51414595 -0.51414595\n",
      "  0.97145103 -0.36505071  1.98352104  1.02578966  0.64895348 -0.37406725\n",
      " -0.50319523 -0.06768717]\n",
      "P is: [0.7232219640914486, 0.40755859745938433, 0.3742221223202066, 0.3742221223202066, 0.3742221223202066, 0.6567745935122566, 0.17694753356083026, 0.6895569282102981, 0.17694753356083026, 0.4097374827637772, 0.44952276050316015, 0.3742221223202066, 0.8940331244370289, 0.4097374827637772, 0.20147182146541806, 0.6895569282102981, 0.8790560068703939, 0.3742221223202066, 0.4097374827637772, 0.4097374827637772, 0.17694753356083026, 0.6895569282102981, 0.40755859745938433, 0.7343435658452216, 0.6567745935122566, 0.17694753356083026, 0.6567745935122566, 0.3742221223202066, 0.17694753356083026, 0.40755859745938433, 0.8790560068703939, 0.17694753356083026, 0.3742221223202066, 0.7250231842169298, 0.8790560068703939, 0.3742221223202066, 0.40755859745938433, 0.4439930180825608, 0.6918962488334571, 0.40755859745938433, 0.3742221223202066, 0.3742221223202066, 0.7254086234772514, 0.4097374827637772, 0.8790560068703939, 0.7360988188822287, 0.6567745935122566, 0.40755859745938433, 0.3767900716979039, 0.4830846660403446]\n",
      "all_sum before preprocessing is: [4.998482844409679, 4.998482844409679, 3.9933681320266374, 5.391436923202361, 3.2475708191133776, 5.72245037280749, 4.998482844409679, 5.329496294014808, 4.998482844409679, 5.391436923202361, 6.244968480401635, 5.508996361162821, 4.998482844409679, 5.852014401608953, 4.998482844409679, 5.329496294014808, 5.391436923202361, 5.391436923202361, 4.494056455105334, 6.755481997154778, 5.622848317659202, 4.998482844409679, 5.391436923202361, 3.6405248979060607, 4.998482844409679, 3.6405248979060607, 3.6405248979060607, 4.998482844409679, 5.391436923202361, 5.391436923202361, 3.2475708191133776, 3.8719362923629013, 4.998482844409679, 5.72245037280749, 3.6405248979060607, 3.2475708191133776, 4.998482844409679, 4.998482844409679, 3.6405248979060607, 5.329496294014808, 5.391436923202361, 3.2475708191133776, 4.101102376312651, 3.6405248979060607, 4.998482844409679, 6.755481997154778, 4.998482844409679, 4.998482844409679, 3.6405248979060607, 5.329496294014808]\n",
      "all_sum after preprocessing is: [ 0.16655262  0.16655262 -0.96788454  0.61006589 -1.8096394   0.98366897\n",
      "  0.16655262  0.54015571  0.16655262  0.61006589  1.57341654  0.74275104\n",
      "  0.16655262  1.12990328  0.16655262  0.54015571  0.61006589  0.61006589\n",
      " -0.40277547  2.14961496  0.87125168  0.16655262  0.61006589 -1.36612613\n",
      "  0.16655262 -1.36612613 -1.36612613  0.16655262  0.61006589  0.61006589\n",
      " -1.8096394  -1.10494034  0.16655262  0.98366897 -1.36612613 -1.8096394\n",
      "  0.16655262  0.16655262 -1.36612613  0.54015571  0.61006589 -1.8096394\n",
      " -0.84628874 -1.36612613  0.16655262  2.14961496  0.16655262  0.16655262\n",
      " -1.36612613  0.54015571]\n",
      "P is: [0.5415421682749744, 0.5415421682749744, 0.2753023580100428, 0.6479558316600692, 0.14068171319589223, 0.7278356140074693, 0.5415421682749744, 0.6318486381298958, 0.5415421682749744, 0.6479558316600692, 0.8282701184161249, 0.67759713892796, 0.5415421682749744, 0.7558210487205138, 0.5415421682749744, 0.6318486381298958, 0.6479558316600692, 0.6479558316600692, 0.4006456854555398, 0.8956327910255791, 0.7050060804063647, 0.5415421682749744, 0.6479558316600692, 0.2032464492060289, 0.5415421682749744, 0.2032464492060289, 0.2032464492060289, 0.5415421682749744, 0.6479558316600692, 0.6479558316600692, 0.14068171319589223, 0.2488153692060261, 0.5415421682749744, 0.7278356140074693, 0.2032464492060289, 0.14068171319589223, 0.5415421682749744, 0.5415421682749744, 0.2032464492060289, 0.6318486381298958, 0.6479558316600692, 0.14068171319589223, 0.30021195762487024, 0.2032464492060289, 0.5415421682749744, 0.8956327910255791, 0.5415421682749744, 0.5415421682749744, 0.2032464492060289, 0.6318486381298958]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.824\n",
      "(*) epoch 2, cost 4.181\n",
      "(*) epoch 3, cost 3.172\n",
      "(*) epoch 4, cost 2.830\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 6.041\n",
      "(*) epoch 2, cost 3.946\n",
      "(*) epoch 3, cost 3.088\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.0543452382651344, 4.067056530587308, 3.4631813728104945, 3.0543452382651344, 3.0543452382651344, 3.0543452382651344, 3.4884963238318187, 3.0543452382651344, 2.450673228737818, 2.450673228737818, 2.450673228737818, 3.2440179745693185, 3.0543452382651344, 4.001797297435527, 3.0543452382651344, 3.02903028724381, 3.0543452382651344, 3.0543452382651344, 1.4768101041258643, 5.183826365468835, 3.6327022967711264, 3.02903028724381, 2.450673228737818, 3.071281694247335, 3.6327022967711264, 2.0804821136531806, 3.02903028724381, 2.6588391721591726, 3.6968654155026712, 4.670728540114625, 4.605469306962843, 3.02903028724381, 4.001797297435527, 3.0543452382651344, 2.0804821136531806, 4.670728540114625, 6.1965376577910085, 3.0543452382651344, 3.0543452382651344, 2.450673228737818, 3.8223750330753106, 1.4768101041258643, 3.6327022967711264, 5.183826365468835, 2.450673228737818, 2.450673228737818, 3.6327022967711264, 5.183826365468835, 2.450673228737818, 2.8848243143045025]\n",
      "all_sum after preprocessing is: [-0.2428758   0.83616921  0.19273955 -0.2428758  -0.2428758  -0.2428758\n",
      "  0.21971266 -0.2428758  -0.88608901 -0.88608901 -0.88608901 -0.04077929\n",
      " -0.2428758   0.76663542 -0.2428758  -0.26984891 -0.2428758  -0.2428758\n",
      " -1.92374125  2.02608872  0.37336429 -0.26984891 -0.88608901 -0.22482999\n",
      "  0.37336429 -1.28052805 -0.26984891 -0.66428796  0.44173016  1.47938241\n",
      "  1.40984863 -0.26984891  0.76663542 -0.2428758  -1.28052805  1.47938241\n",
      "  3.10513373 -0.2428758  -0.2428758  -0.88608901  0.5754608  -1.92374125\n",
      "  0.37336429  2.02608872 -0.88608901 -0.88608901  0.37336429  2.02608872\n",
      " -0.88608901 -0.42350054]\n",
      "P is: [0.43957777620494665, 0.6976577945731036, 0.548036274184873, 0.43957777620494665, 0.43957777620494665, 0.43957777620494665, 0.5547082620103554, 0.43957777620494665, 0.2919175783296238, 0.2919175783296238, 0.2919175783296238, 0.48980658970948127, 0.43957777620494665, 0.6827926195034227, 0.43957777620494665, 0.43294418713364724, 0.43957777620494665, 0.43957777620494665, 0.12744494848204585, 0.8835091293480581, 0.592271658342087, 0.43294418713364724, 0.2919175783296238, 0.444028078632614, 0.592271658342087, 0.2174603507839928, 0.43294418713364724, 0.3397770396839376, 0.6086712167325816, 0.8144792795224175, 0.8037420668530761, 0.43294418713364724, 0.6827926195034227, 0.43957777620494665, 0.2174603507839928, 0.8144792795224175, 0.9571040105079938, 0.43957777620494665, 0.43957777620494665, 0.2919175783296238, 0.6400222693182446, 0.12744494848204585, 0.592271658342087, 0.8835091293480581, 0.2919175783296238, 0.2919175783296238, 0.592271658342087, 0.8835091293480581, 0.2919175783296238, 0.3956794062963214]\n",
      "all_sum before preprocessing is: [3.112266096069354, 4.615714437290567, 3.112266096069354, 4.615714437290567, 4.615714437290567, 4.615714437290567, 4.615714437290567, 4.615714437290567, 3.112266096069354, 4.615714437290567, 3.112266096069354, 4.885199922293072, 3.112266096069354, 4.615714437290567, 4.145493519373789, 4.885199922293072, 4.615714437290567, 3.112266096069354, 3.112266096069354, 4.615714437290567, 3.112266096069354, 4.885199922293072, 4.885199922293072, 4.615714437290567, 3.112266096069354, 3.112266096069354, 4.615714437290567, 4.615714437290567, 4.885199922293072, 4.885199922293072, 4.885199922293072, 4.615714437290567, 4.615714437290567, 4.615714437290567, 4.615714437290567, 4.145493519373789, 4.615714437290567, 3.112266096069354, 4.615714437290567, 4.145493519373789, 4.615714437290567, 4.145493519373789, 4.615714437290567, 4.615714437290567, 3.112266096069354, 4.615714437290567, 4.615714437290567, 4.615714437290567, 4.615714437290567, 4.615714437290567]\n",
      "all_sum after preprocessing is: [-1.72229264  0.54366316 -1.72229264  0.54366316  0.54366316  0.54366316\n",
      "  0.54366316  0.54366316 -1.72229264  0.54366316 -1.72229264  0.94982424\n",
      " -1.72229264  0.54366316 -0.16504082  0.94982424  0.54366316 -1.72229264\n",
      " -1.72229264  0.54366316 -1.72229264  0.94982424  0.94982424  0.54366316\n",
      " -1.72229264 -1.72229264  0.54366316  0.54366316  0.94982424  0.94982424\n",
      "  0.94982424  0.54366316  0.54366316  0.54366316  0.54366316 -0.16504082\n",
      "  0.54366316 -1.72229264  0.54366316 -0.16504082  0.54366316 -0.16504082\n",
      "  0.54366316  0.54366316 -1.72229264  0.54366316  0.54366316  0.54366316\n",
      "  0.54366316  0.54366316]\n",
      "P is: [0.15157609215254217, 0.6326641500269108, 0.15157609215254217, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108, 0.15157609215254217, 0.6326641500269108, 0.15157609215254217, 0.7210798296315264, 0.15157609215254217, 0.6326641500269108, 0.4588331968615739, 0.7210798296315264, 0.6326641500269108, 0.15157609215254217, 0.15157609215254217, 0.6326641500269108, 0.15157609215254217, 0.7210798296315264, 0.7210798296315264, 0.6326641500269108, 0.15157609215254217, 0.15157609215254217, 0.6326641500269108, 0.6326641500269108, 0.7210798296315264, 0.7210798296315264, 0.7210798296315264, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108, 0.4588331968615739, 0.6326641500269108, 0.15157609215254217, 0.6326641500269108, 0.4588331968615739, 0.6326641500269108, 0.4588331968615739, 0.6326641500269108, 0.6326641500269108, 0.15157609215254217, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108, 0.6326641500269108]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.545\n",
      "(*) epoch 2, cost 2.238\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.768\n",
      "(*) epoch 2, cost 2.357\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.5842186362570667, 0.2648780355799438, 1.0959285637756206, 0.2648780355799438, 1.0959285637756206, 2.2508506911259563, 1.0959285637756206, 0.2648780355799438, 1.0959285637756206, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 1.0959285637756206, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 1.4198001629302797, 1.0959285637756206, 1.0959285637756206, 1.0959285637756206, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 1.0959285637756206, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 2.2508506911259563, 1.0959285637756206, 0.2648780355799438, 0.2648780355799438, 1.0959285637756206, 2.4152691644527433, 1.0959285637756206, 0.2648780355799438, 0.2648780355799438, 1.0959285637756206, 0.2648780355799438, 1.0959285637756206, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 0.2648780355799438, 1.0959285637756206, 0.2648780355799438, 2.2508506911259563]\n",
      "all_sum after preprocessing is: [ 1.38281634 -0.7426042   0.59619479 -0.7426042   0.59619479  2.45674179\n",
      "  0.59619479 -0.7426042   0.59619479 -0.7426042  -0.7426042  -0.7426042\n",
      "  0.59619479 -0.7426042  -0.7426042  -0.7426042   1.11794281  0.59619479\n",
      "  0.59619479  0.59619479 -0.7426042  -0.7426042  -0.7426042   0.59619479\n",
      " -0.7426042  -0.7426042  -0.7426042   2.45674179  0.59619479 -0.7426042\n",
      " -0.7426042   0.59619479  2.72161532  0.59619479 -0.7426042  -0.7426042\n",
      "  0.59619479 -0.7426042   0.59619479 -0.7426042  -0.7426042  -0.7426042\n",
      " -0.7426042  -0.7426042  -0.7426042  -0.7426042  -0.7426042   0.59619479\n",
      " -0.7426042   2.45674179]\n",
      "P is: [0.7994429355016363, 0.32243494048306726, 0.6447852521426406, 0.32243494048306726, 0.6447852521426406, 0.9210530694282771, 0.6447852521426406, 0.32243494048306726, 0.6447852521426406, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.6447852521426406, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.7536069293817322, 0.6447852521426406, 0.6447852521426406, 0.6447852521426406, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.6447852521426406, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.9210530694282771, 0.6447852521426406, 0.32243494048306726, 0.32243494048306726, 0.6447852521426406, 0.938290129975936, 0.6447852521426406, 0.32243494048306726, 0.32243494048306726, 0.6447852521426406, 0.32243494048306726, 0.6447852521426406, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.32243494048306726, 0.6447852521426406, 0.32243494048306726, 0.9210530694282771]\n",
      "all_sum before preprocessing is: [7.244397487817997, 4.4065309447282175, 3.9474514774338885, 4.320045236392415, 6.8718037288594696, 6.195178311284498, 6.0839317295553315, 6.8718037288594696, 4.821809185073828, 6.8718037288594696, 6.0839317295553315, 3.9474514774338885, 5.083156362303189, 3.9226906040405236, 4.735323476738026, 4.735323476738026, 7.007811183982001, 5.107917235696553, 6.829126252221065, 4.295284362999051, 4.295284362999051, 7.244397487817997, 4.295284362999051, 6.456525488513859, 6.195178311284498, 3.9226906040405236, 4.025020664620358, 6.0839317295553315, 6.8718037288594696, 3.9474514774338885, 4.295284362999051, 7.244397487817997, 3.9474514774338885, 3.9474514774338885, 4.320045236392415, 3.9474514774338885, 4.735323476738026, 3.9474514774338885, 4.667885126706257, 4.295284362999051, 5.083156362303189, 4.320045236392415, 4.735323476738026, 3.9226906040405236, 6.0839317295553315, 3.9226906040405236, 4.320045236392415, 4.710562603344662, 6.195178311284498, 4.710562603344662]\n",
      "all_sum after preprocessing is: [ 1.85453748 -0.62453113 -1.02556813 -0.70008225  1.5290516   0.93797347\n",
      "  0.84079205  1.5290516  -0.26175746  1.5290516   0.84079205 -1.02556813\n",
      " -0.03345301 -1.04719843 -0.33730859 -0.33730859  1.64786332 -0.01182271\n",
      "  1.49176993 -0.72171255 -0.72171255  1.85453748 -0.72171255  1.16627793\n",
      "  0.93797347 -1.04719843 -0.9578062   0.84079205  1.5290516  -1.02556813\n",
      " -0.72171255  1.85453748 -1.02556813 -1.02556813 -0.70008225 -1.02556813\n",
      " -0.33730859 -1.02556813 -0.39622055 -0.72171255 -0.03345301 -0.70008225\n",
      " -0.33730859 -1.04719843  0.84079205 -1.04719843 -0.70008225 -0.35893889\n",
      "  0.93797347 -0.35893889]\n",
      "P is: [0.8646589752290937, 0.3487516193887256, 0.263944215542857, 0.33179399152038097, 0.8218675092264729, 0.7186901268189934, 0.6986320048038237, 0.8218675092264729, 0.43493173380253103, 0.8218675092264729, 0.6986320048038237, 0.263944215542857, 0.49163752835428093, 0.2597634412404123, 0.41646340121239334, 0.41646340121239334, 0.8386020628818608, 0.49704435785787593, 0.816343781000437, 0.3270159786632296, 0.3270159786632296, 0.8646589752290937, 0.3270159786632296, 0.7624715755326301, 0.7186901268189934, 0.2597634412404123, 0.27731764594659397, 0.6986320048038237, 0.8218675092264729, 0.263944215542857, 0.3270159786632296, 0.8646589752290937, 0.263944215542857, 0.263944215542857, 0.33179399152038097, 0.263944215542857, 0.41646340121239334, 0.263944215542857, 0.4022207304131019, 0.3270159786632296, 0.49163752835428093, 0.33179399152038097, 0.41646340121239334, 0.2597634412404123, 0.6986320048038237, 0.2597634412404123, 0.33179399152038097, 0.4112164557604701, 0.7186901268189934, 0.4112164557604701]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.684\n",
      "(*) epoch 2, cost 1.596\n",
      "(*) epoch 3, cost 1.033\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 7.892\n",
      "(*) epoch 2, cost 4.830\n",
      "(*) epoch 3, cost 3.956\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.326729788224369, 2.205131980765267, 1.883841858234388, 1.883841858234388, 2.2888259198093293, 1.1969763531821718, 1.326729788224369, 2.738984422254924, 1.326729788224369, 1.326729788224369, 1.326729788224369, 1.326729788224369, 1.1978614083096528, 1.1969763531821718, 1.326729788224369, 2.738984422254924, 1.6471348556277663, 0.8765712857787742, 1.883841858234388, 2.738984422254924, 1.326729788224369, 3.0840138788009672, 3.5341723812465617, 3.0840138788009672, 2.610116042340208, 1.326729788224369, 0.8765712857787742, 0.8765712857787742, 1.883841858234388, 1.883841858234388, 1.4336833557887936, 2.2042469256377855, 1.326729788224369, 2.738984422254924, 1.6480199107552476, 0.8765712857787742, 1.326729788224369, 1.883841858234388, 1.326729788224369, 1.4336833557887936, 3.0840138788009672, 1.326729788224369, 1.326729788224369, 1.883841858234388, 1.326729788224369, 1.883841858234388, 3.6411259488109864, 1.326729788224369, 1.6480199107552476, 1.883841858234388]\n",
      "all_sum after preprocessing is: [-0.66882923  0.58405182  0.12578987  0.12578987  0.70342601 -0.85389891\n",
      " -0.66882923  1.34549528 -0.66882923 -0.66882923 -0.66882923 -0.66882923\n",
      " -0.85263654 -0.85389891 -0.66882923  1.34549528 -0.21182964 -1.3108985\n",
      "  0.12578987  1.34549528 -0.66882923  1.83761708  2.47968635  1.83761708\n",
      "  1.16168796 -0.66882923 -1.3108985  -1.3108985   0.12578987  0.12578987\n",
      " -0.5162794   0.58278945 -0.66882923  1.34549528 -0.21056727 -1.3108985\n",
      " -0.66882923  0.12578987 -0.66882923 -0.5162794   1.83761708 -0.66882923\n",
      " -0.66882923  0.12578987 -0.66882923  0.12578987  2.63223617 -0.66882923\n",
      " -0.21056727  0.12578987]\n",
      "P is: [0.3387590464546447, 0.6419991964421381, 0.5314060660289157, 0.5314060660289157, 0.6689469246666803, 0.29861561172995776, 0.3387590464546447, 0.7933921860488421, 0.3387590464546447, 0.3387590464546447, 0.3387590464546447, 0.3387590464546447, 0.2988800752157399, 0.29861561172995776, 0.3387590464546447, 0.7933921860488421, 0.4472397295490805, 0.21233653206330247, 0.5314060660289157, 0.7933921860488421, 0.3387590464546447, 0.862666639838619, 0.9227054313350276, 0.862666639838619, 0.7616392914445993, 0.3387590464546447, 0.21233653206330247, 0.21233653206330247, 0.5314060660289157, 0.5314060660289157, 0.37372264432494456, 0.6417090060459477, 0.3387590464546447, 0.7933921860488421, 0.44755182886440426, 0.21233653206330247, 0.3387590464546447, 0.5314060660289157, 0.3387590464546447, 0.37372264432494456, 0.862666639838619, 0.3387590464546447, 0.3387590464546447, 0.5314060660289157, 0.3387590464546447, 0.5314060660289157, 0.9329076491644247, 0.3387590464546447, 0.44755182886440426, 0.5314060660289157]\n",
      "all_sum before preprocessing is: [1.8222164960486382, 1.8222164960486382, 3.347551239496739, 1.3094214368911483, 3.860346298654229, 1.8222164960486382, 1.415038315451357, 1.8278133500174505, 3.300388364174454, 1.415038315451357, 1.8278133500174505, 1.3150182908599606, 1.9749962499311318, 1.415038315451357, 1.2622585615688635, 3.300388364174454, 1.2622585615688635, 1.2622585615688635, 1.2622585615688635, 1.8222164960486382, 1.2622585615688635, 1.8693793713709228, 1.8693793713709228, 1.2622585615688635, 1.2622585615688635, 1.2622585615688635, 1.2622585615688635, 1.8693793713709228, 1.8222164960486382, 3.4531681180569476, 1.8222164960486382, 1.2622585615688635, 1.2622585615688635, 1.2622585615688635, 1.2622585615688635, 1.8222164960486382, 1.8222164960486382, 1.415038315451357, 1.2622585615688635, 2.0221591252534163, 1.2622585615688635, 1.2622585615688635, 1.415038315451357, 1.8222164960486382, 1.8222164960486382, 3.860346298654229, 1.2622585615688635, 1.415038315451357, 1.2622585615688635, 1.2622585615688635]\n",
      "all_sum after preprocessing is: [ 0.09644048  0.09644048  2.25467641 -0.62912664  2.98024353  0.09644048\n",
      " -0.47968656  0.10435961  2.18794443 -0.47968656  0.10435961 -0.6212075\n",
      "  0.31261254 -0.47968656 -0.69585862  2.18794443 -0.69585862 -0.69585862\n",
      " -0.69585862  0.09644048 -0.69585862  0.16317246  0.16317246 -0.69585862\n",
      " -0.69585862 -0.69585862 -0.69585862  0.16317246  0.09644048  2.40411649\n",
      "  0.09644048 -0.69585862 -0.69585862 -0.69585862 -0.69585862  0.09644048\n",
      "  0.09644048 -0.47968656 -0.69585862  0.37934452 -0.69585862 -0.69585862\n",
      " -0.47968656  0.09644048  0.09644048  2.98024353 -0.69585862 -0.47968656\n",
      " -0.69585862 -0.69585862]\n",
      "P is: [0.5240914496257693, 0.5240914496257693, 0.9050531504107379, 0.3477085967989006, 0.9516735725718172, 0.5240914496257693, 0.3823261427083088, 0.5260662499847226, 0.8991616810012338, 0.3823261427083088, 0.5260662499847226, 0.3495068739495937, 0.5775228235289834, 0.3823261427083088, 0.33273106394474555, 0.8991616810012338, 0.33273106394474555, 0.33273106394474555, 0.33273106394474555, 0.5240914496257693, 0.33273106394474555, 0.5407028447008632, 0.5407028447008632, 0.33273106394474555, 0.33273106394474555, 0.33273106394474555, 0.33273106394474555, 0.5407028447008632, 0.5240914496257693, 0.9171406685139505, 0.5240914496257693, 0.33273106394474555, 0.33273106394474555, 0.33273106394474555, 0.33273106394474555, 0.5240914496257693, 0.5240914496257693, 0.3823261427083088, 0.33273106394474555, 0.5937149996276908, 0.33273106394474555, 0.33273106394474555, 0.3823261427083088, 0.5240914496257693, 0.5240914496257693, 0.9516735725718172, 0.33273106394474555, 0.3823261427083088, 0.33273106394474555, 0.33273106394474555]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.902\n",
      "(*) epoch 2, cost 3.052\n",
      "(*) epoch 3, cost 2.428\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.494\n",
      "(*) epoch 2, cost 3.978\n",
      "(*) epoch 3, cost 2.613\n",
      "(*) epoch 4, cost 2.031\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.0559557868090597, 2.7332904523879584, 1.9770062173551723, 2.7332904523879584, 2.0559557868090597, 1.2996715517762734, 2.7332904523879584, 1.2996715517762734, 2.0559557868090597, 2.0559557868090597, 2.7332904523879584, 1.9770062173551723, 2.0559557868090597, 2.0559557868090597, 2.7332904523879584, 2.7332904523879584, 2.7332904523879584, 1.2996715517762734, 2.0559557868090597, 1.9770062173551723, 2.7332904523879584, 2.7332904523879584, 1.9770062173551723, 1.9770062173551723, 1.2996715517762734, 3.6953049488723773, 2.0559557868090597, 2.7332904523879584, 2.7332904523879584, 1.2996715517762734, 1.2996715517762734, 1.2996715517762734, 2.0559557868090597, 2.0559557868090597, 1.2996715517762734, 1.2996715517762734, 1.2996715517762734, 1.9770062173551723, 1.9770062173551723, 2.0559557868090597, 1.2996715517762734, 1.9770062173551723, 1.9770062173551723, 2.0559557868090597, 2.0559557868090597, 1.2996715517762734, 2.7332904523879584, 1.2996715517762734, 2.7332904523879584, 1.2996715517762734]\n",
      "all_sum after preprocessing is: [ 0.02954726  1.20153025 -0.10705811  1.20153025  0.02954726 -1.27904111\n",
      "  1.20153025 -1.27904111  0.02954726  0.02954726  1.20153025 -0.10705811\n",
      "  0.02954726  0.02954726  1.20153025  1.20153025  1.20153025 -1.27904111\n",
      "  0.02954726 -0.10705811  1.20153025  1.20153025 -0.10705811 -0.10705811\n",
      " -1.27904111  2.8660909   0.02954726  1.20153025  1.20153025 -1.27904111\n",
      " -1.27904111 -1.27904111  0.02954726  0.02954726 -1.27904111 -1.27904111\n",
      " -1.27904111 -0.10705811 -0.10705811  0.02954726 -1.27904111 -0.10705811\n",
      " -0.10705811  0.02954726  0.02954726 -1.27904111  1.20153025 -1.27904111\n",
      "  1.20153025 -1.27904111]\n",
      "P is: [0.5073862769749532, 0.7687968949428204, 0.47326100583166325, 0.7687968949428204, 0.5073862769749532, 0.21771349250114028, 0.7687968949428204, 0.21771349250114028, 0.5073862769749532, 0.5073862769749532, 0.7687968949428204, 0.47326100583166325, 0.5073862769749532, 0.5073862769749532, 0.7687968949428204, 0.7687968949428204, 0.7687968949428204, 0.21771349250114028, 0.5073862769749532, 0.47326100583166325, 0.7687968949428204, 0.7687968949428204, 0.47326100583166325, 0.47326100583166325, 0.21771349250114028, 0.9461445065667756, 0.5073862769749532, 0.7687968949428204, 0.7687968949428204, 0.21771349250114028, 0.21771349250114028, 0.21771349250114028, 0.5073862769749532, 0.5073862769749532, 0.21771349250114028, 0.21771349250114028, 0.21771349250114028, 0.47326100583166325, 0.47326100583166325, 0.5073862769749532, 0.21771349250114028, 0.47326100583166325, 0.47326100583166325, 0.5073862769749532, 0.5073862769749532, 0.21771349250114028, 0.7687968949428204, 0.21771349250114028, 0.7687968949428204, 0.21771349250114028]\n",
      "all_sum before preprocessing is: [1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 3.2039086125808685, 1.2897515727275608, 2.365976538902215, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 4.203655718627896, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 3.2039086125808685, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608, 4.5890898755122755, 1.2897515727275608, 1.2897515727275608, 2.365976538902215, 1.2897515727275608, 1.2897515727275608, 1.2897515727275608]\n",
      "all_sum after preprocessing is: [-0.33789491 -0.33789491 -0.33789491  2.31416176 -0.33789491  1.15321033\n",
      " -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491\n",
      " -0.33789491 -0.33789491  3.69930724 -0.33789491 -0.33789491 -0.33789491\n",
      " -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491\n",
      " -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491\n",
      " -0.33789491 -0.33789491  2.31416176 -0.33789491 -0.33789491 -0.33789491\n",
      " -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491 -0.33789491\n",
      " -0.33789491  4.23332467 -0.33789491 -0.33789491  1.15321033 -0.33789491\n",
      " -0.33789491 -0.33789491]\n",
      "P is: [0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.9100431379171056, 0.4163209187506053, 0.7600968085874351, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.9758566622697479, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.9100431379171056, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053, 0.9857032720691109, 0.4163209187506053, 0.4163209187506053, 0.7600968085874351, 0.4163209187506053, 0.4163209187506053, 0.4163209187506053]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.167\n",
      "(*) epoch 2, cost 1.842\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.078\n",
      "(*) epoch 2, cost 1.185\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 4.210197316068243, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.856953456668494, 3.990793485642846, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 4.210197316068243, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.990793485642846, 3.856953456668494, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992, 3.0552609517978992]\n",
      "all_sum after preprocessing is: [-0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788\n",
      " -0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788\n",
      " -0.3645788  -0.3645788  -0.3645788  -0.3645788   3.27513259 -0.3645788\n",
      " -0.3645788  -0.3645788  -0.3645788   2.16190615  2.58369482 -0.3645788\n",
      " -0.3645788  -0.3645788  -0.3645788  -0.3645788   3.27513259 -0.3645788\n",
      " -0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788\n",
      " -0.3645788  -0.3645788   2.58369482  2.16190615 -0.3645788  -0.3645788\n",
      " -0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788  -0.3645788\n",
      " -0.3645788  -0.3645788 ]\n",
      "P is: [0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.9635657896118353, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.8967761317137851, 0.9298048054236696, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.9635657896118353, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.9298048054236696, 0.8967761317137851, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446, 0.4098516216748446]\n",
      "all_sum before preprocessing is: [1.3851038606669195, 2.489333096956288, 1.388336368955161, 1.3851038606669195, 1.3851038606669195, 1.388336368955161, 1.388336368955161, 1.3851038606669195, 1.3851038606669195, 1.388336368955161, 1.388336368955161, 2.4861005886680463, 1.388336368955161, 1.388336368955161, 1.3851038606669195, 1.388336368955161, 1.388336368955161, 1.388336368955161, 1.388336368955161, 2.489333096956288, 1.388336368955161, 1.388336368955161, 2.489333096956288, 1.3851038606669195, 2.489333096956288, 1.388336368955161, 1.388336368955161, 1.388336368955161, 1.3851038606669195, 2.4861005886680463, 1.388336368955161, 2.489333096956288, 1.388336368955161, 2.4861005886680463, 2.489333096956288, 1.388336368955161, 1.3851038606669195, 2.489333096956288, 1.388336368955161, 2.489333096956288, 1.388336368955161, 1.388336368955161, 1.388336368955161, 1.3851038606669195, 1.3851038606669195, 1.388336368955161, 2.489333096956288, 2.489333096956288, 1.3851038606669195, 1.388336368955161]\n",
      "all_sum after preprocessing is: [-0.59726756  1.68859113 -0.59057597 -0.59726756 -0.59726756 -0.59057597\n",
      " -0.59057597 -0.59726756 -0.59726756 -0.59057597 -0.59057597  1.68189953\n",
      " -0.59057597 -0.59057597 -0.59726756 -0.59057597 -0.59057597 -0.59057597\n",
      " -0.59057597  1.68859113 -0.59057597 -0.59057597  1.68859113 -0.59726756\n",
      "  1.68859113 -0.59057597 -0.59057597 -0.59057597 -0.59726756  1.68189953\n",
      " -0.59057597  1.68859113 -0.59057597  1.68189953  1.68859113 -0.59057597\n",
      " -0.59726756  1.68859113 -0.59057597  1.68859113 -0.59057597 -0.59057597\n",
      " -0.59057597 -0.59726756 -0.59726756 -0.59057597  1.68859113  1.68859113\n",
      " -0.59726756 -0.59057597]\n",
      "P is: [0.3549690807602967, 0.8440387900255986, 0.3565027118517967, 0.3549690807602967, 0.3549690807602967, 0.3565027118517967, 0.3565027118517967, 0.3549690807602967, 0.3549690807602967, 0.3565027118517967, 0.3565027118517967, 0.8431558969003399, 0.3565027118517967, 0.3565027118517967, 0.3549690807602967, 0.3565027118517967, 0.3565027118517967, 0.3565027118517967, 0.3565027118517967, 0.8440387900255986, 0.3565027118517967, 0.3565027118517967, 0.8440387900255986, 0.3549690807602967, 0.8440387900255986, 0.3565027118517967, 0.3565027118517967, 0.3565027118517967, 0.3549690807602967, 0.8431558969003399, 0.3565027118517967, 0.8440387900255986, 0.3565027118517967, 0.8431558969003399, 0.8440387900255986, 0.3565027118517967, 0.3549690807602967, 0.8440387900255986, 0.3565027118517967, 0.8440387900255986, 0.3565027118517967, 0.3565027118517967, 0.3565027118517967, 0.3549690807602967, 0.3549690807602967, 0.3565027118517967, 0.8440387900255986, 0.8440387900255986, 0.3549690807602967, 0.3565027118517967]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.910\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.445\n",
      "(*) epoch 2, cost 1.431\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.6310162207430356, 3.1192625640025304, 4.893375327608943, 3.1192625640025304, 3.1192625640025304, 3.1192625640025304, 3.5016272631379226, 3.1192625640025304, 3.1192625640025304, 3.1192625640025304, 1.6310162207430356, 1.6310162207430356, 3.1192625640025304, 1.6310162207430356, 1.6310162207430356, 3.1192625640025304, 1.6310162207430356, 1.6310162207430356, 3.1192625640025304, 1.6310162207430356, 3.405128984349449, 3.1192625640025304, 1.6310162207430356, 3.1192625640025304, 3.1192625640025304, 3.163871271904712, 1.6310162207430356, 1.6310162207430356, 1.6756249286452172, 1.968772211976246, 3.163871271904712, 1.6310162207430356, 1.6310162207430356, 3.1192625640025304, 1.6756249286452172, 3.1192625640025304, 3.457018555235741, 1.6756249286452172, 1.6310162207430356, 3.1192625640025304, 1.6310162207430356, 3.1192625640025304, 4.893375327608943, 1.6310162207430356, 3.1192625640025304, 3.1192625640025304, 3.1192625640025304, 1.6310162207430356, 3.1192625640025304, 3.1192625640025304]\n",
      "all_sum after preprocessing is: [-1.1045001   0.59803431  2.62759617  0.59803431  0.59803431  0.59803431\n",
      "  1.03545454  0.59803431  0.59803431  0.59803431 -1.1045001  -1.1045001\n",
      "  0.59803431 -1.1045001  -1.1045001   0.59803431 -1.1045001  -1.1045001\n",
      "  0.59803431 -1.1045001   0.92506176  0.59803431 -1.1045001   0.59803431\n",
      "  0.59803431  0.64906609 -1.1045001  -1.1045001  -1.05346832 -0.71811165\n",
      "  0.64906609 -1.1045001  -1.1045001   0.59803431 -1.05346832  0.59803431\n",
      "  0.98442276 -1.05346832 -1.1045001   0.59803431 -1.1045001   0.59803431\n",
      "  2.62759617 -1.1045001   0.59803431  0.59803431  0.59803431 -1.1045001\n",
      "  0.59803431  0.59803431]\n",
      "P is: [0.24889766095595114, 0.645206458022047, 0.9326166430476994, 0.645206458022047, 0.645206458022047, 0.645206458022047, 0.7379720041044604, 0.645206458022047, 0.645206458022047, 0.645206458022047, 0.24889766095595114, 0.24889766095595114, 0.645206458022047, 0.24889766095595114, 0.24889766095595114, 0.645206458022047, 0.24889766095595114, 0.24889766095595114, 0.645206458022047, 0.24889766095595114, 0.7160723513845336, 0.645206458022047, 0.24889766095595114, 0.645206458022047, 0.645206458022047, 0.6567999767137246, 0.24889766095595114, 0.24889766095595114, 0.25855964437638457, 0.3278089455331842, 0.6567999767137246, 0.24889766095595114, 0.24889766095595114, 0.645206458022047, 0.25855964437638457, 0.645206458022047, 0.7279849058606969, 0.25855964437638457, 0.24889766095595114, 0.645206458022047, 0.24889766095595114, 0.645206458022047, 0.9326166430476994, 0.24889766095595114, 0.645206458022047, 0.645206458022047, 0.645206458022047, 0.24889766095595114, 0.645206458022047, 0.645206458022047]\n",
      "all_sum before preprocessing is: [2.4680828762293747, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 2.7978334105200195, 1.60445605995799, 3.3586052796348933, 4.10997579099003, 3.6614602267914043, 3.6614602267914043, 2.215010402909702, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 2.7978334105200195, 3.6614602267914043, 2.7978334105200195, 2.215010402909702, 3.6614602267914043, 2.7978334105200195, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 2.7978334105200195, 2.215010402909702, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 4.10997579099003, 3.6614602267914043, 3.6614602267914043, 3.2463489747186456, 2.215010402909702, 3.6614602267914043, 3.6614602267914043, 2.663525967108328, 3.6614602267914043, 3.6614602267914043, 3.6614602267914043, 2.215010402909702, 3.6614602267914043, 3.6614602267914043]\n",
      "all_sum after preprocessing is: [-1.52765846  0.54169992  0.54169992  0.54169992  0.54169992  0.54169992\n",
      " -0.95585941 -3.02521779  0.01653877  1.31944171  0.54169992  0.54169992\n",
      " -1.96649505  0.54169992  0.54169992  0.54169992  0.54169992 -0.95585941\n",
      "  0.54169992 -0.95585941 -1.96649505  0.54169992 -0.95585941  0.54169992\n",
      "  0.54169992  0.54169992  0.54169992  0.54169992  0.54169992  0.54169992\n",
      " -0.95585941 -1.96649505  0.54169992  0.54169992  0.54169992  0.54169992\n",
      "  1.31944171  0.54169992  0.54169992 -0.17811762 -1.96649505  0.54169992\n",
      "  0.54169992 -1.18875325  0.54169992  0.54169992  0.54169992 -1.96649505\n",
      "  0.54169992  0.54169992]\n",
      "P is: [0.17833653922645323, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.27770797440340267, 0.046299532062860034, 0.5041345973874244, 0.789088806601617, 0.63220777303862, 0.63220777303862, 0.12276585176250515, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.27770797440340267, 0.63220777303862, 0.27770797440340267, 0.12276585176250515, 0.63220777303862, 0.27770797440340267, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.27770797440340267, 0.12276585176250515, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.789088806601617, 0.63220777303862, 0.63220777303862, 0.455587950134169, 0.12276585176250515, 0.63220777303862, 0.63220777303862, 0.23348198936358275, 0.63220777303862, 0.63220777303862, 0.63220777303862, 0.12276585176250515, 0.63220777303862, 0.63220777303862]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.508\n",
      "(*) epoch 2, cost 2.379\n",
      "(*) epoch 3, cost 1.895\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.940\n",
      "(*) epoch 2, cost 2.251\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [0.3632540133528314, 1.5442969733552416, 0.35331245900006203, 1.5442969733552416, 2.378065008732635, 0.35331245900006203, 0.3632540133528314, 0.35331245900006203, 0.35331245900006203, 0.3632540133528314, 0.3632540133528314, 0.35331245900006203, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 1.5343554190024722, 0.3632540133528314, 0.35331245900006203, 0.3632540133528314, 1.5442969733552416, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 1.6428937702166089, 0.35331245900006203, 0.3632540133528314, 0.3632540133528314, 0.35331245900006203, 0.8495312607088166, 2.378065008732635, 0.3632540133528314, 0.3632540133528314, 2.378065008732635, 2.378065008732635, 1.5442969733552416, 1.5442969733552416, 2.368123454379866, 0.3632540133528314, 1.5442969733552416, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 0.3632540133528314, 1.1466749685078543, 0.35331245900006203]\n",
      "all_sum after preprocessing is: [-0.60179775  1.1082679  -0.61619241  1.1082679   2.31550432 -0.61619241\n",
      " -0.60179775 -0.61619241 -0.61619241 -0.60179775 -0.60179775 -0.61619241\n",
      " -0.60179775 -0.60179775 -0.60179775  1.09387324 -0.60179775 -0.61619241\n",
      " -0.60179775  1.1082679  -0.60179775 -0.60179775 -0.60179775 -0.60179775\n",
      "  1.251029   -0.61619241 -0.60179775 -0.60179775 -0.61619241  0.10229689\n",
      "  2.31550432 -0.60179775 -0.60179775  2.31550432  2.31550432  1.1082679\n",
      "  1.1082679   2.30110966 -0.60179775  1.1082679  -0.60179775 -0.60179775\n",
      " -0.60179775 -0.60179775 -0.60179775 -0.60179775 -0.60179775 -0.60179775\n",
      "  0.5325397  -0.61619241]\n",
      "P is: [0.35393250490938183, 0.751806053028725, 0.35064792334304157, 0.751806053028725, 0.9101529856033934, 0.35064792334304157, 0.35393250490938183, 0.35064792334304157, 0.35064792334304157, 0.35393250490938183, 0.35393250490938183, 0.35064792334304157, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.749110375820799, 0.35393250490938183, 0.35064792334304157, 0.35393250490938183, 0.751806053028725, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.777477935227511, 0.35064792334304157, 0.35393250490938183, 0.35393250490938183, 0.35064792334304157, 0.5255519434647739, 0.9101529856033934, 0.35393250490938183, 0.35393250490938183, 0.9101529856033934, 0.9101529856033934, 0.751806053028725, 0.751806053028725, 0.9089688987414225, 0.35393250490938183, 0.751806053028725, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.35393250490938183, 0.6300752623962093, 0.35064792334304157]\n",
      "all_sum before preprocessing is: [2.2133272177225383, 2.8256008998545177, 2.7435388424145657, 2.7435388424145657, 2.259306014218692, 2.2953892751624907, 2.7435388424145657, 2.8256008998545177, 2.8256008998545177, 2.7435388424145657, 2.2953892751624907, 2.7435388424145657, 2.7435388424145657, 2.7435388424145657, 2.2133272177225383, 2.7435388424145657, 2.2133272177225383, 2.8256008998545177, 2.8256008998545177, 2.8256008998545177, 2.7435388424145657, 2.2133272177225383, 2.2133272177225383, 2.7435388424145657, 2.8256008998545177, 2.8256008998545177, 2.8256008998545177, 2.8256008998545177, 2.8256008998545177, 2.8256008998545177, 2.7435388424145657, 2.2133272177225383, 2.8256008998545177, 2.259306014218692, 2.7435388424145657, 2.8256008998545177, 2.7435388424145657, 2.8256008998545177, 2.7435388424145657, 2.8256008998545177, 2.7435388424145657, 2.7435388424145657, 2.7435388424145657, 2.2133272177225383, 2.8256008998545177, 2.7435388424145657, 2.8256008998545177, 2.7435388424145657, 2.7435388424145657, 2.8256008998545177]\n",
      "all_sum after preprocessing is: [-1.95643032  0.70627233  0.34939457  0.34939457 -1.75647421 -1.59955256\n",
      "  0.34939457  0.70627233  0.70627233  0.34939457 -1.59955256  0.34939457\n",
      "  0.34939457  0.34939457 -1.95643032  0.34939457 -1.95643032  0.70627233\n",
      "  0.70627233  0.70627233  0.34939457 -1.95643032 -1.95643032  0.34939457\n",
      "  0.70627233  0.70627233  0.70627233  0.70627233  0.70627233  0.70627233\n",
      "  0.34939457 -1.95643032  0.70627233 -1.75647421  0.34939457  0.70627233\n",
      "  0.34939457  0.70627233  0.34939457  0.70627233  0.34939457  0.34939457\n",
      "  0.34939457 -1.95643032  0.70627233  0.34939457  0.70627233  0.34939457\n",
      "  0.34939457  0.70627233]\n",
      "P is: [0.12385388874038178, 0.6695769583958311, 0.5864707570508292, 0.5864707570508292, 0.14723247055288732, 0.16804415994994046, 0.5864707570508292, 0.6695769583958311, 0.6695769583958311, 0.5864707570508292, 0.16804415994994046, 0.5864707570508292, 0.5864707570508292, 0.5864707570508292, 0.12385388874038178, 0.5864707570508292, 0.12385388874038178, 0.6695769583958311, 0.6695769583958311, 0.6695769583958311, 0.5864707570508292, 0.12385388874038178, 0.12385388874038178, 0.5864707570508292, 0.6695769583958311, 0.6695769583958311, 0.6695769583958311, 0.6695769583958311, 0.6695769583958311, 0.6695769583958311, 0.5864707570508292, 0.12385388874038178, 0.6695769583958311, 0.14723247055288732, 0.5864707570508292, 0.6695769583958311, 0.5864707570508292, 0.6695769583958311, 0.5864707570508292, 0.6695769583958311, 0.5864707570508292, 0.5864707570508292, 0.5864707570508292, 0.12385388874038178, 0.6695769583958311, 0.5864707570508292, 0.6695769583958311, 0.5864707570508292, 0.5864707570508292, 0.6695769583958311]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.033\n",
      "(*) epoch 2, cost 2.274\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.437\n",
      "(*) epoch 2, cost 1.580\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [7.264899244457563, 7.264899244457563, 6.349192721093832, 7.264899244457563, 7.264899244457563, 6.1730547148699015, 3.9205954413137647, 5.012439970901427, 5.012439970901427, 5.012439970901427, 7.264899244457563, 5.012439970901427, 4.096733447537696, 5.012439970901427, 5.012439970901427, 7.264899244457563, 7.264899244457563, 5.012439970901427, 4.493613147969547, 4.096733447537696, 5.012439970901427, 5.012439970901427, 6.746072421525683, 6.1730547148699015, 5.012439970901427, 5.012439970901427, 3.9205954413137647, 5.012439970901427, 5.012439970901427, 7.264899244457563, 3.9205954413137647, 4.493613147969547, 5.012439970901427, 5.012439970901427, 5.012439970901427, 5.012439970901427, 7.264899244457563, 5.012439970901427, 3.401768618381884, 6.1730547148699015, 5.012439970901427, 3.0048889179500335, 7.264899244457563, 7.264899244457563, 5.012439970901427, 7.264899244457563, 7.264899244457563, 5.012439970901427, 5.012439970901427, 7.264899244457563]\n",
      "all_sum after preprocessing is: [ 1.36540315  1.36540315  0.62381269  1.36540315  1.36540315  0.48116626\n",
      " -1.3430015  -0.45876461 -0.45876461 -0.45876461  1.36540315 -0.45876461\n",
      " -1.20035507 -0.45876461 -0.45876461  1.36540315  1.36540315 -0.45876461\n",
      " -0.87893964 -1.20035507 -0.45876461 -0.45876461  0.94522812  0.48116626\n",
      " -0.45876461 -0.45876461 -1.3430015  -0.45876461 -0.45876461  1.36540315\n",
      " -1.3430015  -0.87893964 -0.45876461 -0.45876461 -0.45876461 -0.45876461\n",
      "  1.36540315 -0.45876461 -1.76317654  0.48116626 -0.45876461 -2.08459196\n",
      "  1.36540315  1.36540315 -0.45876461  1.36540315  1.36540315 -0.45876461\n",
      " -0.45876461  1.36540315]\n",
      "P is: [0.7966364486076176, 0.7966364486076176, 0.6510851880579333, 0.7966364486076176, 0.7966364486076176, 0.6180232325166122, 0.20701689655636396, 0.38727893464293445, 0.38727893464293445, 0.38727893464293445, 0.7966364486076176, 0.38727893464293445, 0.23141205766807868, 0.38727893464293445, 0.38727893464293445, 0.7966364486076176, 0.7966364486076176, 0.38727893464293445, 0.29339755876973567, 0.23141205766807868, 0.38727893464293445, 0.38727893464293445, 0.7201545015817575, 0.6180232325166122, 0.38727893464293445, 0.38727893464293445, 0.20701689655636396, 0.38727893464293445, 0.38727893464293445, 0.7966364486076176, 0.20701689655636396, 0.29339755876973567, 0.38727893464293445, 0.38727893464293445, 0.38727893464293445, 0.38727893464293445, 0.7966364486076176, 0.38727893464293445, 0.14639294711915782, 0.6180232325166122, 0.38727893464293445, 0.11060344555015103, 0.7966364486076176, 0.7966364486076176, 0.38727893464293445, 0.7966364486076176, 0.7966364486076176, 0.38727893464293445, 0.38727893464293445, 0.7966364486076176]\n",
      "all_sum before preprocessing is: [1.1086248701810404, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 1.1086248701810404, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 1.1086248701810404, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 1.551813874103167, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 1.1086248701810404, 0.2876860390813119, 1.1086248701810404, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.2876860390813119, 0.5041328788233529, 1.1086248701810404, 0.2876860390813119]\n",
      "all_sum after preprocessing is: [ 2.22044083 -0.41063232 -0.41063232 -0.41063232  2.22044083 -0.41063232\n",
      " -0.41063232 -0.41063232 -0.41063232 -0.41063232 -0.41063232 -0.41063232\n",
      " -0.41063232 -0.41063232 -0.41063232  2.22044083 -0.41063232 -0.41063232\n",
      " -0.41063232 -0.41063232 -0.41063232 -0.41063232 -0.41063232 -0.41063232\n",
      "  3.64084226 -0.41063232 -0.41063232 -0.41063232 -0.41063232 -0.41063232\n",
      " -0.41063232 -0.41063232 -0.41063232 -0.41063232 -0.41063232 -0.41063232\n",
      " -0.41063232 -0.41063232 -0.41063232 -0.41063232  2.22044083 -0.41063232\n",
      "  2.22044083 -0.41063232 -0.41063232 -0.41063232 -0.41063232  0.28307036\n",
      "  2.22044083 -0.41063232]\n",
      "P is: [0.9020701451591236, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.9020701451591236, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.9020701451591236, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.9744401977513991, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.9020701451591236, 0.3987605115592434, 0.9020701451591236, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.3987605115592434, 0.570298801912893, 0.9020701451591236, 0.3987605115592434]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.263\n",
      "(*) epoch 2, cost 2.416\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.013\n",
      "(*) epoch 2, cost 0.597\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.3864623989630089, 1.9860048643347779, 3.0901599103427895, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 1.4906174449710203, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 1.4906174449710203, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.4505556735943762, 2.050098138966145, 0.3864623989630089, 1.9860048643347779, 0.3864623989630089, 0.3864623989630089, 1.9860048643347779, 0.3864623989630089, 0.4505556735943762, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 1.4906174449710203, 1.9860048643347779, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 2.6137902455667628, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 1.9860048643347779, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 0.3864623989630089, 1.9860048643347779, 0.3864623989630089, 1.4906174449710203, 0.3864623989630089]\n",
      "all_sum after preprocessing is: [-0.56781529  1.62212738  3.13383232 -0.56781529 -0.56781529 -0.56781529\n",
      " -0.56781529 -0.56781529 -0.56781529 -0.56781529 -0.56781529  0.94388965\n",
      " -0.56781529 -0.56781529 -0.56781529  0.94388965 -0.56781529 -0.56781529\n",
      " -0.56781529 -0.48006483  1.70987784 -0.56781529  1.62212738 -0.56781529\n",
      " -0.56781529  1.62212738 -0.56781529 -0.48006483 -0.56781529 -0.56781529\n",
      " -0.56781529  0.94388965  1.62212738 -0.56781529 -0.56781529 -0.56781529\n",
      " -0.56781529  2.48163191 -0.56781529 -0.56781529 -0.56781529  1.62212738\n",
      " -0.56781529 -0.56781529 -0.56781529 -0.56781529  1.62212738 -0.56781529\n",
      "  0.94388965 -0.56781529]\n",
      "P is: [0.3617410870760015, 0.8350883123043017, 0.9582669223755845, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.7198846784362314, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.7198846784362314, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.38223681726133873, 0.84682043939491, 0.3617410870760015, 0.8350883123043017, 0.3617410870760015, 0.3617410870760015, 0.8350883123043017, 0.3617410870760015, 0.38223681726133873, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.7198846784362314, 0.8350883123043017, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.9228440746415246, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.8350883123043017, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.3617410870760015, 0.8350883123043017, 0.3617410870760015, 0.7198846784362314, 0.3617410870760015]\n",
      "all_sum before preprocessing is: [0.6679529766057463, 0.6679529766057463, 1.981270992181484, 0.5142272118256883, 1.5540407192719141, 1.91466054570574, 0.6679529766057463, 1.981270992181484, 0.5142272118256883, 1.981270992181484, 0.6679529766057463, 1.981270992181484, 1.8275452274014259, 0.7550682949100603, 0.5142272118256883, 0.5142272118256883, 0.5142272118256883, 0.6679529766057463, 2.6265176517632796, 0.6013425301300024, 2.068386310485798, 0.5142272118256883, 0.6679529766057463, 0.6679529766057463, 1.275077056898165, 1.4669254009675998, 0.5142272118256883, 0.6679529766057463, 0.5142272118256883, 0.6679529766057463, 1.5540407192719141, 0.7550682949100603, 0.6013425301300024, 0.5142272118256883, 0.6679529766057463, 0.7550682949100603, 0.5142272118256883, 0.6013425301300024, 2.7802434165433376, 1.5175922687564933, 1.4669254009675998, 0.5142272118256883, 1.8275452274014259, 0.5142272118256883, 1.8275452274014259, 1.981270992181484, 2.068386310485798, 0.5142272118256883, 0.6679529766057463, 0.7550682949100603]\n",
      "all_sum after preprocessing is: [-0.64060189 -0.64060189  1.34917858 -0.87350856  0.70189099  1.2482585\n",
      " -0.64060189  1.34917858 -0.87350856  1.34917858 -0.64060189  1.34917858\n",
      "  1.11627191 -0.5086153  -0.87350856 -0.87350856 -0.87350856 -0.64060189\n",
      "  2.32677821 -0.74152197  1.48116517 -0.87350856 -0.64060189 -0.64060189\n",
      "  0.27923902  0.56990441 -0.87350856 -0.64060189 -0.87350856 -0.64060189\n",
      "  0.70189099 -0.5086153  -0.74152197 -0.87350856 -0.64060189 -0.5086153\n",
      " -0.87350856 -0.74152197  2.55968488  0.64666871  0.56990441 -0.87350856\n",
      "  1.11627191 -0.87350856  1.11627191  1.34917858  1.48116517 -0.87350856\n",
      " -0.64060189 -0.5086153 ]\n",
      "P is: [0.3451104948022295, 0.3451104948022295, 0.7939953039163055, 0.2945247694180755, 0.6686068960751508, 0.7769982530944326, 0.3451104948022295, 0.7939953039163055, 0.2945247694180755, 0.7939953039163055, 0.3451104948022295, 0.7939953039163055, 0.7532965399404286, 0.3755181870511317, 0.2945247694180755, 0.2945247694180755, 0.2945247694180755, 0.3451104948022295, 0.9110706496161249, 0.3226714202561632, 0.8147485076317117, 0.2945247694180755, 0.3451104948022295, 0.3451104948022295, 0.5693596502065692, 0.6387411175184767, 0.2945247694180755, 0.3451104948022295, 0.2945247694180755, 0.3451104948022295, 0.6686068960751508, 0.3755181870511317, 0.3226714202561632, 0.2945247694180755, 0.3451104948022295, 0.3755181870511317, 0.2945247694180755, 0.3226714202561632, 0.9282214650185606, 0.6562593724805713, 0.6387411175184767, 0.2945247694180755, 0.7532965399404286, 0.2945247694180755, 0.7532965399404286, 0.7939953039163055, 0.8147485076317117, 0.2945247694180755, 0.3451104948022295, 0.3755181870511317]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.921\n",
      "(*) epoch 2, cost 2.108\n",
      "(*) epoch 3, cost 1.471\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.024\n",
      "(*) epoch 2, cost 1.945\n",
      "(*) epoch 3, cost 1.649\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.0769626936267445, 4.0769626936267445, 3.2904617444384017, 4.238849492395012, 2.544738074691351, 3.2904617444384017, 4.0769626936267445, 3.2904617444384017, 3.4523485432066687, 3.2904617444384017, 4.0769626936267445, 3.2904617444384017, 3.4523485432066687, 4.0769626936267445, 3.2904617444384017, 3.2904617444384017, 3.2904617444384017, 3.331239023879694, 4.0769626936267445, 3.2904617444384017, 3.2904617444384017, 3.2904617444384017, 3.2904617444384017, 3.2904617444384017, 2.544738074691351, 4.0769626936267445, 4.0769626936267445, 3.2904617444384017, 3.2904617444384017, 3.2904617444384017, 3.331239023879694, 3.2904617444384017, 3.2904617444384017, 3.286825275606314, 2.544738074691351, 4.238849492395012, 4.073326224794657, 3.2904617444384017, 4.0769626936267445, 3.2904617444384017, 3.2904617444384017, 3.2904617444384017, 4.0769626936267445, 3.2904617444384017, 3.2904617444384017, 3.286825275606314, 4.0769626936267445, 3.2904617444384017, 3.2904617444384017, 3.2904617444384017]\n",
      "all_sum after preprocessing is: [ 1.39566079  1.39566079 -0.44406043  1.77433367 -2.18839864 -0.44406043\n",
      "  1.39566079 -0.44406043 -0.06538755 -0.44406043  1.39566079 -0.44406043\n",
      " -0.06538755  1.39566079 -0.44406043 -0.44406043 -0.44406043 -0.34867742\n",
      "  1.39566079 -0.44406043 -0.44406043 -0.44406043 -0.44406043 -0.44406043\n",
      " -2.18839864  1.39566079  1.39566079 -0.44406043 -0.44406043 -0.44406043\n",
      " -0.34867742 -0.44406043 -0.44406043 -0.45256657 -2.18839864  1.77433367\n",
      "  1.38715464 -0.44406043  1.39566079 -0.44406043 -0.44406043 -0.44406043\n",
      "  1.39566079 -0.44406043 -0.44406043 -0.45256657  1.39566079 -0.44406043\n",
      " -0.44406043 -0.44406043]\n",
      "P is: [0.8014944179270425, 0.8014944179270425, 0.3907738764584453, 0.8549957771745358, 0.10079714348025826, 0.3907738764584453, 0.8014944179270425, 0.3907738764584453, 0.4836589338961426, 0.3907738764584453, 0.8014944179270425, 0.3907738764584453, 0.4836589338961426, 0.8014944179270425, 0.3907738764584453, 0.3907738764584453, 0.3907738764584453, 0.4137031793960908, 0.8014944179270425, 0.3907738764584453, 0.3907738764584453, 0.3907738764584453, 0.3907738764584453, 0.3907738764584453, 0.10079714348025826, 0.8014944179270425, 0.8014944179270425, 0.3907738764584453, 0.3907738764584453, 0.3907738764584453, 0.4137031793960908, 0.3907738764584453, 0.3907738764584453, 0.38875071404831285, 0.10079714348025826, 0.8549957771745358, 0.8001376097933192, 0.3907738764584453, 0.8014944179270425, 0.3907738764584453, 0.3907738764584453, 0.3907738764584453, 0.8014944179270425, 0.3907738764584453, 0.3907738764584453, 0.38875071404831285, 0.8014944179270425, 0.3907738764584453, 0.3907738764584453, 0.3907738764584453]\n",
      "all_sum before preprocessing is: [3.183898655100743, 1.1193669313032557, 1.7513464964324257, 3.183898655100743, 2.2605134432124294, 2.2605134432124294, 2.8924930083415994, 2.2605134432124294, 2.8924930083415994, 2.2605134432124294, 1.1193669313032557, 2.2605134432124294, 2.2605134432124294, 1.1193669313032557, 1.1193669313032557, 2.2605134432124294, 2.0427521431915694, 3.815878220229913, 3.183898655100743, 2.2605134432124294, 2.2605134432124294, 2.2605134432124294, 2.2605134432124294, 2.2605134432124294, 2.2605134432124294, 3.183898655100743, 3.183898655100743, 2.2605134432124294, 2.2605134432124294, 2.2605134432124294, 2.2605134432124294, 2.2605134432124294, 1.1193669313032557, 2.0427521431915694, 1.1193669313032557, 3.183898655100743, 2.2605134432124294, 3.183898655100743, 3.183898655100743, 3.183898655100743, 1.7513464964324257, 2.2605134432124294, 1.1193669313032557, 1.1193669313032557, 2.2605134432124294, 3.183898655100743, 3.183898655100743, 2.0427521431915694, 2.0427521431915694, 2.2605134432124294]\n",
      "all_sum after preprocessing is: [ 1.28578059 -1.71632271 -0.79734049  1.28578059 -0.05694413 -0.05694413\n",
      "  0.86203808 -0.05694413  0.86203808 -0.05694413 -1.71632271 -0.05694413\n",
      " -0.05694413 -1.71632271 -1.71632271 -0.05694413 -0.37359798  2.20476281\n",
      "  1.28578059 -0.05694413 -0.05694413 -0.05694413 -0.05694413 -0.05694413\n",
      " -0.05694413  1.28578059  1.28578059 -0.05694413 -0.05694413 -0.05694413\n",
      " -0.05694413 -0.05694413 -1.71632271 -0.37359798 -1.71632271  1.28578059\n",
      " -0.05694413  1.28578059  1.28578059  1.28578059 -0.79734049 -0.05694413\n",
      " -1.71632271 -1.71632271 -0.05694413  1.28578059  1.28578059 -0.37359798\n",
      " -0.37359798 -0.05694413]\n",
      "P is: [0.78343215452116, 0.15234542871324133, 0.3105947006870986, 0.78343215452116, 0.4857678124102582, 0.4857678124102582, 0.7030862923723034, 0.4857678124102582, 0.7030862923723034, 0.4857678124102582, 0.15234542871324133, 0.4857678124102582, 0.4857678124102582, 0.15234542871324133, 0.15234542871324133, 0.4857678124102582, 0.40767190915796186, 0.9006763980881141, 0.78343215452116, 0.4857678124102582, 0.4857678124102582, 0.4857678124102582, 0.4857678124102582, 0.4857678124102582, 0.4857678124102582, 0.78343215452116, 0.78343215452116, 0.4857678124102582, 0.4857678124102582, 0.4857678124102582, 0.4857678124102582, 0.4857678124102582, 0.15234542871324133, 0.40767190915796186, 0.15234542871324133, 0.78343215452116, 0.4857678124102582, 0.78343215452116, 0.78343215452116, 0.78343215452116, 0.3105947006870986, 0.4857678124102582, 0.15234542871324133, 0.15234542871324133, 0.4857678124102582, 0.78343215452116, 0.78343215452116, 0.40767190915796186, 0.40767190915796186, 0.4857678124102582]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.989\n",
      "(*) epoch 2, cost 2.405\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.127\n",
      "(*) epoch 2, cost 2.393\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.522740863208392, 2.2935728393760337, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 4.402100139828074, 2.2935728393760337, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 2.2935728393760337, 4.402100139828074, 4.402100139828074, 2.2935728393760337]\n",
      "all_sum after preprocessing is: [ 0.6920777  -1.77920308  0.55833404 -1.77920308  0.55833404  0.55833404\n",
      "  0.55833404  0.55833404 -1.77920308  0.55833404  0.55833404  0.55833404\n",
      "  0.55833404  0.55833404  0.55833404 -1.77920308  0.55833404  0.55833404\n",
      " -1.77920308  0.55833404  0.55833404  0.55833404  0.55833404 -1.77920308\n",
      "  0.55833404  0.55833404  0.55833404 -1.77920308 -1.77920308  0.55833404\n",
      "  0.55833404  0.55833404  0.55833404  0.55833404  0.55833404  0.55833404\n",
      " -1.77920308  0.55833404  0.55833404  0.55833404  0.55833404  0.55833404\n",
      "  0.55833404  0.55833404 -1.77920308  0.55833404 -1.77920308  0.55833404\n",
      "  0.55833404 -1.77920308]\n",
      "P is: [0.6664289620140916, 0.1444015650293641, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.1444015650293641, 0.6360669806104639, 0.6360669806104639, 0.1444015650293641]\n",
      "all_sum before preprocessing is: [1.4859298569023052, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 4.677298148296125, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.4119544154691264, 2.712709788373154, 2.712709788373154, 2.712709788373154, 1.4859298569023052, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 1.4859298569023052, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 4.677298148296125, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 2.712709788373154, 4.677298148296125, 2.712709788373154, 2.4119544154691264]\n",
      "all_sum after preprocessing is: [-2.21031936 -0.05659721 -0.05659721 -0.05659721 -0.05659721 -0.05659721\n",
      " -0.05659721 -0.05659721 -0.05659721 -0.05659721  3.39241378 -0.05659721\n",
      " -0.05659721 -0.05659721 -0.58460023 -0.05659721 -0.05659721 -0.05659721\n",
      " -2.21031936 -0.05659721 -0.05659721 -0.05659721 -0.05659721 -0.05659721\n",
      " -0.05659721 -0.05659721 -2.21031936 -0.05659721 -0.05659721 -0.05659721\n",
      " -0.05659721 -0.05659721 -0.05659721 -0.05659721 -0.05659721 -0.05659721\n",
      " -0.05659721  3.39241378 -0.05659721 -0.05659721 -0.05659721 -0.05659721\n",
      " -0.05659721 -0.05659721 -0.05659721 -0.05659721 -0.05659721  3.39241378\n",
      " -0.05659721 -0.58460023]\n",
      "P is: [0.09882762694359491, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.9674666042672162, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.35787476915379635, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.09882762694359491, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.09882762694359491, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.9674666042672162, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.48585447334127085, 0.9674666042672162, 0.48585447334127085, 0.35787476915379635]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.366\n",
      "(*) epoch 2, cost 0.705\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.368\n",
      "(*) epoch 2, cost 3.066\n",
      "(*) epoch 3, cost 2.546\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.329357192203127, 2.2087699921851787, 2.2087699921851787, 4.017978388515093, 4.7716307426406, 4.568222899876033, 4.329357192203127, 2.447635699858085, 2.2087699921851787, 4.329357192203127, 4.568222899876033, 4.329357192203127, 3.7791126808421867, 2.2087699921851787, 4.329357192203127, 2.2087699921851787, 4.568222899876033, 4.568222899876033, 3.7791126808421867, 3.7791126808421867, 4.329357192203127, 3.7791126808421867, 3.7791126808421867, 3.7791126808421867, 3.7791126808421867, 4.017978388515093, 3.2012880539835917, 2.412177834949745, 4.017978388515093, 4.225832957943361, 4.568222899876033, 3.7791126808421867, 3.7791126808421867, 4.225832957943361, 4.568222899876033, 4.7716307426406, 4.017978388515093, 3.7791126808421867, 2.447635699858085, 4.017978388515093, 4.329357192203127, 4.017978388515093, 5.353902096162896, 3.7791126808421867, 2.2087699921851787, 4.329357192203127, 4.568222899876033, 2.2087699921851787, 4.568222899876033, 2.447635699858085]\n",
      "all_sum after preprocessing is: [ 0.64406238 -1.80864412 -1.80864412  0.28391646  1.15560334  0.92033843\n",
      "  0.64406238 -1.53236807 -1.80864412  0.64406238  0.92033843  0.64406238\n",
      "  0.0076404  -1.80864412  0.64406238 -1.80864412  0.92033843  0.92033843\n",
      "  0.0076404   0.0076404   0.64406238  0.0076404   0.0076404   0.0076404\n",
      "  0.0076404   0.28391646 -0.66068119 -1.57337922  0.28391646  0.52432452\n",
      "  0.92033843  0.0076404   0.0076404   0.52432452  0.92033843  1.15560334\n",
      "  0.28391646  0.0076404  -1.53236807  0.28391646  0.64406238  0.28391646\n",
      "  1.82906809  0.0076404  -1.80864412  0.64406238  0.92033843 -1.80864412\n",
      "  0.92033843 -1.53236807]\n",
      "P is: [0.6556711880144442, 0.1408020753739819, 0.1408020753739819, 0.5705061339905537, 0.76053290037523, 0.715111059080421, 0.6556711880144442, 0.17764747363386635, 0.1408020753739819, 0.6556711880144442, 0.715111059080421, 0.6556711880144442, 0.5019100913991036, 0.1408020753739819, 0.6556711880144442, 0.1408020753739819, 0.715111059080421, 0.715111059080421, 0.5019100913991036, 0.5019100913991036, 0.6556711880144442, 0.5019100913991036, 0.5019100913991036, 0.5019100913991036, 0.5019100913991036, 0.5705061339905537, 0.34058660790624007, 0.171735190166054, 0.5705061339905537, 0.6281584266730346, 0.715111059080421, 0.5019100913991036, 0.5019100913991036, 0.6281584266730346, 0.715111059080421, 0.76053290037523, 0.5705061339905537, 0.5019100913991036, 0.17764747363386635, 0.5705061339905537, 0.6556711880144442, 0.5705061339905537, 0.8616506722198424, 0.5019100913991036, 0.1408020753739819, 0.6556711880144442, 0.715111059080421, 0.1408020753739819, 0.715111059080421, 0.17764747363386635]\n",
      "all_sum before preprocessing is: [1.679524389719945, 1.679524389719945, 2.022424961112459, 2.022424961112459, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 2.022424961112459, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 2.022424961112459, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 2.8240536986501437, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 2.6256514637376616, 1.877666695468916, 1.877666695468916, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 2.8240536986501437, 1.679524389719945, 3.0595486120653974, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945, 1.679524389719945]\n",
      "all_sum after preprocessing is: [-0.39764542 -0.39764542  0.67043208  0.67043208 -0.39764542 -0.39764542\n",
      " -0.39764542 -0.39764542 -0.39764542 -0.39764542 -0.39764542  0.67043208\n",
      " -0.39764542 -0.39764542 -0.39764542 -0.39764542  0.67043208 -0.39764542\n",
      " -0.39764542 -0.39764542 -0.39764542 -0.39764542  3.16737054 -0.39764542\n",
      " -0.39764542 -0.39764542 -0.39764542 -0.39764542 -0.39764542 -0.39764542\n",
      " -0.39764542 -0.39764542 -0.39764542  2.54938101  0.21953448  0.21953448\n",
      " -0.39764542 -0.39764542 -0.39764542 -0.39764542 -0.39764542  3.16737054\n",
      " -0.39764542  3.90089752 -0.39764542 -0.39764542 -0.39764542 -0.39764542\n",
      " -0.39764542 -0.39764542]\n",
      "P is: [0.40187818369741984, 0.40187818369741984, 0.6615999033404694, 0.6615999033404694, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.6615999033404694, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.6615999033404694, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.9595877395915171, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.9275319190499087, 0.5546642481636914, 0.5546642481636914, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.9595877395915171, 0.40187818369741984, 0.9801771404816039, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984, 0.40187818369741984]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.597\n",
      "(*) epoch 2, cost 2.293\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.479\n",
      "(*) epoch 2, cost 2.770\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.408887523174672, 4.6501259810995474, 5.303255176393387, 6.365055574795194, 4.6501259810995474, 4.6501259810995474, 4.6501259810995474, 5.7684872552241355, 5.303255176393387, 4.6501259810995474, 4.6501259810995474, 5.7684872552241355, 5.7684872552241355, 4.000216320066705, 4.6501259810995474, 4.6501259810995474, 4.6501259810995474, 4.6501259810995474, 5.303255176393387, 4.6501259810995474, 4.6501259810995474, 3.347087124772865, 4.6501259810995474, 5.303255176393387, 4.6501259810995474, 5.115358059930296, 5.115358059930296, 4.000216320066705, 5.115358059930296, 4.000216320066705, 4.6501259810995474, 4.6501259810995474, 5.303255176393387, 3.347087124772865, 3.347087124772865, 5.303255176393387, 4.6501259810995474, 4.408887523174672, 4.6501259810995474, 6.365055574795194, 5.303255176393387, 4.911976447485644, 4.6501259810995474, 3.347087124772865, 5.455535067066979, 4.6501259810995474, 4.6501259810995474, 5.115358059930296, 5.303255176393387, 6.365055574795194]\n",
      "all_sum after preprocessing is: [-0.60670704 -0.25939685  0.68091107  2.20958154 -0.25939685 -0.25939685\n",
      " -0.25939685  1.35070413  0.68091107 -0.25939685 -0.25939685  1.35070413\n",
      "  1.35070413 -1.19506961 -0.25939685 -0.25939685 -0.25939685 -0.25939685\n",
      "  0.68091107 -0.25939685 -0.25939685 -2.13537752 -0.25939685  0.68091107\n",
      " -0.25939685  0.41039622  0.41039622 -1.19506961  0.41039622 -1.19506961\n",
      " -0.25939685 -0.25939685  0.68091107 -2.13537752 -2.13537752  0.68091107\n",
      " -0.25939685 -0.60670704 -0.25939685  2.20958154  0.68091107  0.11758839\n",
      " -0.25939685 -2.13537752  0.90014792 -0.25939685 -0.25939685  0.41039622\n",
      "  0.68091107  2.20958154]\n",
      "P is: [0.3528107310259163, 0.4355119827083743, 0.6639420077788502, 0.9011066426939047, 0.4355119827083743, 0.4355119827083743, 0.4355119827083743, 0.7942447211554713, 0.6639420077788502, 0.4355119827083743, 0.4355119827083743, 0.7942447211554713, 0.7942447211554713, 0.23235346726791398, 0.4355119827083743, 0.4355119827083743, 0.4355119827083743, 0.4355119827083743, 0.6639420077788502, 0.4355119827083743, 0.4355119827083743, 0.10570556577887398, 0.4355119827083743, 0.6639420077788502, 0.4355119827083743, 0.601182880796549, 0.601182880796549, 0.23235346726791398, 0.601182880796549, 0.23235346726791398, 0.4355119827083743, 0.4355119827083743, 0.6639420077788502, 0.10570556577887398, 0.10570556577887398, 0.6639420077788502, 0.4355119827083743, 0.3528107310259163, 0.4355119827083743, 0.9011066426939047, 0.6639420077788502, 0.5293632721319956, 0.4355119827083743, 0.10570556577887398, 0.7109798982585919, 0.4355119827083743, 0.4355119827083743, 0.601182880796549, 0.6639420077788502, 0.9011066426939047]\n",
      "all_sum before preprocessing is: [3.7480862350243775, 3.7480862350243775, 1.8057639131900174, 1.501198884533895, 1.8057639131900174, 3.7480862350243775, 1.8057639131900174, 1.8057639131900174, 3.2523354466792753, 3.7480862350243775, 1.8057639131900174, 1.8057639131900174, 3.2490342690131064, 1.8057639131900174, 1.501198884533895, 3.4435212063682554, 5.191356590847468, 1.8057639131900174, 1.8057639131900174, 2.1366927904238384, 1.8057639131900174, 1.8090650908561863, 1.8057639131900174, 3.7480862350243775, 3.7480862350243775, 3.2490342690131064, 1.8057639131900174, 1.8057639131900174, 5.191356590847468, 5.400938472921119, 1.8057639131900174, 1.8057639131900174, 2.9444692403569843, 3.2490342690131064, 1.8057639131900174, 3.458616151086759, 3.7480862350243775, 3.7480862350243775, 3.7480862350243775, 1.501198884533895, 1.8057639131900174, 1.8057639131900174, 1.501198884533895, 3.7480862350243775, 3.7480862350243775, 1.8057639131900174, 1.8057639131900174, 1.8057639131900174, 1.8057639131900174, 3.2490342690131064]\n",
      "all_sum after preprocessing is: [ 1.00694615  1.00694615 -0.78346031 -1.06420424 -0.78346031  1.00694615\n",
      " -0.78346031 -0.78346031  0.54996977  1.00694615 -0.78346031 -0.78346031\n",
      "  0.54692679 -0.78346031 -1.06420424  0.72620222  2.33733326 -0.78346031\n",
      " -0.78346031 -0.47841455 -0.78346031 -0.78041733 -0.78346031  1.00694615\n",
      "  1.00694615  0.54692679 -0.78346031 -0.78346031  2.33733326  2.53052301\n",
      " -0.78346031 -0.78346031  0.26618287  0.54692679 -0.78346031  0.74011654\n",
      "  1.00694615  1.00694615  1.00694615 -1.06420424 -0.78346031 -0.78346031\n",
      " -1.06420424  1.00694615  1.00694615 -0.78346031 -0.78346031 -0.78346031\n",
      " -0.78346031  0.54692679]\n",
      "P is: [0.732422081053137, 0.732422081053137, 0.31357458861196996, 0.25650683869253527, 0.31357458861196996, 0.732422081053137, 0.31357458861196996, 0.31357458861196996, 0.6341285785011268, 0.732422081053137, 0.31357458861196996, 0.31357458861196996, 0.633422290209116, 0.31357458861196996, 0.25650683869253527, 0.6739713242012147, 0.9119221273518656, 0.31357458861196996, 0.31357458861196996, 0.3826265764252941, 0.31357458861196996, 0.31422994804307547, 0.31357458861196996, 0.732422081053137, 0.732422081053137, 0.633422290209116, 0.31357458861196996, 0.31357458861196996, 0.9119221273518656, 0.9262540866105142, 0.31357458861196996, 0.31357458861196996, 0.5661555653453424, 0.633422290209116, 0.31357458861196996, 0.6770213398628943, 0.732422081053137, 0.732422081053137, 0.732422081053137, 0.25650683869253527, 0.31357458861196996, 0.31357458861196996, 0.25650683869253527, 0.732422081053137, 0.732422081053137, 0.31357458861196996, 0.31357458861196996, 0.31357458861196996, 0.31357458861196996, 0.633422290209116]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.888\n",
      "(*) epoch 2, cost 2.503\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.059\n",
      "(*) epoch 2, cost 2.520\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.5545662509238145, 4.977564263615657, 3.6720203408632814, 4.5545662509238145, 4.5545662509238145, 4.5545662509238145, 2.4217735817201285, 3.9802502171718546, 2.6538917121622028, 2.865586176669247, 3.74813208672978, 3.6720203408632814, 2.865586176669247, 3.6720203408632814, 5.170301399306537, 2.5667291808006674, 4.998378845872933, 4.977564263615657, 3.6720203408632814, 4.363867235112503, 3.502135907309246, 2.730003458028701, 3.6720203408632814, 3.6720203408632814, 3.2282077459141627, 3.6720203408632814, 4.828494412318898, 3.502135907309246, 4.9734500113994375, 2.210079117213084, 4.998378845872933, 3.74813208672978, 3.8647574765541615, 4.533751668666539, 4.998378845872933, 4.533751668666539, 3.6720203408632814, 3.6720203408632814, 3.6720203408632814, 4.998378845872933, 4.1919446816788986, 3.010541775749786, 3.6720203408632814, 4.171130099421623, 3.6720203408632814, 5.4974886044312745, 2.865586176669247, 4.998378845872933, 4.30857007150328, 5.614113994255656]\n",
      "all_sum after preprocessing is: [ 0.67887681  1.18181859 -0.37046432  0.67887681  0.67887681  0.67887681\n",
      " -1.85699927 -0.00398107 -1.58101238 -1.32930909 -0.27996796 -0.37046432\n",
      " -1.32930909 -0.37046432  1.41098175 -1.68464804  1.20656699  1.18181859\n",
      " -0.37046432  0.45213697 -0.57245576 -1.49051603 -0.37046432 -0.37046432\n",
      " -0.89815449 -0.37046432  1.00457555 -0.57245576  1.17692678 -2.10870256\n",
      "  1.20656699 -0.27996796 -0.14130116  0.65412842  1.20656699  0.65412842\n",
      " -0.37046432 -0.37046432 -0.37046432  1.20656699  0.24772222 -1.15695786\n",
      " -0.37046432  0.22297382 -0.37046432  1.80000512 -1.32930909  1.20656699\n",
      "  0.38638902  1.93867193]\n",
      "P is: [0.6634879676433959, 0.7652746342711907, 0.40842883142558417, 0.6634879676433959, 0.6634879676433959, 0.6634879676433959, 0.1350531949728753, 0.4990047329821466, 0.17065215204776588, 0.20927367255208715, 0.43046163032635265, 0.40842883142558417, 0.20927367255208715, 0.40842883142558417, 0.8039207447619408, 0.1564809720641085, 0.7696909542433432, 0.7652746342711907, 0.40842883142558417, 0.6111471976309267, 0.36067036445502065, 0.18384428700118569, 0.40842883142558417, 0.40842883142558417, 0.2894298970239352, 0.40842883142558417, 0.7319572342242345, 0.36067036445502065, 0.7643947800638947, 0.1082538514995739, 0.7696909542433432, 0.43046163032635265, 0.4647333678016765, 0.6579401876642899, 0.7696909542433432, 0.6579401876642899, 0.40842883142558417, 0.40842883142558417, 0.40842883142558417, 0.7696909542433432, 0.56161578135308, 0.23922049671245504, 0.40842883142558417, 0.5555136456694397, 0.40842883142558417, 0.8581495589581326, 0.20927367255208715, 0.7696909542433432, 0.5954131271985708, 0.8742061680989296]\n",
      "all_sum before preprocessing is: [2.400416803400785, 3.0375261108435256, 2.400416803400785, 1.5061946550370056, 2.400416803400785, 2.143303962479746, 1.5061946550370056, 2.400416803400785, 2.400416803400785, 2.400416803400785, 3.0375261108435256, 2.400416803400785, 2.400416803400785, 2.400416803400785, 2.400416803400785, 2.400416803400785, 3.0375261108435256, 2.143303962479746, 3.0375261108435256, 3.0375261108435256, 2.400416803400785, 2.400416803400785, 3.0375261108435256, 1.5061946550370056, 2.400416803400785, 3.0375261108435256, 3.0375261108435256, 3.0375261108435256, 2.143303962479746, 3.0375261108435256, 2.400416803400785, 3.0375261108435256, 2.400416803400785, 3.0375261108435256, 2.143303962479746, 2.400416803400785, 2.400416803400785, 3.0375261108435256, 3.0375261108435256, 3.0375261108435256, 2.400416803400785, 2.143303962479746, 3.0375261108435256, 2.400416803400785, 2.400416803400785, 2.400416803400785, 3.0375261108435256, 1.5061946550370056, 3.0375261108435256, 2.400416803400785]\n",
      "all_sum after preprocessing is: [-0.29595918  1.13132058 -0.29595918 -2.29923423 -0.29595918 -0.87195446\n",
      " -2.29923423 -0.29595918 -0.29595918 -0.29595918  1.13132058 -0.29595918\n",
      " -0.29595918 -0.29595918 -0.29595918 -0.29595918  1.13132058 -0.87195446\n",
      "  1.13132058  1.13132058 -0.29595918 -0.29595918  1.13132058 -2.29923423\n",
      " -0.29595918  1.13132058  1.13132058  1.13132058 -0.87195446  1.13132058\n",
      " -0.29595918  1.13132058 -0.29595918  1.13132058 -0.87195446 -0.29595918\n",
      " -0.29595918  1.13132058  1.13132058  1.13132058 -0.29595918 -0.87195446\n",
      "  1.13132058 -0.29595918 -0.29595918 -0.29595918  1.13132058 -2.29923423\n",
      "  1.13132058 -0.29595918]\n",
      "P is: [0.4265455903112461, 0.75608252526674, 0.4265455903112461, 0.0911864017005731, 0.4265455903112461, 0.2948477813266509, 0.0911864017005731, 0.4265455903112461, 0.4265455903112461, 0.4265455903112461, 0.75608252526674, 0.4265455903112461, 0.4265455903112461, 0.4265455903112461, 0.4265455903112461, 0.4265455903112461, 0.75608252526674, 0.2948477813266509, 0.75608252526674, 0.75608252526674, 0.4265455903112461, 0.4265455903112461, 0.75608252526674, 0.0911864017005731, 0.4265455903112461, 0.75608252526674, 0.75608252526674, 0.75608252526674, 0.2948477813266509, 0.75608252526674, 0.4265455903112461, 0.75608252526674, 0.4265455903112461, 0.75608252526674, 0.2948477813266509, 0.4265455903112461, 0.4265455903112461, 0.75608252526674, 0.75608252526674, 0.75608252526674, 0.4265455903112461, 0.2948477813266509, 0.75608252526674, 0.4265455903112461, 0.4265455903112461, 0.4265455903112461, 0.75608252526674, 0.0911864017005731, 0.75608252526674, 0.4265455903112461]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.241\n",
      "(*) epoch 2, cost 3.629\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.813\n",
      "(*) epoch 2, cost 3.183\n",
      "(*) epoch 3, cost 2.675\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.107667917366678, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 3.107667917366678, 2.850120184559997, 2.850120184559997, 2.850120184559997, 3.7090372156368607, 3.932664655622726, 2.850120184559997, 2.850120184559997, 3.932664655622726, 2.850120184559997, 2.850120184559997, 3.107667917366678, 3.932664655622726, 3.107667917366678, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 3.7090372156368607, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 3.932664655622726, 2.850120184559997, 2.850120184559997, 3.932664655622726, 3.107667917366678, 3.932664655622726, 3.932664655622726, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 2.850120184559997, 3.932664655622726]\n",
      "all_sum after preprocessing is: [ 0.05890146 -0.56720098 -0.56720098 -0.56720098 -0.56720098 -0.56720098\n",
      " -0.56720098 -0.56720098 -0.56720098  0.05890146 -0.56720098 -0.56720098\n",
      " -0.56720098  1.52083933  2.06448103 -0.56720098 -0.56720098  2.06448103\n",
      " -0.56720098 -0.56720098  0.05890146  2.06448103  0.05890146 -0.56720098\n",
      " -0.56720098 -0.56720098 -0.56720098 -0.56720098 -0.56720098  1.52083933\n",
      " -0.56720098 -0.56720098 -0.56720098 -0.56720098 -0.56720098  2.06448103\n",
      " -0.56720098 -0.56720098  2.06448103  0.05890146  2.06448103  2.06448103\n",
      " -0.56720098 -0.56720098 -0.56720098 -0.56720098 -0.56720098 -0.56720098\n",
      " -0.56720098  2.06448103]\n",
      "P is: [0.5147211096540407, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.5147211096540407, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.8206620436099523, 0.8874026883445303, 0.36188293526801363, 0.36188293526801363, 0.8874026883445303, 0.36188293526801363, 0.36188293526801363, 0.5147211096540407, 0.8874026883445303, 0.5147211096540407, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.8206620436099523, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.8874026883445303, 0.36188293526801363, 0.36188293526801363, 0.8874026883445303, 0.5147211096540407, 0.8874026883445303, 0.8874026883445303, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.36188293526801363, 0.8874026883445303]\n",
      "all_sum before preprocessing is: [3.9223147062894146, 3.9223147062894146, 1.780591833578299, 4.621843202382938, 1.780591833578299, 3.678925190341994, 4.621843202382938, 4.886115680031861, 2.7443928073207458, 4.621843202382938, 3.9223147062894146, 1.2797567761927167, 3.9223147062894146, 5.585644176125385, 2.7443928073207458, 3.9223147062894146, 1.780591833578299, 1.780591833578299, 4.385280622646279, 1.780591833578299, 3.9223147062894146, 1.780591833578299, 3.9223147062894146, 3.9223147062894146, 1.5372023176308787, 2.2435577499351638, 3.421479648903832, 1.780591833578299, 3.9223147062894146, 1.780591833578299, 3.9223147062894146, 3.9223147062894146, 3.9223147062894146, 3.9223147062894146, 1.780591833578299, 3.9223147062894146, 1.780591833578299, 1.780591833578299, 1.780591833578299, 1.780591833578299, 3.9223147062894146, 3.9223147062894146, 4.886115680031861, 3.9223147062894146, 3.9223147062894146, 3.9223147062894146, 1.780591833578299, 1.780591833578299, 1.780591833578299, 1.780591833578299]\n",
      "all_sum after preprocessing is: [ 0.67355037  0.67355037 -1.1267983   1.26157939 -1.1267983   0.46895528\n",
      "  1.26157939  1.48372887 -0.31661981  1.26157939  0.67355037 -1.54780409\n",
      "  0.67355037  2.07175789 -0.31661981  0.67355037 -1.1267983  -1.1267983\n",
      "  1.06272308 -1.1267983   0.67355037 -1.1267983   0.67355037  0.67355037\n",
      " -1.3313934  -0.7376256   0.25254458 -1.1267983   0.67355037 -1.1267983\n",
      "  0.67355037  0.67355037  0.67355037  0.67355037 -1.1267983   0.67355037\n",
      " -1.1267983  -1.1267983  -1.1267983  -1.1267983   0.67355037  0.67355037\n",
      "  1.48372887  0.67355037  0.67355037  0.67355037 -1.1267983  -1.1267983\n",
      " -1.1267983  -1.1267983 ]\n",
      "P is: [0.6622976909951369, 0.6622976909951369, 0.24475244672710397, 0.7792978719254477, 0.24475244672710397, 0.6151364554118203, 0.7792978719254477, 0.8151351434279582, 0.4214997461567205, 0.7792978719254477, 0.6622976909951369, 0.17540365156336754, 0.6622976909951369, 0.8881277387458523, 0.4214997461567205, 0.6622976909951369, 0.24475244672710397, 0.24475244672710397, 0.7432105845154107, 0.24475244672710397, 0.6622976909951369, 0.24475244672710397, 0.6622976909951369, 0.6622976909951369, 0.20892897447042355, 0.32352357737858506, 0.5628027100752907, 0.24475244672710397, 0.6622976909951369, 0.24475244672710397, 0.6622976909951369, 0.6622976909951369, 0.6622976909951369, 0.6622976909951369, 0.24475244672710397, 0.6622976909951369, 0.24475244672710397, 0.24475244672710397, 0.24475244672710397, 0.24475244672710397, 0.6622976909951369, 0.6622976909951369, 0.8151351434279582, 0.6622976909951369, 0.6622976909951369, 0.6622976909951369, 0.24475244672710397, 0.24475244672710397, 0.24475244672710397, 0.24475244672710397]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.115\n",
      "(*) epoch 2, cost 1.572\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.277\n",
      "(*) epoch 2, cost 4.411\n",
      "(*) epoch 3, cost 3.753\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.6598602607347869, 2.4533458234221186, 2.073721145542316, 2.747452270558507, 2.133768608010864, 0.6598602607347869, 0.9794374761460416, 0.6598602607347869, 0.6598602607347869, 2.133768608010864, 1.3423126313643068, 0.6598602607347869, 0.9794374761460416, 1.0140141703397232, 1.0394849386145897, 0.6598602607347869, 0.719907723203335, 2.4278750551472523, 2.4533458234221186, 2.3932983609535707, 2.133768608010864, 2.073721145542316, 0.9626879534845039, 1.0740616328082715, 2.3932983609535707, 1.0394849386145897, 0.6598602607347869, 1.022735415953052, 0.719907723203335, 0.6598602607347869, 2.747452270558507, 0.9626879534845039, 1.0394849386145897, 2.4278750551472523, 1.333591385750978, 2.3932983609535707, 2.073721145542316, 2.4923734577396934, 0.719907723203335, 1.0394849386145897, 2.073721145542316, 2.3932983609535707, 1.0740616328082715, 2.073721145542316, 1.333591385750978, 2.133768608010864, 2.3932983609535707, 0.6598602607347869, 0.6598602607347869, 2.747452270558507]\n",
      "all_sum after preprocessing is: [-1.15585917  1.2341042   0.72822387  1.62602464  0.80824193 -1.15585917\n",
      " -0.7299969  -1.15585917 -1.15585917  0.80824193 -0.24643665 -1.15585917\n",
      " -0.7299969  -0.68392068 -0.64997884 -1.15585917 -1.07584111  1.20016236\n",
      "  1.2341042   1.15408614  0.80824193  0.72822387 -0.75231698 -0.60390262\n",
      "  1.15408614 -0.64997884 -1.15585917 -0.67229892 -1.07584111 -1.15585917\n",
      "  1.62602464 -0.75231698 -0.64997884  1.20016236 -0.25805841  1.15408614\n",
      "  0.72822387  1.28611166 -1.07584111 -0.64997884  0.72822387  1.15408614\n",
      " -0.60390262  0.72822387 -0.25805841  0.80824193  1.15408614 -1.15585917\n",
      " -1.15585917  1.62602464]\n",
      "P is: [0.23942050916263438, 0.7745360984099245, 0.674415391784178, 0.8356243256259038, 0.6917347435108872, 0.23942050916263438, 0.3251954081163434, 0.23942050916263438, 0.23942050916263438, 0.6917347435108872, 0.43870075541044007, 0.23942050916263438, 0.3251954081163434, 0.33538681006619697, 0.34299430622480553, 0.23942050916263438, 0.25429385415027783, 0.7685536653776986, 0.7745360984099245, 0.7602564759470092, 0.6917347435108872, 0.674415391784178, 0.3203166520924738, 0.3534513444039399, 0.7602564759470092, 0.34299430622480553, 0.23942050916263438, 0.33798226539163506, 0.25429385415027783, 0.23942050916263438, 0.8356243256259038, 0.3203166520924738, 0.34299430622480553, 0.7685536653776986, 0.4358410549185317, 0.7602564759470092, 0.674415391784178, 0.7834883195254821, 0.25429385415027783, 0.34299430622480553, 0.674415391784178, 0.7602564759470092, 0.3534513444039399, 0.674415391784178, 0.4358410549185317, 0.6917347435108872, 0.7602564759470092, 0.23942050916263438, 0.23942050916263438, 0.8356243256259038]\n",
      "all_sum before preprocessing is: [2.671697808156135, 3.2044572919767864, 3.2044572919767864, 2.831695888175881, 3.2044572919767864, 3.2044572919767864, 2.671697808156135, 3.2044572919767864, 2.831695888175881, 2.2151749001808465, 3.2044572919767864, 2.671697808156135, 2.671697808156135, 4.014668161765911, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 2.671697808156135, 2.671697808156135, 2.831695888175881, 2.671697808156135, 3.2044572919767864, 3.2044572919767864, 2.671697808156135, 3.2044572919767864, 2.831695888175881, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 2.2151749001808465, 2.831695888175881, 2.831695888175881, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 2.671697808156135, 3.2044572919767864, 3.2044572919767864, 2.2151749001808465, 3.2044572919767864, 3.2044572919767864, 3.2044572919767864, 1.842413496379941, 2.831695888175881, 3.2044572919767864, 3.2044572919767864]\n",
      "all_sum after preprocessing is: [-0.86580948  0.60187675  0.60187675 -0.42503463  0.60187675  0.60187675\n",
      " -0.86580948  0.60187675 -0.42503463 -2.1234734   0.60187675 -0.86580948\n",
      " -0.86580948  2.83390709  0.60187675  0.60187675  0.60187675  0.60187675\n",
      "  0.60187675 -0.86580948 -0.86580948 -0.42503463 -0.86580948  0.60187675\n",
      "  0.60187675 -0.86580948  0.60187675 -0.42503463  0.60187675  0.60187675\n",
      "  0.60187675 -2.1234734  -0.42503463 -0.42503463  0.60187675  0.60187675\n",
      "  0.60187675  0.60187675  0.60187675 -0.86580948  0.60187675  0.60187675\n",
      " -2.1234734   0.60187675  0.60187675  0.60187675 -3.15038478 -0.42503463\n",
      "  0.60187675  0.60187675]\n",
      "P is: [0.296127009990139, 0.6460855587576756, 0.6460855587576756, 0.39531263616984486, 0.6460855587576756, 0.6460855587576756, 0.296127009990139, 0.6460855587576756, 0.39531263616984486, 0.10683617788110122, 0.6460855587576756, 0.296127009990139, 0.296127009990139, 0.9444808333359286, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.296127009990139, 0.296127009990139, 0.39531263616984486, 0.296127009990139, 0.6460855587576756, 0.6460855587576756, 0.296127009990139, 0.6460855587576756, 0.39531263616984486, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.10683617788110122, 0.39531263616984486, 0.39531263616984486, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.296127009990139, 0.6460855587576756, 0.6460855587576756, 0.10683617788110122, 0.6460855587576756, 0.6460855587576756, 0.6460855587576756, 0.04107611934978233, 0.39531263616984486, 0.6460855587576756, 0.6460855587576756]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.940\n",
      "(*) epoch 2, cost 2.262\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.975\n",
      "(*) epoch 2, cost 1.643\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.817275486240682, 1.5201694485887678, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.5201694485887678, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604, 1.137207715762604]\n",
      "all_sum after preprocessing is: [-0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008\n",
      " -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008\n",
      " -0.24201008  5.44900838  2.96273272 -0.24201008 -0.24201008 -0.24201008\n",
      " -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008\n",
      " -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008\n",
      " -0.24201008 -0.24201008 -0.24201008 -0.24201008  2.96273272 -0.24201008\n",
      " -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008\n",
      " -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008 -0.24201008\n",
      " -0.24201008 -0.24201008]\n",
      "P is: [0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.995717848575798, 0.9508618338666239, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.9508618338666239, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937, 0.439791057417937]\n",
      "all_sum before preprocessing is: [0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 1.7974899562902886, 0.8752691954386153, 0.8752691954386153, 1.7974899562902886, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 1.7974899562902886, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153, 0.8752691954386153]\n",
      "all_sum after preprocessing is: [-0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558\n",
      " -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558\n",
      " -0.25264558 -0.25264558  3.95811403 -0.25264558 -0.25264558  3.95811403\n",
      " -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558\n",
      " -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558\n",
      " -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558\n",
      " -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558  3.95811403\n",
      " -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558 -0.25264558\n",
      " -0.25264558 -0.25264558]\n",
      "P is: [0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.9812588386320432, 0.43717244008755474, 0.43717244008755474, 0.9812588386320432, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.9812588386320432, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474, 0.43717244008755474]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.325\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.480\n",
      "(*) epoch 2, cost 1.610\n",
      "(*) epoch 3, cost 0.984\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.720505522710181, 0.9089721451981683, 2.167694118719221, 3.028427360970505, 0.6010503069378446, 0.3561607412072082, 2.475615956979545, 0.9447819169786187, 0.3561607412072082, 2.7410556216570114, 2.5114257287599955, 2.167694118719221, 2.167694118719221, 3.0642371327509554, 0.048238902946884446, 3.0154065241604715, 0.8959513083881345, 2.167694118719221, 3.224486318110657, 0.6010503069378446, 2.475615956979545, 2.167694118719221, 0.048238902946884446, 2.720505522710181, 0.048238902946884446, 3.028427360970505, 0.048238902946884446, 0.9089721451981683, 0.048238902946884446, 2.475615956979545, 2.167694118719221, 2.167694118719221, 0.048238902946884446, 2.167694118719221, 2.720505522710181, 2.5114257287599955, 0.3561607412072082, 0.048238902946884446, 2.167694118719221, 0.048238902946884446, 2.167694118719221, 2.7410556216570114, 2.475615956979545, 2.475615956979545, 2.720505522710181, 0.6010503069378446, 0.6010503069378446, 2.167694118719221, 0.048238902946884446, 2.167694118719221]\n",
      "all_sum after preprocessing is: [ 0.974372   -0.68078695  0.46928015  1.25571353 -0.96212849 -1.1858788\n",
      "  0.75062169 -0.64806833 -1.1858788   0.99314818  0.7833403   0.46928015\n",
      "  0.46928015  1.28843215 -1.46722033  1.24381667 -0.69268381  0.46928015\n",
      "  1.43484837 -0.96212849  0.75062169  0.46928015 -1.46722033  0.974372\n",
      " -1.46722033  1.25571353 -1.46722033 -0.68078695 -1.46722033  0.75062169\n",
      "  0.46928015  0.46928015 -1.46722033  0.46928015  0.974372    0.7833403\n",
      " -1.1858788  -1.46722033  0.46928015 -1.46722033  0.46928015  0.99314818\n",
      "  0.75062169  0.75062169  0.974372   -0.96212849 -0.96212849  0.46928015\n",
      " -1.46722033  0.46928015]\n",
      "P is: [0.7259900709766759, 0.33608568615068063, 0.6152133629030411, 0.7782873338035567, 0.2764522387394306, 0.2339968196762502, 0.6793141461427565, 0.34342496566824143, 0.2339968196762502, 0.7297092976342747, 0.6863995782886811, 0.6152133629030411, 0.6152133629030411, 0.7838816957441987, 0.18736547711154933, 0.776227663000788, 0.33343631307006394, 0.6152133629030411, 0.807655624062743, 0.2764522387394306, 0.6793141461427565, 0.6152133629030411, 0.18736547711154933, 0.7259900709766759, 0.18736547711154933, 0.7782873338035567, 0.18736547711154933, 0.33608568615068063, 0.18736547711154933, 0.6793141461427565, 0.6152133629030411, 0.6152133629030411, 0.18736547711154933, 0.6152133629030411, 0.7259900709766759, 0.6863995782886811, 0.2339968196762502, 0.18736547711154933, 0.6152133629030411, 0.18736547711154933, 0.6152133629030411, 0.7297092976342747, 0.6793141461427565, 0.6793141461427565, 0.7259900709766759, 0.2764522387394306, 0.2764522387394306, 0.6152133629030411, 0.18736547711154933, 0.6152133629030411]\n",
      "all_sum before preprocessing is: [0.37269721013356205, 2.375849992971098, 0.37269721013356205, 0.5770442911360936, 1.2638798447501722, 1.514183321128065, 2.3873529498955817, 2.3991838277562323, 1.2638798447501722, 1.7185304021305967, 2.3873529498955817, 1.9035143506777459, 0.37269721013356205, 1.0431978054410027, 2.1715029119685663, 1.4846673583544878, 1.4682269257527039, 0.5770442911360936, 1.4682269257527039, 0.37269721013356205, 1.4961703152789718, 0.37269721013356205, 1.7185304021305967, 1.9343804400576126, 2.375849992971098, 2.1846839164355054, 1.7185304021305967, 1.2343638819765945, 1.2638798447501722, 0.37269721013356205, 2.387680870831748, 0.8388507244384711, 1.921199435590673, 1.730033359055081, 1.2638798447501722, 1.4682269257527039, 1.2638798447501722, 0.5770442911360936, 1.7185304021305967, 0.5770442911360936, 1.730033359055081, 1.9330303134513236, 1.4961703152789718, 1.030016800974063, 0.5770442911360936, 0.5770442911360936, 2.794696985294356, 0.8273477675139865, 1.7185304021305967, 1.0431978054410027]\n",
      "all_sum after preprocessing is: [-1.5239101   1.46857573 -1.5239101  -1.21863845 -0.19258309  0.18134226\n",
      "  1.48575986  1.50343386 -0.19258309  0.48661391  1.48575986  0.7629592\n",
      " -1.5239101  -0.52225733  1.16330408  0.13724872  0.11268856 -1.21863845\n",
      "  0.11268856 -1.5239101   0.15443285 -1.5239101   0.48661391  0.80906968\n",
      "  1.46857573  1.18299503  0.48661391 -0.23667663 -0.19258309 -1.5239101\n",
      "  1.48624973 -0.82752897  0.78937873  0.50379803 -0.19258309  0.11268856\n",
      " -0.19258309 -1.21863845  0.48661391 -1.21863845  0.50379803  0.80705274\n",
      "  0.15443285 -0.54194827 -1.21863845 -1.21863845  2.09428621 -0.8447131\n",
      "  0.48661391 -0.52225733]\n",
      "P is: [0.178886459296924, 0.8128408071719335, 0.178886459296924, 0.22817614638865874, 0.45200248159011525, 0.5452117341307664, 0.8154409971720482, 0.8180860662570674, 0.45200248159011525, 0.6193084311843314, 0.8154409971720482, 0.6819958628106355, 0.178886459296924, 0.3723245461222577, 0.7619325656303765, 0.5342584190914356, 0.5281423642136729, 0.22817614638865874, 0.5281423642136729, 0.178886459296924, 0.5385316625186917, 0.178886459296924, 0.6193084311843314, 0.6919112229293989, 0.8128408071719335, 0.7654858903576649, 0.6193084311843314, 0.44110550487183553, 0.45200248159011525, 0.178886459296924, 0.8155147108083818, 0.3041678090060944, 0.6876979172182182, 0.6233514673168375, 0.45200248159011525, 0.5281423642136729, 0.45200248159011525, 0.22817614638865874, 0.6193084311843314, 0.22817614638865874, 0.6233514673168375, 0.6914811057737895, 0.5385316625186917, 0.3677344806176038, 0.22817614638865874, 0.22817614638865874, 0.8903465867184224, 0.30054307953523324, 0.6193084311843314, 0.3723245461222577]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.444\n",
      "(*) epoch 2, cost 2.455\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.068\n",
      "(*) epoch 2, cost 2.637\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.33903266871608717, 0.7037496054033398, 1.1767655780911215, 2.205558520974821, 0.33903266871608717, 0.33903266871608717, 0.7037496054033398, 0.8120486414038689, 0.33903266871608717, 0.7037496054033398, 1.581451790571577, 1.604346565030978, 1.1767655780911215, 0.33903266871608717, 0.7037496054033398, 1.7126456010315074, 0.33903266871608717, 2.1990910982163285, 0.8120486414038689, 0.33903266871608717, 0.33903266871608717, 0.33903266871608717, 1.3049615613471826, 0.7037496054033398, 1.1767655780911215, 0.33903266871608717, 0.33903266871608717, 0.7037496054033398, 1.3049615613471826, 0.7037496054033398, 0.33903266871608717, 0.8120486414038689, 1.7126456010315074, 0.33903266871608717, 0.33903266871608717, 0.33903266871608717, 1.1767655780911215, 1.7779775340349642, 1.2396296283437258, 1.7126456010315074, 0.33903266871608717, 1.3049615613471826, 3.0567209548468943, 0.33903266871608717, 0.6808548309439386, 1.7779775340349642, 0.33903266871608717, 0.33903266871608717, 0.33903266871608717, 1.6696784980344348]\n",
      "all_sum after preprocessing is: [-0.89439274 -0.32698118  0.40891754  2.00947113 -0.89439274 -0.89439274\n",
      " -0.32698118 -0.15849402 -0.89439274 -0.32698118  1.03851164  1.07413039\n",
      "  0.40891754 -0.89439274 -0.32698118  1.24261755 -0.89439274  1.99940938\n",
      " -0.15849402 -0.89439274 -0.89439274 -0.89439274  0.60835956 -0.32698118\n",
      "  0.40891754 -0.89439274 -0.89439274 -0.32698118  0.60835956 -0.32698118\n",
      " -0.89439274 -0.15849402  1.24261755 -0.89439274 -0.89439274 -0.89439274\n",
      "  0.40891754  1.34425828  0.50671883  1.24261755 -0.89439274  0.60835956\n",
      "  3.3336745  -0.89439274 -0.36259993  1.34425828 -0.89439274 -0.89439274\n",
      " -0.89439274  1.17577111]\n",
      "P is: [0.2902041531296526, 0.41897532830006656, 0.60082829640099, 0.8817879045543584, 0.2902041531296526, 0.2902041531296526, 0.41897532830006656, 0.4604592347555992, 0.2902041531296526, 0.41897532830006656, 0.7385627240211317, 0.7453816070316456, 0.60082829640099, 0.2902041531296526, 0.41897532830006656, 0.776019308853984, 0.2902041531296526, 0.8807350523678874, 0.4604592347555992, 0.2902041531296526, 0.2902041531296526, 0.2902041531296526, 0.6475665039579688, 0.41897532830006656, 0.60082829640099, 0.2902041531296526, 0.2902041531296526, 0.41897532830006656, 0.6475665039579688, 0.41897532830006656, 0.2902041531296526, 0.4604592347555992, 0.776019308853984, 0.2902041531296526, 0.2902041531296526, 0.2902041531296526, 0.60082829640099, 0.7931893416568327, 0.6240369777052436, 0.776019308853984, 0.2902041531296526, 0.6475665039579688, 0.9655661493426358, 0.2902041531296526, 0.4103303424117309, 0.7931893416568327, 0.2902041531296526, 0.2902041531296526, 0.2902041531296526, 0.7641865862418372]\n",
      "all_sum before preprocessing is: [2.5518548976818325, 1.8874592148682865, 1.8874592148682865, 3.2566605875571835, 2.5922649047436375, 2.5922649047436375, 1.8874592148682865, 1.8874592148682865, 2.5922649047436375, 2.5922649047436375, 3.2566605875571835, 1.8874592148682865, 1.8874592148682865, 2.357000813005415, 2.5922649047436375, 1.8874592148682865, 2.5922649047436375, 2.5922649047436375, 2.5922649047436375, 3.2566605875571835, 1.8874592148682865, 1.8874592148682865, 1.8874592148682865, 1.8874592148682865, 2.5518548976818325, 2.5922649047436375, 2.5922649047436375, 1.8874592148682865, 2.5922649047436375, 2.5922649047436375, 2.5922649047436375, 1.8874592148682865, 2.357000813005415, 2.5922649047436375, 3.2566605875571835, 1.8874592148682865, 2.5922649047436375, 2.5518548976818325, 2.5922649047436375, 1.8874592148682865, 1.8874592148682865, 2.5922649047436375, 3.2566605875571835, 2.5922649047436375, 2.5518548976818325, 2.5922649047436375, 1.8874592148682865, 1.8874592148682865, 1.8874592148682865, 2.5922649047436375]\n",
      "all_sum after preprocessing is: [ 0.39889625 -1.12756971 -1.12756971  2.01820522  0.49173926  0.49173926\n",
      " -1.12756971 -1.12756971  0.49173926  0.49173926  2.01820522 -1.12756971\n",
      " -1.12756971 -0.04878596  0.49173926 -1.12756971  0.49173926  0.49173926\n",
      "  0.49173926  2.01820522 -1.12756971 -1.12756971 -1.12756971 -1.12756971\n",
      "  0.39889625  0.49173926  0.49173926 -1.12756971  0.49173926  0.49173926\n",
      "  0.49173926 -1.12756971 -0.04878596  0.49173926  2.01820522 -1.12756971\n",
      "  0.49173926  0.39889625  0.49173926 -1.12756971 -1.12756971  0.49173926\n",
      "  2.01820522  0.49173926  0.39889625  0.49173926 -1.12756971 -1.12756971\n",
      " -1.12756971  0.49173926]\n",
      "P is: [0.5984224426174827, 0.24460988172529613, 0.24460988172529613, 0.8826952971906667, 0.6205160728058502, 0.6205160728058502, 0.24460988172529613, 0.24460988172529613, 0.6205160728058502, 0.6205160728058502, 0.8826952971906667, 0.24460988172529613, 0.24460988172529613, 0.4878059281530779, 0.6205160728058502, 0.24460988172529613, 0.6205160728058502, 0.6205160728058502, 0.6205160728058502, 0.8826952971906667, 0.24460988172529613, 0.24460988172529613, 0.24460988172529613, 0.24460988172529613, 0.5984224426174827, 0.6205160728058502, 0.6205160728058502, 0.24460988172529613, 0.6205160728058502, 0.6205160728058502, 0.6205160728058502, 0.24460988172529613, 0.4878059281530779, 0.6205160728058502, 0.8826952971906667, 0.24460988172529613, 0.6205160728058502, 0.5984224426174827, 0.6205160728058502, 0.24460988172529613, 0.24460988172529613, 0.6205160728058502, 0.8826952971906667, 0.6205160728058502, 0.5984224426174827, 0.6205160728058502, 0.24460988172529613, 0.24460988172529613, 0.24460988172529613, 0.6205160728058502]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.554\n",
      "(*) epoch 2, cost 2.776\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.677\n",
      "(*) epoch 2, cost 2.440\n",
      "(*) epoch 3, cost 1.932\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.183342663818153, 1.5252969980636508, 1.5252969980636508, 1.8747065548378516, 1.5252969980636508, 2.183342663818153, 2.183342663818153, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 3.3982231261911577, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 2.041753471069791, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 2.183342663818153, 1.5252969980636508, 2.183342663818153, 1.5252969980636508, 1.5252969980636508, 2.183342663818153, 2.183342663818153, 1.5252969980636508, 1.5252969980636508, 2.183342663818153, 1.5252969980636508, 2.183342663818153, 2.183342663818153, 2.183342663818153, 2.183342663818153, 2.183342663818153, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 3.3982231261911577, 2.183342663818153, 1.5252969980636508, 1.5252969980636508, 1.5252969980636508, 2.183342663818153]\n",
      "all_sum after preprocessing is: [ 0.83618472 -0.65743992 -0.65743992  0.13564596 -0.65743992  0.83618472\n",
      "  0.83618472 -0.65743992 -0.65743992 -0.65743992 -0.65743992 -0.65743992\n",
      "  3.59370671 -0.65743992 -0.65743992 -0.65743992 -0.65743992  0.51480717\n",
      " -0.65743992 -0.65743992 -0.65743992 -0.65743992 -0.65743992  0.83618472\n",
      " -0.65743992  0.83618472 -0.65743992 -0.65743992  0.83618472  0.83618472\n",
      " -0.65743992 -0.65743992  0.83618472 -0.65743992  0.83618472  0.83618472\n",
      "  0.83618472  0.83618472  0.83618472 -0.65743992 -0.65743992 -0.65743992\n",
      " -0.65743992 -0.65743992  3.59370671  0.83618472 -0.65743992 -0.65743992\n",
      " -0.65743992  0.83618472]\n",
      "P is: [0.6976610666689413, 0.34131493315828715, 0.34131493315828715, 0.53385958831668, 0.34131493315828715, 0.6976610666689413, 0.6976610666689413, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.9732395894012652, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.6259327090994816, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.6976610666689413, 0.34131493315828715, 0.6976610666689413, 0.34131493315828715, 0.34131493315828715, 0.6976610666689413, 0.6976610666689413, 0.34131493315828715, 0.34131493315828715, 0.6976610666689413, 0.34131493315828715, 0.6976610666689413, 0.6976610666689413, 0.6976610666689413, 0.6976610666689413, 0.6976610666689413, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.9732395894012652, 0.6976610666689413, 0.34131493315828715, 0.34131493315828715, 0.34131493315828715, 0.6976610666689413]\n",
      "all_sum before preprocessing is: [2.379549535703593, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 2.41221036554633, 1.5479450863817124, 2.829944254506152, 2.41221036554633, 1.965678975341534, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 2.41221036554633, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.965678975341534, 1.5479450863817124, 2.41221036554633, 1.5479450863817124, 1.765176547167509, 1.5479450863817124, 1.765176547167509, 1.965678975341534, 1.5479450863817124, 1.5479450863817124, 1.965678975341534, 1.5479450863817124, 1.5479450863817124, 2.829944254506152, 2.41221036554633, 1.5479450863817124, 2.182910436127331, 1.5479450863817124, 1.965678975341534, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.5479450863817124, 1.965678975341534]\n",
      "all_sum after preprocessing is: [ 1.65386492 -0.61664794 -0.61664794 -0.61664794 -0.61664794  1.74303813\n",
      " -0.61664794  2.88356854  1.74303813  0.52388247 -0.61664794 -0.61664794\n",
      " -0.61664794 -0.61664794 -0.61664794 -0.61664794 -0.61664794 -0.61664794\n",
      " -0.61664794 -0.61664794 -0.61664794  1.74303813 -0.61664794 -0.61664794\n",
      " -0.61664794  0.52388247 -0.61664794  1.74303813 -0.61664794 -0.02354526\n",
      " -0.61664794 -0.02354526  0.52388247 -0.61664794 -0.61664794  0.52388247\n",
      " -0.61664794 -0.61664794  2.88356854  1.74303813 -0.61664794  1.11698515\n",
      " -0.61664794  0.52388247 -0.61664794 -0.61664794 -0.61664794 -0.61664794\n",
      " -0.61664794  0.52388247]\n",
      "P is: [0.8394127214634072, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.8510725528147689, 0.35054420804392666, 0.9470281681817304, 0.8510725528147689, 0.6280551692851417, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.8510725528147689, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.6280551692851417, 0.35054420804392666, 0.8510725528147689, 0.35054420804392666, 0.49411395585802204, 0.35054420804392666, 0.49411395585802204, 0.6280551692851417, 0.35054420804392666, 0.35054420804392666, 0.6280551692851417, 0.35054420804392666, 0.35054420804392666, 0.9470281681817304, 0.8510725528147689, 0.35054420804392666, 0.753429064759049, 0.35054420804392666, 0.6280551692851417, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.35054420804392666, 0.6280551692851417]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.417\n",
      "(*) epoch 2, cost 0.801\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.295\n",
      "(*) epoch 2, cost 2.528\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.4381650301691873, 1.475811896695144, 1.4381650301691873, 1.4381650301691873, 1.475811896695144, 0.13722210484097544, 0.13722210484097544, 0.13722210484097544, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 2.7767548220233556, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 0.13722210484097544, 1.4381650301691873, 0.13722210484097544, 1.4381650301691873, 2.7767548220233556, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 0.13722210484097544, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 0.13722210484097544, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.475811896695144, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 1.4381650301691873, 0.13722210484097544, 1.4381650301691873, 1.4381650301691873]\n",
      "all_sum after preprocessing is: [ 0.26959462  0.33621422  0.26959462  0.26959462  0.33621422 -2.03254356\n",
      " -2.03254356 -2.03254356  0.26959462  0.26959462  0.26959462  2.6383524\n",
      "  0.26959462  0.26959462  0.26959462  0.26959462  0.26959462 -2.03254356\n",
      "  0.26959462 -2.03254356  0.26959462  2.6383524   0.26959462  0.26959462\n",
      "  0.26959462  0.26959462  0.26959462 -2.03254356  0.26959462  0.26959462\n",
      "  0.26959462  0.26959462  0.26959462  0.26959462 -2.03254356  0.26959462\n",
      "  0.26959462  0.26959462  0.26959462  0.26959462  0.26959462  0.33621422\n",
      "  0.26959462  0.26959462  0.26959462  0.26959462  0.26959462 -2.03254356\n",
      "  0.26959462  0.26959462]\n",
      "P is: [0.5669933827004505, 0.5832706186740043, 0.5669933827004505, 0.5669933827004505, 0.5832706186740043, 0.1158281762873138, 0.1158281762873138, 0.1158281762873138, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.9332894575908931, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.1158281762873138, 0.5669933827004505, 0.1158281762873138, 0.5669933827004505, 0.9332894575908931, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.1158281762873138, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.1158281762873138, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5832706186740043, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.5669933827004505, 0.1158281762873138, 0.5669933827004505, 0.5669933827004505]\n",
      "all_sum before preprocessing is: [2.4516059961875087, 2.3695713142393404, 2.4516059961875087, 2.4516059961875087, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404, 2.4516059961875087, 2.4516059961875087, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404, 2.4516059961875087, 2.4516059961875087, 2.4516059961875087, 2.4516059961875087, 2.3695713142393404, 2.4516059961875087, 2.3695713142393404]\n",
      "all_sum after preprocessing is: [ 1.39326109 -0.71774056  1.39326109  1.39326109 -0.71774056 -0.71774056\n",
      " -0.71774056 -0.71774056 -0.71774056 -0.71774056 -0.71774056  1.39326109\n",
      " -0.71774056 -0.71774056 -0.71774056  1.39326109 -0.71774056 -0.71774056\n",
      " -0.71774056 -0.71774056 -0.71774056 -0.71774056 -0.71774056 -0.71774056\n",
      " -0.71774056 -0.71774056 -0.71774056 -0.71774056  1.39326109 -0.71774056\n",
      "  1.39326109  1.39326109 -0.71774056  1.39326109 -0.71774056 -0.71774056\n",
      "  1.39326109 -0.71774056 -0.71774056  1.39326109 -0.71774056  1.39326109\n",
      " -0.71774056  1.39326109  1.39326109  1.39326109  1.39326109 -0.71774056\n",
      "  1.39326109 -0.71774056]\n",
      "P is: [0.801112347619997, 0.32789072036268163, 0.801112347619997, 0.801112347619997, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.801112347619997, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.801112347619997, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.32789072036268163, 0.801112347619997, 0.32789072036268163, 0.801112347619997, 0.801112347619997, 0.32789072036268163, 0.801112347619997, 0.32789072036268163, 0.32789072036268163, 0.801112347619997, 0.32789072036268163, 0.32789072036268163, 0.801112347619997, 0.32789072036268163, 0.801112347619997, 0.32789072036268163, 0.801112347619997, 0.801112347619997, 0.801112347619997, 0.801112347619997, 0.32789072036268163, 0.801112347619997, 0.32789072036268163]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.150\n",
      "(*) epoch 2, cost 0.781\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.845\n",
      "(*) epoch 2, cost 1.079\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.80276036518362, 2.3618892073527946, 0.9787445039920054, 2.5104620556526713, 0.9787445039920054, 3.1859050685444092, 1.80276036518362, 2.3618892073527946, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 1.6864461944610571, 1.80276036518362, 0.9787445039920054, 3.1859050685444092, 0.9787445039920054, 0.9787445039920054, 1.80276036518362, 2.3618892073527946, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 1.80276036518362, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 2.3618892073527946, 1.80276036518362, 1.80276036518362, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 1.80276036518362, 0.9787445039920054, 0.9787445039920054, 1.80276036518362, 2.3618892073527946, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 1.80276036518362, 0.9787445039920054, 0.9787445039920054, 1.80276036518362, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054, 0.9787445039920054]\n",
      "all_sum after preprocessing is: [ 0.59647904  1.49459359 -0.72711684  1.7332424  -0.72711684  2.81818947\n",
      "  0.59647904  1.49459359 -0.72711684 -0.72711684 -0.72711684 -0.72711684\n",
      "  0.40964652  0.59647904 -0.72711684  2.81818947 -0.72711684 -0.72711684\n",
      "  0.59647904  1.49459359 -0.72711684 -0.72711684 -0.72711684  0.59647904\n",
      " -0.72711684 -0.72711684 -0.72711684 -0.72711684  1.49459359  0.59647904\n",
      "  0.59647904 -0.72711684 -0.72711684 -0.72711684  0.59647904 -0.72711684\n",
      " -0.72711684  0.59647904  1.49459359 -0.72711684 -0.72711684 -0.72711684\n",
      "  0.59647904 -0.72711684 -0.72711684  0.59647904 -0.72711684 -0.72711684\n",
      " -0.72711684 -0.72711684]\n",
      "P is: [0.6448503535885518, 0.8167667442114895, 0.3258277352542405, 0.8498266896789992, 0.3258277352542405, 0.9436508707764399, 0.6448503535885518, 0.8167667442114895, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.6010031186995726, 0.6448503535885518, 0.3258277352542405, 0.9436508707764399, 0.3258277352542405, 0.3258277352542405, 0.6448503535885518, 0.8167667442114895, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.6448503535885518, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.8167667442114895, 0.6448503535885518, 0.6448503535885518, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.6448503535885518, 0.3258277352542405, 0.3258277352542405, 0.6448503535885518, 0.8167667442114895, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.6448503535885518, 0.3258277352542405, 0.3258277352542405, 0.6448503535885518, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405, 0.3258277352542405]\n",
      "all_sum before preprocessing is: [2.6272295963627474, 1.3451095834421567, 2.626195994885484, 2.626195994885484, 2.626195994885484, 2.626195994885484, 2.160412812053144, 2.3400236470852294, 1.344075981964893, 1.6302483297651476, 2.6272295963627474, 2.6272295963627474, 1.6302483297651476, 2.626195994885484, 2.626195994885484, 1.6302483297651476, 1.6302483297651476, 1.344075981964893, 1.6312819312424112, 2.626195994885484, 1.6302483297651476, 1.6302483297651476, 1.6302483297651476, 1.344075981964893, 2.6272295963627474, 1.6312819312424112, 2.5103048190100465, 1.344075981964893, 1.6302483297651476, 1.6312819312424112, 2.3410572485624925, 2.626195994885484, 1.6302483297651476, 2.626195994885484, 1.6302483297651476, 2.626195994885484, 2.626195994885484, 1.6302483297651476, 2.1593792105758802, 3.1553268756962165, 2.626195994885484, 2.626195994885484, 2.626195994885484, 2.626195994885484, 1.6302483297651476, 1.6312819312424112, 2.3400236470852294, 2.6272295963627474, 2.626195994885484, 1.344075981964893]\n",
      "all_sum after preprocessing is: [ 0.93990642 -1.46580595  0.93796702  0.93796702  0.93796702  0.93796702\n",
      "  0.06399239  0.40100608 -1.46774535 -0.93078442  0.93990642  0.93990642\n",
      " -0.93078442  0.93796702  0.93796702 -0.93078442 -0.93078442 -1.46774535\n",
      " -0.92884502  0.93796702 -0.93078442 -0.93078442 -0.93078442 -1.46774535\n",
      "  0.93990642 -0.92884502  0.72051402 -1.46774535 -0.93078442 -0.92884502\n",
      "  0.40294549  0.93796702 -0.93078442  0.93796702 -0.93078442  0.93796702\n",
      "  0.93796702 -0.93078442  0.06205298  1.93080442  0.93796702  0.93796702\n",
      "  0.93796702  0.93796702 -0.93078442 -0.92884502  0.40100608  0.93990642\n",
      "  0.93796702 -1.46774535]\n",
      "P is: [0.7190807541418593, 0.18758092632524745, 0.7186888212330725, 0.7186888212330725, 0.7186888212330725, 0.7186888212330725, 0.5159926393915029, 0.5989293586876805, 0.18728555132706515, 0.28276559975798715, 0.7190807541418593, 0.7190807541418593, 0.28276559975798715, 0.7186888212330725, 0.7186888212330725, 0.28276559975798715, 0.28276559975798715, 0.18728555132706515, 0.2831590942889523, 0.7186888212330725, 0.28276559975798715, 0.28276559975798715, 0.28276559975798715, 0.18728555132706515, 0.7190807541418593, 0.2831590942889523, 0.6727201982041502, 0.18728555132706515, 0.28276559975798715, 0.2831590942889523, 0.5993951390388511, 0.7186888212330725, 0.28276559975798715, 0.7186888212330725, 0.28276559975798715, 0.7186888212330725, 0.7186888212330725, 0.28276559975798715, 0.5155082697113894, 0.8733384301425475, 0.7186888212330725, 0.7186888212330725, 0.7186888212330725, 0.7186888212330725, 0.28276559975798715, 0.2831590942889523, 0.5989293586876805, 0.7190807541418593, 0.7186888212330725, 0.18728555132706515]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.878\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.744\n",
      "(*) epoch 2, cost 2.372\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.6730634132188023, 1.2675341725265459, 1.7982382387441092, 1.2675341725265459, 0.6098923805994627, 0.6098923805994627, 0.6098923805994627, 0.6098923805994627, 1.2675341725265459, 1.2675341725265459, 0.6098923805994627, 0.6098923805994627, 1.4042814675872668, 0.6098923805994627, 1.2675341725265459, 1.7982382387441092, 0.6098923805994627, 1.7982382387441092, 1.2675341725265459, 2.455880030671192, 1.2675341725265459, 0.6098923805994627, 0.8735774013697036, 0.6098923805994627, 1.2675341725265459, 0.6098923805994627, 0.6098923805994627, 1.7982382387441092, 1.2675341725265459, 0.6098923805994627, 1.2675341725265459, 0.6098923805994627, 1.7982382387441092, 0.6098923805994627, 0.6098923805994627, 2.455880030671192, 1.7982382387441092, 2.0619232595143497, 1.2675341725265459, 0.6098923805994627, 2.455880030671192, 1.7982382387441092, 0.6098923805994627, 1.7982382387441092, 1.7982382387441092, 1.7982382387441092, 0.6098923805994627, 1.7982382387441092, 2.203767479436365, 1.2675341725265459]\n",
      "all_sum after preprocessing is: [ 0.729238    0.0411778   0.94162174  0.0411778  -1.07464098 -1.07464098\n",
      " -1.07464098 -1.07464098  0.0411778   0.0411778  -1.07464098 -1.07464098\n",
      "  0.27319651 -1.07464098  0.0411778   0.94162174 -1.07464098  0.94162174\n",
      "  0.0411778   2.05744052  0.0411778  -1.07464098 -0.62724742 -1.07464098\n",
      "  0.0411778  -1.07464098 -1.07464098  0.94162174  0.0411778  -1.07464098\n",
      "  0.0411778  -1.07464098  0.94162174 -1.07464098 -1.07464098  2.05744052\n",
      "  0.94162174  1.38901529  0.0411778  -1.07464098  2.05744052  0.94162174\n",
      " -1.07464098  0.94162174  0.94162174  0.94162174 -1.07464098  0.94162174\n",
      "  1.62968194  0.0411778 ]\n",
      "P is: [0.6746380347000533, 0.5102929959499165, 0.7194271242178096, 0.5102929959499165, 0.2545215008815036, 0.2545215008815036, 0.2545215008815036, 0.2545215008815036, 0.5102929959499165, 0.5102929959499165, 0.2545215008815036, 0.2545215008815036, 0.5678774747410461, 0.2545215008815036, 0.5102929959499165, 0.7194271242178096, 0.2545215008815036, 0.7194271242178096, 0.5102929959499165, 0.886697285170507, 0.5102929959499165, 0.2545215008815036, 0.34813493760392517, 0.2545215008815036, 0.5102929959499165, 0.2545215008815036, 0.2545215008815036, 0.7194271242178096, 0.5102929959499165, 0.2545215008815036, 0.5102929959499165, 0.2545215008815036, 0.7194271242178096, 0.2545215008815036, 0.2545215008815036, 0.886697285170507, 0.7194271242178096, 0.8004349932083809, 0.5102929959499165, 0.2545215008815036, 0.886697285170507, 0.7194271242178096, 0.2545215008815036, 0.7194271242178096, 0.7194271242178096, 0.7194271242178096, 0.2545215008815036, 0.7194271242178096, 0.8361260624670123, 0.5102929959499165]\n",
      "all_sum before preprocessing is: [1.5529235619104187, 2.161750165839897, 2.161750165839897, 3.496639476237138, 3.496639476237138, 2.161750165839897, 2.161750165839897, 2.161750165839897, 2.161750165839897, 2.161750165839897, 2.161750165839897, 3.496639476237138, 2.161750165839897, 3.496639476237138, 2.161750165839897, 5.071861234831257, 3.496639476237138, 2.161750165839897, 2.161750165839897, 2.161750165839897, 1.5529235619104187, 3.1281453205045384, 1.5529235619104187, 2.161750165839897, 2.161750165839897, 3.496639476237138, 2.161750165839897, 3.496639476237138, 2.161750165839897, 2.161750165839897, 2.161750165839897, 2.161750165839897, 1.5529235619104187, 2.161750165839897, 2.8878128723076597, 1.5529235619104187, 2.161750165839897, 2.161750165839897, 3.7369719244340165, 3.496639476237138, 3.496639476237138, 2.161750165839897, 2.161750165839897, 2.161750165839897, 3.496639476237138, 2.8878128723076597, 2.161750165839897, 2.161750165839897, 2.161750165839897, 3.496639476237138]\n",
      "all_sum after preprocessing is: [-1.32064656 -0.49993869 -0.49993869  1.29951317  1.29951317 -0.49993869\n",
      " -0.49993869 -0.49993869 -0.49993869 -0.49993869 -0.49993869  1.29951317\n",
      " -0.49993869  1.29951317 -0.49993869  3.42293697  1.29951317 -0.49993869\n",
      " -0.49993869 -0.49993869 -1.32064656  0.80277723 -1.32064656 -0.49993869\n",
      " -0.49993869  1.29951317 -0.49993869  1.29951317 -0.49993869 -0.49993869\n",
      " -0.49993869 -0.49993869 -1.32064656 -0.49993869  0.4788053  -1.32064656\n",
      " -0.49993869 -0.49993869  1.62348511  1.29951317  1.29951317 -0.49993869\n",
      " -0.49993869 -0.49993869  1.29951317  0.4788053  -0.49993869 -0.49993869\n",
      " -0.49993869  1.29951317]\n",
      "P is: [0.21071074218455652, 0.3775550769283743, 0.3775550769283743, 0.7857530396933639, 0.7857530396933639, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.7857530396933639, 0.3775550769283743, 0.7857530396933639, 0.3775550769283743, 0.9684137331489375, 0.7857530396933639, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.21071074218455652, 0.6905682449654594, 0.21071074218455652, 0.3775550769283743, 0.3775550769283743, 0.7857530396933639, 0.3775550769283743, 0.7857530396933639, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.21071074218455652, 0.3775550769283743, 0.6174657242503612, 0.21071074218455652, 0.3775550769283743, 0.3775550769283743, 0.8352752082612489, 0.7857530396933639, 0.7857530396933639, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.7857530396933639, 0.6174657242503612, 0.3775550769283743, 0.3775550769283743, 0.3775550769283743, 0.7857530396933639]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.880\n",
      "(*) epoch 2, cost 1.771\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.680\n",
      "(*) epoch 2, cost 2.120\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.563247544934554, 2.6458555300041002, 1.4579298393239644, 1.4579298393239644, 1.4579298393239644, 4.546348014537533, 1.6158955037952198, 2.8038211944753555, 2.6458555300041002, 1.4579298393239644, 2.8038211944753555, 1.4579298393239644, 2.6830938340551214, 2.6458555300041002, 1.4579298393239644, 4.388382350066277, 1.4579298393239644, 1.4579298393239644, 1.375321854254418, 1.4579298393239644, 2.6458555300041002, 2.8038211944753555, 2.6458555300041002, 4.388382350066277, 1.4579298393239644, 1.4579298393239644, 3.2004566593861417, 1.4579298393239644, 3.358422323857397, 2.8038211944753555, 2.6458555300041002, 1.6158955037952198, 1.4579298393239644, 3.2004566593861417, 1.4579298393239644, 2.841059498526377, 1.4579298393239644, 2.8038211944753555, 2.8038211944753555, 1.6158955037952198, 2.6458555300041002, 3.8710195247352575, 3.2004566593861417, 2.6458555300041002, 2.6830938340551214, 4.425620654117299, 2.8038211944753555, 2.6458555300041002, 0.6497330005658989, 1.4579298393239644]\n",
      "all_sum after preprocessing is: [ 0.19596202  0.28419679 -0.9846436  -0.9846436  -0.9846436   2.31413995\n",
      " -0.81591822  0.45292217  0.28419679 -0.9846436   0.45292217 -0.9846436\n",
      "  0.32397156  0.28419679 -0.9846436   2.14541457 -0.9846436  -0.9846436\n",
      " -1.07287837 -0.9846436   0.28419679  0.45292217  0.28419679  2.14541457\n",
      " -0.9846436  -0.9846436   0.87657418 -0.9846436   1.04529956  0.45292217\n",
      "  0.28419679 -0.81591822 -0.9846436   0.87657418 -0.9846436   0.49269694\n",
      " -0.9846436   0.45292217  0.45292217 -0.81591822  0.28419679  1.59281195\n",
      "  0.87657418  0.28419679  0.32397156  2.18518934  0.45292217  0.28419679\n",
      " -1.84789019 -0.9846436 ]\n",
      "P is: [0.54883433117085, 0.5705748214614124, 0.2719713635756182, 0.2719713635756182, 0.2719713635756182, 0.910041352966128, 0.3066307944975099, 0.6113337817535835, 0.5705748214614124, 0.2719713635756182, 0.6113337817535835, 0.2719713635756182, 0.5802918445399421, 0.5705748214614124, 0.2719713635756182, 0.895239507887215, 0.2719713635756182, 0.2719713635756182, 0.25485608291049944, 0.2719713635756182, 0.5705748214614124, 0.6113337817535835, 0.5705748214614124, 0.895239507887215, 0.2719713635756182, 0.2719713635756182, 0.7061118038236436, 0.2719713635756182, 0.7398712645614622, 0.6113337817535835, 0.5705748214614124, 0.3066307944975099, 0.2719713635756182, 0.7061118038236436, 0.2719713635756182, 0.6207415557836721, 0.2719713635756182, 0.6113337817535835, 0.6113337817535835, 0.3066307944975099, 0.5705748214614124, 0.8310113569962819, 0.7061118038236436, 0.5705748214614124, 0.5802918445399421, 0.898911601784932, 0.6113337817535835, 0.5705748214614124, 0.13612080341541216, 0.2719713635756182]\n",
      "all_sum before preprocessing is: [2.1372913813869814, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.1372913813869814, 2.076107149587314, 2.076107149587314, 2.1372913813869814, 2.1372913813869814, 2.076107149587314, 2.076107149587314, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.1372913813869814, 2.909860962166934, 2.076107149587314, 2.1372913813869814, 2.1372913813869814, 2.1372913813869814, 2.1372913813869814, 2.1372913813869814, 0.7262291651674454, 2.076107149587314, 2.076107149587314, 2.1372913813869814, 2.076107149587314, 2.076107149587314, 2.1372913813869814, 2.1372913813869814]\n",
      "all_sum after preprocessing is: [ 0.17433974  0.17433974 -0.09440798  0.17433974 -0.09440798  0.17433974\n",
      "  0.17433974 -0.09440798  0.17433974  0.17433974 -0.09440798 -0.09440798\n",
      "  0.17433974  0.17433974 -0.09440798 -0.09440798 -0.09440798  0.17433974\n",
      " -0.09440798 -0.09440798  0.17433974 -0.09440798  0.17433974 -0.09440798\n",
      "  0.17433974 -0.09440798 -0.09440798  0.17433974 -0.09440798  0.17433974\n",
      "  0.17433974 -0.09440798  0.17433974 -0.09440798  0.17433974  3.5678009\n",
      " -0.09440798  0.17433974  0.17433974  0.17433974  0.17433974  0.17433974\n",
      " -6.02365841 -0.09440798 -0.09440798  0.17433974 -0.09440798 -0.09440798\n",
      "  0.17433974  0.17433974]\n",
      "P is: [0.5434748741817818, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.5434748741817818, 0.4764155184213613, 0.4764155184213613, 0.5434748741817818, 0.5434748741817818, 0.4764155184213613, 0.4764155184213613, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.5434748741817818, 0.9725565554430633, 0.4764155184213613, 0.5434748741817818, 0.5434748741817818, 0.5434748741817818, 0.5434748741817818, 0.5434748741817818, 0.002414950991028103, 0.4764155184213613, 0.4764155184213613, 0.5434748741817818, 0.4764155184213613, 0.4764155184213613, 0.5434748741817818, 0.5434748741817818]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.278\n",
      "(*) epoch 2, cost 3.573\n",
      "(*) epoch 3, cost 2.876\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.818\n",
      "(*) epoch 2, cost 1.392\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.0773277432386488, 2.703511788717347, 2.173706555638858, 2.288303767386223, 2.173706555638858, 2.173706555638858, 1.34980218129223, 2.703511788717347, 2.0773277432386488, 0.9939261427291864, 2.149915421286374, 2.173706555638858, 2.0773277432386488, 2.0773277432386488, 2.0773277432386488, 2.0773277432386488, 2.149915421286374, 2.149915421286374, 1.54752251016016, 3.371705367895685, 2.149915421286374, 2.703511788717347, 2.1919249549860136, 2.8419001348171964, 1.5237313758076754, 1.4881905273920792, 2.1919249549860136, 2.8419001348171964, 0.9939261427291864, 2.703511788717347, 2.288303767386223, 3.371705367895685, 2.703511788717347, 1.5237313758076754, 2.8181090004647116, 2.149915421286374, 1.5237313758076754, 1.54752251016016, 0.9939261427291864, 2.0773277432386488, 1.54752251016016, 2.288303767386223, 2.8181090004647116, 1.54752251016016, 1.5237313758076754, 2.8419001348171964, 0.9939261427291864, 0.9939261427291864, 1.5237313758076754, 2.703511788717347]\n",
      "all_sum after preprocessing is: [-0.00367659  1.03484023  0.15616622  0.34622397  0.15616622  0.15616622\n",
      " -1.21026679  1.03484023 -0.00367659 -1.80048185  0.11670898  0.15616622\n",
      " -0.00367659 -0.00367659 -0.00367659 -0.00367659  0.11670898  0.11670898\n",
      " -0.8823506   2.14302923  0.11670898  1.03484023  0.18638116  1.26435522\n",
      " -0.92180784 -0.9807518   0.18638116  1.26435522 -1.80048185  1.03484023\n",
      "  0.34622397  2.14302923  1.03484023 -0.92180784  1.22489798  0.11670898\n",
      " -0.92180784 -0.8823506  -1.80048185 -0.00367659 -0.8823506   0.34622397\n",
      "  1.22489798 -0.8823506  -0.92180784  1.26435522 -1.80048185 -1.80048185\n",
      " -0.92180784  1.03484023]\n",
      "P is: [0.4990808537671899, 0.737853198995528, 0.5389624033334212, 0.5857016038335061, 0.5389624033334212, 0.5389624033334212, 0.22965384888942741, 0.737853198995528, 0.4990808537671899, 0.14179242007501067, 0.5291441722561536, 0.5389624033334212, 0.4990808537671899, 0.4990808537671899, 0.4990808537671899, 0.4990808537671899, 0.5291441722561536, 0.5291441722561536, 0.29269091397376695, 0.8950155860085686, 0.5291441722561536, 0.737853198995528, 0.5464608722795855, 0.7797749238060151, 0.2845896782182171, 0.27274263560036743, 0.5464608722795855, 0.7797749238060151, 0.14179242007501067, 0.737853198995528, 0.5857016038335061, 0.8950155860085686, 0.737853198995528, 0.2845896782182171, 0.7729243547236863, 0.5291441722561536, 0.2845896782182171, 0.29269091397376695, 0.14179242007501067, 0.4990808537671899, 0.29269091397376695, 0.5857016038335061, 0.7729243547236863, 0.29269091397376695, 0.2845896782182171, 0.7797749238060151, 0.14179242007501067, 0.14179242007501067, 0.2845896782182171, 0.737853198995528]\n",
      "all_sum before preprocessing is: [1.038434142965523, 1.038434142965523, 2.960365218140398, 0.6400668652025354, 0.6400668652025354, 1.038434142965523, 0.6400668652025354, 0.6400668652025354, 0.8956809552252106, 0.6400668652025354, 0.6400668652025354, 1.038434142965523, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 1.038434142965523, 0.6400668652025354, 2.5619979403774105, 1.1533479626287386, 1.038434142965523, 0.6400668652025354, 1.038434142965523, 2.5619979403774105, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 1.1533479626287386, 0.6400668652025354, 1.038434142965523, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 0.6400668652025354, 2.5619979403774105, 2.5619979403774105, 0.6400668652025354, 1.038434142965523, 1.038434142965523, 1.1533479626287386, 0.6400668652025354, 0.6400668652025354, 2.5619979403774105]\n",
      "all_sum after preprocessing is: [ 0.06982287  0.06982287  3.10689243 -0.55968417 -0.55968417  0.06982287\n",
      " -0.55968417 -0.55968417 -0.15575825 -0.55968417 -0.55968417  0.06982287\n",
      " -0.55968417 -0.55968417 -0.55968417 -0.55968417 -0.55968417 -0.55968417\n",
      " -0.55968417 -0.55968417  0.06982287 -0.55968417  2.47738539  0.25141172\n",
      "  0.06982287 -0.55968417  0.06982287  2.47738539 -0.55968417 -0.55968417\n",
      " -0.55968417  0.25141172 -0.55968417  0.06982287 -0.55968417 -0.55968417\n",
      " -0.55968417 -0.55968417 -0.55968417 -0.55968417 -0.55968417  2.47738539\n",
      "  2.47738539 -0.55968417  0.06982287  0.06982287  0.25141172 -0.55968417\n",
      " -0.55968417  2.47738539]\n",
      "P is: [0.5174486288519521, 0.5174486288519521, 0.9571761573387654, 0.3636205406189233, 0.3636205406189233, 0.5174486288519521, 0.3636205406189233, 0.3636205406189233, 0.4611389719184782, 0.3636205406189233, 0.3636205406189233, 0.5174486288519521, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.5174486288519521, 0.3636205406189233, 0.9225411670434917, 0.5625239436376547, 0.5174486288519521, 0.3636205406189233, 0.5174486288519521, 0.9225411670434917, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.5625239436376547, 0.3636205406189233, 0.5174486288519521, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.3636205406189233, 0.9225411670434917, 0.9225411670434917, 0.3636205406189233, 0.5174486288519521, 0.5174486288519521, 0.5625239436376547, 0.3636205406189233, 0.3636205406189233, 0.9225411670434917]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.141\n",
      "(*) epoch 2, cost 3.137\n",
      "(*) epoch 3, cost 2.467\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.621\n",
      "(*) epoch 2, cost 1.419\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.4903757827345014, 1.9953362676013633, 2.5910214037525123, 1.2865251080512394, 3.300356807170523, 1.4903757827345014, 1.5598644067426042, 1.7642393252937532, 1.4909000266023886, 1.5598644067426042, 2.317682105061148, 1.2865251080512394, 2.317682105061148, 1.2865251080512394, 2.317682105061148, 1.5598644067426042, 1.2865251080512394, 2.268675566292728, 1.6947507012856504, 1.2865251080512394, 1.5598644067426042, 1.4909000266023886, 1.5598644067426042, 1.2865251080512394, 1.5598644067426042, 1.2865251080512394, 1.2865251080512394, 1.7637150814258662, 1.2865251080512394, 2.317682105061148, 2.52153277974441, 1.2865251080512394, 1.4909000266023886, 2.5910214037525123, 1.4903757827345014, 1.5598644067426042, 1.2865251080512394, 1.7637150814258662, 1.9680899999770154, 1.7642393252937532, 1.4903757827345014, 1.2865251080512394, 1.4909000266023886, 1.5598644067426042, 1.4909000266023886, 1.4909000266023886, 2.317682105061148, 1.2865251080512394, 1.7642393252937532, 1.4909000266023886]\n",
      "all_sum after preprocessing is: [-0.46387084  0.659878    1.98552723 -0.91752407  3.56409597 -0.46387084\n",
      " -0.30922951  0.14559039 -0.46270417 -0.30922951  1.37723267 -0.91752407\n",
      "  1.37723267 -0.91752407  1.37723267 -0.30922951 -0.91752407  1.26817257\n",
      " -0.00905094 -0.91752407 -0.30922951 -0.46270417 -0.30922951 -0.91752407\n",
      " -0.30922951 -0.91752407 -0.91752407  0.14442373 -0.91752407  1.37723267\n",
      "  1.8308859  -0.91752407 -0.46270417  1.98552723 -0.46387084 -0.30922951\n",
      " -0.91752407  0.14442373  0.59924363  0.14559039 -0.46387084 -0.91752407\n",
      " -0.46270417 -0.30922951 -0.46270417 -0.46270417  1.37723267 -0.91752407\n",
      "  0.14559039 -0.46270417]\n",
      "P is: [0.38606795667350496, 0.6592329824212649, 0.8792691360454956, 0.2854626500258089, 0.9724574962763355, 0.38606795667350496, 0.4233028185830627, 0.5363334420576898, 0.38634451514071294, 0.4233028185830627, 0.7985461865356299, 0.2854626500258089, 0.7985461865356299, 0.2854626500258089, 0.7985461865356299, 0.4233028185830627, 0.2854626500258089, 0.7804297608913773, 0.4977372813163211, 0.2854626500258089, 0.4233028185830627, 0.38634451514071294, 0.4233028185830627, 0.2854626500258089, 0.4233028185830627, 0.2854626500258089, 0.2854626500258089, 0.5360433043127308, 0.2854626500258089, 0.7985461865356299, 0.8618672292588054, 0.2854626500258089, 0.38634451514071294, 0.8792691360454956, 0.38606795667350496, 0.4233028185830627, 0.2854626500258089, 0.5360433043127308, 0.6454832414430591, 0.5363334420576898, 0.38606795667350496, 0.2854626500258089, 0.38634451514071294, 0.4233028185830627, 0.38634451514071294, 0.38634451514071294, 0.7985461865356299, 0.2854626500258089, 0.5363334420576898, 0.38634451514071294]\n",
      "all_sum before preprocessing is: [4.457964603337261, 4.064132794747796, 4.457964603337261, 4.457964603337261, 4.749159824669945, 4.457964603337261, 4.457964603337261, 4.457964603337261, 4.457964603337261, 3.808717563900397, 4.749159824669945, 4.457964603337261, 4.457964603337261, 4.457964603337261, 4.457964603337261, 3.9159137152704426, 4.457964603337261, 4.749159824669945, 4.457964603337261, 4.897378904147299, 4.350768451967214, 4.457964603337261, 4.457964603337261, 4.457964603337261, 4.457964603337261, 4.749159824669945, 4.457964603337261, 1.628760514985063, 4.457964603337261, 4.749159824669945, 3.9159137152704426, 4.064132794747796, 4.457964603337261, 3.624718493937758, 4.749159824669945, 4.897378904147299, 4.749159824669945, 4.749159824669945, 4.457964603337261, 2.8603979970872966, 4.749159824669945, 3.5175223425677116, 4.790182752777254, 5.337413808321772, 4.350768451967214, 4.457964603337261, 4.749159824669945, 4.457964603337261, 4.749159824669945, 3.624718493937758]\n",
      "all_sum after preprocessing is: [ 0.15835982 -0.53840703  0.15835982  0.15835982  0.67354211  0.15835982\n",
      "  0.15835982  0.15835982  0.15835982 -0.9902874   0.67354211  0.15835982\n",
      "  0.15835982  0.15835982  0.15835982 -0.80063607  0.15835982  0.67354211\n",
      "  0.15835982  0.93577116 -0.03129151  0.15835982  0.15835982  0.15835982\n",
      "  0.15835982  0.67354211  0.15835982 -4.84706524  0.15835982  0.67354211\n",
      " -0.80063607 -0.53840703  0.15835982 -1.31581837  0.67354211  0.93577116\n",
      "  0.67354211  0.67354211  0.15835982 -2.66805343  0.67354211 -1.50546969\n",
      "  0.74611984  1.71428048 -0.03129151  0.15835982  0.67354211  0.15835982\n",
      "  0.67354211 -1.31581837]\n",
      "P is: [0.5395074256397405, 0.3685582265316057, 0.5395074256397405, 0.5395074256397405, 0.6622958434066673, 0.5395074256397405, 0.5395074256397405, 0.5395074256397405, 0.5395074256397405, 0.2708553150526267, 0.6622958434066673, 0.5395074256397405, 0.5395074256397405, 0.5395074256397405, 0.5395074256397405, 0.3098894731284749, 0.5395074256397405, 0.6622958434066673, 0.5395074256397405, 0.7182446608072334, 0.4921777617378243, 0.5395074256397405, 0.5395074256397405, 0.5395074256397405, 0.5395074256397405, 0.6622958434066673, 0.5395074256397405, 0.007790221696177413, 0.5395074256397405, 0.6622958434066673, 0.3098894731284749, 0.3685582265316057, 0.5395074256397405, 0.21151484928287084, 0.6622958434066673, 0.7182446608072334, 0.6622958434066673, 0.6622958434066673, 0.5395074256397405, 0.06488497658485962, 0.6622958434066673, 0.1816111551598844, 0.6783326439652309, 0.8473906576751405, 0.4921777617378243, 0.5395074256397405, 0.6622958434066673, 0.5395074256397405, 0.6622958434066673, 0.21151484928287084]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.413\n",
      "(*) epoch 2, cost 2.735\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.289\n",
      "(*) epoch 2, cost 2.941\n",
      "(*) epoch 3, cost 2.552\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.832155050306318, 2.55668331625216, 2.040809015797798, 1.8493894630820469, 2.040809015797798, 2.040809015797798, 1.8493894630820469, 1.8493894630820469, 2.365263763536409, 2.55668331625216, 2.040809015797798, 4.804418967902453, 2.040809015797798, 1.8493894630820469, 2.040809015797798, 1.6001291633420625, 1.8493894630820469, 1.8493894630820469, 2.040809015797798, 3.023574603022069, 2.040809015797798, 2.067020450111971, 3.8216533806781827, 2.040809015797798, 1.6001291633420625, 2.040809015797798, 2.040809015797798, 2.040809015797798, 2.040809015797798, 2.365263763536409, 1.8493894630820469, 1.8493894630820469, 2.040809015797798, 1.8493894630820469, 2.040809015797798, 3.6302338279624315, 2.040809015797798, 2.365263763536409, 1.8493894630820469, 1.8493894630820469, 2.365263763536409, 3.8216533806781827, 3.023574603022069, 3.6302338279624315, 1.8493894630820469, 2.507700302567707, 2.507700302567707, 2.316280749851956, 2.040809015797798, 1.8493894630820469]\n",
      "all_sum after preprocessing is: [ 0.84030984  0.41339618 -0.38608252 -0.68273591 -0.38608252 -0.38608252\n",
      " -0.68273591 -0.68273591  0.1167428   0.41339618 -0.38608252  3.89683544\n",
      " -0.38608252 -0.68273591 -0.38608252 -1.06902827 -0.68273591 -0.68273591\n",
      " -0.38608252  1.13696322 -0.38608252 -0.34546123  2.37378969 -0.38608252\n",
      " -1.06902827 -0.38608252 -0.38608252 -0.38608252 -0.38608252  0.1167428\n",
      " -0.68273591 -0.68273591 -0.38608252 -0.68273591 -0.38608252  2.07713631\n",
      " -0.38608252  0.1167428  -0.68273591 -0.68273591  0.1167428   2.37378969\n",
      "  1.13696322  2.07713631 -0.68273591  0.33748452  0.33748452  0.04083114\n",
      " -0.38608252 -0.68273591]\n",
      "P is: [0.6985304680896147, 0.6019019392494659, 0.40466070796430115, 0.33565095042474946, 0.40466070796430115, 0.40466070796430115, 0.33565095042474946, 0.33565095042474946, 0.5291525975200573, 0.6019019392494659, 0.40466070796430115, 0.9800980604667848, 0.40466070796430115, 0.33565095042474946, 0.40466070796430115, 0.2555879246488878, 0.33565095042474946, 0.33565095042474946, 0.40466070796430115, 0.7571216469956081, 0.40466070796430115, 0.4144834929179556, 0.9148066763109896, 0.40466070796430115, 0.2555879246488878, 0.40466070796430115, 0.40466070796430115, 0.40466070796430115, 0.40466070796430115, 0.5291525975200573, 0.33565095042474946, 0.33565095042474946, 0.40466070796430115, 0.33565095042474946, 0.40466070796430115, 0.8886610072318772, 0.40466070796430115, 0.5291525975200573, 0.33565095042474946, 0.33565095042474946, 0.5291525975200573, 0.9148066763109896, 0.7571216469956081, 0.8886610072318772, 0.33565095042474946, 0.5835793531863613, 0.5835793531863613, 0.5102063659171202, 0.40466070796430115, 0.33565095042474946]\n",
      "all_sum before preprocessing is: [1.625885571365157, 3.785431665031422, 3.785431665031422, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 3.785431665031422, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 3.785431665031422, 3.848231198492062, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 3.848231198492062, 3.069531924591689, 3.848231198492062, 3.785431665031422, 4.193851197847446, 3.848231198492062, 2.7239119252363038, 2.7239119252363038, 3.848231198492062, 3.848231198492062, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.6874053111602754, 3.848231198492062, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.7239119252363038, 2.750204844620915, 2.7239119252363038, 3.785431665031422]\n",
      "all_sum after preprocessing is: [-2.58259096  1.4098104   1.4098104  -0.55264498 -0.55264498 -0.55264498\n",
      " -0.55264498 -0.55264498 -0.55264498 -0.55264498 -0.55264498 -0.55264498\n",
      " -0.55264498 -0.55264498 -0.55264498  1.4098104  -0.55264498 -0.55264498\n",
      " -0.55264498  1.4098104   1.5259093  -0.55264498 -0.55264498 -0.55264498\n",
      " -0.55264498 -0.55264498 -0.55264498 -0.55264498  1.5259093   0.08631047\n",
      "  1.5259093   1.4098104   2.16486476  1.5259093  -0.55264498 -0.55264498\n",
      "  1.5259093   1.5259093  -0.55264498 -0.55264498 -0.55264498 -0.62013558\n",
      "  1.5259093  -0.55264498 -0.55264498 -0.55264498 -0.55264498 -0.50403667\n",
      " -0.55264498  1.4098104 ]\n",
      "P is: [0.07026727523934714, 0.8037360364338126, 0.8037360364338126, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.8037360364338126, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.8037360364338126, 0.8214070079977623, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.8214070079977623, 0.5215642321327819, 0.8214070079977623, 0.8037360364338126, 0.897049685080246, 0.8214070079977623, 0.36525097028861303, 0.36525097028861303, 0.8214070079977623, 0.8214070079977623, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.3497506160235526, 0.8214070079977623, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.36525097028861303, 0.37659250534016403, 0.36525097028861303, 0.8037360364338126]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.976\n",
      "(*) epoch 2, cost 3.621\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.005\n",
      "(*) epoch 2, cost 1.477\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [2.210440797102405, 2.210440797102405, 2.7514438333370994, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.7514438333370994, 2.7514438333370994, 2.210440797102405, 2.7514438333370994, 2.210440797102405, 2.210440797102405, 2.85310925846799, 2.7514438333370994, 2.7514438333370994, 2.33650595392205, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.5101977236780506, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.5101977236780506, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.7514438333370994, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405, 2.210440797102405]\n",
      "all_sum after preprocessing is: [-0.50003128 -0.50003128  2.12367714 -0.50003128 -0.50003128 -0.50003128\n",
      " -0.50003128  2.12367714  2.12367714 -0.50003128  2.12367714 -0.50003128\n",
      " -0.50003128  2.61672507  2.12367714  2.12367714  0.11134831 -0.50003128\n",
      " -0.50003128 -0.50003128 -0.50003128 -0.50003128  0.95370321 -0.50003128\n",
      " -0.50003128 -0.50003128 -0.50003128 -0.50003128 -0.50003128 -0.50003128\n",
      " -0.50003128 -0.50003128 -0.50003128  0.95370321 -0.50003128 -0.50003128\n",
      " -0.50003128 -0.50003128 -0.50003128 -0.50003128 -0.50003128 -0.50003128\n",
      "  2.12367714 -0.50003128 -0.50003128 -0.50003128 -0.50003128 -0.50003128\n",
      " -0.50003128 -0.50003128]\n",
      "P is: [0.3775333189333615, 0.3775333189333615, 0.8931832612784509, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.8931832612784509, 0.8931832612784509, 0.3775333189333615, 0.8931832612784509, 0.3775333189333615, 0.3775333189333615, 0.931930250949219, 0.8931832612784509, 0.8931832612784509, 0.5278083518351896, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.7218593129310008, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.7218593129310008, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.8931832612784509, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615, 0.3775333189333615]\n",
      "all_sum before preprocessing is: [4.394356947717255, 5.788276007368609, 4.027003472239604, 4.38853117828425, 5.734827127417846, 7.371830728336116, 5.272080330565255, 5.734827127417846, 4.38853117828425, 7.849227047365479, 4.38853117828425, 4.9047268550876035, 4.38853117828425, 3.5584309059540074, 4.38853117828425, 5.272080330565255, 6.618376279698851, 6.618376279698851, 5.495113011740142, 6.618376279698851, 6.618376279698851, 6.488281576055111, 5.610558193207112, 4.38853117828425, 5.734827127417846, 4.38853117828425, 4.7327561288859, 5.272080330565255, 4.857103744569847, 5.272080330565255, 4.38853117828425, 4.38853117828425, 4.38853117828425, 4.38853117828425, 4.38853117828425, 3.5584309059540074, 5.272080330565255, 3.5108077954362504, 3.5108077954362504, 5.272080330565255, 3.5584309059540074, 6.618376279698851, 4.9047268550876035, 5.141985626921514, 3.5584309059540074, 6.618376279698851, 4.38853117828425, 3.5584309059540074, 7.849227047365479, 6.618376279698851]\n",
      "all_sum after preprocessing is: [-0.63927985  0.57384652 -0.95898721 -0.64435001  0.52733001  1.95201261\n",
      "  0.12460194  0.52733001 -0.64435001  2.36749015 -0.64435001 -0.19510543\n",
      " -0.64435001 -1.36678545 -0.64435001  0.12460194  1.29628196  1.29628196\n",
      "  0.31870706  1.29628196  1.29628196  1.18306067  0.41917888 -0.64435001\n",
      "  0.52733001 -0.64435001 -0.34477138  0.12460194 -0.23655177  0.12460194\n",
      " -0.64435001 -0.64435001 -0.64435001 -0.64435001 -0.64435001 -1.36678545\n",
      "  0.12460194 -1.40823179 -1.40823179  0.12460194 -1.36678545  1.29628196\n",
      " -0.19510543  0.01138064 -1.36678545  1.29628196 -0.64435001 -1.36678545\n",
      "  2.36749015  1.29628196]\n",
      "P is: [0.34540934885819313, 0.6396502644458023, 0.27708101792851497, 0.3442638768835935, 0.6288601643868668, 0.8756659306799478, 0.5311102437651526, 0.6288601643868668, 0.3442638768835935, 0.9143144343572065, 0.3442638768835935, 0.45137778369894715, 0.3442638768835935, 0.20313970224966807, 0.3442638768835935, 0.5311102437651526, 0.7852085773035101, 0.7852085773035101, 0.5790091193431627, 0.7852085773035101, 0.7852085773035101, 0.7654976731712972, 0.6032867467249987, 0.3442638768835935, 0.6288601643868668, 0.3442638768835935, 0.4146509197520497, 0.5311102437651526, 0.4411362862758699, 0.5311102437651526, 0.3442638768835935, 0.3442638768835935, 0.3442638768835935, 0.3442638768835935, 0.3442638768835935, 0.20313970224966807, 0.5311102437651526, 0.19651309882602427, 0.19651309882602427, 0.5311102437651526, 0.20313970224966807, 0.7852085773035101, 0.45137778369894715, 0.502845130519293, 0.20313970224966807, 0.7852085773035101, 0.3442638768835935, 0.20313970224966807, 0.9143144343572065, 0.7852085773035101]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.148\n",
      "(*) epoch 2, cost 1.358\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 8\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.403\n",
      "(*) epoch 2, cost 5.038\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.685988676585241, 3.0011274070495544, 4.450680599567772, 4.450680599567772, 3.0011274070495544, 3.0011274070495544, 3.0011274070495544, 3.0011274070495544, 3.0011274070495544, 5.15402056488938, 4.450680599567772, 3.0011274070495544, 3.0011274070495544, 6.5717609499117895, 4.797632137527891, 2.685988676585241, 3.348078945009674, 3.0011274070495544, 3.0011274070495544, 4.450680599567772, 3.0011274070495544, 3.0011274070495544, 3.0011274070495544, 4.482493407063578, 3.0011274070495544, 3.032940214545362, 3.0011274070495544, 3.348078945009674, 3.348078945009674, 5.469159295353693, 2.685988676585241, 3.348078945009674, 3.032940214545362, 5.122207757393573, 4.482493407063578, 3.0011274070495544, 4.482493407063578, 3.348078945009674, 4.450680599567772, 5.122207757393573, 3.0011274070495544, 5.469159295353693, 3.0011274070495544, 3.0011274070495544, 3.348078945009674, 4.450680599567772, 4.450680599567772, 1.065256062680366, 3.0011274070495544, 5.122207757393573]\n",
      "all_sum after preprocessing is: [-0.95907851 -0.64704596  0.78821966  0.78821966 -0.64704596 -0.64704596\n",
      " -0.64704596 -0.64704596 -0.64704596  1.48462712  0.78821966 -0.64704596\n",
      " -0.64704596  2.88839349  1.13175145 -0.95907851 -0.30351416 -0.64704596\n",
      " -0.64704596  0.78821966 -0.64704596 -0.64704596 -0.64704596  0.8197189\n",
      " -0.64704596 -0.61554671 -0.64704596 -0.30351416 -0.30351416  1.79665967\n",
      " -0.95907851 -0.30351416 -0.61554671  1.45312788  0.8197189  -0.64704596\n",
      "  0.8197189  -0.30351416  0.78821966  1.45312788 -0.64704596  1.79665967\n",
      " -0.64704596 -0.64704596 -0.30351416  0.78821966  0.78821966 -2.56383631\n",
      " -0.64704596  1.45312788]\n",
      "P is: [0.2770627307056582, 0.34365553278438254, 0.687448928418531, 0.687448928418531, 0.34365553278438254, 0.34365553278438254, 0.34365553278438254, 0.34365553278438254, 0.34365553278438254, 0.8152704630991887, 0.687448928418531, 0.34365553278438254, 0.34365553278438254, 0.9472696943578308, 0.7561619784811395, 0.2770627307056582, 0.42469864308003696, 0.34365553278438254, 0.34365553278438254, 0.687448928418531, 0.34365553278438254, 0.34365553278438254, 0.34365553278438254, 0.6941766669558513, 0.34365553278438254, 0.3507949583916115, 0.34365553278438254, 0.42469864308003696, 0.42469864308003696, 0.8577418328565154, 0.2770627307056582, 0.42469864308003696, 0.3507949583916115, 0.8104793508660453, 0.6941766669558513, 0.34365553278438254, 0.6941766669558513, 0.42469864308003696, 0.687448928418531, 0.8104793508660453, 0.34365553278438254, 0.8577418328565154, 0.34365553278438254, 0.34365553278438254, 0.42469864308003696, 0.687448928418531, 0.687448928418531, 0.07150243154868946, 0.34365553278438254, 0.8104793508660453]\n",
      "all_sum before preprocessing is: [1.1689175418691822, 0.9155903786820998, 0.8156543866983444, 0.8156543866983444, 0.9155903786820998, 0.8636377886919734, 0.9155903786820998, 0.8156543866983444, 0.9155903786820998, 0.8156543866983444, 0.9155903786820998, 0.9155903786820998, 0.8156543866983444, 1.216900943862811, 0.8156543866983444, 0.9155903786820998, 0.9155903786820998, 0.9155903786820998, 0.8156543866983444, 0.9155903786820998, 0.8156543866983444, 0.9155903786820998, 0.9155903786820998, 0.9155903786820998, 0.9155903786820998, 0.9155903786820998, 1.1602722646731976, 0.527741520236402, 0.9155903786820998, 0.8156543866983444, 0.9155903786820998, 1.2688535338529374, 0.8156543866983444, 0.8156543866983444, 0.8156543866983444, 0.9155903786820998, 0.527741520236402, 0.9155903786820998, 0.9155903786820998, 0.8156543866983444, 0.9155903786820998, 0.9155903786820998, 0.8636377886919734, 0.9155903786820998, 0.9155903786820998, 0.9155903786820998, 0.8156543866983444, 1.1689175418691822, 0.9155903786820998, 0.9155903786820998]\n",
      "all_sum after preprocessing is: [ 2.09583638  0.13510735 -0.63838807 -0.63838807  0.13510735 -0.26700093\n",
      "  0.13510735 -0.63838807  0.13510735 -0.63838807  0.13510735  0.13510735\n",
      " -0.63838807  2.46722352 -0.63838807  0.13510735  0.13510735  0.13510735\n",
      " -0.63838807  0.13510735 -0.63838807  0.13510735  0.13510735  0.13510735\n",
      "  0.13510735  0.13510735  2.02892273 -2.86680727  0.13510735 -0.63838807\n",
      "  0.13510735  2.86933181 -0.63838807 -0.63838807 -0.63838807  0.13510735\n",
      " -2.86680727  0.13510735  0.13510735 -0.63838807  0.13510735  0.13510735\n",
      " -0.26700093  0.13510735  0.13510735  0.13510735 -0.63838807  2.09583638\n",
      "  0.13510735  0.13510735]\n",
      "P is: [0.8904978382798857, 0.5337255517304839, 0.3456110097132073, 0.3456110097132073, 0.5337255517304839, 0.43364350924183326, 0.5337255517304839, 0.3456110097132073, 0.5337255517304839, 0.3456110097132073, 0.5337255517304839, 0.5337255517304839, 0.3456110097132073, 0.9218118849742196, 0.3456110097132073, 0.5337255517304839, 0.5337255517304839, 0.5337255517304839, 0.3456110097132073, 0.5337255517304839, 0.3456110097132073, 0.5337255517304839, 0.5337255517304839, 0.5337255517304839, 0.5337255517304839, 0.5337255517304839, 0.883800491177764, 0.05381900227754708, 0.5337255517304839, 0.3456110097132073, 0.5337255517304839, 0.9463094085431578, 0.3456110097132073, 0.3456110097132073, 0.3456110097132073, 0.5337255517304839, 0.05381900227754708, 0.5337255517304839, 0.5337255517304839, 0.3456110097132073, 0.5337255517304839, 0.5337255517304839, 0.43364350924183326, 0.5337255517304839, 0.5337255517304839, 0.5337255517304839, 0.3456110097132073, 0.8904978382798857, 0.5337255517304839, 0.5337255517304839]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 6.482\n",
      "(*) epoch 2, cost 4.220\n",
      "(*) epoch 3, cost 3.488\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.160\n",
      "(*) epoch 2, cost 2.657\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [6.048145754795556, 6.048145754795556, 3.646620995935817, 3.062299582601552, 3.062299582601552, 3.062299582601552, 6.63246716812982, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552, 6.63246716812982, 3.062299582601552, 3.062299582601552, 6.048145754795556, 3.062299582601552, 3.062299582601552, 3.062299582601552, 6.048145754795556, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552, 6.048145754795556, 3.062299582601552, 3.646620995935817, 3.062299582601552, 6.048145754795556, 3.062299582601552, 6.048145754795556, 6.048145754795556, 6.63246716812982, 1.2904682941355214, 3.062299582601552, 3.646620995935817, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552, 6.048145754795556, 6.048145754795556, 3.646620995935817, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552, 3.062299582601552]\n",
      "all_sum after preprocessing is: [ 1.54467642  1.54467642 -0.17021404 -0.58746863 -0.58746863 -0.58746863\n",
      "  1.96193101 -0.58746863 -0.58746863 -0.58746863 -0.58746863  1.96193101\n",
      " -0.58746863 -0.58746863  1.54467642 -0.58746863 -0.58746863 -0.58746863\n",
      "  1.54467642 -0.58746863 -0.58746863 -0.58746863 -0.58746863 -0.58746863\n",
      " -0.58746863  1.54467642 -0.58746863 -0.17021404 -0.58746863  1.54467642\n",
      " -0.58746863  1.54467642  1.54467642  1.96193101 -1.85270504 -0.58746863\n",
      " -0.17021404 -0.58746863 -0.58746863 -0.58746863 -0.58746863 -0.58746863\n",
      "  1.54467642  1.54467642 -0.17021404 -0.58746863 -0.58746863 -0.58746863\n",
      " -0.58746863 -0.58746863]\n",
      "P is: [0.8241435114539728, 0.8241435114539728, 0.45754893434582916, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.876741779970681, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.876741779970681, 0.3572158794746344, 0.3572158794746344, 0.8241435114539728, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.8241435114539728, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.8241435114539728, 0.3572158794746344, 0.45754893434582916, 0.3572158794746344, 0.8241435114539728, 0.3572158794746344, 0.8241435114539728, 0.8241435114539728, 0.876741779970681, 0.13555560674810938, 0.3572158794746344, 0.45754893434582916, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.8241435114539728, 0.8241435114539728, 0.45754893434582916, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344, 0.3572158794746344]\n",
      "all_sum before preprocessing is: [1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 2.2762237743737623, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 2.2762237743737623, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 2.2762237743737623, 2.2762237743737623, 1.4751572347024513, 1.4751572347024513, 1.6280387952473856, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 2.2762237743737623, 1.4751572347024513, 2.2762237743737623, 1.4751572347024513, 1.4751572347024513, 2.2762237743737623, 2.2762237743737623, 2.2762237743737623, 2.2762237743737623, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513, 1.4751572347024513]\n",
      "all_sum after preprocessing is: [-0.51084172 -0.51084172 -0.51084172 -0.51084172 -0.51084172 -0.51084172\n",
      " -0.51084172 -0.51084172 -0.51084172  1.99553332 -0.51084172 -0.51084172\n",
      " -0.51084172 -0.51084172  1.99553332 -0.51084172 -0.51084172 -0.51084172\n",
      "  1.99553332  1.99553332 -0.51084172 -0.51084172 -0.03250626 -0.51084172\n",
      " -0.51084172 -0.51084172  1.99553332 -0.51084172  1.99553332 -0.51084172\n",
      " -0.51084172  1.99553332  1.99553332  1.99553332  1.99553332 -0.51084172\n",
      " -0.51084172 -0.51084172 -0.51084172 -0.51084172 -0.51084172 -0.51084172\n",
      " -0.51084172 -0.51084172 -0.51084172 -0.51084172 -0.51084172 -0.51084172\n",
      " -0.51084172 -0.51084172]\n",
      "P is: [0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.8803273068167777, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.8803273068167777, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.8803273068167777, 0.8803273068167777, 0.3749962284005376, 0.3749962284005376, 0.49187414990454487, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.8803273068167777, 0.3749962284005376, 0.8803273068167777, 0.3749962284005376, 0.3749962284005376, 0.8803273068167777, 0.8803273068167777, 0.8803273068167777, 0.8803273068167777, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376, 0.3749962284005376]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.591\n",
      "(*) epoch 2, cost 3.049\n",
      "(*) epoch 3, cost 2.290\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.246\n",
      "(*) epoch 2, cost 1.486\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.6768883492124904, 1.796567234717549, 1.796567234717549, 1.796567234717549, 1.6768883492124904, 1.796567234717549, 1.6768883492124904, 1.2749648077602138, 1.6768883492124904, 1.6768883492124904, 1.6768883492124904, 1.1552859222551553, 1.1552859222551553, 1.796567234717549, 1.1552859222551553, 1.796567234717549, 1.1552859222551553, 1.1552859222551553, 1.6768883492124904, 1.796567234717549, 1.796567234717549, 2.712369063427123, 1.6768883492124904, 1.6768883492124904, 1.6768883492124904, 1.6768883492124904, 1.796567234717549, 1.2749648077602138, 1.6768883492124904, 2.4635752949162475, 1.6768883492124904, 1.796567234717549, 1.2749648077602138, 1.796567234717549, 1.6768883492124904, 1.2749648077602138, 1.6768883492124904, 1.6768883492124904, 1.2749648077602138, 1.796567234717549, 1.1552859222551553, 1.1552859222551553, 1.2749648077602138, 1.796567234717549, 1.6768883492124904, 1.796567234717549, 1.796567234717549, 1.2749648077602138, 1.796567234717549, 1.796567234717549]\n",
      "all_sum after preprocessing is: [ 0.16775366  0.55266122  0.55266122  0.55266122  0.16775366  0.55266122\n",
      "  0.16775366 -1.1249005   0.16775366  0.16775366  0.16775366 -1.50980806\n",
      " -1.50980806  0.55266122 -1.50980806  0.55266122 -1.50980806 -1.50980806\n",
      "  0.16775366  0.55266122  0.55266122  3.49803496  0.16775366  0.16775366\n",
      "  0.16775366  0.16775366  0.55266122 -1.1249005   0.16775366  2.69787207\n",
      "  0.16775366  0.55266122 -1.1249005   0.55266122  0.16775366 -1.1249005\n",
      "  0.16775366  0.16775366 -1.1249005   0.55266122 -1.50980806 -1.50980806\n",
      " -1.1249005   0.55266122  0.16775366  0.55266122  0.55266122 -1.1249005\n",
      "  0.55266122  0.55266122]\n",
      "P is: [0.5418403406059077, 0.6347527932108582, 0.6347527932108582, 0.6347527932108582, 0.5418403406059077, 0.6347527932108582, 0.5418403406059077, 0.24510342265856094, 0.5418403406059077, 0.5418403406059077, 0.5418403406059077, 0.18096724032576034, 0.18096724032576034, 0.6347527932108582, 0.18096724032576034, 0.6347527932108582, 0.18096724032576034, 0.18096724032576034, 0.5418403406059077, 0.6347527932108582, 0.6347527932108582, 0.9706318060718656, 0.5418403406059077, 0.5418403406059077, 0.5418403406059077, 0.5418403406059077, 0.6347527932108582, 0.24510342265856094, 0.5418403406059077, 0.9369009629933512, 0.5418403406059077, 0.6347527932108582, 0.24510342265856094, 0.6347527932108582, 0.5418403406059077, 0.24510342265856094, 0.5418403406059077, 0.5418403406059077, 0.24510342265856094, 0.6347527932108582, 0.18096724032576034, 0.18096724032576034, 0.24510342265856094, 0.6347527932108582, 0.5418403406059077, 0.6347527932108582, 0.6347527932108582, 0.24510342265856094, 0.6347527932108582, 0.6347527932108582]\n",
      "all_sum before preprocessing is: [3.2958221215533885, 3.610127444898257, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 2.9035976775960215, 1.4683622048352394, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 3.747634910220371, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 1.4683622048352394, 1.920174993502222, 3.2958221215533885, 3.5816706160548355, 2.451784888929039, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 1.4683622048352394, 3.2958221215533885, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 1.4683622048352394, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 3.2958221215533885, 2.451784888929039]\n",
      "all_sum after preprocessing is: [ 0.57668992  0.97937454 -1.76463218  0.57668992  0.57668992 -1.76463218\n",
      "  0.57668992  0.57668992  0.57668992  0.07417615 -1.76463218 -1.76463218\n",
      "  0.57668992  0.57668992  1.15554763 -1.76463218  0.57668992  0.57668992\n",
      "  0.57668992 -1.76463218  0.57668992  0.57668992 -1.76463218  0.57668992\n",
      "  0.57668992 -1.76463218 -1.18577447  0.57668992  0.94291595 -0.50468156\n",
      "  0.57668992  0.57668992  0.57668992  0.57668992 -1.76463218  0.57668992\n",
      " -1.76463218  0.57668992  0.57668992  0.57668992  0.57668992  0.57668992\n",
      " -1.76463218  0.57668992  0.57668992  0.57668992  0.57668992  0.57668992\n",
      "  0.57668992 -0.50468156]\n",
      "P is: [0.6403054011884467, 0.7269840929991904, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.5185355406098864, 0.146211140091105, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.7605227549314285, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.146211140091105, 0.23401551980352275, 0.6403054011884467, 0.7196882895039822, 0.37644111747581604, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.146211140091105, 0.6403054011884467, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.146211140091105, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.6403054011884467, 0.37644111747581604]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.153\n",
      "(*) epoch 2, cost 2.174\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 6.011\n",
      "(*) epoch 2, cost 2.907\n",
      "(*) epoch 3, cost 2.157\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.533654780750994, 2.704033483254406, 2.533654780750994, 2.533654780750994, 2.450746880051499, 2.450746880051499, 2.450746880051499, 2.450746880051499, 2.533654780750994, 2.450746880051499, 2.533654780750994, 2.450746880051499, 2.533654780750994, 2.533654780750994, 2.9705105308722453, 2.533654780750994, 2.450746880051499, 2.533654780750994, 2.450746880051499, 2.533654780750994, 2.450746880051499, 2.450746880051499, 2.533654780750994, 1.9009036585923351, 2.533654780750994, 2.450746880051499, 2.533654780750994, 2.450746880051499, 2.450746880051499, 2.533654780750994, 2.533654780750994, 2.533654780750994, 1.9009036585923351, 2.533654780750994, 2.450746880051499, 2.450746880051499, 2.533654780750994, 2.533654780750994, 2.450746880051499, 2.450746880051499, 2.450746880051499, 3.05341843157174, 1.98381155929183, 3.05341843157174, 3.3769644459617774, 2.533654780750994, 2.533654780750994, 2.533654780750994, 2.450746880051499, 2.533654780750994]\n",
      "all_sum after preprocessing is: [ 0.0776659   0.81238333  0.0776659   0.0776659  -0.2798546  -0.2798546\n",
      " -0.2798546  -0.2798546   0.0776659  -0.2798546   0.0776659  -0.2798546\n",
      "  0.0776659   0.0776659   1.9615019   0.0776659  -0.2798546   0.0776659\n",
      " -0.2798546   0.0776659  -0.2798546  -0.2798546   0.0776659  -2.65092206\n",
      "  0.0776659  -0.2798546   0.0776659  -0.2798546  -0.2798546   0.0776659\n",
      "  0.0776659   0.0776659  -2.65092206  0.0776659  -0.2798546  -0.2798546\n",
      "  0.0776659   0.0776659  -0.2798546  -0.2798546  -0.2798546   2.31902241\n",
      " -2.29340156  2.31902241  3.71423725  0.0776659   0.0776659   0.0776659\n",
      " -0.2798546   0.0776659 ]\n",
      "P is: [0.5194067217801278, 0.6926171451047096, 0.5194067217801278, 0.5194067217801278, 0.43048942313401856, 0.43048942313401856, 0.43048942313401856, 0.43048942313401856, 0.5194067217801278, 0.43048942313401856, 0.5194067217801278, 0.43048942313401856, 0.5194067217801278, 0.5194067217801278, 0.8766954007219817, 0.5194067217801278, 0.43048942313401856, 0.5194067217801278, 0.43048942313401856, 0.5194067217801278, 0.43048942313401856, 0.43048942313401856, 0.5194067217801278, 0.06593220155897453, 0.5194067217801278, 0.43048942313401856, 0.5194067217801278, 0.43048942313401856, 0.43048942313401856, 0.5194067217801278, 0.5194067217801278, 0.5194067217801278, 0.06593220155897453, 0.5194067217801278, 0.43048942313401856, 0.43048942313401856, 0.5194067217801278, 0.5194067217801278, 0.43048942313401856, 0.43048942313401856, 0.43048942313401856, 0.910440260744052, 0.09167091764124029, 0.910440260744052, 0.976205931970906, 0.5194067217801278, 0.5194067217801278, 0.5194067217801278, 0.43048942313401856, 0.5194067217801278]\n",
      "all_sum before preprocessing is: [1.6765421355411902, 1.6765421355411902, 1.5011003895450874, 0.1619974059295416, 0.33743915192564455, 0.1619974059295416, 1.6765421355411902, 0.33743915192564455, 0.33743915192564455, 0.33743915192564455, 1.6765421355411902, 0.1619974059295416, 1.6765421355411902, 1.6765421355411902, 1.5011003895450874, 0.33743915192564455, 1.5011003895450874, 0.1619974059295416, 1.5011003895450874, 0.1619974059295416, 1.6765421355411902, 0.33743915192564455, 0.33743915192564455, 1.5011003895450874, 1.6765421355411902, 1.5011003895450874, 1.5011003895450874, 0.33743915192564455, 1.6765421355411902, 1.6765421355411902, 1.624522481153807, 0.33743915192564455, 1.6765421355411902, 1.6765421355411902, 1.6765421355411902, 1.5011003895450874, 1.5011003895450874, 0.1619974059295416, 0.33743915192564455, 1.6765421355411902, 0.33743915192564455, 1.6765421355411902, 1.6765421355411902, 1.6765421355411902, 0.33743915192564455, 0.1619974059295416, 1.5011003895450874, 1.6765421355411902, 1.6765421355411902, 0.1619974059295416]\n",
      "all_sum after preprocessing is: [ 0.90043032  0.90043032  0.63707192 -1.37307695 -1.10971854 -1.37307695\n",
      "  0.90043032 -1.10971854 -1.10971854 -1.10971854  0.90043032 -1.37307695\n",
      "  0.90043032  0.90043032  0.63707192 -1.10971854  0.63707192 -1.37307695\n",
      "  0.63707192 -1.37307695  0.90043032 -1.10971854 -1.10971854  0.63707192\n",
      "  0.90043032  0.63707192  0.63707192 -1.10971854  0.90043032  0.90043032\n",
      "  0.82234279 -1.10971854  0.90043032  0.90043032  0.90043032  0.63707192\n",
      "  0.63707192 -1.37307695 -1.10971854  0.90043032 -1.10971854  0.90043032\n",
      "  0.90043032  0.90043032 -1.10971854 -1.37307695  0.63707192  0.90043032\n",
      "  0.90043032 -1.37307695]\n",
      "P is: [0.7110379263153862, 0.7110379263153862, 0.6540912641045442, 0.20212317373756822, 0.24792336437842225, 0.20212317373756822, 0.7110379263153862, 0.24792336437842225, 0.24792336437842225, 0.24792336437842225, 0.7110379263153862, 0.20212317373756822, 0.7110379263153862, 0.7110379263153862, 0.6540912641045442, 0.24792336437842225, 0.6540912641045442, 0.20212317373756822, 0.6540912641045442, 0.20212317373756822, 0.7110379263153862, 0.24792336437842225, 0.24792336437842225, 0.6540912641045442, 0.7110379263153862, 0.6540912641045442, 0.6540912641045442, 0.24792336437842225, 0.7110379263153862, 0.7110379263153862, 0.6947334230361815, 0.24792336437842225, 0.7110379263153862, 0.7110379263153862, 0.7110379263153862, 0.6540912641045442, 0.6540912641045442, 0.20212317373756822, 0.24792336437842225, 0.7110379263153862, 0.24792336437842225, 0.7110379263153862, 0.7110379263153862, 0.7110379263153862, 0.24792336437842225, 0.20212317373756822, 0.6540912641045442, 0.7110379263153862, 0.7110379263153862, 0.20212317373756822]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.101\n",
      "(*) epoch 2, cost 1.836\n",
      "(*) epoch 3, cost 1.646\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.525\n",
      "(*) epoch 2, cost 1.830\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.3432072889043734, 3.851301801775059, 3.1866935770154727, 3.851301801775059, 3.851301801775059, 3.3432072889043734, 3.851301801775059, 3.3432072889043734, 3.851301801775059, 3.851301801775059, 3.851301801775059, 3.851301801775059, 3.1866935770154727, 3.851301801775059, 5.048961315530127, 2.6785990641447874, 3.1866935770154727, 4.698907407436914, 3.851301801775059, 4.698907407436914, 3.3432072889043734, 3.1866935770154727, 3.1866935770154727, 4.698907407436914, 3.851301801775059, 3.851301801775059, 3.851301801775059, 3.851301801775059, 2.6785990641447874, 3.1866935770154727, 3.851301801775059, 2.160741674363259, 2.6785990641447874, 3.851301801775059, 3.851301801775059, 3.3432072889043734, 3.851301801775059, 2.3691463392967718, 4.698907407436914, 3.526204669806641, 3.851301801775059, 4.046792924190312, 3.3432072889043734, 2.525660051185672, 3.1866935770154727, 3.008347280025113, 2.6785990641447874, 3.851301801775059, 3.3432072889043734, 3.1866935770154727]\n",
      "all_sum after preprocessing is: [-0.35890753  0.47320787 -0.61523281  0.47320787  0.47320787 -0.35890753\n",
      "  0.47320787 -0.35890753  0.47320787  0.47320787  0.47320787  0.47320787\n",
      " -0.61523281  0.47320787  2.43463611 -1.44734821 -0.61523281  1.86134661\n",
      "  0.47320787  1.86134661 -0.35890753 -0.61523281 -0.61523281  1.86134661\n",
      "  0.47320787  0.47320787  0.47320787  0.47320787 -1.44734821 -0.61523281\n",
      "  0.47320787 -2.29545244 -1.44734821  0.47320787  0.47320787 -0.35890753\n",
      "  0.47320787 -1.95414442  1.86134661 -0.05920947  0.47320787  0.79336715\n",
      " -0.35890753 -1.69781914 -0.61523281 -0.9073137  -1.44734821  0.47320787\n",
      " -0.35890753 -0.61523281]\n",
      "P is: [0.4112240488896364, 0.6161427351960818, 0.35086644968135283, 0.6161427351960818, 0.6161427351960818, 0.4112240488896364, 0.6161427351960818, 0.4112240488896364, 0.6161427351960818, 0.6161427351960818, 0.6161427351960818, 0.6161427351960818, 0.35086644968135283, 0.6161427351960818, 0.9194306344938867, 0.1904100151613844, 0.35086644968135283, 0.8654538292669739, 0.6161427351960818, 0.8654538292669739, 0.4112240488896364, 0.35086644968135283, 0.35086644968135283, 0.8654538292669739, 0.6161427351960818, 0.6161427351960818, 0.6161427351960818, 0.6161427351960818, 0.1904100151613844, 0.35086644968135283, 0.6161427351960818, 0.09150028882552956, 0.1904100151613844, 0.6161427351960818, 0.6161427351960818, 0.4112240488896364, 0.6161427351960818, 0.12410215367543254, 0.8654538292669739, 0.48520195588139314, 0.6161427351960818, 0.6885538657307532, 0.4112240488896364, 0.15475031246291127, 0.35086644968135283, 0.2875498510781466, 0.1904100151613844, 0.6161427351960818, 0.4112240488896364, 0.35086644968135283]\n",
      "all_sum before preprocessing is: [2.5602479727736167, 2.5602479727736167, 1.2944767846849503, 2.5602479727736167, 3.7011792072737655, 3.874809104463109, 2.3866180755842734, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 3.874809104463109, 1.1208468874956068, 2.3866180755842734, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.3866180755842734, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.3866180755842734, 2.5602479727736167, 2.3866180755842734, 2.5602479727736167, 2.5602479727736167, 2.3866180755842734, 3.7011792072737655, 2.5602479727736167, 2.5602479727736167, 3.874809104463109, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 3.224775383850649, 2.5602479727736167, 3.874809104463109, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 2.5602479727736167, 3.874809104463109, 3.874809104463109]\n",
      "all_sum after preprocessing is: [-0.24851491 -0.24851491 -2.46787199 -0.24851491  1.75195234  2.05638867\n",
      " -0.55295125 -0.24851491 -0.24851491 -0.24851491 -0.24851491 -0.24851491\n",
      "  2.05638867 -2.77230832 -0.55295125 -0.24851491 -0.24851491 -0.24851491\n",
      " -0.24851491 -0.24851491 -0.24851491 -0.55295125 -0.24851491 -0.24851491\n",
      " -0.24851491 -0.55295125 -0.24851491 -0.55295125 -0.24851491 -0.24851491\n",
      " -0.55295125  1.75195234 -0.24851491 -0.24851491  2.05638867 -0.24851491\n",
      " -0.24851491 -0.24851491 -0.24851491 -0.24851491 -0.24851491  0.91664323\n",
      " -0.24851491  2.05638867 -0.24851491 -0.24851491 -0.24851491 -0.24851491\n",
      "  2.05638867  2.05638867]\n",
      "P is: [0.43818906323312734, 0.43818906323312734, 0.07814138943608791, 0.43818906323312734, 0.8521988796695414, 0.8865915685644343, 0.3651799683208185, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.8865915685644343, 0.058839055062688564, 0.3651799683208185, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.3651799683208185, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.3651799683208185, 0.43818906323312734, 0.3651799683208185, 0.43818906323312734, 0.43818906323312734, 0.3651799683208185, 0.8521988796695414, 0.43818906323312734, 0.43818906323312734, 0.8865915685644343, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.7143576480530116, 0.43818906323312734, 0.8865915685644343, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.43818906323312734, 0.8865915685644343, 0.8865915685644343]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.659\n",
      "(*) epoch 2, cost 3.962\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.058\n",
      "(*) epoch 2, cost 2.680\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "exception 2\n",
      "all_sum before preprocessing is: [0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.7978432743905609, 0.7978432743905609, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.7978432743905609, 0.24779359596696157, 0.7978432743905609, 0.7978432743905609, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.7978432743905609, 0.7978432743905609, 0.24779359596696157, 0.24779359596696157, 0.7978432743905609, 0.7978432743905609, 0.7978432743905609, 0.24779359596696157, 0.7978432743905609, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.24779359596696157, 0.7978432743905609]\n",
      "all_sum after preprocessing is: [-0.56195149 -0.56195149 -0.56195149 -0.56195149  1.77951304  1.77951304\n",
      " -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149\n",
      " -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149\n",
      "  1.77951304 -0.56195149  1.77951304  1.77951304 -0.56195149 -0.56195149\n",
      " -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149\n",
      "  1.77951304  1.77951304 -0.56195149 -0.56195149  1.77951304  1.77951304\n",
      "  1.77951304 -0.56195149  1.77951304 -0.56195149 -0.56195149 -0.56195149\n",
      " -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149 -0.56195149\n",
      " -0.56195149  1.77951304]\n",
      "P is: [0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.8556367260474952, 0.8556367260474952, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.8556367260474952, 0.36309604364258324, 0.8556367260474952, 0.8556367260474952, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.8556367260474952, 0.8556367260474952, 0.36309604364258324, 0.36309604364258324, 0.8556367260474952, 0.8556367260474952, 0.8556367260474952, 0.36309604364258324, 0.8556367260474952, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.36309604364258324, 0.8556367260474952]\n",
      "all_sum before preprocessing is: [1.415619690877351, 1.415619690877351, 1.415619690877351, 1.415619690877351, 1.6431733041593677, 1.5362710913041147, 2.0954376471147125, 1.415619690877351, 1.415619690877351, 1.5362710913041147, 1.415619690877351, 1.415619690877351, 1.6431733041593677, 1.6431733041593677, 1.415619690877351, 1.415619690877351, 1.415619690877351, 2.0954376471147125, 2.0954376471147125, 1.415619690877351, 1.415619690877351, 1.415619690877351, 1.415619690877351, 2.0954376471147125, 1.415619690877351, 1.415619690877351, 1.415619690877351, 1.415619690877351, 1.6431733041593677, 1.415619690877351, 1.415619690877351, 2.0954376471147125, 1.415619690877351, 1.415619690877351, 1.415619690877351, 2.012561226695258, 1.415619690877351, 1.415619690877351, 1.415619690877351, 1.415619690877351, 2.322991260396729, 1.5362710913041147, 2.0954376471147125, 2.0954376471147125, 2.0954376471147125, 1.415619690877351, 1.5362710913041147, 1.415619690877351, 2.0954376471147125, 1.415619690877351]\n",
      "all_sum after preprocessing is: [-0.63918775 -0.63918775 -0.63918775 -0.63918775  0.16747614 -0.21148578\n",
      "  1.77072609 -0.63918775 -0.63918775 -0.21148578 -0.63918775 -0.63918775\n",
      "  0.16747614  0.16747614 -0.63918775 -0.63918775 -0.63918775  1.77072609\n",
      "  1.77072609 -0.63918775 -0.63918775 -0.63918775 -0.63918775  1.77072609\n",
      " -0.63918775 -0.63918775 -0.63918775 -0.63918775  0.16747614 -0.63918775\n",
      " -0.63918775  1.77072609 -0.63918775 -0.63918775 -0.63918775  1.47693415\n",
      " -0.63918775 -0.63918775 -0.63918775 -0.63918775  2.57738998 -0.21148578\n",
      "  1.77072609  1.77072609  1.77072609 -0.63918775 -0.21148578 -0.63918775\n",
      "  1.77072609 -0.63918775]\n",
      "P is: [0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.5417714468628577, 0.4473247386410794, 0.8545479438372783, 0.3454301718521109, 0.3454301718521109, 0.4473247386410794, 0.3454301718521109, 0.3454301718521109, 0.5417714468628577, 0.5417714468628577, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.8545479438372783, 0.8545479438372783, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.8545479438372783, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.5417714468628577, 0.3454301718521109, 0.3454301718521109, 0.8545479438372783, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.8141090558523223, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.3454301718521109, 0.9293921855908344, 0.4473247386410794, 0.8545479438372783, 0.8545479438372783, 0.8545479438372783, 0.3454301718521109, 0.4473247386410794, 0.3454301718521109, 0.8545479438372783, 0.3454301718521109]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 2\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.531\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.121\n",
      "(*) epoch 2, cost 2.500\n",
      "(*) epoch 3, cost 1.970\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.7817923696099518, 1.010375514102087, 0.7817923696099518, 0.7817923696099518, 1.6217290761526908, 1.4430913766052245, 1.4430913766052245, 1.6716745210973596, 0.7817923696099518, 1.010375514102087, 1.4430913766052245, 0.7817923696099518, 1.6716745210973596, 1.4430913766052245, 0.7817923696099518, 1.4430913766052245, 0.7817923696099518, 1.3931459316605557, 1.665396128796216, 0.8254594222534771, 0.7817923696099518, 2.0544449386558283, 0.8254594222534771, 0.7817923696099518, 1.4430913766052245, 0.7817923696099518, 0.7817923696099518, 2.0544449386558283, 0.7817923696099518, 2.2830280831479635, 0.7817923696099518, 1.010375514102087, 1.010375514102087, 0.7817923696099518, 1.010375514102087, 1.6217290761526908, 1.4430913766052245, 1.4430913766052245, 1.3931459316605557, 0.7817923696099518, 1.3931459316605557, 2.0544449386558283, 1.4430913766052245, 1.6716745210973596, 1.3931459316605557, 0.7817923696099518, 2.0544449386558283, 1.010375514102087, 1.6716745210973596, 1.3931459316605557]\n",
      "all_sum after preprocessing is: [-1.06561856 -0.54025204 -1.06561856 -1.06561856  0.86485896  0.45428509\n",
      "  0.45428509  0.97965161 -1.06561856 -0.54025204  0.45428509 -1.06561856\n",
      "  0.97965161  0.45428509 -1.06561856  0.45428509 -1.06561856  0.33949244\n",
      "  0.9652216  -0.96525592 -1.06561856  1.85939609 -0.96525592 -1.06561856\n",
      "  0.45428509 -1.06561856 -1.06561856  1.85939609 -1.06561856  2.38476261\n",
      " -1.06561856 -0.54025204 -0.54025204 -1.06561856 -0.54025204  0.86485896\n",
      "  0.45428509  0.45428509  0.33949244 -1.06561856  0.33949244  1.85939609\n",
      "  0.45428509  0.97965161  0.33949244 -1.06561856  1.85939609 -0.54025204\n",
      "  0.97965161  0.33949244]\n",
      "P is: [0.2562372063760744, 0.36812895330436324, 0.2562372063760744, 0.2562372063760744, 0.7036748295549629, 0.6116575685454604, 0.6116575685454604, 0.7270390821134824, 0.2562372063760744, 0.36812895330436324, 0.6116575685454604, 0.2562372063760744, 0.7270390821134824, 0.6116575685454604, 0.2562372063760744, 0.6116575685454604, 0.2562372063760744, 0.5840672262525441, 0.7241660368854916, 0.2758271076126935, 0.2562372063760744, 0.8652265420168275, 0.2758271076126935, 0.2562372063760744, 0.6116575685454604, 0.2562372063760744, 0.2562372063760744, 0.8652265420168275, 0.2562372063760744, 0.9156579718562301, 0.2562372063760744, 0.36812895330436324, 0.36812895330436324, 0.2562372063760744, 0.36812895330436324, 0.7036748295549629, 0.6116575685454604, 0.6116575685454604, 0.5840672262525441, 0.2562372063760744, 0.5840672262525441, 0.8652265420168275, 0.6116575685454604, 0.7270390821134824, 0.5840672262525441, 0.2562372063760744, 0.8652265420168275, 0.36812895330436324, 0.7270390821134824, 0.5840672262525441]\n",
      "all_sum before preprocessing is: [1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 2.6811922604349108, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 2.5880830510924455, 1.9541827216311112, 2.6811922604349108, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 2.6811922604349108, 2.5880830510924455, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 2.6811922604349108, 1.9541827216311112, 1.9541827216311112, 1.9541827216311112, 1.1491021228467464, 1.9541827216311112, 1.9541827216311112]\n",
      "all_sum after preprocessing is: [-0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611\n",
      "  2.55252675 -0.26088611 -0.26088611 -0.26088611 -0.26088611  2.19220871\n",
      " -0.26088611  2.55252675 -0.26088611 -0.26088611 -0.26088611 -0.26088611\n",
      " -0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611\n",
      " -0.26088611  2.55252675  2.19220871 -0.26088611 -0.26088611 -0.26088611\n",
      " -0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611\n",
      " -0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611 -0.26088611\n",
      " -0.26088611  2.55252675 -0.26088611 -0.26088611 -0.26088611 -3.37642172\n",
      " -0.26088611 -0.26088611]\n",
      "P is: [0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.9277430803544287, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.8995476656295988, 0.4351458954467226, 0.9277430803544287, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.9277430803544287, 0.8995476656295988, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.9277430803544287, 0.4351458954467226, 0.4351458954467226, 0.4351458954467226, 0.033040525997308556, 0.4351458954467226, 0.4351458954467226]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.991\n",
      "(*) epoch 2, cost 1.704\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.172\n",
      "(*) epoch 2, cost 2.907\n",
      "(*) epoch 3, cost 2.268\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.8508232699064107, 2.8508232699064107, 2.1144821993669702, 2.1144821993669702, 2.8508232699064107, 0.24138280264919004, 2.9345582693209082, 2.6350631114796363, 2.1144821993669702, 2.8508232699064107, 2.1144821993669702, 2.1144821993669702, 2.1144821993669702, 2.1144821993669702, 2.1144821993669702, 0.24138280264919004, 2.1144821993669702, 0.9777238731886309, 3.670899339860349, 2.1144821993669702, 2.1144821993669702, 0.9777238731886309, 2.8508232699064107, 3.670899339860349, 0.24138280264919004, 2.8508232699064107, 2.9345582693209082, 3.670899339860349, 1.7977999431425689, 2.1144821993669702, 2.1144821993669702, 2.1144821993669702, 3.670899339860349, 2.9345582693209082, 2.8508232699064107, 2.9345582693209082, 3.670899339860349, 0.24138280264919004, 2.1144821993669702, 2.1144821993669702, 2.1144821993669702, 2.1144821993669702, 2.8508232699064107, 2.1144821993669702, 2.8508232699064107, 2.9345582693209082, 2.8508232699064107, 2.8508232699064107, 0.24138280264919004, 2.1144821993669702]\n",
      "all_sum after preprocessing is: [ 0.62840615  0.62840615 -0.18999156 -0.18999156  0.62840615 -2.27182609\n",
      "  0.72147245  0.38860204 -0.18999156  0.62840615 -0.18999156 -0.18999156\n",
      " -0.18999156 -0.18999156 -0.18999156 -2.27182609 -0.18999156 -1.45342837\n",
      "  1.53987016 -0.18999156 -0.18999156 -1.45342837  0.62840615  1.53987016\n",
      " -2.27182609  0.62840615  0.72147245  1.53987016 -0.54196437 -0.18999156\n",
      " -0.18999156 -0.18999156  1.53987016  0.72147245  0.62840615  0.72147245\n",
      "  1.53987016 -2.27182609 -0.18999156 -0.18999156 -0.18999156 -0.18999156\n",
      "  0.62840615 -0.18999156  0.62840615  0.72147245  0.62840615  0.62840615\n",
      " -2.27182609 -0.18999156]\n",
      "P is: [0.6521279748153993, 0.6521279748153993, 0.4526444728983391, 0.4526444728983391, 0.6521279748153993, 0.09348334683380799, 0.6729311771373925, 0.5959461229520349, 0.4526444728983391, 0.6521279748153993, 0.4526444728983391, 0.4526444728983391, 0.4526444728983391, 0.4526444728983391, 0.4526444728983391, 0.09348334683380799, 0.4526444728983391, 0.18947449654723786, 0.8234458495364377, 0.4526444728983391, 0.4526444728983391, 0.18947449654723786, 0.6521279748153993, 0.8234458495364377, 0.09348334683380799, 0.6521279748153993, 0.6729311771373925, 0.8234458495364377, 0.3677307384341474, 0.4526444728983391, 0.4526444728983391, 0.4526444728983391, 0.8234458495364377, 0.6729311771373925, 0.6521279748153993, 0.6729311771373925, 0.8234458495364377, 0.09348334683380799, 0.4526444728983391, 0.4526444728983391, 0.4526444728983391, 0.4526444728983391, 0.6521279748153993, 0.4526444728983391, 0.6521279748153993, 0.6729311771373925, 0.6521279748153993, 0.6521279748153993, 0.09348334683380799, 0.4526444728983391]\n",
      "all_sum before preprocessing is: [0.13050948665542117, 1.961708869949256, 1.4338779393549452, 0.13050948665542117, 1.961708869949256, 0.6583404172497319, 1.961708869949256, 1.961708869949256, 0.6583404172497319, 1.961708869949256, 0.6583404172497319, 1.961708869949256, 0.6583404172497319, 0.6583404172497319, 0.6583404172497319, 1.961708869949256, 0.6583404172497319, 0.13050948665542117, 0.6583404172497319, 0.6583404172497319, 0.6583404172497319, 0.6583404172497319, 0.13050948665542117, 0.6583404172497319, 1.961708869949256, 0.6583404172497319, 0.6583404172497319, 0.6583404172497319, 0.6583404172497319, 1.961708869949256, 1.961708869949256, 1.4338779393549452, 1.961708869949256, 1.961708869949256, 0.6583404172497319, 1.961708869949256, 1.961708869949256, 1.961708869949256, 1.961708869949256, 0.6583404172497319, 0.6583404172497319, 0.6583404172497319, 1.4338779393549452, 0.13050948665542117, 0.6583404172497319, 1.961708869949256, 0.6583404172497319, 0.6583404172497319, 1.4338779393549452, 0.6583404172497319]\n",
      "all_sum after preprocessing is: [-1.46305797  1.27011092  0.48229333 -1.46305797  1.27011092 -0.67524038\n",
      "  1.27011092  1.27011092 -0.67524038  1.27011092 -0.67524038  1.27011092\n",
      " -0.67524038 -0.67524038 -0.67524038  1.27011092 -0.67524038 -1.46305797\n",
      " -0.67524038 -0.67524038 -0.67524038 -0.67524038 -1.46305797 -0.67524038\n",
      "  1.27011092 -0.67524038 -0.67524038 -0.67524038 -0.67524038  1.27011092\n",
      "  1.27011092  0.48229333  1.27011092  1.27011092 -0.67524038  1.27011092\n",
      "  1.27011092  1.27011092  1.27011092 -0.67524038 -0.67524038 -0.67524038\n",
      "  0.48229333 -1.46305797 -0.67524038  1.27011092 -0.67524038 -0.67524038\n",
      "  0.48229333 -0.67524038]\n",
      "P is: [0.18800006264566918, 0.7807617350463535, 0.6182892658871668, 0.18800006264566918, 0.7807617350463535, 0.3373244267236329, 0.7807617350463535, 0.7807617350463535, 0.3373244267236329, 0.7807617350463535, 0.3373244267236329, 0.7807617350463535, 0.3373244267236329, 0.3373244267236329, 0.3373244267236329, 0.7807617350463535, 0.3373244267236329, 0.18800006264566918, 0.3373244267236329, 0.3373244267236329, 0.3373244267236329, 0.3373244267236329, 0.18800006264566918, 0.3373244267236329, 0.7807617350463535, 0.3373244267236329, 0.3373244267236329, 0.3373244267236329, 0.3373244267236329, 0.7807617350463535, 0.7807617350463535, 0.6182892658871668, 0.7807617350463535, 0.7807617350463535, 0.3373244267236329, 0.7807617350463535, 0.7807617350463535, 0.7807617350463535, 0.7807617350463535, 0.3373244267236329, 0.3373244267236329, 0.3373244267236329, 0.6182892658871668, 0.18800006264566918, 0.3373244267236329, 0.7807617350463535, 0.3373244267236329, 0.3373244267236329, 0.6182892658871668, 0.3373244267236329]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.665\n",
      "(*) epoch 2, cost 2.624\n",
      "(*) epoch 3, cost 2.132\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.050\n",
      "(*) epoch 2, cost 1.650\n",
      "(*) epoch 3, cost 1.255\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [3.7514938796340846, 4.047479562121921, 1.4078279763060708, 1.4078279763060708, 1.111842293818235, 3.800377327272065, 1.111842293818235, 1.4078279763060708, 4.047479562121921, 1.111842293818235, 1.4567114239440508, 1.4078279763060708, 1.4078279763060708, 1.6851255683650415, 1.4078279763060708, 1.111842293818235, 1.5064224879432733, 1.4078279763060708, 1.4078279763060708, 1.4078279763060708, 1.4078279763060708, 4.047479562121921, 1.4078279763060708, 1.4078279763060708, 1.4078279763060708, 1.4078279763060708, 1.4567114239440508, 4.047479562121921, 2.048593815603169, 4.047479562121921, 1.4567114239440508, 4.688245401419019, 4.096363009759901, 1.4078279763060708, 4.047479562121921, 1.111842293818235, 1.4567114239440508, 4.16048203226764, 2.048593815603169, 1.4078279763060708, 1.4078279763060708, 1.4567114239440508, 1.4078279763060708, 1.4078279763060708, 1.4078279763060708, 1.1607257414562153, 4.047479562121921, 1.4078279763060708, 1.4629677095468323, 1.4078279763060708]\n",
      "all_sum after preprocessing is: [ 1.47675940e+00  1.73382251e+00 -5.58710848e-01 -5.58710848e-01\n",
      " -8.15773960e-01  1.51921460e+00 -8.15773960e-01 -5.58710848e-01\n",
      "  1.73382251e+00 -8.15773960e-01 -5.16255649e-01 -5.58710848e-01\n",
      " -5.58710848e-01 -3.17878314e-01 -5.58710848e-01 -8.15773960e-01\n",
      " -4.73081666e-01 -5.58710848e-01 -5.58710848e-01 -5.58710848e-01\n",
      " -5.58710848e-01  1.73382251e+00 -5.58710848e-01 -5.58710848e-01\n",
      " -5.58710848e-01 -5.58710848e-01 -5.16255649e-01  1.73382251e+00\n",
      " -2.20669847e-03  1.73382251e+00 -5.16255649e-01  2.29032666e+00\n",
      "  1.77627771e+00 -5.58710848e-01  1.73382251e+00 -8.15773960e-01\n",
      " -5.16255649e-01  1.83196498e+00 -2.20669847e-03 -5.58710848e-01\n",
      " -5.58710848e-01 -5.16255649e-01 -5.58710848e-01 -5.58710848e-01\n",
      " -5.58710848e-01 -7.73318760e-01  1.73382251e+00 -5.58710848e-01\n",
      " -5.10822074e-01 -5.58710848e-01]\n",
      "P is: [0.8140826078596812, 0.8499007083680781, 0.3638457970298414, 0.3638457970298414, 0.30666146655093734, 0.8204227969361265, 0.30666146655093734, 0.3638457970298414, 0.8499007083680781, 0.30666146655093734, 0.3737282042584082, 0.3638457970298414, 0.3638457970298414, 0.42119290576298435, 0.3638457970298414, 0.30666146655093734, 0.3838871144750161, 0.3638457970298414, 0.3638457970298414, 0.3638457970298414, 0.3638457970298414, 0.8499007083680781, 0.3638457970298414, 0.3638457970298414, 0.3638457970298414, 0.3638457970298414, 0.3737282042584082, 0.8499007083680781, 0.4994483256063905, 0.8499007083680781, 0.3737282042584082, 0.9080727221287711, 0.8552366295649354, 0.3638457970298414, 0.8499007083680781, 0.30666146655093734, 0.3737282042584082, 0.8619956457157408, 0.4994483256063905, 0.3638457970298414, 0.3638457970298414, 0.3737282042584082, 0.3638457970298414, 0.3638457970298414, 0.3638457970298414, 0.31576162937656616, 0.8499007083680781, 0.3638457970298414, 0.37500083191259354, 0.3638457970298414]\n",
      "all_sum before preprocessing is: [2.2210238360222796, 2.591629687681527, 2.591629687681527, 2.591629687681527, 2.591629687681527, 2.591629687681527, 2.591629687681527, 2.2210238360222796, 2.591629687681527, 2.2210238360222796, 2.591629687681527, 1.063902203878342, 2.591629687681527, 1.063902203878342, 2.591629687681527, 2.2210238360222796, 1.063902203878342, 2.2210238360222796, 2.2210238360222796, 2.591629687681527, 2.591629687681527, 1.063902203878342, 2.591629687681527, 1.063902203878342, 1.063902203878342, 1.4345080555375895, 2.591629687681527, 2.591629687681527, 2.2210238360222796, 1.4345080555375895, 2.591629687681527, 2.591629687681527, 1.4345080555375895, 2.2210238360222796, 2.2210238360222796, 1.4345080555375895, 2.2210238360222796, 1.063902203878342, 2.2210238360222796, 2.591629687681527, 2.2210238360222796, 2.2210238360222796, 2.2210238360222796, 2.591629687681527, 1.4345080555375895, 2.591629687681527, 2.591629687681527, 1.063902203878342, 1.4345080555375895, 2.591629687681527]\n",
      "all_sum after preprocessing is: [ 0.20110316  0.84109412  0.84109412  0.84109412  0.84109412  0.84109412\n",
      "  0.84109412  0.20110316  0.84109412  0.20110316  0.84109412 -1.79710434\n",
      "  0.84109412 -1.79710434  0.84109412  0.20110316 -1.79710434  0.20110316\n",
      "  0.20110316  0.84109412  0.84109412 -1.79710434  0.84109412 -1.79710434\n",
      " -1.79710434 -1.15711337  0.84109412  0.84109412  0.20110316 -1.15711337\n",
      "  0.84109412  0.84109412 -1.15711337  0.20110316  0.20110316 -1.15711337\n",
      "  0.20110316 -1.79710434  0.20110316  0.84109412  0.20110316  0.20110316\n",
      "  0.20110316  0.84109412 -1.15711337  0.84109412  0.84109412 -1.79710434\n",
      " -1.15711337  0.84109412]\n",
      "P is: [0.5501070321653267, 0.6986956010319888, 0.6986956010319888, 0.6986956010319888, 0.6986956010319888, 0.6986956010319888, 0.6986956010319888, 0.5501070321653267, 0.6986956010319888, 0.5501070321653267, 0.6986956010319888, 0.14220391767262772, 0.6986956010319888, 0.14220391767262772, 0.6986956010319888, 0.5501070321653267, 0.14220391767262772, 0.5501070321653267, 0.5501070321653267, 0.6986956010319888, 0.6986956010319888, 0.14220391767262772, 0.6986956010319888, 0.14220391767262772, 0.14220391767262772, 0.2391921961370957, 0.6986956010319888, 0.6986956010319888, 0.5501070321653267, 0.2391921961370957, 0.6986956010319888, 0.6986956010319888, 0.2391921961370957, 0.5501070321653267, 0.5501070321653267, 0.2391921961370957, 0.5501070321653267, 0.14220391767262772, 0.5501070321653267, 0.6986956010319888, 0.5501070321653267, 0.5501070321653267, 0.5501070321653267, 0.6986956010319888, 0.2391921961370957, 0.6986956010319888, 0.6986956010319888, 0.14220391767262772, 0.2391921961370957, 0.6986956010319888]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.643\n",
      "(*) epoch 2, cost 2.378\n",
      "(*) epoch 3, cost 1.635\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 4.908\n",
      "(*) epoch 2, cost 2.214\n",
      "(*) epoch 3, cost 1.421\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.17 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [4.02483841129514, 3.4019105658282536, 3.70587149554094, 3.4019105658282536, 3.4019105658282536, 3.0829436500740535, 4.375529014184491, 4.375529014184491, 2.820572620973136, 2.820572620973136, 4.998456859651378, 2.820572620973136, 4.02483841129514, 2.1093252017178163, 3.4019105658282536, 4.998456859651378, 2.820572620973136, 3.4019105658282536, 1.8786778597520493, 4.02483841129514, 2.732253047184703, 2.1976447755062494, 2.820572620973136, 2.1976447755062494, 3.70587149554094, 4.02483841129514, 4.02483841129514, 4.998456859651378, 2.5016057052189358, 3.4019105658282536, 4.02483841129514, 3.794191069329373, 3.4019105658282536, 3.0829436500740535, 2.732253047184703, 2.732253047184703, 4.02483841129514, 2.1093252017178163, 4.02483841129514, 2.1976447755062494, 2.1976447755062494, 2.1976447755062494, 2.732253047184703, 4.998456859651378, 3.4019105658282536, 4.02483841129514, 4.02483841129514, 4.02483841129514, 2.732253047184703, 4.02483841129514]\n",
      "all_sum after preprocessing is: [ 0.77204621  0.02666431  0.39037734  0.02666431  0.02666431 -0.35500456\n",
      "  1.19167495  1.19167495 -0.66895203 -0.66895203  1.93705685 -0.66895203\n",
      "  0.77204621 -1.52001521  0.02666431  1.93705685 -0.66895203  0.02666431\n",
      " -1.7960028   0.77204621 -0.77463331 -1.41433393 -0.66895203 -1.41433393\n",
      "  0.39037734  0.77204621  0.77204621  1.93705685 -1.0506209   0.02666431\n",
      "  0.77204621  0.49605862  0.02666431 -0.35500456 -0.77463331 -0.77463331\n",
      "  0.77204621 -1.52001521  0.77204621 -1.41433393 -1.41433393 -1.41433393\n",
      " -0.77463331  1.93705685  0.02666431  0.77204621  0.77204621  0.77204621\n",
      " -0.77463331  0.77204621]\n",
      "P is: [0.6839633633440655, 0.5066656814883845, 0.5963735326220116, 0.5066656814883845, 0.5066656814883845, 0.4121693557881578, 0.7670404940650838, 0.7670404940650838, 0.3387315392017616, 0.3387315392017616, 0.8740284516374669, 0.3387315392017616, 0.6839633633440655, 0.17945927977980078, 0.5066656814883845, 0.8740284516374669, 0.3387315392017616, 0.5066656814883845, 0.14233833848960112, 0.6839633633440655, 0.31547768228318923, 0.1955513817319788, 0.3387315392017616, 0.1955513817319788, 0.5963735326220116, 0.6839633633440655, 0.6839633633440655, 0.8740284516374669, 0.25910588950499447, 0.5066656814883845, 0.6839633633440655, 0.621532645863349, 0.5066656814883845, 0.4121693557881578, 0.31547768228318923, 0.31547768228318923, 0.6839633633440655, 0.17945927977980078, 0.6839633633440655, 0.1955513817319788, 0.1955513817319788, 0.1955513817319788, 0.31547768228318923, 0.8740284516374669, 0.5066656814883845, 0.6839633633440655, 0.6839633633440655, 0.6839633633440655, 0.31547768228318923, 0.6839633633440655]\n",
      "all_sum before preprocessing is: [3.5955938153834355, 5.40060225835884, 4.995212787320726, 4.995212787320726, 5.40060225835884, 4.995212787320726, 4.995212787320726, 5.40060225835884, 4.995212787320726, 5.40060225835884, 4.995212787320726, 4.995212787320726, 4.995212787320726, 5.40060225835884, 5.40060225835884, 4.995212787320726, 5.40060225835884, 4.995212787320726, 3.1902043443453216, 4.995212787320726, 5.268335768366089, 4.862946297327976, 4.862946297327976, 3.5955938153834355, 5.40060225835884, 4.995212787320726, 5.40060225835884, 4.995212787320726, 4.995212787320726, 5.40060225835884, 4.862946297327976, 5.268335768366089, 3.1902043443453216, 4.995212787320726, 3.1902043443453216, 5.40060225835884, 5.40060225835884, 4.995212787320726, 4.995212787320726, 4.995212787320726, 5.40060225835884, 3.1902043443453216, 4.862946297327976, 3.4633273253906847, 5.40060225835884, 3.1902043443453216, 4.995212787320726, 4.001918717965088, 5.40060225835884, 4.995212787320726]\n",
      "all_sum after preprocessing is: [-1.75074257  0.8088963   0.23402329  0.23402329  0.8088963   0.23402329\n",
      "  0.23402329  0.8088963   0.23402329  0.8088963   0.23402329  0.23402329\n",
      "  0.23402329  0.8088963   0.8088963   0.23402329  0.8088963   0.23402329\n",
      " -2.32561559  0.23402329  0.62133239  0.04645937  0.04645937 -1.75074257\n",
      "  0.8088963   0.23402329  0.8088963   0.23402329  0.23402329  0.8088963\n",
      "  0.04645937  0.62133239 -2.32561559  0.23402329 -2.32561559  0.8088963\n",
      "  0.8088963   0.23402329  0.23402329  0.23402329  0.8088963  -2.32561559\n",
      "  0.04645937 -1.93830648  0.8088963  -2.32561559  0.23402329 -1.17454304\n",
      "  0.8088963   0.23402329]\n",
      "P is: [0.1479535627402786, 0.6918742636938998, 0.5582402610287617, 0.5582402610287617, 0.6918742636938998, 0.5582402610287617, 0.5582402610287617, 0.6918742636938998, 0.5582402610287617, 0.6918742636938998, 0.5582402610287617, 0.5582402610287617, 0.5582402610287617, 0.6918742636938998, 0.6918742636938998, 0.5582402610287617, 0.6918742636938998, 0.5582402610287617, 0.0890235919886157, 0.5582402610287617, 0.6505215192223555, 0.5116127545179725, 0.5116127545179725, 0.1479535627402786, 0.6918742636938998, 0.5582402610287617, 0.6918742636938998, 0.5582402610287617, 0.5582402610287617, 0.6918742636938998, 0.5116127545179725, 0.6505215192223555, 0.0890235919886157, 0.5582402610287617, 0.0890235919886157, 0.6918742636938998, 0.6918742636938998, 0.5582402610287617, 0.5582402610287617, 0.5582402610287617, 0.6918742636938998, 0.0890235919886157, 0.5116127545179725, 0.125834024898922, 0.6918742636938998, 0.0890235919886157, 0.5582402610287617, 0.23603479038164804, 0.6918742636938998, 0.5582402610287617]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.183\n",
      "(*) epoch 2, cost 2.914\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.993\n",
      "(*) epoch 2, cost 2.408\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.11535297274796277, 0.30337732766746517, 0.30337732766746517, 0.6980245290709315, 1.729491223449473, 0.30337732766746517, 0.8860488839904339, 0.30337732766746517, 0.11535297274796277, 0.8860488839904339, 1.729491223449473, 0.11535297274796277, 0.11535297274796277, 0.11535297274796277, 0.30337732766746517, 0.11535297274796277, 0.11535297274796277, 0.11535297274796277, 1.729491223449473, 0.11535297274796277, 1.6622642203673457, 3.464426825988358, 0.11535297274796277, 0.30337732766746517, 0.30337732766746517, 0.11535297274796277, 0.11535297274796277, 0.6980245290709315, 0.11535297274796277, 0.30337732766746517, 0.30337732766746517, 1.729491223449473, 0.8860488839904339, 0.11535297274796277, 0.30337732766746517, 4.3089300834003, 0.30337732766746517, 1.729491223449473, 1.9175155783689755, 0.30337732766746517, 0.11535297274796277, 0.30337732766746517, 2.312162779772442, 0.11535297274796277, 0.30337732766746517, 0.30337732766746517, 0.11535297274796277, 0.11535297274796277, 0.30337732766746517, 0.11535297274796277]\n",
      "all_sum after preprocessing is: [-0.61786937 -0.40775128 -0.40775128  0.03326882  1.18593767 -0.40775128\n",
      "  0.24338691 -0.40775128 -0.61786937  0.24338691  1.18593767 -0.61786937\n",
      " -0.61786937 -0.61786937 -0.40775128 -0.61786937 -0.61786937 -0.61786937\n",
      "  1.18593767 -0.61786937  1.11081118  3.12473632 -0.61786937 -0.40775128\n",
      " -0.40775128 -0.61786937 -0.61786937  0.03326882 -0.61786937 -0.40775128\n",
      " -0.40775128  1.18593767  0.24338691 -0.61786937 -0.40775128  4.06847266\n",
      " -0.40775128  1.18593767  1.39605577 -0.40775128 -0.61786937 -0.40775128\n",
      "  1.83707586 -0.61786937 -0.40775128 -0.40775128 -0.61786937 -0.61786937\n",
      " -0.40775128 -0.61786937]\n",
      "P is: [0.35026618440097446, 0.3994514452318451, 0.3994514452318451, 0.5083164370231379, 0.766013732612263, 0.3994514452318451, 0.5605481309304999, 0.3994514452318451, 0.35026618440097446, 0.5605481309304999, 0.766013732612263, 0.35026618440097446, 0.35026618440097446, 0.35026618440097446, 0.3994514452318451, 0.35026618440097446, 0.35026618440097446, 0.35026618440097446, 0.766013732612263, 0.35026618440097446, 0.75228030948612, 0.9579016400954719, 0.35026618440097446, 0.3994514452318451, 0.3994514452318451, 0.35026618440097446, 0.35026618440097446, 0.5083164370231379, 0.35026618440097446, 0.3994514452318451, 0.3994514452318451, 0.766013732612263, 0.5605481309304999, 0.35026618440097446, 0.3994514452318451, 0.983184118806107, 0.3994514452318451, 0.766013732612263, 0.8015572520883393, 0.3994514452318451, 0.35026618440097446, 0.3994514452318451, 0.8626025071953816, 0.35026618440097446, 0.3994514452318451, 0.3994514452318451, 0.35026618440097446, 0.35026618440097446, 0.3994514452318451, 0.35026618440097446]\n",
      "all_sum before preprocessing is: [1.4117823824145421, 2.8344968544747244, 2.4593831386928935, 2.2115676764898597, 3.2216480066172464, 1.6591697328107504, 1.159189308755057, 0.8902092990852557, 3.2216480066172464, 1.5295254130804368, 2.3297388189625803, 1.9425876668200583, 0.8902092990852557, 3.743221089946532, 2.0771457453030955, 3.4906280162870473, 3.2216480066172464, 3.743221089946532, 1.9165404179266856, 0.5030581469427335, 2.3297388189625803, 1.0198536188155694, 2.4593831386928935, 2.9690549329577616, 2.0771457453030955, 3.098699252688075, 2.0771457453030955, 0.6376162254257709, 1.9165404179266856, 2.851311902291867, 2.598718828632382, 2.3297388189625803, 0.5030581469427335, 2.9690549329577616, 2.8344968544747244, 0.6376162254257709, 0.5030581469427335, 2.851311902291867, 1.4117823824145421, 2.5819037808152396, 2.206790065033409, 1.9165404179266856, 1.7821184867399216, 3.2216480066172464, 0.6327024666730472, 2.3297388189625803, 1.4117823824145421, 2.598718828632382, 0.8902092990852557, 1.9117628064702352]\n",
      "all_sum after preprocessing is: [-0.73814833  0.83271125  0.41853751  0.1449174   1.26017587 -0.46500091\n",
      " -1.01704354 -1.31403203  1.26017587 -0.60814489  0.27539353 -0.15207109\n",
      " -1.31403203  1.83605957 -0.00350168  1.55716436  1.26017587  1.83605957\n",
      " -0.1808306  -1.74149665  0.27539353 -1.17088804  0.41853751  0.98128066\n",
      " -0.00350168  1.12442465 -0.00350168 -1.59292724 -0.1808306   0.85127723\n",
      "  0.57238202  0.27539353 -1.74149665  0.98128066  0.83271125 -1.59292724\n",
      " -1.74149665  0.85127723 -0.73814833  0.55381604  0.1396423  -0.1808306\n",
      " -0.32924968  1.26017587 -1.59835266  0.27539353 -0.73814833  0.57238202\n",
      " -1.31403203 -0.1861057 ]\n",
      "P is: [0.323409186069018, 0.6969279048333128, 0.6031332367353882, 0.5361660786269493, 0.7790563815170213, 0.3858001424546889, 0.2656036835853717, 0.21181292192616846, 0.7790563815170213, 0.3524824888723074, 0.5684165256264094, 0.46205532363846935, 0.21181292192616846, 0.8624820131158598, 0.49912458020788386, 0.8259460809130694, 0.7790563815170213, 0.8624820131158598, 0.454915138145999, 0.14912293241796862, 0.5684165256264094, 0.23669450400969472, 0.6031332367353882, 0.72736225375435, 0.49912458020788386, 0.754808520765041, 0.49912458020788386, 0.168972453530187, 0.454915138145999, 0.7008350013996252, 0.6393126315589555, 0.5684165256264094, 0.14912293241796862, 0.72736225375435, 0.6969279048333128, 0.168972453530187, 0.14912293241796862, 0.7008350013996252, 0.323409186069018, 0.6350204885736931, 0.5348539568614875, 0.454915138145999, 0.41842319771553743, 0.7790563815170213, 0.168211979415952, 0.5684165256264094, 0.323409186069018, 0.6393126315589555, 0.21181292192616846, 0.453607400361005]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.878\n",
      "(*) epoch 2, cost 3.084\n",
      "(*) epoch 3, cost 2.176\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.842\n",
      "(*) epoch 2, cost 3.076\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.5777042069274505, 2.185829723618594, 2.185829723618594, 2.185829723618594, 1.7724872331765689, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.5777042069274505, 2.185829723618594, 2.185829723618594, 2.5777042069274505, 2.5777042069274505, 2.185829723618594, 2.3222397283374425, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.6801830209481547, 2.185829723618594, 2.5777042069274505, 2.3222397283374425, 2.185829723618594, 1.7724872331765689, 2.185829723618594, 2.185829723618594, 3.3514752268922763, 2.9596007435834197, 2.5777042069274505, 2.5777042069274505, 2.185829723618594, 2.5777042069274505, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.5777042069274505, 2.185829723618594, 2.5777042069274505, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.185829723618594, 2.185829723618594, 1.9088972378954177, 2.185829723618594]\n",
      "all_sum after preprocessing is: [ 1.05130439 -0.41252151 -0.41252151 -0.41252151 -1.95653998 -0.41252151\n",
      " -0.41252151 -0.41252151 -0.41252151  1.05130439 -0.41252151 -0.41252151\n",
      "  1.05130439  1.05130439 -0.41252151  0.09703067 -0.41252151 -0.41252151\n",
      " -0.41252151 -0.41252151 -0.41252151 -0.41252151  1.43410845 -0.41252151\n",
      "  1.05130439  0.09703067 -0.41252151 -1.95653998 -0.41252151 -0.41252151\n",
      "  3.94168411  2.47785821  1.05130439  1.05130439 -0.41252151  1.05130439\n",
      " -0.41252151 -0.41252151 -0.41252151  1.05130439 -0.41252151  1.05130439\n",
      " -0.41252151 -0.41252151 -0.41252151 -0.41252151 -0.41252151 -0.41252151\n",
      " -1.4469878  -0.41252151]\n",
      "P is: [0.7410252992782203, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.12384198883286292, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.7410252992782203, 0.39830766529212025, 0.39830766529212025, 0.7410252992782203, 0.7410252992782203, 0.39830766529212025, 0.524238654175821, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.807540652411478, 0.39830766529212025, 0.7410252992782203, 0.524238654175821, 0.39830766529212025, 0.12384198883286292, 0.39830766529212025, 0.39830766529212025, 0.9809542923168982, 0.9225749472882274, 0.7410252992782203, 0.7410252992782203, 0.39830766529212025, 0.7410252992782203, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.7410252992782203, 0.39830766529212025, 0.7410252992782203, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.39830766529212025, 0.19046557911174, 0.39830766529212025]\n",
      "all_sum before preprocessing is: [2.6180468786632165, 1.6990505590172953, 2.468759691457822, 2.468759691457822, 2.066619578143276, 1.6990505590172953, 1.6990505590172953, 2.6180468786632165, 2.2549619688483378, 1.7030089830823008, 1.6990505590172953, 2.696971093363751, 1.6990505590172953, 2.6180468786632165, 1.6990505590172953, 1.6990505590172953, 1.6990505590172953, 1.6990505590172953, 2.6180468786632165, 2.468759691457822, 1.6990505590172953, 1.6990505590172953, 2.6180468786632165, 2.6220053027282217, 1.6990505590172953, 1.6990505590172953, 2.5117226632406693, 1.6990505590172953, 2.6180468786632165, 2.5117226632406693, 1.3359656492024166, 1.7030089830823008, 2.6220053027282217, 2.472718115522828, 2.87929168236665, 2.6180468786632165, 1.6990505590172953, 1.6990505590172953, 1.7030089830823008, 2.6220053027282217, 3.4307189828865905, 2.6180468786632165, 2.468759691457822, 2.5156810873056745, 2.87929168236665, 1.6990505590172953, 1.7030089830823008, 2.8363287105838033, 1.6990505590172953, 1.5497633718119008]\n",
      "all_sum after preprocessing is: [ 0.92276361 -0.93040191  0.62172446  0.62172446 -0.18919521 -0.93040191\n",
      " -0.93040191  0.92276361  0.19059916 -0.9224197  -0.93040191  1.0819151\n",
      " -0.93040191  0.92276361 -0.93040191 -0.93040191 -0.93040191 -0.93040191\n",
      "  0.92276361  0.62172446 -0.93040191 -0.93040191  0.92276361  0.93074581\n",
      " -0.93040191 -0.93040191  0.70835973 -0.93040191  0.92276361  0.70835973\n",
      " -1.66256635 -0.9224197   0.93074581  0.62970666  1.44956643  0.92276361\n",
      " -0.93040191 -0.93040191 -0.9224197   0.93074581  2.56152525  0.92276361\n",
      "  0.62172446  0.71634194  1.44956643 -0.93040191 -0.9224197   1.36293116\n",
      " -0.93040191 -1.23144105]\n",
      "P is: [0.7156048746837369, 0.282843183732626, 0.6506106485803679, 0.6506106485803679, 0.45284178313437096, 0.282843183732626, 0.282843183732626, 0.7156048746837369, 0.5475060598213147, 0.28446511986084894, 0.282843183732626, 0.7468562262026841, 0.282843183732626, 0.7156048746837369, 0.282843183732626, 0.282843183732626, 0.282843183732626, 0.282843183732626, 0.7156048746837369, 0.6506106485803679, 0.282843183732626, 0.282843183732626, 0.7156048746837369, 0.7172265694400785, 0.282843183732626, 0.282843183732626, 0.670038619808856, 0.282843183732626, 0.7156048746837369, 0.670038619808856, 0.15941779534494238, 0.28446511986084894, 0.7172265694400785, 0.6524229460597969, 0.8099316988290906, 0.7156048746837369, 0.282843183732626, 0.282843183732626, 0.28446511986084894, 0.7172265694400785, 0.9283439855802953, 0.7156048746837369, 0.6506106485803679, 0.6718009786378173, 0.8099316988290906, 0.282843183732626, 0.28446511986084894, 0.7962356751516932, 0.282843183732626, 0.2259293076772495]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.492\n",
      "(*) epoch 2, cost 1.845\n",
      "(*) epoch 3, cost 1.528\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.226\n",
      "(*) epoch 2, cost 2.626\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.7649015769069323, 0.7652907983624445, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7652907983624445, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7652907983624445, 0.7649015769069323, 0.7652907983624445, 0.7652907983624445, 0.7652907983624445, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7652907983624445, 0.7649015769069323, 0.7652907983624445, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7652907983624445, 0.7649015769069323, 0.8236760061657016, 0.7652907983624445, 0.7649015769069323, 0.7652907983624445, 0.7652907983624445, 0.7649015769069323, 0.7652907983624445, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323, 0.7649015769069323]\n",
      "all_sum after preprocessing is: [-0.15539544 -0.10802026 -0.15539544 -0.15539544 -0.15539544 -0.15539544\n",
      " -0.15539544 -0.15539544 -0.10802026 -0.15539544 -0.15539544 -0.15539544\n",
      " -0.15539544 -0.10802026 -0.15539544 -0.10802026 -0.10802026 -0.10802026\n",
      " -0.15539544 -0.15539544 -0.15539544 -0.10802026 -0.15539544 -0.10802026\n",
      " -0.15539544 -0.15539544 -0.15539544 -0.15539544 -0.15539544 -0.10802026\n",
      " -0.15539544  6.99849929 -0.10802026 -0.15539544 -0.10802026 -0.10802026\n",
      " -0.15539544 -0.10802026 -0.15539544 -0.15539544 -0.15539544 -0.15539544\n",
      " -0.15539544 -0.15539544 -0.15539544 -0.15539544 -0.15539544 -0.15539544\n",
      " -0.15539544 -0.15539544]\n",
      "P is: [0.46122912716570796, 0.4730211632864776, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.4730211632864776, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.4730211632864776, 0.46122912716570796, 0.4730211632864776, 0.4730211632864776, 0.4730211632864776, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.4730211632864776, 0.46122912716570796, 0.4730211632864776, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.4730211632864776, 0.46122912716570796, 0.9990875818058914, 0.4730211632864776, 0.46122912716570796, 0.4730211632864776, 0.4730211632864776, 0.46122912716570796, 0.4730211632864776, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796, 0.46122912716570796]\n",
      "all_sum before preprocessing is: [2.4460236249072667, 2.4460236249072667, 2.4460236249072667, 2.22929785558134, 2.4460236249072667, 2.6352938739026075, 2.4460236249072667, 2.4460236249072667, 2.040027606585999, 2.6352938739026075, 2.6352938739026075, 2.6352938739026075, 2.4460236249072667, 2.9209752449672144, 2.4460236249072667, 2.4460236249072667, 2.4460236249072667, 2.4460236249072667, 2.22929785558134, 2.6352938739026075, 2.4460236249072667, 2.4460236249072667, 2.4460236249072667, 2.6352938739026075, 2.6352938739026075, 2.6352938739026075, 2.6352938739026075, 2.4460236249072667, 2.22929785558134, 2.040027606585999, 2.6352938739026075, 2.6352938739026075, 2.6352938739026075, 2.6352938739026075, 2.4460236249072667, 2.4460236249072667, 2.6352938739026075, 2.6352938739026075, 2.4460236249072667, 2.4460236249072667, 2.4460236249072667, 2.4460236249072667, 2.040027606585999, 2.4460236249072667, 2.4460236249072667, 2.22929785558134, 2.6352938739026075, 2.6352938739026075, 2.6352938739026075, 2.6352938739026075]\n",
      "all_sum after preprocessing is: [-0.22860813 -0.22860813 -0.22860813 -1.47584892 -0.22860813  0.86062816\n",
      " -0.22860813 -0.22860813 -2.56508522  0.86062816  0.86062816  0.86062816\n",
      " -0.22860813  2.50470334 -0.22860813 -0.22860813 -0.22860813 -0.22860813\n",
      " -1.47584892  0.86062816 -0.22860813 -0.22860813 -0.22860813  0.86062816\n",
      "  0.86062816  0.86062816  0.86062816 -0.22860813 -1.47584892 -2.56508522\n",
      "  0.86062816  0.86062816  0.86062816  0.86062816 -0.22860813 -0.22860813\n",
      "  0.86062816  0.86062816 -0.22860813 -0.22860813 -0.22860813 -0.22860813\n",
      " -2.56508522 -0.22860813 -0.22860813 -1.47584892  0.86062816  0.86062816\n",
      "  0.86062816  0.86062816]\n",
      "P is: [0.4430955775569611, 0.4430955775569611, 0.4430955775569611, 0.18605523403597773, 0.4430955775569611, 0.7027918787995705, 0.4430955775569611, 0.4430955775569611, 0.07141956075143398, 0.7027918787995705, 0.7027918787995705, 0.7027918787995705, 0.4430955775569611, 0.9244708847252685, 0.4430955775569611, 0.4430955775569611, 0.4430955775569611, 0.4430955775569611, 0.18605523403597773, 0.7027918787995705, 0.4430955775569611, 0.4430955775569611, 0.4430955775569611, 0.7027918787995705, 0.7027918787995705, 0.7027918787995705, 0.7027918787995705, 0.4430955775569611, 0.18605523403597773, 0.07141956075143398, 0.7027918787995705, 0.7027918787995705, 0.7027918787995705, 0.7027918787995705, 0.4430955775569611, 0.4430955775569611, 0.7027918787995705, 0.7027918787995705, 0.4430955775569611, 0.4430955775569611, 0.4430955775569611, 0.4430955775569611, 0.07141956075143398, 0.4430955775569611, 0.4430955775569611, 0.18605523403597773, 0.7027918787995705, 0.7027918787995705, 0.7027918787995705, 0.7027918787995705]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.498\n",
      "(*) epoch 2, cost 1.026\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.990\n",
      "(*) epoch 2, cost 3.538\n",
      "(*) epoch 3, cost 2.814\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [5.183666845525034, 6.072369100020004, 3.762822493290952, 6.072369100020004, 7.093699232368968, 6.474735759840345, 5.897809068280391, 6.072369100020004, 5.358226877264647, 6.072369100020004, 4.651524747785923, 5.358226877264647, 4.651524747785923, 4.651524747785923, 6.095470310304369, 7.807841455124325, 6.072369100020004, 7.807841455124325, 6.072369100020004, 6.072369100020004, 3.937382525030566, 6.64929579157996, 6.072369100020004, 6.386997102890244, 5.358226877264647, 6.882274359758559, 4.651524747785923, 6.072369100020004, 5.358226877264647, 5.897809068280391, 6.160539038093529, 5.897809068280391, 4.514309216590521, 6.64929579157996, 6.072369100020004, 7.807841455124325, 7.093699232368968, 6.072369100020004, 6.64929579157996, 4.651524747785923, 5.358226877264647, 6.64929579157996, 5.183666845525034, 6.072369100020004, 6.072369100020004, 7.807841455124325, 6.474735759840345, 6.64929579157996, 6.745058828563156, 7.807841455124325]\n",
      "all_sum after preprocessing is: [-0.86318775  0.05497885 -2.33113927  0.05497885  1.11017051  0.47068571\n",
      " -0.12536861  0.05497885 -0.6828403   0.05497885 -1.41297268 -0.6828403\n",
      " -1.41297268 -1.41297268  0.07884596  1.84798966  0.05497885  1.84798966\n",
      "  0.05497885  0.05497885 -2.15079182  0.65103317  0.05497885  0.38003813\n",
      " -0.6828403   0.89173599 -1.41297268  0.05497885 -0.6828403  -0.12536861\n",
      "  0.146072   -0.12536861 -1.5547375   0.65103317  0.05497885  1.84798966\n",
      "  1.11017051  0.05497885  0.65103317 -1.41297268 -0.6828403   0.65103317\n",
      " -0.86318775  0.05497885  0.05497885  1.84798966  0.47068571  0.65103317\n",
      "  0.74997116  1.84798966]\n",
      "P is: [0.29667376322738365, 0.513741250280427, 0.08857664561130758, 0.513741250280427, 0.7521608989417492, 0.6155460418470919, 0.4686988341410745, 0.513741250280427, 0.3356276727835607, 0.513741250280427, 0.19576561078236468, 0.3356276727835607, 0.19576561078236468, 0.19576561078236468, 0.5197012850125263, 0.8638908927081271, 0.513741250280427, 0.8638908927081271, 0.513741250280427, 0.513741250280427, 0.10425725389060335, 0.6572432463962287, 0.513741250280427, 0.5938823005528169, 0.3356276727835607, 0.7092482892602829, 0.19576561078236468, 0.513741250280427, 0.3356276727835607, 0.4686988341410745, 0.5364532062215339, 0.4686988341410745, 0.17440307916558248, 0.6572432463962287, 0.513741250280427, 0.8638908927081271, 0.7521608989417492, 0.513741250280427, 0.6572432463962287, 0.19576561078236468, 0.3356276727835607, 0.6572432463962287, 0.29667376322738365, 0.513741250280427, 0.513741250280427, 0.8638908927081271, 0.6155460418470919, 0.6572432463962287, 0.6791724158494431, 0.8638908927081271]\n",
      "all_sum before preprocessing is: [0.11281544140612894, 0.4125913504375493, 0.4125913504375493, 0.11281544140612894, 0.4125913504375493, 0.4125913504375493, 0.11281544140612894, 0.4125913504375493, 0.4125913504375493, 0.4125913504375493, 0.11281544140612894, 1.1239770078563427, 0.4125913504375493, 0.4125913504375493, 0.4125913504375493, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 1.1239770078563427, 0.4125913504375493, 0.4125913504375493, 0.4125913504375493, 0.11281544140612894, 0.11281544140612894, 0.4125913504375493, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.6075974051937871, 0.4125913504375493, 0.4125913504375493, 0.4125913504375493, 0.6075974051937871, 0.9073733142252074, 0.20335023782163586, 0.11281544140612894, 0.4125913504375493, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.11281544140612894, 0.4125913504375493]\n",
      "all_sum after preprocessing is: [-0.77793527  0.43760216  0.43760216 -0.77793527  0.43760216  0.43760216\n",
      " -0.77793527  0.43760216  0.43760216  0.43760216 -0.77793527  3.32214315\n",
      "  0.43760216  0.43760216  0.43760216 -0.77793527 -0.77793527 -0.77793527\n",
      " -0.77793527  3.32214315  0.43760216  0.43760216  0.43760216 -0.77793527\n",
      " -0.77793527  0.43760216 -0.77793527 -0.77793527 -0.77793527  1.22831666\n",
      "  0.43760216  0.43760216  0.43760216  1.22831666  2.4438541  -0.41083295\n",
      " -0.77793527  0.43760216 -0.77793527 -0.77793527 -0.77793527 -0.77793527\n",
      " -0.77793527 -0.77793527 -0.77793527 -0.77793527 -0.77793527 -0.77793527\n",
      " -0.77793527  0.43760216]\n",
      "P is: [0.3147650524837294, 0.607687525523903, 0.607687525523903, 0.3147650524837294, 0.607687525523903, 0.607687525523903, 0.3147650524837294, 0.607687525523903, 0.607687525523903, 0.607687525523903, 0.3147650524837294, 0.9651806879065518, 0.607687525523903, 0.607687525523903, 0.607687525523903, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.9651806879065518, 0.607687525523903, 0.607687525523903, 0.607687525523903, 0.3147650524837294, 0.3147650524837294, 0.607687525523903, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.7735238154789871, 0.607687525523903, 0.607687525523903, 0.607687525523903, 0.7735238154789871, 0.9201108496741204, 0.39871241336999874, 0.3147650524837294, 0.607687525523903, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.3147650524837294, 0.607687525523903]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.917\n",
      "(*) epoch 2, cost 4.280\n",
      "(*) epoch 3, cost 3.677\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.836\n",
      "(*) epoch 2, cost 1.673\n",
      "(*) epoch 3, cost 1.139\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [7.5916191638233865, 7.1896419452110045, 6.945574799631902, 6.7164170574368045, 5.798412010003756, 6.711748853896444, 5.674044335444025, 6.836116528456175, 6.592049382877073, 5.678712538984385, 6.711748853896444, 6.836116528456175, 5.327369018627804, 6.711748853896444, 7.347552018244285, 5.674044335444025, 6.7164170574368045, 5.798412010003756, 5.798412010003756, 5.678712538984385, 5.405816111955963, 5.401147908415603, 6.592049382877073, 6.711748853896444, 4.843043670687977, 8.32225790433597, 6.836116528456175, 6.836116528456175, 6.836116528456175, 5.674044335444025, 6.7164170574368045, 6.592049382877073, 6.592049382877073, 6.711748853896444, 5.322700815087445, 5.674044335444025, 6.711748853896444, 6.7164170574368045, 6.836116528456175, 6.592049382877073, 4.4093639711947565, 5.554344864424654, 8.566325049915074, 5.554344864424654, 6.000447660159768, 5.678712538984385, 5.9070007867068695, 7.8623453665021446, 6.7164170574368045, 5.401147908415603]\n",
      "all_sum after preprocessing is: [ 1.48798031  1.00304732  0.7086122   0.43216332 -0.67528982  0.42653175\n",
      " -0.82532317  0.5765651   0.28212997 -0.81969159  0.42653175  0.5765651\n",
      " -1.24354164  0.42653175  1.19354519 -0.82532317  0.43216332 -0.67528982\n",
      " -0.67528982 -0.81969159 -1.14890547 -1.15453705  0.28212997  0.42653175\n",
      " -1.82781689  2.36940049  0.5765651   0.5765651   0.5765651  -0.82532317\n",
      "  0.43216332  0.28212997  0.28212997  0.42653175 -1.24917322 -0.82532317\n",
      "  0.42653175  0.43216332  0.5765651   0.28212997 -2.35099479 -0.96972494\n",
      "  2.66383561 -0.96972494 -0.43156021 -0.81969159 -0.54429165  1.8145761\n",
      "  0.43216332 -1.15453705]\n",
      "P is: [0.8157749350582124, 0.7316572961686052, 0.6700944339910019, 0.6063901318096812, 0.337313375412293, 0.6050451781750724, 0.3046348684994631, 0.6402766526572137, 0.570068338068761, 0.30582913025996145, 0.6050451781750724, 0.6402766526572137, 0.22382011316226014, 0.6050451781750724, 0.7673745191723162, 0.3046348684994631, 0.6063901318096812, 0.337313375412293, 0.337313375412293, 0.30582913025996145, 0.24068905929990272, 0.23966134787244317, 0.570068338068761, 0.6050451781750724, 0.13849854863886435, 0.9144639786969696, 0.6402766526572137, 0.6402766526572137, 0.6402766526572137, 0.3046348684994631, 0.6063901318096812, 0.570068338068761, 0.570068338068761, 0.6050451781750724, 0.22284329105718703, 0.3046348684994631, 0.6050451781750724, 0.6063901318096812, 0.6402766526572137, 0.570068338068761, 0.08698673389767385, 0.27493533056053676, 0.9348586374217085, 0.27493533056053676, 0.3937538304229469, 0.30582913025996145, 0.3671898012892644, 0.8599140288079742, 0.6063901318096812, 0.23966134787244317]\n",
      "all_sum before preprocessing is: [3.05738695266368, 2.9057625363085973, 3.671000914784041, 3.4568860639860306, 1.9011015078043199, 3.3173050628203393, 5.375262755668555, 3.4568860639860306, 4.273554166119638, 4.344479802736938, 4.573655867177523, 3.686062128426616, 2.729813025127318, 3.686062128426616, 2.56312739512966, 3.50529798919101, 3.874055054797287, 3.686062128426616, 3.686062128426616, 2.7177696099379265, 3.6174067638782255, 3.686062128426616, 2.9057625363085973, 4.258492952477062, 4.273554166119638, 3.671000914784041, 4.273554166119638, 3.605363348688834, 4.573655867177523, 2.9027447378554134, 3.686062128426616, 3.874055054797287, 4.273554166119638, 4.461547092490308, 5.161147904870544, 4.573655867177523, 4.273554166119638, 4.558594653534948, 5.075161054610669, 3.4568860639860306, 3.3173050628203393, 3.686062128426616, 5.1944986164329485, 4.273554166119638, 3.8053996902488962, 3.6448789903567014, 4.273554166119638, 5.075161054610669, 3.874055054797287, 3.6448789903567014]\n",
      "all_sum after preprocessing is: [-1.09958964 -1.31036983 -0.2465762  -0.54422726 -2.70699608 -0.73826533\n",
      "  2.12259783 -0.54422726  0.59106124  0.68965828  1.00824664 -0.2256389\n",
      " -1.55496547 -0.2256389  -1.78668295 -0.47692758  0.03569885 -0.2256389\n",
      " -0.2256389  -1.57170758 -0.32107993 -0.2256389  -1.31036983  0.57012394\n",
      "  0.59106124 -0.2465762   0.59106124 -0.33782205  1.00824664 -1.31456501\n",
      " -0.2256389   0.03569885  0.59106124  0.85239899  1.82494677  1.00824664\n",
      "  0.59106124  0.98730934  1.70541243 -0.54422726 -0.73826533 -0.2256389\n",
      "  1.87130916  0.59106124 -0.05974218 -0.28288951  0.59106124  1.70541243\n",
      "  0.03569885 -0.28288951]\n",
      "P is: [0.24981679074333513, 0.21242496463979288, 0.43866639206208163, 0.36720476325550844, 0.06256179349793224, 0.323383584389919, 0.8930802447077499, 0.36720476325550844, 0.6436086055215421, 0.665890904775685, 0.732676872903825, 0.4438283944031219, 0.17437025681830792, 0.4438283944031219, 0.14347988478288828, 0.3829778947119175, 0.5089237651753243, 0.4438283944031219, 0.4438283944031219, 0.1719730984619509, 0.4204125827260915, 0.4438283944031219, 0.21242496463979288, 0.6387917730190722, 0.6436086055215421, 0.43866639206208163, 0.6436086055215421, 0.41633862488563755, 0.732676872903825, 0.21172395481434544, 0.4438283944031219, 0.5089237651753243, 0.6436086055215421, 0.7010701428888365, 0.8611586425686089, 0.732676872903825, 0.6436086055215421, 0.7285561389484385, 0.846240308673138, 0.36720476325550844, 0.323383584389919, 0.4438283944031219, 0.8666096850828315, 0.6436086055215421, 0.4850688958187545, 0.42974551797774635, 0.6436086055215421, 0.846240308673138, 0.5089237651753243, 0.42974551797774635]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 9\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.335\n",
      "(*) epoch 2, cost 5.405\n",
      "(*) epoch 3, cost 4.657\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 7\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.200\n",
      "(*) epoch 2, cost 4.080\n",
      "(*) epoch 3, cost 3.734\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.6008096667673573, 3.1705179274329462, 1.9497066482040304, 1.6008096667673573, 1.6008096667673573, 1.6008096667673573, 2.236648954723054, 0.7170470538268248, 1.6008096667673573, 1.6008096667673573, 2.2867553144924138, 3.5194149088696194, 1.6008096667673573, 3.1705179274329462, 1.6008096667673573, 0.7170470538268248, 2.5855459361597273, 1.6008096667673573, 3.1705179274329462, 0.7170470538268248, 0.7170470538268248, 3.1705179274329462, 2.2867553144924138, 1.6008096667673573, 3.1705179274329462, 1.9497066482040304, 0.7170470538268248, 3.5194149088696194, 3.1705179274329462, 1.9497066482040304, 3.1705179274329462, 1.6008096667673573, 1.6008096667673573, 1.6008096667673573, 1.9497066482040304, 1.6008096667673573, 0.7170470538268248, 1.6008096667673573, 1.9497066482040304, 1.9497066482040304, 1.6008096667673573, 1.6008096667673573, 1.6008096667673573, 2.635652295929087, 1.6008096667673573, 1.6008096667673573, 3.5194149088696194, 1.6008096667673573, 1.9497066482040304, 3.5194149088696194]\n",
      "all_sum after preprocessing is: [-0.4879276   1.44330661 -0.05867472 -0.4879276  -0.4879276  -0.4879276\n",
      "  0.29435444 -1.5752332  -0.4879276  -0.4879276   0.356001    1.87255948\n",
      " -0.4879276   1.44330661 -0.4879276  -1.5752332   0.72360732 -0.4879276\n",
      "  1.44330661 -1.5752332  -1.5752332   1.44330661  0.356001   -0.4879276\n",
      "  1.44330661 -0.05867472 -1.5752332   1.87255948  1.44330661 -0.05867472\n",
      "  1.44330661 -0.4879276  -0.4879276  -0.4879276  -0.05867472 -0.4879276\n",
      " -1.5752332  -0.4879276  -0.05867472 -0.05867472 -0.4879276  -0.4879276\n",
      " -0.4879276   0.78525388 -0.4879276  -0.4879276   1.87255948 -0.4879276\n",
      " -0.05867472  1.87255948]\n",
      "P is: [0.38038189398081274, 0.8089661762307823, 0.4853355262553084, 0.38038189398081274, 0.38038189398081274, 0.38038189398081274, 0.5730618368318302, 0.17147163677531388, 0.38038189398081274, 0.38038189398081274, 0.5880720462841988, 0.8667541531898592, 0.38038189398081274, 0.8089661762307823, 0.38038189398081274, 0.17147163677531388, 0.67340087796848, 0.38038189398081274, 0.8089661762307823, 0.17147163677531388, 0.17147163677531388, 0.8089661762307823, 0.5880720462841988, 0.38038189398081274, 0.8089661762307823, 0.4853355262553084, 0.17147163677531388, 0.8667541531898592, 0.8089661762307823, 0.4853355262553084, 0.8089661762307823, 0.38038189398081274, 0.38038189398081274, 0.38038189398081274, 0.4853355262553084, 0.38038189398081274, 0.17147163677531388, 0.38038189398081274, 0.4853355262553084, 0.4853355262553084, 0.38038189398081274, 0.38038189398081274, 0.38038189398081274, 0.6868113390078557, 0.38038189398081274, 0.38038189398081274, 0.8667541531898592, 0.38038189398081274, 0.4853355262553084, 0.8667541531898592]\n",
      "all_sum before preprocessing is: [2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.0944145340755216, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277, 2.045571989980277]\n",
      "all_sum after preprocessing is: [-0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714  7.         -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      " -0.14285714 -0.14285714]\n",
      "P is: [0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.9990889488055994, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236, 0.4643463291660236]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.571\n",
      "(*) epoch 2, cost 1.838\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 0.210\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.6720087198362534, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.6720087198362534, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557, 1.579584983369557]\n",
      "all_sum after preprocessing is: [-0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415  4.89897949\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415  4.89897949 -0.20412415\n",
      " -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415 -0.20412415\n",
      " -0.20412415 -0.20412415]\n",
      "P is: [0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.9926009674715031, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.9926009674715031, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348, 0.4491454195938348]\n",
      "all_sum before preprocessing is: [1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 3.430841759684828, 3.9886877978627697, 2.0725152367704283, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8419583414732958, 2.3998043796512376, 1.8527178193417757, 1.8419583414732958, 1.8527178193417757, 1.8527178193417757, 3.4416012375533076, 1.8527178193417757, 2.0725152367704283, 1.8527178193417757, 3.4416012375533076, 1.8527178193417757, 2.389044901782758, 1.8527178193417757, 2.3998043796512376, 1.8419583414732958, 3.9886877978627697, 3.97792831999429, 1.8527178193417757, 2.3998043796512376, 2.3998043796512376, 1.8527178193417757, 1.8527178193417757, 1.8419583414732958, 3.4416012375533076, 1.8527178193417757, 2.0725152367704283, 2.3998043796512376, 1.8527178193417757, 1.8527178193417757, 1.8527178193417757, 1.8419583414732958, 1.8527178193417757, 3.4416012375533076, 1.8527178193417757]\n",
      "all_sum after preprocessing is: [-0.55497134 -0.55497134 -0.55497134 -0.55497134 -0.55497134  1.8500312\n",
      "  2.70016794 -0.2200082  -0.55497134 -0.55497134 -0.55497134 -0.55497134\n",
      " -0.55497134 -0.55497134 -0.55497134 -0.57136839  0.27876835 -0.55497134\n",
      " -0.57136839 -0.55497134 -0.55497134  1.86642825 -0.55497134 -0.2200082\n",
      " -0.55497134  1.86642825 -0.55497134  0.26237131 -0.55497134  0.27876835\n",
      " -0.57136839  2.70016794  2.68377089 -0.55497134  0.27876835  0.27876835\n",
      " -0.55497134 -0.55497134 -0.57136839  1.86642825 -0.55497134 -0.2200082\n",
      "  0.27876835 -0.55497134 -0.55497134 -0.55497134 -0.57136839 -0.55497134\n",
      "  1.86642825 -0.55497134]\n",
      "P is: [0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.8641307663835727, 0.9370365529721713, 0.4452187391911398, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.36092113694268857, 0.5692442433076892, 0.3647117912307773, 0.36092113694268857, 0.3647117912307773, 0.3647117912307773, 0.8660444548120507, 0.3647117912307773, 0.4452187391911398, 0.3647117912307773, 0.8660444548120507, 0.3647117912307773, 0.5652191217301052, 0.3647117912307773, 0.5692442433076892, 0.36092113694268857, 0.9370365529721713, 0.9360621821680079, 0.3647117912307773, 0.5692442433076892, 0.5692442433076892, 0.3647117912307773, 0.3647117912307773, 0.36092113694268857, 0.8660444548120507, 0.3647117912307773, 0.4452187391911398, 0.5692442433076892, 0.3647117912307773, 0.3647117912307773, 0.3647117912307773, 0.36092113694268857, 0.3647117912307773, 0.8660444548120507, 0.3647117912307773]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.222\n",
      "(*) epoch 2, cost 1.437\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.806\n",
      "(*) epoch 2, cost 1.346\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [1.2256552911485854, 3.175449961481537, 1.2256552911485854, 1.2256552911485854, 4.806382253223519, 4.609142206737752, 1.2256552911485854, 2.6593475364048, 3.4440788981649217, 3.175449961481537, 2.6593475364048, 1.2256552911485854, 3.5407458410861485, 2.6593475364048, 3.125216519573952, 2.6593475364048, 1.2256552911485854, 3.4440788981649217, 3.175449961481537, 3.89689706908399, 1.2256552911485854, 2.6593475364048, 3.175449961481537, 2.9279764730881848, 2.6593475364048, 3.5407458410861485, 2.6593475364048, 1.2256552911485854, 2.6593475364048, 1.2256552911485854, 5.490540511419101, 4.806382253223519, 1.2256552911485854, 2.6593475364048, 1.2256552911485854, 4.056848266162886, 2.107053595829934, 2.6593475364048, 2.6593475364048, 1.2256552911485854, 2.107053595829934, 3.4440788981649217, 5.490540511419101, 1.2256552911485854, 2.107053595829934, 2.6593475364048, 3.175449961481537, 3.5407458410861485, 2.107053595829934, 2.6593475364048]\n",
      "all_sum after preprocessing is: [-1.28090783  0.41364696 -1.28090783 -1.28090783  1.83108038  1.65966025\n",
      " -1.28090783 -0.03489455  0.64711075  0.41364696 -0.03489455 -1.28090783\n",
      "  0.73112341 -0.03489455  0.36998938 -0.03489455 -1.28090783  0.64711075\n",
      "  0.41364696  1.04065229 -1.28090783 -0.03489455  0.41364696  0.19856924\n",
      " -0.03489455  0.73112341 -0.03489455 -1.28090783 -0.03489455 -1.28090783\n",
      "  2.4256782   1.83108038 -1.28090783 -0.03489455 -1.28090783  1.17966491\n",
      " -0.51488988 -0.03489455 -0.03489455 -1.28090783 -0.51488988  0.64711075\n",
      "  2.4256782  -1.28090783 -0.51488988 -0.03489455  0.41364696  0.73112341\n",
      " -0.51488988 -0.03489455]\n",
      "P is: [0.2173957296447793, 0.6019620279919088, 0.2173957296447793, 0.2173957296447793, 0.8618903807618346, 0.8401923899311504, 0.2173957296447793, 0.4912772482575154, 0.6563590814265329, 0.6019620279919088, 0.4912772482575154, 0.2173957296447793, 0.6750517478506517, 0.4912772482575154, 0.5914564116767951, 0.4912772482575154, 0.2173957296447793, 0.6563590814265329, 0.6019620279919088, 0.7389758464915663, 0.2173957296447793, 0.4912772482575154, 0.6019620279919088, 0.5494798358568068, 0.4912772482575154, 0.6750517478506517, 0.4912772482575154, 0.2173957296447793, 0.4912772482575154, 0.2173957296447793, 0.9187645530511721, 0.8618903807618346, 0.2173957296447793, 0.4912772482575154, 0.2173957296447793, 0.7648875487515603, 0.3740479245743144, 0.4912772482575154, 0.4912772482575154, 0.2173957296447793, 0.3740479245743144, 0.6563590814265329, 0.9187645530511721, 0.2173957296447793, 0.3740479245743144, 0.4912772482575154, 0.6019620279919088, 0.6750517478506517, 0.3740479245743144, 0.4912772482575154]\n",
      "all_sum before preprocessing is: [0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7891404119538936, 2.1771483673952887, 0.7546665813748744, 0.7546665813748744, 2.1771483673952887, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 2.211622197974308, 0.7546665813748744, 0.7546665813748744, 2.1771483673952887, 2.1771483673952887, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 2.798874791298529, 0.7891404119538936, 2.1771483673952887, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7891404119538936, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 0.7891404119538936, 0.7546665813748744, 0.7891404119538936, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 2.1771483673952887, 0.7546665813748744, 0.7546665813748744, 0.7546665813748744, 2.1771483673952887, 0.7546665813748744]\n",
      "all_sum after preprocessing is: [-0.47093366 -0.47093366 -0.47093366 -0.4113819   1.98632992 -0.47093366\n",
      " -0.47093366  1.98632992 -0.47093366 -0.47093366 -0.47093366 -0.47093366\n",
      " -0.47093366 -0.47093366  2.04588168 -0.47093366 -0.47093366  1.98632992\n",
      "  1.98632992 -0.47093366 -0.47093366 -0.47093366 -0.47093366 -0.47093366\n",
      " -0.47093366  3.06033011 -0.4113819   1.98632992 -0.47093366 -0.47093366\n",
      " -0.47093366 -0.4113819  -0.47093366 -0.47093366 -0.47093366 -0.47093366\n",
      " -0.47093366 -0.47093366 -0.4113819  -0.47093366 -0.4113819  -0.47093366\n",
      " -0.47093366 -0.47093366  1.98632992 -0.47093366 -0.47093366 -0.47093366\n",
      "  1.98632992 -0.47093366]\n",
      "P is: [0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.3985808129614011, 0.8793543199261478, 0.38439528271400675, 0.38439528271400675, 0.8793543199261478, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.8855308236129831, 0.38439528271400675, 0.38439528271400675, 0.8793543199261478, 0.8793543199261478, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.9552264174966933, 0.3985808129614011, 0.8793543199261478, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.3985808129614011, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.3985808129614011, 0.38439528271400675, 0.3985808129614011, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.8793543199261478, 0.38439528271400675, 0.38439528271400675, 0.38439528271400675, 0.8793543199261478, 0.38439528271400675]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 4.235\n",
      "(*) epoch 2, cost 2.892\n",
      "(*) epoch 3, cost 2.276\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 2.464\n",
      "(*) epoch 2, cost 1.523\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.7045402212114453, 2.7045402212114453, 2.7045402212114453, 2.7045402212114453, 2.7045402212114453, 1.2010855333815629, 2.7045402212114453, 2.7045402212114453, 2.8780581395589433, 1.2010855333815629, 2.7045402212114453, 2.7045402212114453, 1.2010855333815629, 2.7045402212114453, 2.7045402212114453, 2.7045402212114453, 1.2010855333815629, 1.3746034517290606, 1.2010855333815629, 1.2010855333815629, 2.8780581395589433, 1.3746034517290606, 1.2010855333815629, 2.7045402212114453, 2.7045402212114453, 2.7045402212114453, 1.2010855333815629, 1.2010855333815629, 1.2010855333815629, 1.2062937059938894, 1.2010855333815629, 1.2010855333815629, 1.2010855333815629, 2.7045402212114453, 2.7045402212114453, 1.2010855333815629, 2.7045402212114453, 1.2010855333815629, 1.2010855333815629, 1.2010855333815629, 2.8780581395589433, 1.2010855333815629, 2.7045402212114453, 1.2010855333815629, 2.7045402212114453, 1.2010855333815629, 2.7045402212114453, 2.709748393823772, 2.88326631217127, 2.7045402212114453]\n",
      "all_sum after preprocessing is: [ 0.88591878  0.88591878  0.88591878  0.88591878  0.88591878 -1.1007018\n",
      "  0.88591878  0.88591878  1.11520023 -1.1007018   0.88591878  0.88591878\n",
      " -1.1007018   0.88591878  0.88591878  0.88591878 -1.1007018  -0.87142036\n",
      " -1.1007018  -1.1007018   1.11520023 -0.87142036 -1.1007018   0.88591878\n",
      "  0.88591878  0.88591878 -1.1007018  -1.1007018  -1.1007018  -1.09381988\n",
      " -1.1007018  -1.1007018  -1.1007018   0.88591878  0.88591878 -1.1007018\n",
      "  0.88591878 -1.1007018  -1.1007018  -1.1007018   1.11520023 -1.1007018\n",
      "  0.88591878 -1.1007018   0.88591878 -1.1007018   0.88591878  0.8928007\n",
      "  1.12208215  0.88591878]\n",
      "P is: [0.7080472344337205, 0.7080472344337205, 0.7080472344337205, 0.7080472344337205, 0.7080472344337205, 0.24960842043847262, 0.7080472344337205, 0.7080472344337205, 0.7530973229874427, 0.24960842043847262, 0.7080472344337205, 0.7080472344337205, 0.24960842043847262, 0.7080472344337205, 0.7080472344337205, 0.7080472344337205, 0.24960842043847262, 0.29495884135338507, 0.24960842043847262, 0.24960842043847262, 0.7530973229874427, 0.29495884135338507, 0.24960842043847262, 0.7080472344337205, 0.7080472344337205, 0.7080472344337205, 0.24960842043847262, 0.24960842043847262, 0.24960842043847262, 0.25089965289906596, 0.24960842043847262, 0.24960842043847262, 0.24960842043847262, 0.7080472344337205, 0.7080472344337205, 0.24960842043847262, 0.7080472344337205, 0.24960842043847262, 0.24960842043847262, 0.24960842043847262, 0.7530973229874427, 0.24960842043847262, 0.7080472344337205, 0.24960842043847262, 0.7080472344337205, 0.24960842043847262, 0.7080472344337205, 0.7094678013839341, 0.7543747301697474, 0.7080472344337205]\n",
      "all_sum before preprocessing is: [2.4320082907781617, 2.832397186918848, 2.832397186918848, 2.832397186918848, 2.832397186918848, 2.4320082907781617, 2.4320082907781617, 2.4320082907781617, 2.4320082907781617, 2.4320082907781617, 2.832397186918848, 2.832397186918848, 2.4320082907781617, 2.4320082907781617, 2.4320082907781617, 2.4320082907781617, 2.4320082907781617, 2.832397186918848, 2.832397186918848, 2.4320082907781617, 2.832397186918848, 2.4320082907781617, 2.832397186918848, 2.4320082907781617, 2.4320082907781617, 1.4910460709523365, 2.832397186918848, 2.4320082907781617, 2.4320082907781617, 2.4320082907781617, 2.832397186918848, 2.4320082907781617, 2.832397186918848, 2.4320082907781617, 2.832397186918848, 2.4320082907781617, 2.832397186918848, 2.4320082907781617, 2.832397186918848, 2.832397186918848, 2.1030845772484534, 2.4320082907781617, 2.832397186918848, 2.4320082907781617, 2.832397186918848, 2.832397186918848, 2.832397186918848, 2.832397186918848, 2.4320082907781617, 2.832397186918848]\n",
      "all_sum after preprocessing is: [-0.60709841  0.92378499  0.92378499  0.92378499  0.92378499 -0.60709841\n",
      " -0.60709841 -0.60709841 -0.60709841 -0.60709841  0.92378499  0.92378499\n",
      " -0.60709841 -0.60709841 -0.60709841 -0.60709841 -0.60709841  0.92378499\n",
      "  0.92378499 -0.60709841  0.92378499 -0.60709841  0.92378499 -0.60709841\n",
      " -0.60709841 -4.20485911  0.92378499 -0.60709841 -0.60709841 -0.60709841\n",
      "  0.92378499 -0.60709841  0.92378499 -0.60709841  0.92378499 -0.60709841\n",
      "  0.92378499 -0.60709841  0.92378499  0.92378499 -1.86473531 -0.60709841\n",
      "  0.92378499 -0.60709841  0.92378499  0.92378499  0.92378499  0.92378499\n",
      " -0.60709841  0.92378499]\n",
      "P is: [0.352721373750009, 0.7158126944101786, 0.7158126944101786, 0.7158126944101786, 0.7158126944101786, 0.352721373750009, 0.352721373750009, 0.352721373750009, 0.352721373750009, 0.352721373750009, 0.7158126944101786, 0.7158126944101786, 0.352721373750009, 0.352721373750009, 0.352721373750009, 0.352721373750009, 0.352721373750009, 0.7158126944101786, 0.7158126944101786, 0.352721373750009, 0.7158126944101786, 0.352721373750009, 0.7158126944101786, 0.352721373750009, 0.352721373750009, 0.014703470096672026, 0.7158126944101786, 0.352721373750009, 0.352721373750009, 0.352721373750009, 0.7158126944101786, 0.352721373750009, 0.7158126944101786, 0.352721373750009, 0.7158126944101786, 0.352721373750009, 0.7158126944101786, 0.352721373750009, 0.7158126944101786, 0.7158126944101786, 0.13415206692667653, 0.352721373750009, 0.7158126944101786, 0.352721373750009, 0.7158126944101786, 0.7158126944101786, 0.7158126944101786, 0.7158126944101786, 0.352721373750009, 0.7158126944101786]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 7.035\n",
      "(*) epoch 2, cost 3.190\n",
      "(*) epoch 3, cost 1.793\n",
      "(*) epoch 4, cost 1.330\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 3.116\n",
      "(*) epoch 2, cost 2.618\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [0.873052062868562, 0.873052062868562, 0.873052062868562, 1.7685640050477045, 1.1141992846596052, 1.9017953192027017, 0.873052062868562, 0.873052062868562, 1.1141992846596052, 0.873052062868562, 0.873052062868562, 0.873052062868562, 0.873052062868562, 1.006283377023559, 0.873052062868562, 1.1141992846596052, 1.6536442304677177, 0.873052062868562, 0.873052062868562, 0.873052062868562, 0.873052062868562, 1.7685640050477045, 1.7685640050477045, 0.873052062868562, 0.873052062868562, 1.006283377023559, 0.873052062868562, 1.006283377023559, 1.7685640050477045, 1.9017953192027017, 0.873052062868562, 1.2474305988146024, 0.873052062868562, 1.006283377023559, 0.873052062868562, 1.9017953192027017, 1.7685640050477045, 1.7685640050477045, 1.006283377023559, 0.873052062868562, 0.873052062868562, 1.7685640050477045, 1.7685640050477045, 0.873052062868562, 0.873052062868562, 1.006283377023559, 0.873052062868562, 0.873052062868562, 0.873052062868562, 1.006283377023559]\n",
      "all_sum after preprocessing is: [-0.68712187 -0.68712187 -0.68712187  1.66839848 -0.05281744  2.01884503\n",
      " -0.68712187 -0.68712187 -0.05281744 -0.68712187 -0.68712187 -0.68712187\n",
      " -0.68712187 -0.33667532 -0.68712187 -0.05281744  1.3661179  -0.68712187\n",
      " -0.68712187 -0.68712187 -0.68712187  1.66839848  1.66839848 -0.68712187\n",
      " -0.68712187 -0.33667532 -0.68712187 -0.33667532  1.66839848  2.01884503\n",
      " -0.68712187  0.29762911 -0.68712187 -0.33667532 -0.68712187  2.01884503\n",
      "  1.66839848  1.66839848 -0.33667532 -0.68712187 -0.68712187  1.66839848\n",
      "  1.66839848 -0.68712187 -0.68712187 -0.33667532 -0.68712187 -0.68712187\n",
      " -0.68712187 -0.33667532]\n",
      "P is: [0.3346736341886521, 0.3346736341886521, 0.3346736341886521, 0.8413621796240914, 0.48679870836016137, 0.8827615295371632, 0.3346736341886521, 0.3346736341886521, 0.48679870836016137, 0.3346736341886521, 0.3346736341886521, 0.3346736341886521, 0.3346736341886521, 0.416617308104458, 0.3346736341886521, 0.48679870836016137, 0.7967522176201371, 0.3346736341886521, 0.3346736341886521, 0.3346736341886521, 0.3346736341886521, 0.8413621796240914, 0.8413621796240914, 0.3346736341886521, 0.3346736341886521, 0.416617308104458, 0.3346736341886521, 0.416617308104458, 0.8413621796240914, 0.8827615295371632, 0.3346736341886521, 0.5738628305618725, 0.3346736341886521, 0.416617308104458, 0.3346736341886521, 0.8827615295371632, 0.8413621796240914, 0.8413621796240914, 0.416617308104458, 0.3346736341886521, 0.3346736341886521, 0.8413621796240914, 0.8413621796240914, 0.3346736341886521, 0.3346736341886521, 0.416617308104458, 0.3346736341886521, 0.3346736341886521, 0.3346736341886521, 0.416617308104458]\n",
      "all_sum before preprocessing is: [2.2783768934688555, 2.459565237763244, 2.459565237763244, 1.2033390893761253, 1.8344361790777546, 2.2783768934688555, 2.2783768934688555, 2.909473983170485, 1.2033390893761253, 2.2783768934688555, 3.090662327464874, 2.459565237763244, 2.2783768934688555, 2.909473983170485, 2.2783768934688555, 1.2033390893761253, 1.8344361790777546, 2.2783768934688555, 1.2033390893761253, 3.090662327464874, 2.2783768934688555, 2.2783768934688555, 1.8344361790777546, 2.459565237763244, 1.8344361790777546, 3.090662327464874, 2.909473983170485, 2.909473983170485, 2.909473983170485, 2.2783768934688555, 2.288972245025906, 2.909473983170485, 2.2783768934688555, 2.2783768934688555, 2.0156245233721437, 2.909473983170485, 1.384527433670514, 3.090662327464874, 2.2783768934688555, 2.459565237763244, 2.0156245233721437, 2.459565237763244, 3.090662327464874, 2.2783768934688555, 2.909473983170485, 2.909473983170485, 2.2783768934688555, 3.090662327464874, 2.909473983170485, 1.2033390893761253]\n",
      "all_sum after preprocessing is: [-0.1339181   0.19291011  0.19291011 -2.07307526 -0.9347     -0.1339181\n",
      " -0.1339181   1.00445717 -2.07307526 -0.1339181   1.33128537  0.19291011\n",
      " -0.1339181   1.00445717 -0.1339181  -2.07307526 -0.9347     -0.1339181\n",
      " -2.07307526  1.33128537 -0.1339181  -0.1339181  -0.9347      0.19291011\n",
      " -0.9347      1.33128537  1.00445717  1.00445717  1.00445717 -0.1339181\n",
      " -0.11480616  1.00445717 -0.1339181  -0.1339181  -0.60787179  1.00445717\n",
      " -1.74624705  1.33128537 -0.1339181   0.19291011 -0.60787179  0.19291011\n",
      "  1.33128537 -0.1339181   1.00445717  1.00445717 -0.1339181   1.33128537\n",
      "  1.00445717 -2.07307526]\n",
      "P is: [0.46657042166649465, 0.5480785187476924, 0.5480785187476924, 0.11174143830125761, 0.28197216069760095, 0.46657042166649465, 0.46657042166649465, 0.7319340074433507, 0.11174143830125761, 0.46657042166649465, 0.7910531705228108, 0.5480785187476924, 0.46657042166649465, 0.7319340074433507, 0.46657042166649465, 0.11174143830125761, 0.28197216069760095, 0.46657042166649465, 0.11174143830125761, 0.7910531705228108, 0.46657042166649465, 0.46657042166649465, 0.28197216069760095, 0.5480785187476924, 0.28197216069760095, 0.7910531705228108, 0.7319340074433507, 0.7319340074433507, 0.7319340074433507, 0.46657042166649465, 0.47132994294970015, 0.7319340074433507, 0.46657042166649465, 0.46657042166649465, 0.3525448236699491, 0.7319340074433507, 0.14852117980577012, 0.7910531705228108, 0.46657042166649465, 0.5480785187476924, 0.3525448236699491, 0.5480785187476924, 0.7910531705228108, 0.46657042166649465, 0.7319340074433507, 0.7319340074433507, 0.46657042166649465, 0.7910531705228108, 0.7319340074433507, 0.11174143830125761]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 3\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.343\n",
      "(*) epoch 2, cost 1.743\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 5.768\n",
      "(*) epoch 2, cost 3.668\n",
      "(*) epoch 3, cost 2.812\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.28 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.2661439218920294, 3.365488418899325, 3.6869226764348064, 2.2661439218920294, 3.9035272857938916, 4.754962115646304, 3.365488418899325, 3.365488418899325, 3.365488418899325, 5.29300098254087, 4.786267173442102, 3.655617618639008, 2.2661439218920294, 3.365488418899325, 3.365488418899325, 3.365488418899325, 3.365488418899325, 3.365488418899325, 3.365488418899325, 4.754962115646304, 4.754962115646304, 2.891805557506193, 3.365488418899325, 2.2661439218920294, 3.365488418899325, 3.655617618639008, 3.655617618639008, 2.2661439218920294, 2.987365530938778, 4.754962115646304, 3.365488418899325, 2.2661439218920294, 3.365488418899325, 4.754962115646304, 3.365488418899325, 3.365488418899325, 3.9911500545134886, 4.754962115646304, 3.365488418899325, 2.2661439218920294, 4.754962115646304, 2.2661439218920294, 3.365488418899325, 3.655617618639008, 3.396793476695124, 3.365488418899325, 2.2661439218920294, 2.2661439218920294, 3.365488418899325, 3.365488418899325]\n",
      "all_sum after preprocessing is: [-1.460067   -0.09687678  0.30170259 -1.460067    0.5702929   1.62607445\n",
      " -0.09687678 -0.09687678 -0.09687678  2.29324413  1.66489281  0.26288423\n",
      " -1.460067   -0.09687678 -0.09687678 -0.09687678 -0.09687678 -0.09687678\n",
      " -0.09687678  1.62607445  1.62607445 -0.68424484 -0.09687678 -1.460067\n",
      " -0.09687678  0.26288423  0.26288423 -1.460067   -0.56575021  1.62607445\n",
      " -0.09687678 -1.460067   -0.09687678  1.62607445 -0.09687678 -0.09687678\n",
      "  0.67894538  1.62607445 -0.09687678 -1.460067    1.62607445 -1.460067\n",
      " -0.09687678  0.26288423 -0.05805842 -0.09687678 -1.460067   -1.460067\n",
      " -0.09687678 -0.09687678]\n",
      "P is: [0.18845707817897214, 0.47579972868192255, 0.5748586756958848, 0.18845707817897214, 0.6388307581520529, 0.8356311674935942, 0.47579972868192255, 0.47579972868192255, 0.47579972868192255, 0.9083159730997586, 0.840893711091675, 0.5653451666532403, 0.18845707817897214, 0.47579972868192255, 0.47579972868192255, 0.47579972868192255, 0.47579972868192255, 0.47579972868192255, 0.47579972868192255, 0.8356311674935942, 0.8356311674935942, 0.33531455786603415, 0.47579972868192255, 0.18845707817897214, 0.47579972868192255, 0.5653451666532403, 0.5653451666532403, 0.18845707817897214, 0.3622180193228041, 0.8356311674935942, 0.47579972868192255, 0.18845707817897214, 0.47579972868192255, 0.8356311674935942, 0.47579972868192255, 0.47579972868192255, 0.6635032761238614, 0.8356311674935942, 0.47579972868192255, 0.18845707817897214, 0.8356311674935942, 0.18845707817897214, 0.47579972868192255, 0.5653451666532403, 0.48548947011337323, 0.47579972868192255, 0.18845707817897214, 0.18845707817897214, 0.47579972868192255, 0.47579972868192255]\n",
      "all_sum before preprocessing is: [2.384665791770999, 0.6094717339116837, 2.384665791770999, 2.384665791770999, 3.920802530400449, 2.145608472541134, 0.6094717339116837, 2.384665791770999, 3.920802530400449, 2.145608472541134, 2.145608472541134, 2.384665791770999, 2.145608472541134, 2.384665791770999, 3.920802530400449, 2.384665791770999, 3.920802530400449, 3.920802530400449, 3.920802530400449, 3.920802530400449, 2.145608472541134, 0.6094717339116837, 2.384665791770999, 3.920802530400449, 3.920802530400449, 3.920802530400449, 2.384665791770999, 2.145608472541134, 2.384665791770999, 0.6094717339116837, 2.384665791770999, 2.145608472541134, 2.273332181131729, 2.145608472541134, 2.145608472541134, 3.920802530400449, 2.145608472541134, 2.145608472541134, 0.6094717339116837, 3.920802530400449, 2.145608472541134, 3.920802530400449, 3.920802530400449, 2.145608472541134, 2.145608472541134, 2.384665791770999, 0.6094717339116837, 0.6094717339116837, 2.384665791770999, 0.6094717339116837]\n",
      "all_sum after preprocessing is: [-0.07095733 -1.70844613 -0.07095733 -0.07095733  1.34601829 -0.29147051\n",
      " -1.70844613 -0.07095733  1.34601829 -0.29147051 -0.29147051 -0.07095733\n",
      " -0.29147051 -0.07095733  1.34601829 -0.07095733  1.34601829  1.34601829\n",
      "  1.34601829  1.34601829 -0.29147051 -1.70844613 -0.07095733  1.34601829\n",
      "  1.34601829  1.34601829 -0.07095733 -0.29147051 -0.07095733 -1.70844613\n",
      " -0.07095733 -0.29147051 -0.17365458 -0.29147051 -0.29147051  1.34601829\n",
      " -0.29147051 -0.29147051 -1.70844613  1.34601829 -0.29147051  1.34601829\n",
      "  1.34601829 -0.29147051 -0.29147051 -0.07095733 -1.70844613 -1.70844613\n",
      " -0.07095733 -1.70844613]\n",
      "P is: [0.4822681063748481, 0.1533653678304274, 0.4822681063748481, 0.4822681063748481, 0.7934779055049359, 0.427643900079474, 0.1533653678304274, 0.4822681063748481, 0.7934779055049359, 0.427643900079474, 0.427643900079474, 0.4822681063748481, 0.427643900079474, 0.4822681063748481, 0.7934779055049359, 0.4822681063748481, 0.7934779055049359, 0.7934779055049359, 0.7934779055049359, 0.7934779055049359, 0.427643900079474, 0.1533653678304274, 0.4822681063748481, 0.7934779055049359, 0.7934779055049359, 0.7934779055049359, 0.4822681063748481, 0.427643900079474, 0.4822681063748481, 0.1533653678304274, 0.4822681063748481, 0.427643900079474, 0.45669512575403837, 0.427643900079474, 0.427643900079474, 0.7934779055049359, 0.427643900079474, 0.427643900079474, 0.1533653678304274, 0.7934779055049359, 0.427643900079474, 0.7934779055049359, 0.7934779055049359, 0.427643900079474, 0.427643900079474, 0.4822681063748481, 0.1533653678304274, 0.1533653678304274, 0.4822681063748481, 0.1533653678304274]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.779\n",
      "(*) epoch 2, cost 2.465\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 2.870\n",
      "(*) epoch 2, cost 2.575\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "all_sum before preprocessing is: [2.2676361206095192, 2.2676361206095192, 2.1306729608386723, 3.9485627397648746, 5.229841399613783, 0.9863574607606116, 2.2676361206095192, 2.1306729608386723, 3.41195162068758, 0.9863574607606116, 5.229841399613783, 2.2676361206095192, 2.1306729608386723, 3.9485627397648746, 3.41195162068758, 0.9863574607606116, 3.41195162068758, 2.2676361206095192, 3.41195162068758, 2.2676361206095192, 0.9863574607606116, 3.41195162068758, 0.9863574607606116, 2.1306729608386723, 2.1306729608386723, 2.1306729608386723, 2.2676361206095192, 2.1306729608386723, 2.1306729608386723, 3.41195162068758, 3.41195162068758, 0.9863574607606116, 2.2676361206095192, 0.9863574607606116, 2.1306729608386723, 2.1306729608386723, 3.41195162068758, 5.229841399613783, 3.41195162068758, 3.41195162068758, 3.9485627397648746, 3.41195162068758, 5.229841399613783, 3.41195162068758, 2.1306729608386723, 3.41195162068758, 3.41195162068758, 2.2676361206095192, 3.41195162068758, 3.41195162068758]\n",
      "all_sum after preprocessing is: [-0.43708915 -0.43708915 -0.55815054  1.04867769  2.1811967  -1.56960815\n",
      " -0.43708915 -0.55815054  0.57436847 -1.56960815  2.1811967  -0.43708915\n",
      " -0.55815054  1.04867769  0.57436847 -1.56960815  0.57436847 -0.43708915\n",
      "  0.57436847 -0.43708915 -1.56960815  0.57436847 -1.56960815 -0.55815054\n",
      " -0.55815054 -0.55815054 -0.43708915 -0.55815054 -0.55815054  0.57436847\n",
      "  0.57436847 -1.56960815 -0.43708915 -1.56960815 -0.55815054 -0.55815054\n",
      "  0.57436847  2.1811967   0.57436847  0.57436847  1.04867769  0.57436847\n",
      "  2.1811967   0.57436847 -0.55815054  0.57436847  0.57436847 -0.43708915\n",
      "  0.57436847  0.57436847]\n",
      "P is: [0.39243478551758315, 0.39243478551758315, 0.36397549664640216, 0.7405208993977838, 0.8985482147106891, 0.17227225960889403, 0.39243478551758315, 0.36397549664640216, 0.6397705637035039, 0.17227225960889403, 0.8985482147106891, 0.39243478551758315, 0.36397549664640216, 0.7405208993977838, 0.6397705637035039, 0.17227225960889403, 0.6397705637035039, 0.39243478551758315, 0.6397705637035039, 0.39243478551758315, 0.17227225960889403, 0.6397705637035039, 0.17227225960889403, 0.36397549664640216, 0.36397549664640216, 0.36397549664640216, 0.39243478551758315, 0.36397549664640216, 0.36397549664640216, 0.6397705637035039, 0.6397705637035039, 0.17227225960889403, 0.39243478551758315, 0.17227225960889403, 0.36397549664640216, 0.36397549664640216, 0.6397705637035039, 0.8985482147106891, 0.6397705637035039, 0.6397705637035039, 0.7405208993977838, 0.6397705637035039, 0.8985482147106891, 0.6397705637035039, 0.36397549664640216, 0.6397705637035039, 0.6397705637035039, 0.39243478551758315, 0.6397705637035039, 0.6397705637035039]\n",
      "all_sum before preprocessing is: [3.075678336569557, 3.075678336569557, 1.4247177096435002, 3.075678336569557, 1.4247177096435002, 3.075678336569557, 3.075678336569557, 3.075678336569557, 1.4247177096435002, 3.075678336569557, 1.4247177096435002, 1.4247177096435002, 1.4247177096435002, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 1.4247177096435002, 3.075678336569557, 3.075678336569557, 4.404509786875567, 1.4247177096435002, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557, 3.075678336569557]\n",
      "all_sum after preprocessing is: [ 0.36879987  0.36879987 -2.19404871  0.36879987 -2.19404871  0.36879987\n",
      "  0.36879987  0.36879987 -2.19404871  0.36879987 -2.19404871 -2.19404871\n",
      " -2.19404871  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987\n",
      "  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987\n",
      "  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987\n",
      "  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987\n",
      " -2.19404871  0.36879987  0.36879987  2.43159515 -2.19404871  0.36879987\n",
      "  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987  0.36879987\n",
      "  0.36879987  0.36879987]\n",
      "P is: [0.5911689521852186, 0.5911689521852186, 0.10028619119506835, 0.5911689521852186, 0.10028619119506835, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.10028619119506835, 0.5911689521852186, 0.10028619119506835, 0.10028619119506835, 0.10028619119506835, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.10028619119506835, 0.5911689521852186, 0.5911689521852186, 0.919205079222473, 0.10028619119506835, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186, 0.5911689521852186]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 3.501\n",
      "(*) epoch 2, cost 2.951\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.16 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 4\n",
      "(*) no. of hidden units: 3\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wanxinli/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*) epoch 1, cost 1.246\n",
      "(*) epoch 2, cost 0.907\n",
      "(*) training time: 0.00 sec.\n",
      "\n",
      "training time: 0.27 sec.\n",
      "\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n"
     ]
    }
   ],
   "source": [
    "target_accuracies, target_precisions, target_recalls, target_f1s, \\\n",
    "    source_accuracies, source_precisions, source_recalls, source_f1s, \\\n",
    "    trans_source_accuracies, trans_source_precisions, trans_source_recalls, trans_source_f1s = \\\n",
    "    run_proc_multi(simulate_wrapper, custom_train_reps, svm.SVC , n_times = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = \"../outputs/sim1_svm_scores.csv\"\n",
    "save_scores(target_accuracies, target_precisions, target_recalls, target_f1s, \\\n",
    "        source_accuracies, source_precisions, source_recalls, source_f1s, \\\n",
    "        trans_source_accuracies, trans_source_precisions, trans_source_recalls, trans_source_f1s, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans source to source accuracy increment is 10.1%\n",
      "median trans source to source accuracy increment is 4.0%\n",
      "average trans source to source accuracy f1 is 14.8%\n",
      "median trans source to source accuracy f1 is 6.7%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Larger is better (>0)\n",
    "\"\"\"\n",
    "hist_plot(score_path, filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average trans source to source accuracy increment is 18.2%\n",
      "median trans source to source accuracy increment is 13.0%\n",
      "average trans source to source accuracy f1 is 23.0%\n",
      "median trans source to source accuracy f1 is 20.7%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "source accuracy > 0.7 filtered out \n",
    "\"\"\"\n",
    "\n",
    "hist_plot(score_path, filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
