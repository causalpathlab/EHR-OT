{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simulate features and labels (not used)\n",
    "\n",
    "* Use all to train SDA\n",
    "\n",
    "* Simulate embeddings\n",
    "\n",
    "* Use the trained decoder to generate features for the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/wanxinli/OTTEHR/synthetic_exp\")\n",
    "\n",
    "from common import *\n",
    "from OTTEHR.sda import SDA\n",
    "from math import floor, exp, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import dirichlet\n",
    "import ot\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.utils import check_random_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Simulation scheme\n",
    "\"\"\"\n",
    "\n",
    "def simulate(D, d_1, d_2, num_patient):\n",
    "    \"\"\" \n",
    "    Simulate features and labels for domain 1 and domain 2\n",
    "    :param int D:  total number of features\n",
    "    :param int d_1: number of features with higher frequency in domain 1\n",
    "    :param int d_2: number of features with higher frequency in domain 2\n",
    "    :param int num_patient: number of patients in each domain\n",
    "\n",
    "    Variables in the implementation are consistent with the variables in the scheme\n",
    "\n",
    "    TODO: reconsider the choice of alpha_1 and alpha_2\n",
    "\n",
    "    :return\n",
    "        list[list[int]] domain 1 features\n",
    "        list[int] domain 1 labels\n",
    "        list[list[int]] domain 2 features\n",
    "        list[int] domain 2 labels\n",
    "    \"\"\"\n",
    "\n",
    "    d_1 = randint(0, floor(0.25*D))\n",
    "    d_2 = randint(0, floor(0.25*D))\n",
    "    delta_1 = np.random.choice(size = d_1, a = range(1, D+1), replace=False)\n",
    "    remaining_set = list(set(list(range(1, D+1)))-set(delta_1))\n",
    "    delta_2 = np.random.choice(size = d_1, a = remaining_set, replace=False)\n",
    "    \n",
    "    unit_1 = 1/(2*d_1-2*d_2+3*D)\n",
    "    alpha_1 = [5*unit_1]*d_1\n",
    "    alpha_1.extend([unit_1]*d_2)\n",
    "    alpha_1.extend([3*unit_1]*(D-d_1-d_2))\n",
    "  \n",
    "    unit_2 = 1/(-2*d_1+2*d_2+3*D)\n",
    "    alpha_2 = [unit_2]*d_1\n",
    "    alpha_2.extend([5*unit_2]*d_2)\n",
    "    alpha_2.extend([3*unit_2]*(D-d_1-d_2))  \n",
    "\n",
    "    def gen_feature_vector_label(alpha):\n",
    "        \"\"\" \n",
    "        Generate feature vectors and labels\n",
    "        :param list[float] alpha: concentration parameteres for the dirichlet distribution\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + exp(-x))\n",
    "\n",
    "        rho = dirichlet(alpha=alpha, size=1)[0]\n",
    "        W = np.random.normal(size=D)\n",
    "        W = [abs(W_k) for W_k in W] # only sample positive weights\n",
    "        X = []\n",
    "        Y = []\n",
    "        b = 0\n",
    "        all_sum = []\n",
    "\n",
    "        for _ in range(num_patient):\n",
    "            X_i = np.random.multinomial(len(rho), rho)\n",
    "            for k in range(len(X_i)):\n",
    "                if X_i[k] > 0:\n",
    "                    X_i[k] = 1 # dominant effect\n",
    "            X.append(X_i)\n",
    "            cur_sum = np.sum(np.multiply(W, X_i))\n",
    "            all_sum.append(cur_sum)\n",
    "        \n",
    "        # print(\"all_sum before preprocessing is:\", all_sum)\n",
    "        # standardize\n",
    "        all_sum = preprocessing.scale(all_sum)\n",
    "        # print(\"all_sum after preprocessing is:\", all_sum)\n",
    "\n",
    "        all_sum = np.array(all_sum)\n",
    "        \n",
    "        P = []\n",
    "        for cur_sum in all_sum:\n",
    "            p_i = sigmoid(cur_sum)\n",
    "            P.append(p_i)\n",
    "            Y_i = 0\n",
    "            if p_i >= 0.5: # TODO: mimic exact logistic regression, change to np.random.binomial later\n",
    "                Y_i = 1\n",
    "            # Y_i = np.random.binomial(1, p_i) # too much noise, domain 1 data cannot learn well\n",
    "            Y.append(int(Y_i))\n",
    "        # print(\"P is:\", P)\n",
    "\n",
    "            \n",
    "        return X, Y, W, b\n",
    "    \n",
    "    def feature_vector_to_feature(feature_vectors):\n",
    "        \"\"\" \n",
    "        Convert feature vectors to features\n",
    "        :param list[list[int]]: feature vectors consisting of indicators\n",
    "\n",
    "        Returns\n",
    "            - features consisting of actual codes\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for feature_vector in feature_vectors:\n",
    "            features.append([i for i, e in enumerate(feature_vector) if e != 0])\n",
    "        return features\n",
    "    \n",
    "    def pad_features(features_list):\n",
    "        \"\"\" \n",
    "        Pad features to the same length (maximum length of the original features)\\\n",
    "            in each domain by -1\n",
    "        \"\"\"\n",
    "        max_len = 0\n",
    "        for features in features_list:\n",
    "            max_len = max(max_len, len(features))\n",
    "\n",
    "        for i in range(len(features_list)):\n",
    "            features_list[i] += [-1] * (max_len - len(features_list[i]))\n",
    "        return features_list\n",
    "\n",
    "\n",
    "\n",
    "    feature_vector_1, label_1, W_1, b_1 = gen_feature_vector_label(alpha_1)\n",
    "    feature_1 = pad_features(feature_vector_to_feature(feature_vector_1))\n",
    "    feature_vector_2, label_2, W_2, b_2 = gen_feature_vector_label(alpha_2)\n",
    "    feature_2 = pad_features(feature_vector_to_feature(feature_vector_2))\n",
    "    return np.array(feature_1), label_1, np.array(feature_2), label_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Wrapper function with different set ups for simulate()\n",
    "\"\"\"\n",
    "def simulate_wrapper(num_patient):\n",
    "    D = 20\n",
    "    d_1 = 8\n",
    "    d_2 = 8\n",
    "    return simulate(D, d_1, d_2, num_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train deep patient model and generate representations for seqs\n",
    "\"\"\"\n",
    "\n",
    "def train_SDA(seqs):\n",
    "    \"\"\" \n",
    "    Customized training algorithm for generating target representations and source representations\n",
    "    \n",
    "    :returns: the trained SDA model\n",
    "    \"\"\"\n",
    "\n",
    "    # customized parameters\n",
    "    nhidden = 2\n",
    "    nlayer = 1\n",
    "\n",
    "    # for targets\n",
    "    # initiate the model\n",
    "    sda = SDA(seqs.shape[1],\n",
    "                nhidden=nhidden,\n",
    "                nlayer=nlayer,\n",
    "                param={\n",
    "        'epochs': 100,\n",
    "        'batch_size': 5,\n",
    "        'corrupt_lvl': 0.05\n",
    "    })\n",
    "\n",
    "    # train the model\n",
    "    sda.train(seqs)\n",
    "    return sda\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_emb_label(dataset, n, nz=.5, theta=0, p=.5, random_state=None, **kwargs):\n",
    "    \"\"\" Simulate desired embeddings and labels\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : str\n",
    "        type of classification problem (see code)\n",
    "    n : int\n",
    "        number of training samples\n",
    "    nz : float\n",
    "        noise level (>0)\n",
    "    p : float\n",
    "        proportion of one class in the binary setting\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray, shape (n, d), the desired embedding\n",
    "        `n` observation of size `d`\n",
    "    y : ndarray, shape (n,), the labels\n",
    "        labels of the samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    generator = check_random_state(random_state)\n",
    "\n",
    "    if dataset.lower() == '2gauss': # this pair of simulation can be transported well\n",
    "        y = np.floor((np.arange(n) * 1.0 / n * 2)) + 1\n",
    "        x = np.zeros((n, 2))\n",
    "        # class 1\n",
    "        x[y == 1, 0] = -1\n",
    "        x[y == 1, 1] = -1\n",
    "        x[y == 2, 0] = 1\n",
    "        x[y == 2, 1] = 0\n",
    "        x[y != 2, :] += 1.5 * nz * generator.randn(sum(y != 2), 2)\n",
    "        x[y == 2, :] += 2 * nz * generator.randn(sum(y == 2), 2)\n",
    "    elif dataset.lower() == '2gauss2':\n",
    "        y = np.floor((np.arange(n) * 1.0 / n * 2)) + 1\n",
    "        x = np.zeros((n, 2))\n",
    "        # class 1\n",
    "        x[y == 1, 0] = -2.\n",
    "        x[y == 1, 1] = -2.\n",
    "        x[y == 2, 0] = 2.\n",
    "        x[y == 2, 1] = 0.\n",
    "        x[y != 2, :] += 1 * nz * generator.randn(sum(y != 2), 2)\n",
    "        x[y == 2, :] += 2 * nz * generator.randn(sum(y == 2), 2)\n",
    "        \n",
    "    return x, y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 5\n",
      "(*) no. of hidden units: 2\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.413\n",
      "(*) epoch 2, cost 1.056\n",
      "(*) epoch 3, cost 0.875\n",
      "(*) epoch 4, cost 0.711\n",
      "(*) epoch 5, cost 0.573\n",
      "(*) epoch 6, cost 0.530\n",
      "(*) epoch 7, cost 0.489\n",
      "(*) epoch 8, cost 0.460\n",
      "(*) epoch 9, cost 0.455\n",
      "(*) training time: 0.14 sec.\n",
      "\n",
      "training time: 0.30 sec.\n",
      "\n",
      "initializing: 1-layer SDAs\n",
      "\n",
      "initialized: DA [layer: 1]\n",
      "(*) no. of visible units: 6\n",
      "(*) no. of hidden units: 2\n",
      "(*) data corruption level: 0.05\n",
      "(*) learning rate: 0.10\n",
      "(*) batch size: 5\n",
      "(*) no. of epochs: 100\n",
      "\n",
      "training: 1-layer SDAs\n",
      "\n",
      "training: DA [layer: 1]\n",
      "(*) preprocessing: normalize features\n",
      "(*) epoch 1, cost 1.715\n",
      "(*) epoch 2, cost 1.425\n",
      "(*) epoch 3, cost 1.353\n",
      "(*) epoch 4, cost 1.309\n",
      "(*) epoch 5, cost 1.270\n",
      "(*) epoch 6, cost 1.284\n",
      "(*) epoch 7, cost 1.265\n",
      "(*) epoch 8, cost 1.258\n",
      "(*) training time: 0.13 sec.\n",
      "\n",
      "training time: 0.42 sec.\n",
      "\n",
      "(*) applying: DA [layer: 1]\n",
      "applying: 1-layer SDA\n",
      "(*) applying: DA [layer: 1]\n"
     ]
    }
   ],
   "source": [
    "source_training_feature, _, target_training_feature, _ =  simulate_wrapper(1000)\n",
    "target_sda = train_SDA(target_training_feature)\n",
    "source_sda = train_SDA(source_training_feature)\n",
    "source_desired_reps, source_labels = simulate_emb_label('2gauss', 1000)\n",
    "target_desired_reps, target_labels = simulate_emb_label('2gauss2', 1000)\n",
    "source_features = source_sda.reconstructed_input(source_desired_reps).eval()\n",
    "source_reps = source_sda.apply(source_features)\n",
    "# source_sda.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999901, 0.99698226],\n",
       "       [0.99999951, 0.99911652],\n",
       "       [0.99999898, 0.99703403],\n",
       "       ...,\n",
       "       [0.99999994, 0.99928706],\n",
       "       [0.99999994, 0.99935386],\n",
       "       [0.99999946, 0.9990624 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.38914986, -0.52207827],\n",
       "       [-1.02589079,  0.52429362],\n",
       "       [-1.98127675, -0.42843879],\n",
       "       ...,\n",
       "       [ 1.00426494, -0.55308607],\n",
       "       [ 1.43077877, -0.74269375],\n",
       "       [-1.29870691,  0.70423841]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_desired_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
